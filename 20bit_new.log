/home/lliu/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.40it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.29it/s]
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Token indices sequence length is longer than the specified maximum sequence length for this model (2824491 > 2048). Running this sequence through the model will result in indexing errors
Starting...
Ready.
0 self_attn.q_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
48 H_error tensor(5.4532, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.4318, device='cuda:6', grad_fn=<DivBackward0>)
43351 MiB free out of 48676 MiB total
0 self_attn.k_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(5.5481, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.4233, device='cuda:6', grad_fn=<DivBackward0>)
43351 MiB free out of 48676 MiB total
0 self_attn.v_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(0.2403, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3622, device='cuda:6', grad_fn=<DivBackward0>)
43351 MiB free out of 48676 MiB total
0 self_attn.o_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
48 H_error tensor(0.0325, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.4163, device='cuda:6', grad_fn=<DivBackward0>)
43415 MiB free out of 48676 MiB total
0 mlp.gate_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
117 H_error tensor(3.3294, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3362, device='cuda:6', grad_fn=<DivBackward0>)
43447 MiB free out of 48676 MiB total
0 mlp.up_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
117 H_error tensor(2.4515, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3278, device='cuda:6', grad_fn=<DivBackward0>)
43479 MiB free out of 48676 MiB total
0 mlp.down_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 2752])
123 H_error tensor(0.0534, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3361, device='cuda:6', grad_fn=<DivBackward0>)
43625 MiB free out of 48676 MiB total
1 self_attn.q_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
47 H_error tensor(42.6353, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.4024, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
1 self_attn.k_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(70.4818, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.4059, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
1 self_attn.v_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
45 H_error tensor(1.1858, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3582, device='cuda:6', grad_fn=<DivBackward0>)
43159 MiB free out of 48676 MiB total
1 self_attn.o_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
49 H_error tensor(0.1554, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3952, device='cuda:6', grad_fn=<DivBackward0>)
43191 MiB free out of 48676 MiB total
1 mlp.gate_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
117 H_error tensor(12.5882, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3249, device='cuda:6', grad_fn=<DivBackward0>)
43309 MiB free out of 48676 MiB total
1 mlp.up_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
117 H_error tensor(9.3916, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3183, device='cuda:6', grad_fn=<DivBackward0>)
43341 MiB free out of 48676 MiB total
1 mlp.down_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 2752])
123 H_error tensor(0.1335, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3246, device='cuda:6', grad_fn=<DivBackward0>)
43195 MiB free out of 48676 MiB total
2 self_attn.q_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(65.3925, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3632, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
2 self_attn.k_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
46 H_error tensor(63.0621, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3697, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
2 self_attn.v_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
45 H_error tensor(3.1114, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3250, device='cuda:6', grad_fn=<DivBackward0>)
43159 MiB free out of 48676 MiB total
2 self_attn.o_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(0.4778, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3340, device='cuda:6', grad_fn=<DivBackward0>)
43191 MiB free out of 48676 MiB total
2 mlp.gate_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
117 H_error tensor(31.7101, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3220, device='cuda:6', grad_fn=<DivBackward0>)
43309 MiB free out of 48676 MiB total
2 mlp.up_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
117 H_error tensor(19.8996, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3163, device='cuda:6', grad_fn=<DivBackward0>)
43341 MiB free out of 48676 MiB total
2 mlp.down_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 2752])
reducing lr to  0.0009000000000000001
123 H_error tensor(-54.0772, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.4451, device='cuda:6', grad_fn=<DivBackward0>)
43195 MiB free out of 48676 MiB total
3 self_attn.q_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(66.9711, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3500, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
3 self_attn.k_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(82.2599, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3583, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
3 self_attn.v_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
45 H_error tensor(12.9949, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3204, device='cuda:6', grad_fn=<DivBackward0>)
43159 MiB free out of 48676 MiB total
3 self_attn.o_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(0.7359, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3429, device='cuda:6', grad_fn=<DivBackward0>)
43191 MiB free out of 48676 MiB total
3 mlp.gate_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
117 H_error tensor(39.0326, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3190, device='cuda:6', grad_fn=<DivBackward0>)
43309 MiB free out of 48676 MiB total
3 mlp.up_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
117 H_error tensor(30.6067, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3143, device='cuda:6', grad_fn=<DivBackward0>)
43341 MiB free out of 48676 MiB total
3 mlp.down_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 2752])
123 H_error tensor(0.4849, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3187, device='cuda:6', grad_fn=<DivBackward0>)
43195 MiB free out of 48676 MiB total
4 self_attn.q_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(91.9067, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3539, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
4 self_attn.k_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(104.7072, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3581, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
4 self_attn.v_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
45 H_error tensor(18.9904, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3249, device='cuda:6', grad_fn=<DivBackward0>)
43159 MiB free out of 48676 MiB total
4 self_attn.o_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(1.2582, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3484, device='cuda:6', grad_fn=<DivBackward0>)
43191 MiB free out of 48676 MiB total
4 mlp.gate_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
117 H_error tensor(58.5457, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3226, device='cuda:6', grad_fn=<DivBackward0>)
43309 MiB free out of 48676 MiB total
4 mlp.up_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
117 H_error tensor(41.3878, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3154, device='cuda:6', grad_fn=<DivBackward0>)
43341 MiB free out of 48676 MiB total
4 mlp.down_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 2752])
123 H_error tensor(0.8883, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3228, device='cuda:6', grad_fn=<DivBackward0>)
43195 MiB free out of 48676 MiB total
5 self_attn.q_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(67.0557, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.4492, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
5 self_attn.k_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(124.3741, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3867, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
5 self_attn.v_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(-103.1071, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.4438, device='cuda:6', grad_fn=<DivBackward0>)
43159 MiB free out of 48676 MiB total
5 self_attn.o_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(1.2270, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3430, device='cuda:6', grad_fn=<DivBackward0>)
43191 MiB free out of 48676 MiB total
5 mlp.gate_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
118 H_error tensor(71.4992, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3228, device='cuda:6', grad_fn=<DivBackward0>)
43309 MiB free out of 48676 MiB total
5 mlp.up_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
117 H_error tensor(51.7908, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3146, device='cuda:6', grad_fn=<DivBackward0>)
43341 MiB free out of 48676 MiB total
5 mlp.down_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 2752])
124 H_error tensor(0.9736, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3193, device='cuda:6', grad_fn=<DivBackward0>)
43195 MiB free out of 48676 MiB total
6 self_attn.q_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
47 H_error tensor(122.6635, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3479, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
6 self_attn.k_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(139.2787, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3508, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
6 self_attn.v_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
reducing lr to  3.8152042447694614e-05
reducing lr to  3.433683820292515e-05
reducing lr to  3.090315438263264e-05
45 H_error tensor(32.8053, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3225, device='cuda:6', grad_fn=<DivBackward0>)
43159 MiB free out of 48676 MiB total
6 self_attn.o_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(2.7107, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3450, device='cuda:6', grad_fn=<DivBackward0>)
43191 MiB free out of 48676 MiB total
6 mlp.gate_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
117 H_error tensor(74.3069, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3222, device='cuda:6', grad_fn=<DivBackward0>)
43309 MiB free out of 48676 MiB total
6 mlp.up_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
117 H_error tensor(56.4218, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3150, device='cuda:6', grad_fn=<DivBackward0>)
43341 MiB free out of 48676 MiB total
6 mlp.down_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 2752])
123 H_error tensor(1.3012, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3216, device='cuda:6', grad_fn=<DivBackward0>)
43195 MiB free out of 48676 MiB total
7 self_attn.q_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(140.4431, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3533, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
7 self_attn.k_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(140.4526, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3546, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
7 self_attn.v_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
reducing lr to  3.8152042447694614e-05
reducing lr to  3.433683820292515e-05
reducing lr to  3.090315438263264e-05
reducing lr to  2.7812838944369376e-05
reducing lr to  2.503155504993244e-05
reducing lr to  2.2528399544939195e-05
reducing lr to  2.0275559590445276e-05
45 H_error tensor(36.7743, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3238, device='cuda:6', grad_fn=<DivBackward0>)
43159 MiB free out of 48676 MiB total
7 self_attn.o_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(3.0085, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3325, device='cuda:6', grad_fn=<DivBackward0>)
43191 MiB free out of 48676 MiB total
7 mlp.gate_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
118 H_error tensor(80.9536, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3245, device='cuda:6', grad_fn=<DivBackward0>)
43309 MiB free out of 48676 MiB total
7 mlp.up_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
117 H_error tensor(62.9286, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3155, device='cuda:6', grad_fn=<DivBackward0>)
43341 MiB free out of 48676 MiB total
7 mlp.down_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 2752])
123 H_error tensor(1.5645, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3227, device='cuda:6', grad_fn=<DivBackward0>)
43195 MiB free out of 48676 MiB total
8 self_attn.q_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
47 H_error tensor(156.4102, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3562, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
8 self_attn.k_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(152.6608, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3555, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
8 self_attn.v_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
reducing lr to  3.8152042447694614e-05
reducing lr to  3.433683820292515e-05
reducing lr to  3.090315438263264e-05
reducing lr to  2.7812838944369376e-05
45 H_error tensor(41.6707, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3222, device='cuda:6', grad_fn=<DivBackward0>)
43159 MiB free out of 48676 MiB total
8 self_attn.o_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(5.2184, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3325, device='cuda:6', grad_fn=<DivBackward0>)
43191 MiB free out of 48676 MiB total
8 mlp.gate_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
117 H_error tensor(88.0646, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3257, device='cuda:6', grad_fn=<DivBackward0>)
43309 MiB free out of 48676 MiB total
8 mlp.up_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
117 H_error tensor(66.8005, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3153, device='cuda:6', grad_fn=<DivBackward0>)
43341 MiB free out of 48676 MiB total
8 mlp.down_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 2752])
123 H_error tensor(2.1590, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3245, device='cuda:6', grad_fn=<DivBackward0>)
43195 MiB free out of 48676 MiB total
9 self_attn.q_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(163.4107, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3564, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
9 self_attn.k_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(161.7921, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3565, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
9 self_attn.v_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
45 H_error tensor(47.4838, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3226, device='cuda:6', grad_fn=<DivBackward0>)
43159 MiB free out of 48676 MiB total
9 self_attn.o_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(7.1865, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3332, device='cuda:6', grad_fn=<DivBackward0>)
43191 MiB free out of 48676 MiB total
9 mlp.gate_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
117 H_error tensor(90.7357, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3254, device='cuda:6', grad_fn=<DivBackward0>)
43309 MiB free out of 48676 MiB total
9 mlp.up_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
117 H_error tensor(72.9749, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3154, device='cuda:6', grad_fn=<DivBackward0>)
43341 MiB free out of 48676 MiB total
9 mlp.down_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 2752])
124 H_error tensor(2.3826, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3252, device='cuda:6', grad_fn=<DivBackward0>)
43195 MiB free out of 48676 MiB total
10 self_attn.q_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(165.3121, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3498, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
10 self_attn.k_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
46 H_error tensor(172.3487, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3520, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
10 self_attn.v_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
reducing lr to  3.8152042447694614e-05
reducing lr to  3.433683820292515e-05
reducing lr to  3.090315438263264e-05
reducing lr to  2.7812838944369376e-05
reducing lr to  2.503155504993244e-05
45 H_error tensor(54.2596, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3218, device='cuda:6', grad_fn=<DivBackward0>)
43159 MiB free out of 48676 MiB total
10 self_attn.o_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(14.3579, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3374, device='cuda:6', grad_fn=<DivBackward0>)
43191 MiB free out of 48676 MiB total
10 mlp.gate_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
118 H_error tensor(92.5342, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3248, device='cuda:6', grad_fn=<DivBackward0>)
43309 MiB free out of 48676 MiB total
10 mlp.up_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
117 H_error tensor(78.3176, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3157, device='cuda:6', grad_fn=<DivBackward0>)
43341 MiB free out of 48676 MiB total
10 mlp.down_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 2752])
123 H_error tensor(2.6354, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3232, device='cuda:6', grad_fn=<DivBackward0>)
43195 MiB free out of 48676 MiB total
11 self_attn.q_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(145.7186, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3440, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
11 self_attn.k_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(158.1669, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3494, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
11 self_attn.v_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
reducing lr to  3.8152042447694614e-05
reducing lr to  3.433683820292515e-05
reducing lr to  3.090315438263264e-05
reducing lr to  2.7812838944369376e-05
reducing lr to  2.503155504993244e-05
reducing lr to  2.2528399544939195e-05
45 H_error tensor(50.0902, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3213, device='cuda:6', grad_fn=<DivBackward0>)
43159 MiB free out of 48676 MiB total
11 self_attn.o_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(11.4975, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3231, device='cuda:6', grad_fn=<DivBackward0>)
43191 MiB free out of 48676 MiB total
11 mlp.gate_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
117 H_error tensor(107.6738, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3284, device='cuda:6', grad_fn=<DivBackward0>)
43309 MiB free out of 48676 MiB total
11 mlp.up_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
117 H_error tensor(89.4680, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3166, device='cuda:6', grad_fn=<DivBackward0>)
43341 MiB free out of 48676 MiB total
11 mlp.down_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 2752])
123 H_error tensor(4.1741, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3246, device='cuda:6', grad_fn=<DivBackward0>)
43195 MiB free out of 48676 MiB total
12 self_attn.q_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(186.1981, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3501, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
12 self_attn.k_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(196.5705, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3525, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
12 self_attn.v_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
reducing lr to  3.8152042447694614e-05
reducing lr to  3.433683820292515e-05
reducing lr to  3.090315438263264e-05
reducing lr to  2.7812838944369376e-05
reducing lr to  2.503155504993244e-05
45 H_error tensor(64.0052, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3193, device='cuda:6', grad_fn=<DivBackward0>)
43159 MiB free out of 48676 MiB total
12 self_attn.o_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(13.4040, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3235, device='cuda:6', grad_fn=<DivBackward0>)
43191 MiB free out of 48676 MiB total
12 mlp.gate_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
117 H_error tensor(123.2027, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3277, device='cuda:6', grad_fn=<DivBackward0>)
43309 MiB free out of 48676 MiB total
12 mlp.up_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
117 H_error tensor(102.6566, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3152, device='cuda:6', grad_fn=<DivBackward0>)
43341 MiB free out of 48676 MiB total
12 mlp.down_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 2752])
123 H_error tensor(4.3186, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3220, device='cuda:6', grad_fn=<DivBackward0>)
43195 MiB free out of 48676 MiB total
13 self_attn.q_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(188.3485, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3479, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
13 self_attn.k_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(204.6708, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3527, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
13 self_attn.v_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
reducing lr to  3.8152042447694614e-05
reducing lr to  3.433683820292515e-05
45 H_error tensor(77.5232, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3200, device='cuda:6', grad_fn=<DivBackward0>)
43159 MiB free out of 48676 MiB total
13 self_attn.o_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(15.5495, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3254, device='cuda:6', grad_fn=<DivBackward0>)
43191 MiB free out of 48676 MiB total
13 mlp.gate_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
117 H_error tensor(132.0676, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3257, device='cuda:6', grad_fn=<DivBackward0>)
43309 MiB free out of 48676 MiB total
13 mlp.up_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
117 H_error tensor(114.4045, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3147, device='cuda:6', grad_fn=<DivBackward0>)
43341 MiB free out of 48676 MiB total
13 mlp.down_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 2752])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
124 H_error tensor(4.7871, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3213, device='cuda:6', grad_fn=<DivBackward0>)
43195 MiB free out of 48676 MiB total
14 self_attn.q_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(195.8408, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3485, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
14 self_attn.k_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(211.0783, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3522, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
14 self_attn.v_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
reducing lr to  3.8152042447694614e-05
45 H_error tensor(77.2532, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3188, device='cuda:6', grad_fn=<DivBackward0>)
43159 MiB free out of 48676 MiB total
14 self_attn.o_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
45 H_error tensor(16.3102, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3211, device='cuda:6', grad_fn=<DivBackward0>)
43191 MiB free out of 48676 MiB total
14 mlp.gate_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
117 H_error tensor(148.5343, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3257, device='cuda:6', grad_fn=<DivBackward0>)
43309 MiB free out of 48676 MiB total
14 mlp.up_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
117 H_error tensor(127.9181, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3146, device='cuda:6', grad_fn=<DivBackward0>)
43341 MiB free out of 48676 MiB total
14 mlp.down_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 2752])
123 H_error tensor(5.5240, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3215, device='cuda:6', grad_fn=<DivBackward0>)
43195 MiB free out of 48676 MiB total
15 self_attn.q_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(193.0537, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3489, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
15 self_attn.k_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(207.3172, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3536, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
15 self_attn.v_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
reducing lr to  3.8152042447694614e-05
45 H_error tensor(76.9880, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3178, device='cuda:6', grad_fn=<DivBackward0>)
43159 MiB free out of 48676 MiB total
15 self_attn.o_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(20.2297, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3219, device='cuda:6', grad_fn=<DivBackward0>)
43191 MiB free out of 48676 MiB total
15 mlp.gate_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
118 H_error tensor(157.4529, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3244, device='cuda:6', grad_fn=<DivBackward0>)
43309 MiB free out of 48676 MiB total
15 mlp.up_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
117 H_error tensor(138.7280, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3145, device='cuda:6', grad_fn=<DivBackward0>)
43341 MiB free out of 48676 MiB total
15 mlp.down_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 2752])
124 H_error tensor(6.8633, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3207, device='cuda:6', grad_fn=<DivBackward0>)
43195 MiB free out of 48676 MiB total
16 self_attn.q_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(188.6205, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3432, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
16 self_attn.k_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(217.2388, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3483, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
16 self_attn.v_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
reducing lr to  3.8152042447694614e-05
reducing lr to  3.433683820292515e-05
reducing lr to  3.090315438263264e-05
45 H_error tensor(86.5790, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3170, device='cuda:6', grad_fn=<DivBackward0>)
43159 MiB free out of 48676 MiB total
16 self_attn.o_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
45 H_error tensor(16.7647, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3203, device='cuda:6', grad_fn=<DivBackward0>)
43191 MiB free out of 48676 MiB total
16 mlp.gate_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
117 H_error tensor(187.6257, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3257, device='cuda:6', grad_fn=<DivBackward0>)
43309 MiB free out of 48676 MiB total
16 mlp.up_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
117 H_error tensor(158.5836, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3145, device='cuda:6', grad_fn=<DivBackward0>)
43341 MiB free out of 48676 MiB total
16 mlp.down_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 2752])
123 H_error tensor(9.3841, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3218, device='cuda:6', grad_fn=<DivBackward0>)
43195 MiB free out of 48676 MiB total
17 self_attn.q_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(201.8698, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3446, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
17 self_attn.k_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(218.9876, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3503, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
17 self_attn.v_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
reducing lr to  3.8152042447694614e-05
reducing lr to  3.433683820292515e-05
reducing lr to  3.090315438263264e-05
reducing lr to  2.7812838944369376e-05
45 H_error tensor(98.4729, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3167, device='cuda:6', grad_fn=<DivBackward0>)
43159 MiB free out of 48676 MiB total
17 self_attn.o_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(18.7198, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3202, device='cuda:6', grad_fn=<DivBackward0>)
43191 MiB free out of 48676 MiB total
17 mlp.gate_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
117 H_error tensor(203.5741, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3229, device='cuda:6', grad_fn=<DivBackward0>)
43309 MiB free out of 48676 MiB total
17 mlp.up_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
117 H_error tensor(177.0673, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3143, device='cuda:6', grad_fn=<DivBackward0>)
43341 MiB free out of 48676 MiB total
17 mlp.down_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 2752])
123 H_error tensor(11.2158, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3210, device='cuda:6', grad_fn=<DivBackward0>)
43195 MiB free out of 48676 MiB total
18 self_attn.q_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(208.3086, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3484, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
18 self_attn.k_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(228.2429, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3533, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
18 self_attn.v_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
reducing lr to  3.8152042447694614e-05
reducing lr to  3.433683820292515e-05
reducing lr to  3.090315438263264e-05
reducing lr to  2.7812838944369376e-05
45 H_error tensor(102.7759, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3157, device='cuda:6', grad_fn=<DivBackward0>)
43159 MiB free out of 48676 MiB total
18 self_attn.o_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(24.5576, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3215, device='cuda:6', grad_fn=<DivBackward0>)
43191 MiB free out of 48676 MiB total
18 mlp.gate_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
117 H_error tensor(231.6570, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3224, device='cuda:6', grad_fn=<DivBackward0>)
43309 MiB free out of 48676 MiB total
18 mlp.up_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
117 H_error tensor(197.0712, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3138, device='cuda:6', grad_fn=<DivBackward0>)
43341 MiB free out of 48676 MiB total
18 mlp.down_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 2752])
123 H_error tensor(12.9965, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3203, device='cuda:6', grad_fn=<DivBackward0>)
43195 MiB free out of 48676 MiB total
19 self_attn.q_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(194.9040, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3463, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
19 self_attn.k_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(214.8881, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3503, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
19 self_attn.v_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
reducing lr to  3.8152042447694614e-05
reducing lr to  3.433683820292515e-05
reducing lr to  3.090315438263264e-05
reducing lr to  2.7812838944369376e-05
45 H_error tensor(112.6410, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3175, device='cuda:6', grad_fn=<DivBackward0>)
43159 MiB free out of 48676 MiB total
19 self_attn.o_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(33.3309, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3298, device='cuda:6', grad_fn=<DivBackward0>)
43191 MiB free out of 48676 MiB total
19 mlp.gate_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
118 H_error tensor(250.8197, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3215, device='cuda:6', grad_fn=<DivBackward0>)
43309 MiB free out of 48676 MiB total
19 mlp.up_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
117 H_error tensor(210.1028, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3136, device='cuda:6', grad_fn=<DivBackward0>)
43341 MiB free out of 48676 MiB total
19 mlp.down_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 2752])
123 H_error tensor(14.7645, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3211, device='cuda:6', grad_fn=<DivBackward0>)
43195 MiB free out of 48676 MiB total
20 self_attn.q_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(219.9832, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3430, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
20 self_attn.k_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(240.3478, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3465, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
20 self_attn.v_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
reducing lr to  3.8152042447694614e-05
reducing lr to  3.433683820292515e-05
reducing lr to  3.090315438263264e-05
reducing lr to  2.7812838944369376e-05
reducing lr to  2.503155504993244e-05
reducing lr to  2.2528399544939195e-05
reducing lr to  2.0275559590445276e-05
reducing lr to  1.8248003631400748e-05
reducing lr to  1.6423203268260675e-05
45 H_error tensor(127.9858, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3161, device='cuda:6', grad_fn=<DivBackward0>)
43159 MiB free out of 48676 MiB total
20 self_attn.o_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
45 H_error tensor(24.5799, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3207, device='cuda:6', grad_fn=<DivBackward0>)
43191 MiB free out of 48676 MiB total
20 mlp.gate_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
117 H_error tensor(278.1389, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3214, device='cuda:6', grad_fn=<DivBackward0>)
43309 MiB free out of 48676 MiB total
20 mlp.up_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
117 H_error tensor(231.9598, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3137, device='cuda:6', grad_fn=<DivBackward0>)
43341 MiB free out of 48676 MiB total
20 mlp.down_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 2752])
123 H_error tensor(18.4047, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3215, device='cuda:6', grad_fn=<DivBackward0>)
43195 MiB free out of 48676 MiB total
21 self_attn.q_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(209.8107, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3459, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
21 self_attn.k_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(229.5811, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3500, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
21 self_attn.v_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
45 H_error tensor(134.4004, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3154, device='cuda:6', grad_fn=<DivBackward0>)
43159 MiB free out of 48676 MiB total
21 self_attn.o_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(54.4417, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3287, device='cuda:6', grad_fn=<DivBackward0>)
43191 MiB free out of 48676 MiB total
21 mlp.gate_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
117 H_error tensor(300.5013, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3197, device='cuda:6', grad_fn=<DivBackward0>)
43309 MiB free out of 48676 MiB total
21 mlp.up_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
117 H_error tensor(251.3430, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3134, device='cuda:6', grad_fn=<DivBackward0>)
43341 MiB free out of 48676 MiB total
21 mlp.down_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 2752])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
123 H_error tensor(22.2860, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3206, device='cuda:6', grad_fn=<DivBackward0>)
43195 MiB free out of 48676 MiB total
22 self_attn.q_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(229.2985, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3411, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
22 self_attn.k_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(252.3678, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3452, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
22 self_attn.v_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
45 H_error tensor(143.5401, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3153, device='cuda:6', grad_fn=<DivBackward0>)
43159 MiB free out of 48676 MiB total
22 self_attn.o_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(72.1568, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3506, device='cuda:6', grad_fn=<DivBackward0>)
43191 MiB free out of 48676 MiB total
22 mlp.gate_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
117 H_error tensor(306.4237, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3179, device='cuda:6', grad_fn=<DivBackward0>)
43309 MiB free out of 48676 MiB total
22 mlp.up_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
117 H_error tensor(265.8144, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3129, device='cuda:6', grad_fn=<DivBackward0>)
43341 MiB free out of 48676 MiB total
22 mlp.down_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 2752])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
123 H_error tensor(22.2847, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3205, device='cuda:6', grad_fn=<DivBackward0>)
43195 MiB free out of 48676 MiB total
23 self_attn.q_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(228.4633, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3471, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
23 self_attn.k_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(262.0973, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3516, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
23 self_attn.v_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
reducing lr to  3.8152042447694614e-05
reducing lr to  3.433683820292515e-05
reducing lr to  3.090315438263264e-05
reducing lr to  2.7812838944369376e-05
reducing lr to  2.503155504993244e-05
reducing lr to  2.2528399544939195e-05
reducing lr to  2.0275559590445276e-05
reducing lr to  1.8248003631400748e-05
45 H_error tensor(161.3958, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3162, device='cuda:6', grad_fn=<DivBackward0>)
43159 MiB free out of 48676 MiB total
23 self_attn.o_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(107.8912, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3407, device='cuda:6', grad_fn=<DivBackward0>)
43191 MiB free out of 48676 MiB total
23 mlp.gate_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
117 H_error tensor(328.5527, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3171, device='cuda:6', grad_fn=<DivBackward0>)
43309 MiB free out of 48676 MiB total
23 mlp.up_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
117 H_error tensor(286.6620, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3127, device='cuda:6', grad_fn=<DivBackward0>)
43341 MiB free out of 48676 MiB total
23 mlp.down_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 2752])
123 H_error tensor(24.8795, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3190, device='cuda:6', grad_fn=<DivBackward0>)
43195 MiB free out of 48676 MiB total
24 self_attn.q_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(246.2847, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3430, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
24 self_attn.k_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(275.7311, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3481, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
24 self_attn.v_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
reducing lr to  3.8152042447694614e-05
reducing lr to  3.433683820292515e-05
45 H_error tensor(182.5007, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3154, device='cuda:6', grad_fn=<DivBackward0>)
43159 MiB free out of 48676 MiB total
24 self_attn.o_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(77.6622, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3382, device='cuda:6', grad_fn=<DivBackward0>)
43191 MiB free out of 48676 MiB total
24 mlp.gate_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
117 H_error tensor(357.1894, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3177, device='cuda:6', grad_fn=<DivBackward0>)
43309 MiB free out of 48676 MiB total
24 mlp.up_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
117 H_error tensor(307.9254, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3123, device='cuda:6', grad_fn=<DivBackward0>)
43341 MiB free out of 48676 MiB total
24 mlp.down_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 2752])
124 H_error tensor(27.1466, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3191, device='cuda:6', grad_fn=<DivBackward0>)
43195 MiB free out of 48676 MiB total
25 self_attn.q_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(269.7854, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3374, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
25 self_attn.k_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(304.1012, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3421, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
25 self_attn.v_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
45 H_error tensor(195.2328, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3162, device='cuda:6', grad_fn=<DivBackward0>)
43159 MiB free out of 48676 MiB total
25 self_attn.o_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
45 H_error tensor(42.0732, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3314, device='cuda:6', grad_fn=<DivBackward0>)
43191 MiB free out of 48676 MiB total
25 mlp.gate_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
117 H_error tensor(391.4562, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3186, device='cuda:6', grad_fn=<DivBackward0>)
43309 MiB free out of 48676 MiB total
25 mlp.up_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
117 H_error tensor(337.4004, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3125, device='cuda:6', grad_fn=<DivBackward0>)
43341 MiB free out of 48676 MiB total
25 mlp.down_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 2752])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
123 H_error tensor(30.9025, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3189, device='cuda:6', grad_fn=<DivBackward0>)
43195 MiB free out of 48676 MiB total
26 self_attn.q_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(293.6899, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3368, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
26 self_attn.k_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(324.3357, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3409, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
26 self_attn.v_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
reducing lr to  3.8152042447694614e-05
reducing lr to  3.433683820292515e-05
reducing lr to  3.090315438263264e-05
reducing lr to  2.7812838944369376e-05
reducing lr to  2.503155504993244e-05
reducing lr to  2.2528399544939195e-05
45 H_error tensor(227.3135, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3154, device='cuda:6', grad_fn=<DivBackward0>)
43159 MiB free out of 48676 MiB total
26 self_attn.o_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
45 H_error tensor(50.3161, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3307, device='cuda:6', grad_fn=<DivBackward0>)
43191 MiB free out of 48676 MiB total
26 mlp.gate_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
118 H_error tensor(413.0536, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3190, device='cuda:6', grad_fn=<DivBackward0>)
43309 MiB free out of 48676 MiB total
26 mlp.up_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
117 H_error tensor(360.4059, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3124, device='cuda:6', grad_fn=<DivBackward0>)
43341 MiB free out of 48676 MiB total
26 mlp.down_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 2752])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
123 H_error tensor(33.1761, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3187, device='cuda:6', grad_fn=<DivBackward0>)
43195 MiB free out of 48676 MiB total
27 self_attn.q_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(290.0312, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3375, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
27 self_attn.k_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(320.4392, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3421, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
27 self_attn.v_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
reducing lr to  3.8152042447694614e-05
45 H_error tensor(237.2571, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3152, device='cuda:6', grad_fn=<DivBackward0>)
43159 MiB free out of 48676 MiB total
27 self_attn.o_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(52.5591, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3439, device='cuda:6', grad_fn=<DivBackward0>)
43191 MiB free out of 48676 MiB total
27 mlp.gate_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
118 H_error tensor(452.8483, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3214, device='cuda:6', grad_fn=<DivBackward0>)
43309 MiB free out of 48676 MiB total
27 mlp.up_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
118 H_error tensor(389.6945, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3133, device='cuda:6', grad_fn=<DivBackward0>)
43341 MiB free out of 48676 MiB total
27 mlp.down_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 2752])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
123 H_error tensor(37.4010, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3208, device='cuda:6', grad_fn=<DivBackward0>)
43195 MiB free out of 48676 MiB total
28 self_attn.q_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
47 H_error tensor(275.2396, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3446, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
28 self_attn.k_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(311.9284, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3502, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
28 self_attn.v_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
45 H_error tensor(230.5132, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3171, device='cuda:6', grad_fn=<DivBackward0>)
43159 MiB free out of 48676 MiB total
28 self_attn.o_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(80.1371, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3380, device='cuda:6', grad_fn=<DivBackward0>)
43191 MiB free out of 48676 MiB total
28 mlp.gate_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
118 H_error tensor(480.7822, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3232, device='cuda:6', grad_fn=<DivBackward0>)
43309 MiB free out of 48676 MiB total
28 mlp.up_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
117 H_error tensor(421.4949, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3147, device='cuda:6', grad_fn=<DivBackward0>)
43341 MiB free out of 48676 MiB total
28 mlp.down_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 2752])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
123 H_error tensor(43.4539, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3256, device='cuda:6', grad_fn=<DivBackward0>)
43195 MiB free out of 48676 MiB total
29 self_attn.q_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(283.4655, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3417, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
29 self_attn.k_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(313.7088, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3461, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
29 self_attn.v_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
45 H_error tensor(257.4430, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3158, device='cuda:6', grad_fn=<DivBackward0>)
43159 MiB free out of 48676 MiB total
29 self_attn.o_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(116.1270, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3465, device='cuda:6', grad_fn=<DivBackward0>)
43191 MiB free out of 48676 MiB total
29 mlp.gate_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
117 H_error tensor(495.5561, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3255, device='cuda:6', grad_fn=<DivBackward0>)
43309 MiB free out of 48676 MiB total
29 mlp.up_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
117 H_error tensor(431.5395, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3159, device='cuda:6', grad_fn=<DivBackward0>)
43341 MiB free out of 48676 MiB total
29 mlp.down_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 2752])
124 H_error tensor(49.5253, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3318, device='cuda:6', grad_fn=<DivBackward0>)
43195 MiB free out of 48676 MiB total
30 self_attn.q_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
46 H_error tensor(266.5182, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3411, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
30 self_attn.k_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(321.3969, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3484, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
30 self_attn.v_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
45 H_error tensor(233.9880, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3174, device='cuda:6', grad_fn=<DivBackward0>)
43159 MiB free out of 48676 MiB total
30 self_attn.o_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(133.1929, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3424, device='cuda:6', grad_fn=<DivBackward0>)
43191 MiB free out of 48676 MiB total
30 mlp.gate_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
117 H_error tensor(498.9011, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3264, device='cuda:6', grad_fn=<DivBackward0>)
43309 MiB free out of 48676 MiB total
30 mlp.up_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
117 H_error tensor(472.6962, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3198, device='cuda:6', grad_fn=<DivBackward0>)
43341 MiB free out of 48676 MiB total
30 mlp.down_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 2752])
123 H_error tensor(265.3427, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3548, device='cuda:6', grad_fn=<DivBackward0>)
43195 MiB free out of 48676 MiB total
31 self_attn.q_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
46 H_error tensor(176.7681, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3427, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
31 self_attn.k_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(222.1724, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3531, device='cuda:6', grad_fn=<DivBackward0>)
43127 MiB free out of 48676 MiB total
31 self_attn.v_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
45 H_error tensor(126.2054, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3206, device='cuda:6', grad_fn=<DivBackward0>)
43159 MiB free out of 48676 MiB total
31 self_attn.o_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 1024])
45 H_error tensor(181.9961, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3478, device='cuda:6', grad_fn=<DivBackward0>)
43191 MiB free out of 48676 MiB total
31 mlp.gate_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
118 H_error tensor(472.1219, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3368, device='cuda:6', grad_fn=<DivBackward0>)
43309 MiB free out of 48676 MiB total
31 mlp.up_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([11008, 1024])
117 H_error tensor(626.9695, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3333, device='cuda:6', grad_fn=<DivBackward0>)
43341 MiB free out of 48676 MiB total
31 mlp.down_proj
Pruning ...
using 0.0 of the magnitude
using all the weights
torch.Size([4096, 2752])
124 H_error tensor(-1928.8905, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.5307, device='cuda:6', grad_fn=<DivBackward0>)
43195 MiB free out of 48676 MiB total
17580.079472780228
/home/lliu/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Token indices sequence length is longer than the specified maximum sequence length for this model (2824491 > 2048). Running this sequence through the model will result in indexing errors
Dataset: wikitext2
Evaluating ...
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
Perplexity: 12.339300
