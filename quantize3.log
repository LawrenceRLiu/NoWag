wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: m6481. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /data/lliu/huffman/wandb/run-20250106_011752-deaztxbx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sea-68
wandb: ‚≠êÔ∏è View project at https://wandb.ai/m6481/compression_no_finetune
wandb: üöÄ View run at https://wandb.ai/m6481/compression_no_finetune/runs/deaztxbx
Namespace(models_to_compress=['meta-llama/Llama-2-13b-hf'], seqlens=[4096], batch_size=1, hessian_path='/data/lliu/huffman/models/{model_name}/hessians_new/pajama/2048', save_path='/data/lliu/huffman/models/{model_name}/compressed', self_attn_compression_algorithm='quantize', mlp_compression_algorithm='quantize', devices=['cuda:6', 'cuda:7'], yaml_path='/data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml', self_attn_yaml_path=None, mlp_yaml_path=None, use_already_done=False, use_wandb=True, resume_wandb=False, wandb_id=None, wandb_project='compression_no_finetune')
  0%|          | 0/280 [00:00<?, ?it/s]  0%|          | 1/280 [04:40<21:42:04, 280.02s/it]  1%|          | 2/280 [04:55<9:35:07, 124.13s/it]   1%|          | 3/280 [06:20<8:10:35, 106.26s/it]  1%|‚ñè         | 4/280 [06:35<5:23:05, 70.24s/it]   2%|‚ñè         | 5/280 [08:20<6:19:23, 82.77s/it]  2%|‚ñè         | 6/280 [10:05<6:52:31, 90.33s/it]  2%|‚ñé         | 7/280 [12:20<7:57:28, 104.94s/it]  3%|‚ñé         | 8/280 [14:25<8:24:41, 111.33s/it]n_commands 280
sample command python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_3/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_3/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_3/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_3/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_3/mlp.gate_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_3/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_3/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_3/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_3/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_3/mlp.gate_proj/compressed.log
best_loss 52.63066482543945 running bpv: 2.011401
COMMANDS_FINISHED 1 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_3/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_3/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_3/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_3/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_3/mlp.up_proj/compressed.log
best_loss 44.500816345214844 running bpv: 2.011401
COMMANDS_FINISHED 2 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_3/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_3/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_3/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_3/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_3/self_attn.q_proj/compressed.log
best_loss 49.79484558105469 running bpv: 2.013185
COMMANDS_FINISHED 3 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_3/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_3/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_3/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_3/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_3/self_attn.k_proj/compressed.log
best_loss 56.93232727050781 running bpv: 2.014486
COMMANDS_FINISHED 4 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_3/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_3/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_3/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_3/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_3/self_attn.o_proj/compressed.log
best_loss 0.41269606351852417 running bpv: 2.015478
COMMANDS_FINISHED 5 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_3/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_3/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_3/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_3/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_3/self_attn.v_proj/compressed.log
best_loss 15.285591125488281 running bpv: 2.016258
COMMANDS_FINISHED 6 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_5/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_5/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_5/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_3/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_3/mlp.down_proj/compressed.log
best_loss 1.270653486251831 running bpv: 2.014826
COMMANDS_FINISHED 7 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_5/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_5/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_5/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_5/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_5/mlp.gate_proj/compressed.log
best_loss 96.70064544677734 running bpv: 2.014201
COMMANDS_FINISHED 8 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_5/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_5/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_5/self_attn.q_proj/compressed.log 2>&1 &
  3%|‚ñé         | 9/280 [16:00<7:59:47, 106.23s/it]  4%|‚ñé         | 10/280 [16:35<6:19:04, 84.24s/it]  4%|‚ñç         | 11/280 [17:40<5:51:17, 78.35s/it]  4%|‚ñç         | 12/280 [18:35<5:18:15, 71.25s/it]  5%|‚ñç         | 13/280 [20:10<5:49:05, 78.45s/it]  5%|‚ñå         | 14/280 [24:25<9:44:13, 131.78s/it]  5%|‚ñå         | 15/280 [24:40<7:06:33, 96.58s/it]   6%|‚ñå         | 16/280 [26:25<7:16:06, 99.12s/it]  6%|‚ñå         | 17/280 [28:00<7:09:02, 97.88s/it]  6%|‚ñã         | 18/280 [28:55<6:11:09, 85.00s/it]meta-llama/Llama-2-13b-hf/layer_5/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_5/self_attn.q_proj/compressed.log
best_loss 120.4705810546875 running bpv: 2.014746
COMMANDS_FINISHED 9 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_5/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_5/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_5/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_5/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_5/mlp.up_proj/compressed.log
best_loss 79.28170776367188 running bpv: 2.014258
COMMANDS_FINISHED 10 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_5/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_5/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_5/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_5/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_5/self_attn.k_proj/compressed.log
best_loss 118.31754302978516 running bpv: 2.014697
COMMANDS_FINISHED 11 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_5/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_5/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_5/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_5/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_5/self_attn.o_proj/compressed.log
best_loss 1.1219104528427124 running bpv: 2.015093
COMMANDS_FINISHED 12 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_5/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_5/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_5/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_5/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_5/self_attn.v_proj/compressed.log
best_loss 42.36798095703125 running bpv: 2.015452
COMMANDS_FINISHED 13 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_8/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_8/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_8/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_8/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_8/mlp.gate_proj/compressed.log
best_loss 161.03228759765625 running bpv: 2.015
COMMANDS_FINISHED 14 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_8/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_8/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_8/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_5/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_5/mlp.down_proj/compressed.log
best_loss 3.2955713272094727 running bpv: 2.014482
COMMANDS_FINISHED 15 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_8/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_8/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_8/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_8/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_8/self_attn.q_proj/compressed.log
best_loss 180.6120147705078 running bpv: 2.014781
COMMANDS_FINISHED 16 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_8/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_8/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_8/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_8/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_8/self_attn.k_proj/compressed.log
best_loss 186.7101593017578 running bpv: 2.015059
COMMANDS_FINISHED 17 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_8/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_8/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_8/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_8/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_8/mlp.up_proj/compressed.log
best_loss 131.24562072753906 running bpv: 2.014746
COMMANDS_FINISHED 18 n_commands 280
  7%|‚ñã         | 19/280 [30:00<5:43:37, 78.99s/it]  7%|‚ñã         | 20/280 [31:45<6:16:08, 86.80s/it]  8%|‚ñä         | 21/280 [35:40<9:26:44, 131.29s/it]  8%|‚ñä         | 22/280 [35:55<6:54:29, 96.39s/it]   8%|‚ñä         | 23/280 [37:30<6:51:05, 95.98s/it]  9%|‚ñä         | 24/280 [39:05<6:48:15, 95.69s/it]  9%|‚ñâ         | 25/280 [39:50<5:42:02, 80.48s/it]  9%|‚ñâ         | 26/280 [41:05<5:33:44, 78.84s/it] 10%|‚ñâ         | 27/280 [42:50<6:05:32, 86.69s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_8/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_8/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_8/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_8/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_8/self_attn.o_proj/compressed.log
best_loss 3.9962849617004395 running bpv: 2.014994
COMMANDS_FINISHED 19 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_8/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_8/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_8/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_8/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_8/self_attn.v_proj/compressed.log
best_loss 71.3651123046875 running bpv: 2.015226
COMMANDS_FINISHED 20 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_39/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_39/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_39/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_8/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_8/mlp.down_proj/compressed.log
best_loss 8.524335861206055 running bpv: 2.014826
COMMANDS_FINISHED 21 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_39/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_39/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_39/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_39/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_39/mlp.gate_proj/compressed.log
best_loss 648.8736572265625 running bpv: 2.014589
COMMANDS_FINISHED 22 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_39/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_39/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_39/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_39/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_39/self_attn.q_proj/compressed.log
best_loss 261.9704284667969 running bpv: 2.014794
COMMANDS_FINISHED 23 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_39/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_39/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_39/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_39/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_39/self_attn.k_proj/compressed.log
best_loss 268.6131286621094 running bpv: 2.01499
COMMANDS_FINISHED 24 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_39/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_39/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_39/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_39/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_39/mlp.up_proj/compressed.log
best_loss 550.9303588867188 running bpv: 2.014768
COMMANDS_FINISHED 25 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_39/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_39/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_39/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_39/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_39/self_attn.o_proj/compressed.log
best_loss 77.7052001953125 running bpv: 2.014948
COMMANDS_FINISHED 26 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_39/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_39/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_39/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_39/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_39/self_attn.v_proj/compressed.log
best_loss 275.3065185546875 running bpv: 2.01512
COMMANDS_FINISHED 27 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_12/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_12/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_12/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_39/mlp.down_proj is done
reading log  10%|‚ñà         | 28/280 [46:45<9:10:59, 131.19s/it] 10%|‚ñà         | 29/280 [47:10<6:55:32, 99.33s/it]  11%|‚ñà         | 30/280 [48:55<7:00:58, 101.04s/it] 11%|‚ñà         | 31/280 [50:40<7:04:14, 102.23s/it] 11%|‚ñà‚ñè        | 32/280 [51:25<5:51:35, 85.06s/it]  12%|‚ñà‚ñè        | 33/280 [52:30<5:25:24, 79.04s/it] 12%|‚ñà‚ñè        | 34/280 [54:15<5:56:01, 86.83s/it] 12%|‚ñà‚ñé        | 35/280 [58:10<8:56:05, 131.29s/it] 13%|‚ñà‚ñé        | 37/280 [1:00:00<6:29:07, 96.08s/it]/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_39/mlp.down_proj/compressed.log
best_loss 241.32089233398438 running bpv: 2.014826
COMMANDS_FINISHED 28 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_12/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_12/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_12/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_12/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_12/mlp.gate_proj/compressed.log
best_loss 191.92994689941406 running bpv: 2.014645
COMMANDS_FINISHED 29 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_12/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_12/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_12/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_12/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_12/self_attn.q_proj/compressed.log
best_loss 234.87738037109375 running bpv: 2.014801
COMMANDS_FINISHED 30 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_12/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_12/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_12/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_12/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_12/self_attn.k_proj/compressed.log
best_loss 244.34085083007812 running bpv: 2.014952
COMMANDS_FINISHED 31 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_12/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_12/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_12/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_12/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_12/mlp.up_proj/compressed.log
best_loss 178.87814331054688 running bpv: 2.014781
COMMANDS_FINISHED 32 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_12/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_12/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_12/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_12/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_12/self_attn.o_proj/compressed.log
best_loss 10.731170654296875 running bpv: 2.014922
COMMANDS_FINISHED 33 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_12/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_12/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_12/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_12/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_12/self_attn.v_proj/compressed.log
best_loss 101.05662536621094 running bpv: 2.015059
COMMANDS_FINISHED 34 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_1/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_1/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_1/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_1/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_1/mlp.gate_proj/compressed.log
best_loss 11.92888069152832 running bpv: 2.014895
COMMANDS_FINISHED 35 n_commands 280
meta-llama/Llama-2-13b-hf/layer_12/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_12/mlp.down_proj/compressed.log
best_loss 14.827077865600586 running bpv: 2.014679
COMMANDS_FINISHED 36 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_1/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_1/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_1/mlp.up_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_1/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_1/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_1/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_1/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_1/self_attn.q_proj/compressed.log
best_loss 5.430135250091553 running bpv: 2.014806
COMMANDS_FINISHED 37 n_commands 280
 14%|‚ñà‚ñé        | 38/280 [1:02:05<6:56:27, 103.25s/it] 14%|‚ñà‚ñç        | 39/280 [1:02:20<5:22:01, 80.17s/it]  14%|‚ñà‚ñç        | 40/280 [1:04:05<5:47:42, 86.93s/it] 15%|‚ñà‚ñç        | 41/280 [1:05:50<6:06:25, 91.99s/it] 15%|‚ñà‚ñå        | 42/280 [1:07:35<6:19:38, 95.71s/it] 15%|‚ñà‚ñå        | 43/280 [1:10:20<7:37:21, 115.79s/it] 16%|‚ñà‚ñå        | 44/280 [1:12:05<7:23:01, 112.63s/it] 16%|‚ñà‚ñå        | 45/280 [1:12:20<5:28:22, 83.84s/it]  16%|‚ñà‚ñã        | 46/280 [1:13:55<5:39:53, 87.15s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_1/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_1/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_1/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_1/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_1/self_attn.k_proj/compressed.log
best_loss 5.773484230041504 running bpv: 2.014929
COMMANDS_FINISHED 38 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_1/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_1/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_1/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_1/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_1/mlp.up_proj/compressed.log
best_loss 10.586471557617188 running bpv: 2.014789
COMMANDS_FINISHED 39 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_1/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_1/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_1/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_1/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_1/self_attn.o_proj/compressed.log
best_loss 0.08594890683889389 running bpv: 2.014905
COMMANDS_FINISHED 40 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_1/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_1/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_1/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_1/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_1/self_attn.v_proj/compressed.log
best_loss 1.3221856355667114 running bpv: 2.015018
COMMANDS_FINISHED 41 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_7/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_7/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_7/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_1/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_1/mlp.down_proj/compressed.log
best_loss 0.2745172381401062 running bpv: 2.014826
COMMANDS_FINISHED 42 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_7/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_7/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_7/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_7/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_7/mlp.gate_proj/compressed.log
best_loss 142.08309936523438 running bpv: 2.014703
COMMANDS_FINISHED 43 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_7/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_7/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_7/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_7/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_7/self_attn.q_proj/compressed.log
best_loss 149.58326721191406 running bpv: 2.014809
COMMANDS_FINISHED 44 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_7/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_7/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_7/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_7/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_7/mlp.up_proj/compressed.log
best_loss 112.97161865234375 running bpv: 2.014693
COMMANDS_FINISHED 45 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_7/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_7/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_7/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_7/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_7/self_attn.k_proj/compressed.log
best_loss 154.53311157226562 running bpv: 2.014794
COMMANDS_FINISHED 46 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_7/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_7/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_7/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_7/self_attn.o_proj is done
reading log  17%|‚ñà‚ñã        | 47/280 [1:14:30<4:38:12, 71.64s/it] 17%|‚ñà‚ñã        | 48/280 [1:16:15<5:15:29, 81.59s/it] 18%|‚ñà‚ñä        | 49/280 [1:19:20<7:13:05, 112.49s/it] 18%|‚ñà‚ñä        | 50/280 [1:20:35<6:28:13, 101.28s/it] 18%|‚ñà‚ñä        | 51/280 [1:22:30<6:42:14, 105.39s/it] 19%|‚ñà‚ñä        | 52/280 [1:24:15<6:40:02, 105.27s/it] 19%|‚ñà‚ñâ        | 53/280 [1:24:30<4:55:56, 78.22s/it]  19%|‚ñà‚ñâ        | 54/280 [1:26:15<5:24:52, 86.25s/it] 20%|‚ñà‚ñâ        | 55/280 [1:28:20<6:07:01, 97.87s/it] 20%|‚ñà‚ñà        | 56/280 [1:31:25<7:42:57, 124.01s/it]/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_7/self_attn.o_proj/compressed.log
best_loss 2.952326774597168 running bpv: 2.014893
COMMANDS_FINISHED 47 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_7/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_7/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_7/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_7/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_7/self_attn.v_proj/compressed.log
best_loss 55.60504913330078 running bpv: 2.01499
COMMANDS_FINISHED 48 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_33/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_33/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_33/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_7/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_7/mlp.down_proj/compressed.log
best_loss 6.693534851074219 running bpv: 2.014826
COMMANDS_FINISHED 49 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_33/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_33/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_33/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_33/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_33/mlp.gate_proj/compressed.log
best_loss 681.4337158203125 running bpv: 2.01472
COMMANDS_FINISHED 50 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_33/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_33/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_33/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_33/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_33/self_attn.q_proj/compressed.log
best_loss 401.47882080078125 running bpv: 2.014811
COMMANDS_FINISHED 51 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_33/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_33/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_33/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_33/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_33/self_attn.k_proj/compressed.log
best_loss 412.583740234375 running bpv: 2.014901
COMMANDS_FINISHED 52 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_33/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_33/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_33/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_33/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_33/mlp.up_proj/compressed.log
best_loss 588.1000366210938 running bpv: 2.014798
COMMANDS_FINISHED 53 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_33/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_33/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_33/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_33/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_33/self_attn.o_proj/compressed.log
best_loss 18.733535766601562 running bpv: 2.014884
COMMANDS_FINISHED 54 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_33/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_33/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_33/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_33/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_33/self_attn.v_proj/compressed.log
best_loss 330.9508056640625 running bpv: 2.014969
COMMANDS_FINISHED 55 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_34/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_34/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_34/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_33/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_33/mlp.down_proj/compressed.log
best_loss 83.76520538330078 running bpv: 2.014826
COMMANDS_FINISHED 56 n_commands 280
 20%|‚ñà‚ñà        | 57/280 [1:32:50<6:57:24, 112.31s/it] 21%|‚ñà‚ñà        | 58/280 [1:34:35<6:47:26, 110.12s/it] 21%|‚ñà‚ñà        | 59/280 [1:36:20<6:39:57, 108.59s/it] 21%|‚ñà‚ñà‚ñè       | 60/280 [1:36:35<4:55:13, 80.51s/it]  22%|‚ñà‚ñà‚ñè       | 61/280 [1:38:20<5:20:41, 87.86s/it] 22%|‚ñà‚ñà‚ñè       | 62/280 [1:40:25<5:59:43, 99.01s/it] 22%|‚ñà‚ñà‚ñé       | 63/280 [1:43:30<7:31:23, 124.81s/it] 23%|‚ñà‚ñà‚ñé       | 64/280 [1:44:45<6:35:31, 109.87s/it] 23%|‚ñà‚ñà‚ñé       | 65/280 [1:46:50<6:49:58, 114.41s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_34/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_34/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_34/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_34/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_34/mlp.gate_proj/compressed.log
best_loss 702.5319213867188 running bpv: 2.014733
COMMANDS_FINISHED 57 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_34/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_34/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_34/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_34/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_34/self_attn.q_proj/compressed.log
best_loss 405.76568603515625 running bpv: 2.014813
COMMANDS_FINISHED 58 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_34/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_34/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_34/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_34/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_34/self_attn.k_proj/compressed.log
best_loss 415.7171936035156 running bpv: 2.014892
COMMANDS_FINISHED 59 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_34/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_34/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_34/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_34/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_34/mlp.up_proj/compressed.log
best_loss 620.7053833007812 running bpv: 2.014801
COMMANDS_FINISHED 60 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_34/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_34/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_34/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_34/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_34/self_attn.o_proj/compressed.log
best_loss 25.32843780517578 running bpv: 2.014878
COMMANDS_FINISHED 61 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_34/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_34/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_34/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_34/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_34/self_attn.v_proj/compressed.log
best_loss 363.3495178222656 running bpv: 2.014952
COMMANDS_FINISHED 62 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_0/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_0/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_0/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_34/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_34/mlp.down_proj/compressed.log
best_loss 93.26335144042969 running bpv: 2.014826
COMMANDS_FINISHED 63 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_0/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_0/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_0/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_0/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_0/mlp.gate_proj/compressed.log
best_loss 2.1351215839385986 running bpv: 2.014743
COMMANDS_FINISHED 64 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_0/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_0/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_0/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_0/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_0/self_attn.q_proj/compressed.log
best_loss 0.29016250371932983 running bpv: 2.014814
COMMANDS_FINISHED 65 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_0/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_0/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_0/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_0/mlp.up_proj is done
reading log  24%|‚ñà‚ñà‚ñé       | 66/280 [1:47:55<5:55:12, 99.59s/it]  24%|‚ñà‚ñà‚ñç       | 67/280 [1:49:00<5:16:42, 89.21s/it] 24%|‚ñà‚ñà‚ñç       | 68/280 [1:49:55<4:38:57, 78.95s/it] 25%|‚ñà‚ñà‚ñç       | 69/280 [1:51:30<4:54:35, 83.77s/it] 25%|‚ñà‚ñà‚ñå       | 70/280 [1:55:25<7:32:00, 129.14s/it] 25%|‚ñà‚ñà‚ñå       | 71/280 [1:55:50<5:41:01, 97.90s/it]  26%|‚ñà‚ñà‚ñå       | 72/280 [1:57:35<5:46:47, 100.03s/it] 26%|‚ñà‚ñà‚ñå       | 73/280 [1:59:20<5:50:15, 101.53s/it] 26%|‚ñà‚ñà‚ñã       | 74/280 [2:00:25<5:10:57, 90.57s/it]  27%|‚ñà‚ñà‚ñã       | 75/280 [2:01:20<4:32:59, 79.90s/it]/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_0/mlp.up_proj/compressed.log
best_loss 1.9971861839294434 running bpv: 2.014735
COMMANDS_FINISHED 66 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_0/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_0/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_0/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_0/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_0/self_attn.k_proj/compressed.log
best_loss 0.12350098043680191 running bpv: 2.014804
COMMANDS_FINISHED 67 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_0/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_0/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_0/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_0/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_0/self_attn.o_proj/compressed.log
best_loss 0.0045587169006466866 running bpv: 2.014872
COMMANDS_FINISHED 68 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_0/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_0/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_0/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_0/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_0/self_attn.v_proj/compressed.log
best_loss 0.024840133264660835 running bpv: 2.014939
COMMANDS_FINISHED 69 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_32/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_32/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_32/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_0/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_0/mlp.down_proj/compressed.log
best_loss 0.03441648557782173 running bpv: 2.014826
COMMANDS_FINISHED 70 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_32/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_32/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_32/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_32/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_32/mlp.gate_proj/compressed.log
best_loss 662.11962890625 running bpv: 2.014751
COMMANDS_FINISHED 71 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_32/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_32/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_32/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_32/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_32/self_attn.q_proj/compressed.log
best_loss 436.82061767578125 running bpv: 2.014816
COMMANDS_FINISHED 72 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_32/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_32/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_32/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_32/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_32/self_attn.k_proj/compressed.log
best_loss 443.155517578125 running bpv: 2.014879
COMMANDS_FINISHED 73 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_32/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_32/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_32/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_32/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_32/mlp.up_proj/compressed.log
best_loss 565.180908203125 running bpv: 2.014806
COMMANDS_FINISHED 74 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_32/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_32/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_32/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_32/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_32/self_attn.o_proj/compressed.log
best_loss 19.55544662475586 running bpv: 2.014868
COMMANDS_FINISHED 75 n_commands 280
 27%|‚ñà‚ñà‚ñã       | 76/280 [2:03:25<5:17:40, 93.43s/it] 28%|‚ñà‚ñà‚ñä       | 77/280 [2:07:30<7:49:58, 138.91s/it] 28%|‚ñà‚ñà‚ñä       | 78/280 [2:07:45<5:42:31, 101.74s/it] 28%|‚ñà‚ñà‚ñä       | 79/280 [2:09:30<5:44:06, 102.72s/it] 29%|‚ñà‚ñà‚ñä       | 80/280 [2:11:15<5:44:41, 103.41s/it] 29%|‚ñà‚ñà‚ñâ       | 81/280 [2:12:50<5:34:36, 100.89s/it] 29%|‚ñà‚ñà‚ñâ       | 82/280 [2:13:15<4:17:48, 78.12s/it]  30%|‚ñà‚ñà‚ñâ       | 83/280 [2:15:10<4:52:50, 89.19s/it] 30%|‚ñà‚ñà‚ñà       | 84/280 [2:18:55<7:04:27, 129.94s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_32/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_32/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_32/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_32/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_32/self_attn.v_proj/compressed.log
best_loss 370.3378601074219 running bpv: 2.014929
COMMANDS_FINISHED 76 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_31/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_31/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_31/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_32/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_32/mlp.down_proj/compressed.log
best_loss 79.25564575195312 running bpv: 2.014826
COMMANDS_FINISHED 77 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_31/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_31/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_31/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_31/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_31/mlp.gate_proj/compressed.log
best_loss 640.360595703125 running bpv: 2.014758
COMMANDS_FINISHED 78 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_31/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_31/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_31/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_31/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_31/self_attn.q_proj/compressed.log
best_loss 416.37091064453125 running bpv: 2.014816
COMMANDS_FINISHED 79 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_31/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_31/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_31/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_31/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_31/self_attn.k_proj/compressed.log
best_loss 431.43231201171875 running bpv: 2.014874
COMMANDS_FINISHED 80 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_31/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_31/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_31/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_31/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_31/mlp.up_proj/compressed.log
best_loss 539.8885498046875 running bpv: 2.014808
COMMANDS_FINISHED 81 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_31/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_31/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_31/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_31/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_31/self_attn.o_proj/compressed.log
best_loss 18.881324768066406 running bpv: 2.014864
COMMANDS_FINISHED 82 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_31/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_31/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_31/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_31/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_31/self_attn.v_proj/compressed.log
best_loss 321.1759338378906 running bpv: 2.01492
COMMANDS_FINISHED 83 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_21/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_21/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_21/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_21/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_21/mlp.gate_proj/compressed.log
best_loss 404.766845703125 running bpv: 2.014855
COMMANDS_FINISHED 84 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_21/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_21/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_21/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_31/mlp.down_proj is done
reading log  30%|‚ñà‚ñà‚ñà       | 85/280 [2:19:40<5:39:29, 104.46s/it] 31%|‚ñà‚ñà‚ñà       | 86/280 [2:21:15<5:28:34, 101.62s/it] 31%|‚ñà‚ñà‚ñà       | 87/280 [2:22:50<5:20:30, 99.64s/it]  31%|‚ñà‚ñà‚ñà‚ñè      | 88/280 [2:23:15<4:07:11, 77.25s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 89/280 [2:24:40<4:13:19, 79.58s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 90/280 [2:26:35<4:45:39, 90.21s/it] 32%|‚ñà‚ñà‚ñà‚ñé      | 91/280 [2:30:10<6:42:05, 127.65s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 92/280 [2:30:55<5:22:16, 102.86s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 93/280 [2:32:40<5:22:34, 103.50s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 94/280 [2:34:25<5:22:15, 103.95s/it]/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_31/mlp.down_proj/compressed.log
best_loss 74.41387939453125 running bpv: 2.014763
COMMANDS_FINISHED 85 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_21/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_21/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_21/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_21/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_21/self_attn.q_proj/compressed.log
best_loss 298.10003662109375 running bpv: 2.014817
COMMANDS_FINISHED 86 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_21/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_21/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_21/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_21/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_21/self_attn.k_proj/compressed.log
best_loss 308.8340759277344 running bpv: 2.014871
COMMANDS_FINISHED 87 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_21/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_21/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_21/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_21/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_21/mlp.up_proj/compressed.log
best_loss 358.4977722167969 running bpv: 2.014809
COMMANDS_FINISHED 88 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_21/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_21/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_21/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_21/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_21/self_attn.o_proj/compressed.log
best_loss 23.588075637817383 running bpv: 2.014861
COMMANDS_FINISHED 89 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_21/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_21/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_21/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_21/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_21/self_attn.v_proj/compressed.log
best_loss 181.2523956298828 running bpv: 2.014913
COMMANDS_FINISHED 90 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_26/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_26/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_26/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_21/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_21/mlp.down_proj/compressed.log
best_loss 53.59178161621094 running bpv: 2.014826
COMMANDS_FINISHED 91 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_26/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_26/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_26/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_26/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_26/mlp.gate_proj/compressed.log
best_loss 530.438720703125 running bpv: 2.014768
COMMANDS_FINISHED 92 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_26/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_26/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_26/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_26/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_26/self_attn.q_proj/compressed.log
best_loss 355.49658203125 running bpv: 2.014818
COMMANDS_FINISHED 93 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_26/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_26/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_26/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_26/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_26/self_attn.k_proj/compressed.log
best_loss 363.7631530761719 running bpv: 2.014867
COMMANDS_FINISHED 94 n_commands 280
 34%|‚ñà‚ñà‚ñà‚ñç      | 95/280 [2:35:20<4:35:14, 89.27s/it]  34%|‚ñà‚ñà‚ñà‚ñç      | 96/280 [2:36:25<4:11:26, 81.99s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 97/280 [2:38:30<4:49:26, 94.90s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 98/280 [2:42:05<6:37:09, 130.93s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 99/280 [2:42:40<5:08:09, 102.15s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 100/280 [2:44:15<5:00:02, 100.01s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 101/280 [2:46:00<5:02:50, 101.51s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 102/280 [2:46:25<3:53:03, 78.56s/it]  37%|‚ñà‚ñà‚ñà‚ñã      | 103/280 [2:47:50<3:57:27, 80.49s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_26/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_26/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_26/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_26/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_26/mlp.up_proj/compressed.log
best_loss 443.37213134765625 running bpv: 2.01481
COMMANDS_FINISHED 95 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_26/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_26/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_26/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_26/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_26/self_attn.o_proj/compressed.log
best_loss 17.700408935546875 running bpv: 2.014859
COMMANDS_FINISHED 96 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_26/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_26/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_26/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_26/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_26/self_attn.v_proj/compressed.log
best_loss 269.0794677734375 running bpv: 2.014906
COMMANDS_FINISHED 97 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_14/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_14/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_14/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_26/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_26/mlp.down_proj/compressed.log
best_loss 64.30322265625 running bpv: 2.014826
COMMANDS_FINISHED 98 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_14/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_14/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_14/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_14/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_14/mlp.gate_proj/compressed.log
best_loss 221.093994140625 running bpv: 2.014772
COMMANDS_FINISHED 99 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_14/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_14/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_14/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_14/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_14/self_attn.q_proj/compressed.log
best_loss 273.32635498046875 running bpv: 2.014818
COMMANDS_FINISHED 100 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_14/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_14/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_14/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_14/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_14/self_attn.k_proj/compressed.log
best_loss 284.80999755859375 running bpv: 2.014864
COMMANDS_FINISHED 101 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_14/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_14/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_14/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_14/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_14/mlp.up_proj/compressed.log
best_loss 213.31703186035156 running bpv: 2.014811
COMMANDS_FINISHED 102 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_14/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_14/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_14/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_14/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_14/self_attn.o_proj/compressed.log
best_loss 15.556816101074219 running bpv: 2.014856
COMMANDS_FINISHED 103 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_14/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_14/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_14/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_14/self_attn.v_proj is done
 37%|‚ñà‚ñà‚ñà‚ñã      | 104/280 [2:49:35<4:17:41, 87.85s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 105/280 [2:53:10<6:07:29, 126.00s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 106/280 [2:53:55<4:54:55, 101.70s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 107/280 [2:55:40<4:56:05, 102.69s/it] 39%|‚ñà‚ñà‚ñà‚ñä      | 108/280 [2:57:25<4:56:22, 103.39s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 109/280 [2:57:50<3:47:38, 79.87s/it]  39%|‚ñà‚ñà‚ñà‚ñâ      | 110/280 [2:59:05<3:42:10, 78.41s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 111/280 [3:00:50<4:03:20, 86.39s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 112/280 [3:04:35<5:58:20, 127.98s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 113/280 [3:05:00<4:30:13, 97.09s/it] reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_14/self_attn.v_proj/compressed.log
best_loss 121.00245666503906 running bpv: 2.014901
COMMANDS_FINISHED 104 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_15/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_15/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_15/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_14/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_14/mlp.down_proj/compressed.log
best_loss 20.52213478088379 running bpv: 2.014826
COMMANDS_FINISHED 105 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_15/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_15/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_15/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_15/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_15/mlp.gate_proj/compressed.log
best_loss 239.20828247070312 running bpv: 2.014775
COMMANDS_FINISHED 106 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_15/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_15/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_15/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_15/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_15/self_attn.q_proj/compressed.log
best_loss 258.0733337402344 running bpv: 2.014819
COMMANDS_FINISHED 107 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_15/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_15/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_15/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_15/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_15/self_attn.k_proj/compressed.log
best_loss 274.53338623046875 running bpv: 2.014862
COMMANDS_FINISHED 108 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_15/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_15/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_15/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_15/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_15/mlp.up_proj/compressed.log
best_loss 232.25169372558594 running bpv: 2.014812
COMMANDS_FINISHED 109 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_15/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_15/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_15/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_15/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_15/self_attn.o_proj/compressed.log
best_loss 18.021915435791016 running bpv: 2.014854
COMMANDS_FINISHED 110 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_15/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_15/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_15/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_15/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_15/self_attn.v_proj/compressed.log
best_loss 126.00527954101562 running bpv: 2.014896
COMMANDS_FINISHED 111 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_4/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_4/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_4/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_15/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_15/mlp.down_proj/compressed.log
best_loss 23.524864196777344 running bpv: 2.014826
COMMANDS_FINISHED 112 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_4/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_4/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_4/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_4/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_4/mlp.gate_proj/compressed.log
best_loss 72.69149780273438 running bpv: 2.014778
COMMANDS_FINISHED 113 n_commands 280
 41%|‚ñà‚ñà‚ñà‚ñà      | 114/280 [3:06:35<4:26:52, 96.46s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 115/280 [3:08:11<4:24:04, 96.03s/it] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 116/280 [3:08:46<3:32:26, 77.72s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 117/280 [3:10:11<3:37:04, 79.91s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 118/280 [3:11:56<3:56:04, 87.44s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 119/280 [3:15:31<5:37:19, 125.71s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 120/280 [3:16:06<4:22:39, 98.50s/it]  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 121/280 [3:17:51<4:26:11, 100.45s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 122/280 [3:19:46<4:36:01, 104.82s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_4/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_4/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_4/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_4/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_4/self_attn.q_proj/compressed.log
best_loss 106.16407775878906 running bpv: 2.014819
COMMANDS_FINISHED 114 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_4/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_4/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_4/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_4/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_4/self_attn.k_proj/compressed.log
best_loss 108.65252685546875 running bpv: 2.01486
COMMANDS_FINISHED 115 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_4/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_4/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_4/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_4/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_4/mlp.up_proj/compressed.log
best_loss 61.187137603759766 running bpv: 2.014813
COMMANDS_FINISHED 116 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_4/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_4/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_4/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_4/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_4/self_attn.o_proj/compressed.log
best_loss 0.7150027751922607 running bpv: 2.014853
COMMANDS_FINISHED 117 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_4/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_4/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_4/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_4/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_4/self_attn.v_proj/compressed.log
best_loss 34.423316955566406 running bpv: 2.014892
COMMANDS_FINISHED 118 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_27/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_27/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_27/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_4/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_4/mlp.down_proj/compressed.log
best_loss 2.066394567489624 running bpv: 2.014826
COMMANDS_FINISHED 119 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_27/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_27/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_27/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_27/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_27/mlp.gate_proj/compressed.log
best_loss 555.6549072265625 running bpv: 2.014781
COMMANDS_FINISHED 120 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_27/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_27/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_27/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_27/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_27/self_attn.q_proj/compressed.log
best_loss 405.7305908203125 running bpv: 2.01482
COMMANDS_FINISHED 121 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_27/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_27/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_27/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_27/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_27/self_attn.k_proj/compressed.log
best_loss 412.34661865234375 running bpv: 2.014858
COMMANDS_FINISHED 122 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_27/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_27/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_27/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_27/mlp.up_proj is done
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 123/280 [3:20:31<3:47:19, 86.88s/it]  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 124/280 [3:21:46<3:36:37, 83.31s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 125/280 [3:23:51<4:07:32, 95.82s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 126/280 [3:27:16<5:30:01, 128.58s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 127/280 [3:27:51<4:16:17, 100.51s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 128/280 [3:29:36<4:18:02, 101.86s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 129/280 [3:31:21<4:18:43, 102.80s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 130/280 [3:31:36<3:11:09, 76.46s/it]  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 131/280 [3:33:21<3:31:09, 85.03s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 132/280 [3:35:16<3:51:55, 94.02s/it]reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_27/mlp.up_proj/compressed.log
best_loss 462.4849853515625 running bpv: 2.014814
COMMANDS_FINISHED 123 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_27/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_27/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_27/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_27/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_27/self_attn.o_proj/compressed.log
best_loss 15.254124641418457 running bpv: 2.014851
COMMANDS_FINISHED 124 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_27/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_27/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_27/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_27/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_27/self_attn.v_proj/compressed.log
best_loss 302.2208557128906 running bpv: 2.014888
COMMANDS_FINISHED 125 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_2/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_2/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_2/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_27/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_27/mlp.down_proj/compressed.log
best_loss 65.7623062133789 running bpv: 2.014826
COMMANDS_FINISHED 126 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_2/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_2/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_2/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_2/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_2/mlp.gate_proj/compressed.log
best_loss 32.02157974243164 running bpv: 2.014784
COMMANDS_FINISHED 127 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_2/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_2/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_2/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_2/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_2/self_attn.q_proj/compressed.log
best_loss 34.47319030761719 running bpv: 2.01482
COMMANDS_FINISHED 128 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_2/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_2/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_2/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_2/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_2/self_attn.k_proj/compressed.log
best_loss 37.89091110229492 running bpv: 2.014856
COMMANDS_FINISHED 129 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_2/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_2/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_2/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_2/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_2/mlp.up_proj/compressed.log
best_loss 27.24395751953125 running bpv: 2.014814
COMMANDS_FINISHED 130 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_2/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_2/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_2/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_2/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_2/self_attn.o_proj/compressed.log
best_loss 0.21780073642730713 running bpv: 2.01485
COMMANDS_FINISHED 131 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_2/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_2/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_2/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_2/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_2/self_attn.v_proj/compressed.log
best_loss 9.961153030395508 running bpv: 2.014885
COMMANDS_FINISHED 132 n_commands 280
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 133/280 [3:37:21<4:13:07, 103.32s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 134/280 [3:39:46<4:41:50, 115.83s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 135/280 [3:41:21<4:24:49, 109.58s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 136/280 [3:42:06<3:36:29, 90.21s/it]  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 137/280 [3:43:01<3:09:49, 79.65s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 138/280 [3:44:06<2:58:06, 75.26s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 139/280 [3:46:11<3:31:55, 90.18s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 140/280 [3:49:56<5:04:48, 130.63s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 141/280 [3:50:31<3:56:10, 101.94s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_36/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_36/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_36/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_2/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_2/mlp.down_proj/compressed.log
best_loss 0.7052313089370728 running bpv: 2.014826
COMMANDS_FINISHED 133 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_36/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_36/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_36/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_36/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_36/mlp.gate_proj/compressed.log
best_loss 751.1549072265625 running bpv: 2.014786
COMMANDS_FINISHED 134 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_36/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_36/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_36/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_36/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_36/self_attn.q_proj/compressed.log
best_loss 358.003662109375 running bpv: 2.01482
COMMANDS_FINISHED 135 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_36/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_36/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_36/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_36/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_36/mlp.up_proj/compressed.log
best_loss 689.4896240234375 running bpv: 2.014781
COMMANDS_FINISHED 136 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_36/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_36/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_36/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_36/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_36/self_attn.k_proj/compressed.log
best_loss 371.4327392578125 running bpv: 2.014815
COMMANDS_FINISHED 137 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_36/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_36/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_36/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_36/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_36/self_attn.o_proj/compressed.log
best_loss 39.43663024902344 running bpv: 2.014849
COMMANDS_FINISHED 138 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_36/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_36/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_36/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_36/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_36/self_attn.v_proj/compressed.log
best_loss 338.86651611328125 running bpv: 2.014882
COMMANDS_FINISHED 139 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_28/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_28/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_28/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_36/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_36/mlp.down_proj/compressed.log
best_loss 122.26194763183594 running bpv: 2.014826
COMMANDS_FINISHED 140 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_28/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_28/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_28/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_28/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_28/mlp.gate_proj/compressed.log
best_loss 570.0704956054688 running bpv: 2.014788
COMMANDS_FINISHED 141 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_28/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_28/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_28/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_28/self_attn.q_proj is done
reading log  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 142/280 [3:52:16<3:56:34, 102.86s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 143/280 [3:54:01<3:56:20, 103.51s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 144/280 [3:55:16<3:35:14, 94.96s/it]  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 145/280 [3:56:01<2:59:56, 79.97s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 146/280 [3:58:06<3:28:46, 93.48s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 147/280 [4:02:11<5:07:59, 138.94s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 148/280 [4:02:26<3:43:52, 101.76s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 149/280 [4:04:11<3:44:18, 102.73s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 150/280 [4:05:56<3:44:04, 103.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 151/280 [4:06:51<3:11:07, 88.89s/it] /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_28/self_attn.q_proj/compressed.log
best_loss 400.96942138671875 running bpv: 2.01482
COMMANDS_FINISHED 142 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_28/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_28/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_28/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_28/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_28/self_attn.k_proj/compressed.log
best_loss 407.46942138671875 running bpv: 2.014853
COMMANDS_FINISHED 143 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_28/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_28/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_28/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_28/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_28/mlp.up_proj/compressed.log
best_loss 475.3158264160156 running bpv: 2.014816
COMMANDS_FINISHED 144 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_28/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_28/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_28/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_28/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_28/self_attn.o_proj/compressed.log
best_loss 16.068626403808594 running bpv: 2.014847
COMMANDS_FINISHED 145 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_28/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_28/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_28/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_28/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_28/self_attn.v_proj/compressed.log
best_loss 304.9877014160156 running bpv: 2.014879
COMMANDS_FINISHED 146 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_18/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_18/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_18/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_28/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_28/mlp.down_proj/compressed.log
best_loss 66.23995208740234 running bpv: 2.014826
COMMANDS_FINISHED 147 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_18/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_18/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_18/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_18/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_18/mlp.gate_proj/compressed.log
best_loss 321.656494140625 running bpv: 2.01479
COMMANDS_FINISHED 148 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_18/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_18/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_18/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_18/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_18/self_attn.q_proj/compressed.log
best_loss 297.3505859375 running bpv: 2.014821
COMMANDS_FINISHED 149 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_18/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_18/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_18/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_18/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_18/self_attn.k_proj/compressed.log
best_loss 311.9167175292969 running bpv: 2.014852
COMMANDS_FINISHED 150 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_18/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_18/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_18/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_18/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_18/mlp.up_proj/compressed.log
best_loss 297.034912109375 running bpv: 2.014816
COMMANDS_FINISHED 151 n_commands 280
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 152/280 [4:07:56<2:54:21, 81.73s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 153/280 [4:10:01<3:20:28, 94.71s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 154/280 [4:13:46<4:40:59, 133.80s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 155/280 [4:14:21<3:37:00, 104.16s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 156/280 [4:15:56<3:29:35, 101.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 157/280 [4:17:31<3:23:57, 99.49s/it]  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 158/280 [4:18:26<2:55:10, 86.15s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 159/280 [4:19:31<2:40:56, 79.81s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 160/280 [4:21:36<3:06:43, 93.37s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_18/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_18/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_18/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_18/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_18/self_attn.o_proj/compressed.log
best_loss 15.36898422241211 running bpv: 2.014846
COMMANDS_FINISHED 152 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_18/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_18/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_18/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_18/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_18/self_attn.v_proj/compressed.log
best_loss 163.2393798828125 running bpv: 2.014877
COMMANDS_FINISHED 153 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_25/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_25/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_25/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_18/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_18/mlp.down_proj/compressed.log
best_loss 34.37509536743164 running bpv: 2.014826
COMMANDS_FINISHED 154 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_25/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_25/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_25/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_25/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_25/mlp.gate_proj/compressed.log
best_loss 511.50115966796875 running bpv: 2.014791
COMMANDS_FINISHED 155 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_25/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_25/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_25/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_25/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_25/self_attn.q_proj/compressed.log
best_loss 356.71710205078125 running bpv: 2.014821
COMMANDS_FINISHED 156 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_25/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_25/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_25/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_25/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_25/self_attn.k_proj/compressed.log
best_loss 365.42803955078125 running bpv: 2.01485
COMMANDS_FINISHED 157 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_25/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_25/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_25/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_25/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_25/mlp.up_proj/compressed.log
best_loss 429.15155029296875 running bpv: 2.014816
COMMANDS_FINISHED 158 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_25/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_25/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_25/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_25/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_25/self_attn.o_proj/compressed.log
best_loss 16.82323455810547 running bpv: 2.014846
COMMANDS_FINISHED 159 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_25/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_25/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_25/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_25/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_25/self_attn.v_proj/compressed.log
best_loss 263.4461364746094 running bpv: 2.014874
COMMANDS_FINISHED 160 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_37/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_37/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_37/mlp.gate_proj/compressed.log 2>&1 &
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 161/280 [4:25:21<4:23:30, 132.86s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 162/280 [4:25:56<3:23:33, 103.50s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 163/280 [4:27:31<3:16:51, 100.96s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 164/280 [4:29:16<3:17:31, 102.17s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 165/280 [4:29:41<2:31:27, 79.02s/it]  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 166/280 [4:31:16<2:39:15, 83.82s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 167/280 [4:33:11<2:55:28, 93.18s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 168/280 [4:36:26<3:50:57, 123.73s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 169/280 [4:37:21<3:10:45, 103.11s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 170/280 [4:39:06<3:10:04, 103.68s/it]meta-llama/Llama-2-13b-hf/layer_25/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_25/mlp.down_proj/compressed.log
best_loss 61.66242218017578 running bpv: 2.014826
COMMANDS_FINISHED 161 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_37/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_37/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_37/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_37/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_37/mlp.gate_proj/compressed.log
best_loss 756.5382080078125 running bpv: 2.014793
COMMANDS_FINISHED 162 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_37/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_37/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_37/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_37/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_37/self_attn.q_proj/compressed.log
best_loss 320.82965087890625 running bpv: 2.014821
COMMANDS_FINISHED 163 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_37/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_37/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_37/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_37/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_37/self_attn.k_proj/compressed.log
best_loss 320.2957763671875 running bpv: 2.014849
COMMANDS_FINISHED 164 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_37/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_37/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_37/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_37/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_37/mlp.up_proj/compressed.log
best_loss 696.7886962890625 running bpv: 2.014817
COMMANDS_FINISHED 165 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_37/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_37/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_37/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_37/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_37/self_attn.o_proj/compressed.log
best_loss 40.23541259765625 running bpv: 2.014845
COMMANDS_FINISHED 166 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_37/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_37/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_37/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_37/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_37/self_attn.v_proj/compressed.log
best_loss 342.3365478515625 running bpv: 2.014872
COMMANDS_FINISHED 167 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_30/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_30/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_30/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_37/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_37/mlp.down_proj/compressed.log
best_loss 142.93531799316406 running bpv: 2.014826
COMMANDS_FINISHED 168 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_30/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_30/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_30/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_30/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_30/mlp.gate_proj/compressed.log
best_loss 617.6572265625 running bpv: 2.014794
COMMANDS_FINISHED 169 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_30/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_30/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_30/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_30/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_30/self_attn.q_proj/compressed.log
best_loss 459.0182189941406 running bpv: 2.014821
COMMANDS_FINISHED 170 n_commands 280
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 171/280 [4:40:51<3:09:04, 104.08s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 172/280 [4:41:56<2:46:14, 92.36s/it]  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 173/280 [4:42:51<2:24:43, 81.15s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 174/280 [4:44:46<2:41:18, 91.31s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 175/280 [4:49:01<4:05:44, 140.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 177/280 [4:50:51<2:53:22, 101.00s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 178/280 [4:52:36<2:53:23, 101.99s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 179/280 [4:54:21<2:53:00, 102.78s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_30/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_30/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_30/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_30/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_30/self_attn.k_proj/compressed.log
best_loss 465.51513671875 running bpv: 2.014848
COMMANDS_FINISHED 171 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_30/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_30/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_30/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_30/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_30/mlp.up_proj/compressed.log
best_loss 519.7293701171875 running bpv: 2.014817
COMMANDS_FINISHED 172 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_30/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_30/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_30/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_30/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_30/self_attn.o_proj/compressed.log
best_loss 17.634260177612305 running bpv: 2.014844
COMMANDS_FINISHED 173 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_30/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_30/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_30/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_30/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_30/self_attn.v_proj/compressed.log
best_loss 381.17083740234375 running bpv: 2.014871
COMMANDS_FINISHED 174 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_29/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_29/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_29/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_30/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_30/mlp.down_proj/compressed.log
best_loss 72.35499572753906 running bpv: 2.014826
COMMANDS_FINISHED 175 n_commands 280
meta-llama/Llama-2-13b-hf/layer_29/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_29/mlp.gate_proj/compressed.log
best_loss 589.5758056640625 running bpv: 2.014795
COMMANDS_FINISHED 176 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_29/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_29/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_29/mlp.up_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_29/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_29/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_29/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_29/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_29/self_attn.q_proj/compressed.log
best_loss 426.2095947265625 running bpv: 2.014821
COMMANDS_FINISHED 177 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_29/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_29/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_29/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_29/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_29/self_attn.k_proj/compressed.log
best_loss 436.8916015625 running bpv: 2.014848
COMMANDS_FINISHED 178 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_29/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_29/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_29/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_29/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_29/mlp.up_proj/compressed.log
best_loss 495.56689453125 running bpv: 2.014817
COMMANDS_FINISHED 179 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_29/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_29/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_29/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_29/self_attn.o_proj is done
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 180/280 [4:54:36<2:11:30, 78.91s/it]  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 181/280 [4:56:31<2:26:51, 89.01s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 182/280 [5:00:46<3:42:49, 136.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 183/280 [5:01:11<2:48:21, 104.14s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 184/280 [5:02:56<2:47:01, 104.39s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 185/280 [5:04:41<2:45:34, 104.57s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 186/280 [5:04:56<2:02:14, 78.02s/it]  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 187/280 [5:06:31<2:08:46, 83.08s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 188/280 [5:08:26<2:21:59, 92.60s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 189/280 [5:11:51<3:11:22, 126.18s/it]reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_29/self_attn.o_proj/compressed.log
best_loss 16.12392234802246 running bpv: 2.014843
COMMANDS_FINISHED 180 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_29/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_29/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_29/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_29/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_29/self_attn.v_proj/compressed.log
best_loss 318.56353759765625 running bpv: 2.014869
COMMANDS_FINISHED 181 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_16/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_16/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_16/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_16/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_16/mlp.gate_proj/compressed.log
best_loss 263.7446594238281 running bpv: 2.014839
COMMANDS_FINISHED 182 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_16/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_16/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_16/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_29/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_29/mlp.down_proj/compressed.log
best_loss 68.95626831054688 running bpv: 2.014796
COMMANDS_FINISHED 183 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_16/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_16/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_16/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_16/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_16/self_attn.q_proj/compressed.log
best_loss 285.2616882324219 running bpv: 2.014822
COMMANDS_FINISHED 184 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_16/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_16/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_16/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_16/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_16/self_attn.k_proj/compressed.log
best_loss 297.38958740234375 running bpv: 2.014847
COMMANDS_FINISHED 185 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_16/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_16/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_16/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_16/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_16/mlp.up_proj/compressed.log
best_loss 254.74533081054688 running bpv: 2.014818
COMMANDS_FINISHED 186 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_16/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_16/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_16/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_16/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_16/self_attn.o_proj/compressed.log
best_loss 18.056068420410156 running bpv: 2.014843
COMMANDS_FINISHED 187 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_16/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_16/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_16/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_16/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_16/self_attn.v_proj/compressed.log
best_loss 142.4270477294922 running bpv: 2.014867
COMMANDS_FINISHED 188 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_13/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_13/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_13/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_16/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_16/mlp.down_proj/compressed.log
best_loss 29.50295639038086 running bpv: 2.014826
COMMANDS_FINISHED 189 n_commands 280
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 190/280 [5:12:46<2:37:20, 104.89s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 191/280 [5:14:21<2:31:12, 101.93s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 192/280 [5:15:56<2:26:27, 99.86s/it]  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 193/280 [5:16:21<1:52:15, 77.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 194/280 [5:17:46<1:54:14, 79.70s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 195/280 [5:19:31<2:03:39, 87.29s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 196/280 [5:23:16<3:00:01, 128.59s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 197/280 [5:24:01<2:23:12, 103.52s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 198/280 [5:25:36<2:17:59, 100.97s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_13/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_13/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_13/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_13/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_13/mlp.gate_proj/compressed.log
best_loss 205.59182739257812 running bpv: 2.014798
COMMANDS_FINISHED 190 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_13/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_13/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_13/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_13/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_13/self_attn.q_proj/compressed.log
best_loss 269.490478515625 running bpv: 2.014822
COMMANDS_FINISHED 191 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_13/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_13/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_13/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_13/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_13/self_attn.k_proj/compressed.log
best_loss 268.3334655761719 running bpv: 2.014846
COMMANDS_FINISHED 192 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_13/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_13/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_13/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_13/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_13/mlp.up_proj/compressed.log
best_loss 195.14019775390625 running bpv: 2.014818
COMMANDS_FINISHED 193 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_13/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_13/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_13/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_13/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_13/self_attn.o_proj/compressed.log
best_loss 12.824721336364746 running bpv: 2.014842
COMMANDS_FINISHED 194 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_13/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_13/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_13/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_13/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_13/self_attn.v_proj/compressed.log
best_loss 125.49089050292969 running bpv: 2.014866
COMMANDS_FINISHED 195 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_10/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_10/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_10/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_13/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_13/mlp.down_proj/compressed.log
best_loss 17.427574157714844 running bpv: 2.014826
COMMANDS_FINISHED 196 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_10/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_10/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_10/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_10/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_10/mlp.gate_proj/compressed.log
best_loss 180.54074096679688 running bpv: 2.014799
COMMANDS_FINISHED 197 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_10/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_10/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_10/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_10/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_10/self_attn.q_proj/compressed.log
best_loss 219.66502380371094 running bpv: 2.014822
COMMANDS_FINISHED 198 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_10/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_10/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_10/self_attn.k_proj/compressed.log 2>&1 &
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 199/280 [5:27:21<2:17:56, 102.18s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 200/280 [5:27:36<1:41:22, 76.03s/it]  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 201/280 [5:29:11<1:47:36, 81.72s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 202/280 [5:30:56<1:55:19, 88.71s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 203/280 [5:34:21<2:38:37, 123.60s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 204/280 [5:35:06<2:06:41, 100.02s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 205/280 [5:36:41<2:03:08, 98.52s/it]  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 206/280 [5:38:16<2:00:12, 97.46s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 207/280 [5:38:51<1:35:47, 78.73s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 208/280 [5:40:16<1:36:44, 80.61s/it]meta-llama/Llama-2-13b-hf/layer_10/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_10/self_attn.k_proj/compressed.log
best_loss 227.95318603515625 running bpv: 2.014845
COMMANDS_FINISHED 199 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_10/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_10/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_10/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_10/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_10/mlp.up_proj/compressed.log
best_loss 158.88812255859375 running bpv: 2.014818
COMMANDS_FINISHED 200 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_10/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_10/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_10/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_10/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_10/self_attn.o_proj/compressed.log
best_loss 8.021867752075195 running bpv: 2.014841
COMMANDS_FINISHED 201 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_10/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_10/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_10/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_10/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_10/self_attn.v_proj/compressed.log
best_loss 86.99641418457031 running bpv: 2.014864
COMMANDS_FINISHED 202 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_19/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_19/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_19/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_10/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_10/mlp.down_proj/compressed.log
best_loss 12.067973136901855 running bpv: 2.014826
COMMANDS_FINISHED 203 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_19/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_19/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_19/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_19/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_19/mlp.gate_proj/compressed.log
best_loss 348.57635498046875 running bpv: 2.014799
COMMANDS_FINISHED 204 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_19/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_19/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_19/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_19/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_19/self_attn.q_proj/compressed.log
best_loss 295.354248046875 running bpv: 2.014822
COMMANDS_FINISHED 205 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_19/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_19/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_19/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_19/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_19/self_attn.k_proj/compressed.log
best_loss 305.10498046875 running bpv: 2.014845
COMMANDS_FINISHED 206 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_19/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_19/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_19/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_19/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_19/mlp.up_proj/compressed.log
best_loss 316.6585998535156 running bpv: 2.014819
COMMANDS_FINISHED 207 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_19/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_19/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_19/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_19/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_19/self_attn.o_proj/compressed.log
best_loss 16.815017700195312 running bpv: 2.014841
COMMANDS_FINISHED 208 n_commands 280
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 209/280 [5:42:11<1:47:36, 90.93s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 210/280 [5:45:36<2:26:00, 125.15s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 211/280 [5:46:21<1:56:16, 101.11s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 212/280 [5:47:56<1:52:30, 99.28s/it]  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 213/280 [5:49:41<1:52:46, 101.00s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 214/280 [5:49:56<1:22:43, 75.20s/it]  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 215/280 [5:51:41<1:31:09, 84.14s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 216/280 [5:53:26<1:36:25, 90.40s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 217/280 [5:56:41<2:07:52, 121.78s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_19/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_19/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_19/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_19/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_19/self_attn.v_proj/compressed.log
best_loss 169.0325927734375 running bpv: 2.014863
COMMANDS_FINISHED 209 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_6/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_6/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_6/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_19/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_19/mlp.down_proj/compressed.log
best_loss 38.4509391784668 running bpv: 2.014826
COMMANDS_FINISHED 210 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_6/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_6/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_6/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_6/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_6/mlp.gate_proj/compressed.log
best_loss 122.7906723022461 running bpv: 2.0148
COMMANDS_FINISHED 211 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_6/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_6/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_6/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_6/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_6/self_attn.q_proj/compressed.log
best_loss 150.5028533935547 running bpv: 2.014822
COMMANDS_FINISHED 212 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_6/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_6/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_6/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_6/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_6/self_attn.k_proj/compressed.log
best_loss 155.41744995117188 running bpv: 2.014844
COMMANDS_FINISHED 213 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_6/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_6/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_6/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_6/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_6/mlp.up_proj/compressed.log
best_loss 98.1108169555664 running bpv: 2.014819
COMMANDS_FINISHED 214 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_6/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_6/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_6/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_6/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_6/self_attn.o_proj/compressed.log
best_loss 1.824314832687378 running bpv: 2.01484
COMMANDS_FINISHED 215 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_6/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_6/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_6/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_6/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_6/self_attn.v_proj/compressed.log
best_loss 55.34739685058594 running bpv: 2.014862
COMMANDS_FINISHED 216 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_11/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_11/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_11/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_6/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_6/mlp.down_proj/compressed.log
best_loss 4.940138816833496 running bpv: 2.014826
COMMANDS_FINISHED 217 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_11/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_11/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_11/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_11/mlp.gate_proj is done
reading log  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 218/280 [5:57:46<1:48:14, 104.75s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 219/280 [5:59:21<1:43:31, 101.83s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 220/280 [6:00:56<1:39:46, 99.78s/it]  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 221/280 [6:01:11<1:13:06, 74.35s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 222/280 [6:02:46<1:17:51, 80.55s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 223/280 [6:04:21<1:20:38, 84.89s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 224/280 [6:07:56<1:55:39, 123.92s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 225/280 [6:08:31<1:29:08, 97.25s/it]  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 226/280 [6:10:06<1:26:55, 96.58s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 227/280 [6:11:41<1:24:53, 96.11s/it]/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_11/mlp.gate_proj/compressed.log
best_loss 182.86639404296875 running bpv: 2.014801
COMMANDS_FINISHED 218 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_11/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_11/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_11/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_11/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_11/self_attn.q_proj/compressed.log
best_loss 216.49819946289062 running bpv: 2.014822
COMMANDS_FINISHED 219 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_11/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_11/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_11/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_11/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_11/self_attn.k_proj/compressed.log
best_loss 226.72323608398438 running bpv: 2.014843
COMMANDS_FINISHED 220 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_11/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_11/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_11/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_11/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_11/mlp.up_proj/compressed.log
best_loss 166.951171875 running bpv: 2.014819
COMMANDS_FINISHED 221 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_11/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_11/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_11/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_11/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_11/self_attn.o_proj/compressed.log
best_loss 9.404729843139648 running bpv: 2.01484
COMMANDS_FINISHED 222 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_11/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_11/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_11/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_11/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_11/self_attn.v_proj/compressed.log
best_loss 83.21031188964844 running bpv: 2.014861
COMMANDS_FINISHED 223 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_20/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_20/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_20/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_11/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_11/mlp.down_proj/compressed.log
best_loss 13.476226806640625 running bpv: 2.014826
COMMANDS_FINISHED 224 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_20/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_20/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_20/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_20/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_20/mlp.gate_proj/compressed.log
best_loss 368.8113708496094 running bpv: 2.014802
COMMANDS_FINISHED 225 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_20/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_20/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_20/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_20/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_20/self_attn.q_proj/compressed.log
best_loss 278.6129150390625 running bpv: 2.014822
COMMANDS_FINISHED 226 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_20/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_20/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_20/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_20/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_20/self_attn.k_proj/compressed.log
best_loss 291.0906982421875 running bpv: 2.014843
COMMANDS_FINISHED 227 n_commands 280
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 228/280 [6:12:26<1:10:00, 80.78s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 229/280 [6:13:41<1:07:11, 79.05s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 230/280 [6:15:26<1:12:21, 86.83s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 231/280 [6:19:21<1:47:13, 131.29s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 232/280 [6:19:46<1:19:31, 99.40s/it]  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 233/280 [6:21:31<1:19:10, 101.08s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 234/280 [6:23:06<1:16:06, 99.26s/it]  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 235/280 [6:23:51<1:02:14, 82.99s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 236/280 [6:25:06<59:06, 80.59s/it]  running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_20/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_20/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_20/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_20/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_20/mlp.up_proj/compressed.log
best_loss 333.7713623046875 running bpv: 2.014819
COMMANDS_FINISHED 228 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_20/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_20/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_20/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_20/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_20/self_attn.o_proj/compressed.log
best_loss 18.71965789794922 running bpv: 2.014839
COMMANDS_FINISHED 229 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_20/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_20/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_20/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_20/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_20/self_attn.v_proj/compressed.log
best_loss 156.19766235351562 running bpv: 2.01486
COMMANDS_FINISHED 230 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_23/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_23/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_23/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_20/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_20/mlp.down_proj/compressed.log
best_loss 42.90498352050781 running bpv: 2.014826
COMMANDS_FINISHED 231 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_23/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_23/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_23/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_23/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_23/mlp.gate_proj/compressed.log
best_loss 463.83978271484375 running bpv: 2.014803
COMMANDS_FINISHED 232 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_23/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_23/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_23/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_23/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_23/self_attn.q_proj/compressed.log
best_loss 321.2347106933594 running bpv: 2.014822
COMMANDS_FINISHED 233 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_23/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_23/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_23/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_23/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_23/self_attn.k_proj/compressed.log
best_loss 329.7814636230469 running bpv: 2.014842
COMMANDS_FINISHED 234 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_23/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_23/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_23/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_23/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_23/mlp.up_proj/compressed.log
best_loss 395.6556091308594 running bpv: 2.014819
COMMANDS_FINISHED 235 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_23/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_23/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_23/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_23/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_23/self_attn.o_proj/compressed.log
best_loss 16.061819076538086 running bpv: 2.014839
COMMANDS_FINISHED 236 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_23/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_23/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_23/self_attn.v_proj/compressed.log 2>&1 &
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 237/280 [6:27:11<1:07:18, 93.92s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 238/280 [6:30:37<1:29:04, 127.25s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 239/280 [6:31:22<1:10:05, 102.57s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 240/280 [6:32:57<1:06:52, 100.30s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 241/280 [6:34:42<1:06:06, 101.72s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 242/280 [6:35:07<49:50, 78.70s/it]    87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 243/280 [6:36:42<51:32, 83.59s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 244/280 [6:38:47<57:36, 96.02s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 245/280 [6:42:02<1:13:20, 125.72s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 246/280 [6:43:07<1:00:55, 107.50s/it]meta-llama/Llama-2-13b-hf/layer_23/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_23/self_attn.v_proj/compressed.log
best_loss 225.0196990966797 running bpv: 2.014859
COMMANDS_FINISHED 237 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_35/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_35/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_35/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_23/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_23/mlp.down_proj/compressed.log
best_loss 57.51835632324219 running bpv: 2.014826
COMMANDS_FINISHED 238 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_35/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_35/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_35/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_35/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_35/mlp.gate_proj/compressed.log
best_loss 725.5789184570312 running bpv: 2.014803
COMMANDS_FINISHED 239 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_35/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_35/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_35/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_35/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_35/self_attn.q_proj/compressed.log
best_loss 377.0025329589844 running bpv: 2.014823
COMMANDS_FINISHED 240 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_35/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_35/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_35/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_35/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_35/self_attn.k_proj/compressed.log
best_loss 387.29022216796875 running bpv: 2.014842
COMMANDS_FINISHED 241 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_35/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_35/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_35/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_35/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_35/mlp.up_proj/compressed.log
best_loss 657.1760864257812 running bpv: 2.01482
COMMANDS_FINISHED 242 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_35/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_35/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_35/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_35/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_35/self_attn.o_proj/compressed.log
best_loss 25.372671127319336 running bpv: 2.014839
COMMANDS_FINISHED 243 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_35/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_35/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_35/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_35/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_35/self_attn.v_proj/compressed.log
best_loss 344.00787353515625 running bpv: 2.014858
COMMANDS_FINISHED 244 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_38/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_38/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_38/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_35/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_35/mlp.down_proj/compressed.log
best_loss 105.18589782714844 running bpv: 2.014826
COMMANDS_FINISHED 245 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_38/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_38/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_38/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_38/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_38/mlp.gate_proj/compressed.log
best_loss 763.3490600585938 running bpv: 2.014804
COMMANDS_FINISHED 246 n_commands 280
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 247/280 [6:44:42<57:03, 103.75s/it]   89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 248/280 [6:46:17<53:56, 101.13s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 249/280 [6:46:32<38:54, 75.29s/it]  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 250/280 [6:48:07<40:36, 81.21s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 251/280 [6:50:02<44:09, 91.35s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 252/280 [6:53:17<57:08, 122.45s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 253/280 [6:54:12<45:59, 102.21s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 254/280 [6:55:57<44:39, 103.05s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 255/280 [6:57:42<43:10, 103.64s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_38/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_38/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_38/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_38/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_38/self_attn.q_proj/compressed.log
best_loss 309.171630859375 running bpv: 2.014823
COMMANDS_FINISHED 247 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_38/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_38/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_38/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_38/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_38/mlp.up_proj/compressed.log
best_loss 674.2345581054688 running bpv: 2.014801
COMMANDS_FINISHED 248 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_38/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_38/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_38/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_38/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_38/self_attn.k_proj/compressed.log
best_loss 313.174560546875 running bpv: 2.01482
COMMANDS_FINISHED 249 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_38/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_38/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_38/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_38/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_38/self_attn.o_proj/compressed.log
best_loss 62.30037307739258 running bpv: 2.014838
COMMANDS_FINISHED 250 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_38/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_38/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_38/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_38/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_38/self_attn.v_proj/compressed.log
best_loss 368.9475402832031 running bpv: 2.014857
COMMANDS_FINISHED 251 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_17/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_17/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_17/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_38/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_38/mlp.down_proj/compressed.log
best_loss 170.562255859375 running bpv: 2.014826
COMMANDS_FINISHED 252 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_17/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_17/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_17/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_17/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_17/mlp.gate_proj/compressed.log
best_loss 293.6839904785156 running bpv: 2.014804
COMMANDS_FINISHED 253 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_17/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_17/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_17/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_17/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_17/self_attn.q_proj/compressed.log
best_loss 283.08026123046875 running bpv: 2.014823
COMMANDS_FINISHED 254 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_17/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_17/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_17/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_17/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_17/self_attn.k_proj/compressed.log
best_loss 297.010009765625 running bpv: 2.014841
COMMANDS_FINISHED 255 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_17/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_17/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_17/self_attn.o_proj/compressed.log 2>&1 &
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 256/280 [6:57:57<30:49, 77.05s/it]  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 257/280 [6:59:42<32:45, 85.44s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 258/280 [7:01:37<34:34, 94.31s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 259/280 [7:04:52<43:34, 124.52s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 260/280 [7:05:57<35:33, 106.67s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 261/280 [7:07:42<33:37, 106.17s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 262/280 [7:09:27<31:44, 105.82s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 264/280 [7:11:07<21:20, 80.06s/it]  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 265/280 [7:12:52<21:33, 86.25s/it]meta-llama/Llama-2-13b-hf/layer_17/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_17/mlp.up_proj/compressed.log
best_loss 276.87420654296875 running bpv: 2.01482
COMMANDS_FINISHED 256 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_17/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_17/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_17/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_17/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_17/self_attn.o_proj/compressed.log
best_loss 17.560710906982422 running bpv: 2.014838
COMMANDS_FINISHED 257 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_17/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_17/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_17/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_17/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_17/self_attn.v_proj/compressed.log
best_loss 147.00698852539062 running bpv: 2.014856
COMMANDS_FINISHED 258 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_9/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_9/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_9/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_17/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_17/mlp.down_proj/compressed.log
best_loss 32.36125564575195 running bpv: 2.014826
COMMANDS_FINISHED 259 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_9/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_9/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_9/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_9/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_9/mlp.gate_proj/compressed.log
best_loss 175.73812866210938 running bpv: 2.014805
COMMANDS_FINISHED 260 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_9/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_9/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_9/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_9/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_9/self_attn.q_proj/compressed.log
best_loss 220.73387145996094 running bpv: 2.014823
COMMANDS_FINISHED 261 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_9/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_9/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_9/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_9/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_9/mlp.up_proj/compressed.log
best_loss 149.20574951171875 running bpv: 2.014802
COMMANDS_FINISHED 262 n_commands 280
meta-llama/Llama-2-13b-hf/layer_9/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_9/self_attn.k_proj/compressed.log
best_loss 221.29855346679688 running bpv: 2.01482
COMMANDS_FINISHED 263 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_9/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_9/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_9/self_attn.o_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_9/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_9/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_9/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_9/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_9/self_attn.o_proj/compressed.log
best_loss 5.6408586502075195 running bpv: 2.014838
COMMANDS_FINISHED 264 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_9/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_9/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_9/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_9/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_9/self_attn.v_proj/compressed.log
best_loss 87.46488189697266 running bpv: 2.014855
COMMANDS_FINISHED 265 n_commands 280
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 266/280 [7:16:27<27:58, 119.92s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 267/280 [7:17:12<21:34, 99.55s/it]  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 268/280 [7:18:47<19:39, 98.28s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 269/280 [7:20:32<18:22, 100.20s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 270/280 [7:20:47<12:35, 75.51s/it]  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 271/280 [7:22:12<11:44, 78.29s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 272/280 [7:24:17<12:16, 92.07s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 273/280 [7:27:52<14:59, 128.51s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 274/280 [7:28:47<10:39, 106.65s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_22/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_22/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_22/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_9/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_9/mlp.down_proj/compressed.log
best_loss 10.11546516418457 running bpv: 2.014826
COMMANDS_FINISHED 266 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_22/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_22/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_22/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_22/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_22/mlp.gate_proj/compressed.log
best_loss 437.6702880859375 running bpv: 2.014806
COMMANDS_FINISHED 267 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_22/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_22/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_22/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_22/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_22/self_attn.q_proj/compressed.log
best_loss 331.2530517578125 running bpv: 2.014823
COMMANDS_FINISHED 268 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_22/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_22/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_22/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_22/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_22/self_attn.k_proj/compressed.log
best_loss 344.82171630859375 running bpv: 2.01484
COMMANDS_FINISHED 269 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_22/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_22/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_22/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_22/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_22/mlp.up_proj/compressed.log
best_loss 380.125244140625 running bpv: 2.01482
COMMANDS_FINISHED 270 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_22/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_22/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_22/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_22/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_22/self_attn.o_proj/compressed.log
best_loss 15.881129264831543 running bpv: 2.014837
COMMANDS_FINISHED 271 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_22/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_22/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_22/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_22/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_22/self_attn.v_proj/compressed.log
best_loss 228.32041931152344 running bpv: 2.014854
COMMANDS_FINISHED 272 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_24/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_24/mlp.gate_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_24/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_22/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_22/mlp.down_proj/compressed.log
best_loss 55.65411376953125 running bpv: 2.014826
COMMANDS_FINISHED 273 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_24/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_24/mlp.up_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_24/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_24/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_24/mlp.gate_proj/compressed.log
best_loss 484.25213623046875 running bpv: 2.014806
COMMANDS_FINISHED 274 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_24/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_24/self_attn.q_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_24/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_24/self_attn.q_proj is done
reading log  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 275/280 [7:30:32<08:50, 106.16s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 276/280 [7:32:17<07:03, 105.81s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 277/280 [7:32:32<03:55, 78.65s/it]  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 278/280 [7:34:17<02:53, 86.54s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 279/280 [7:36:22<01:38, 98.07s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 280/280 [7:39:32<00:00, 125.62s/it]/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_24/self_attn.q_proj/compressed.log
best_loss 332.7686767578125 running bpv: 2.014823
COMMANDS_FINISHED 275 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_24/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_24/self_attn.k_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_24/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_24/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_24/self_attn.k_proj/compressed.log
best_loss 341.3013916015625 running bpv: 2.01484
COMMANDS_FINISHED 276 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_24/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_24/self_attn.o_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_24/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_24/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_24/mlp.up_proj/compressed.log
best_loss 409.56939697265625 running bpv: 2.01482
COMMANDS_FINISHED 277 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_24/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_24/mlp.down_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_24/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_24/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_24/self_attn.o_proj/compressed.log
best_loss 14.24763011932373 running bpv: 2.014837
COMMANDS_FINISHED 278 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_24/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_24/self_attn.v_proj/compressed.pt --yaml_path tmp/smart-sea-68/yaml.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_24/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_24/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_24/self_attn.v_proj/compressed.log
best_loss 233.6929931640625 running bpv: 2.014854
COMMANDS_FINISHED 279 n_commands 280
meta-llama/Llama-2-13b-hf/layer_24/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_24/mlp.down_proj/compressed.log
best_loss 58.559471130371094 running bpv: 2.014826
COMMANDS_FINISHED 280 n_commands 280
done with meta-llama/Llama-2-13b-hf
done with {'meta-llama/Llama-2-13b-hf/layer_3/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_3/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_3/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_3/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_3/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_3/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_3/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_3/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_3/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_3/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_3/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_3/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_3/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_3/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_5/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_5/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_5/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_5/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_5/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_5/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_5/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_5/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_5/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_5/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_5/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_5/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_8/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_8/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_5/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_5/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_8/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_8/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_8/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_8/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_8/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_8/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_8/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_8/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_8/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_8/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_8/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_8/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_39/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_39/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_39/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_39/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_39/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_39/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_39/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_39/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_39/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_39/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_39/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_39/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_39/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_39/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_12/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_12/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_12/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_12/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_12/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_12/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_12/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_12/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_12/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_12/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_12/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_12/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_1/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_1/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_12/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_12/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_1/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_1/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_1/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_1/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_1/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_1/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_1/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_1/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_1/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_1/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_1/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_1/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_7/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_7/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_7/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_7/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_7/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_7/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_7/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_7/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_7/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_7/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_7/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_7/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_7/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_7/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_33/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_33/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_33/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_33/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_33/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_33/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_33/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_33/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_33/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_33/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_33/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_33/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_33/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_33/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_34/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_34/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_34/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_34/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_34/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_34/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_34/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_34/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_34/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_34/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_34/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_34/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_34/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_34/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_0/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_0/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_0/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_0/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_0/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_0/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_0/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_0/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_0/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_0/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_0/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_0/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_0/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_0/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_32/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_32/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_32/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_32/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_32/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_32/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_32/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_32/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_32/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_32/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_32/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_32/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_32/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_32/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_31/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_31/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_31/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_31/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_31/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_31/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_31/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_31/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_31/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_31/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_31/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_31/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_21/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_21/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_31/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_31/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_21/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_21/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_21/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_21/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_21/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_21/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_21/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_21/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_21/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_21/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_21/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_21/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_26/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_26/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_26/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_26/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_26/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_26/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_26/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_26/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_26/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_26/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_26/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_26/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_26/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_26/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_14/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_14/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_14/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_14/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_14/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_14/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_14/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_14/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_14/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_14/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_14/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_14/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_14/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_14/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_15/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_15/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_15/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_15/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_15/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_15/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_15/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_15/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_15/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_15/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_15/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_15/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_15/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_15/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_4/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_4/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_4/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_4/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_4/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_4/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_4/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_4/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_4/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_4/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_4/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_4/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_4/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_4/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_27/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_27/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_27/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_27/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_27/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_27/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_27/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_27/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_27/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_27/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_27/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_27/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_27/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_27/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_2/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_2/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_2/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_2/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_2/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_2/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_2/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_2/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_2/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_2/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_2/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_2/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_2/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_2/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_36/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_36/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_36/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_36/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_36/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_36/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_36/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_36/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_36/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_36/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_36/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_36/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_36/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_36/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_28/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_28/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_28/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_28/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_28/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_28/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_28/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_28/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_28/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_28/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_28/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_28/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_28/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_28/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_18/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_18/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_18/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_18/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_18/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_18/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_18/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_18/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_18/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_18/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_18/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_18/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_18/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_18/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_25/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_25/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_25/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_25/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_25/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_25/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_25/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_25/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_25/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_25/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_25/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_25/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_25/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_25/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_37/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_37/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_37/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_37/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_37/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_37/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_37/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_37/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_37/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_37/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_37/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_37/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_37/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_37/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_30/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_30/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_30/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_30/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_30/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_30/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_30/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_30/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_30/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_30/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_30/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_30/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_30/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_30/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_29/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_29/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_29/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_29/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_29/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_29/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_29/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_29/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_29/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_29/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_29/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_29/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_16/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_16/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_29/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_29/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_16/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_16/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_16/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_16/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_16/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_16/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_16/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_16/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_16/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_16/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_16/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_16/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_13/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_13/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_13/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_13/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_13/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_13/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_13/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_13/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_13/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_13/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_13/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_13/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_13/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_13/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_10/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_10/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_10/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_10/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_10/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_10/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_10/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_10/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_10/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_10/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_10/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_10/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_10/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_10/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_19/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_19/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_19/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_19/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_19/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_19/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_19/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_19/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_19/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_19/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_19/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_19/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_19/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_19/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_6/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_6/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_6/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_6/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_6/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_6/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_6/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_6/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_6/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_6/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_6/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_6/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_6/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_6/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_11/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_11/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_11/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_11/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_11/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_11/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_11/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_11/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_11/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_11/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_11/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_11/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_11/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_11/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_20/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_20/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_20/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_20/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_20/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_20/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_20/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_20/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_20/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_20/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_20/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_20/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_20/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_20/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_23/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_23/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_23/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_23/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_23/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_23/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_23/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_23/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_23/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_23/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_23/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_23/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_23/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_23/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_35/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_35/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_35/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_35/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_35/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_35/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_35/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_35/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_35/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_35/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_35/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_35/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_35/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_35/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_38/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_38/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_38/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_38/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_38/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_38/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_38/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_38/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_38/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_38/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_38/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_38/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_38/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_38/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_17/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_17/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_17/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_17/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_17/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_17/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_17/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_17/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_17/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_17/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_17/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_17/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_17/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_17/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_9/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_9/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_9/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_9/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_9/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_9/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_9/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_9/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_9/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_9/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_9/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_9/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_9/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_9/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_22/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_22/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_22/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_22/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_22/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_22/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_22/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_22/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_22/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_22/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_22/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_22/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_22/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_22/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_24/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_24/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_24/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_24/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_24/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_24/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_24/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_24/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_24/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_24/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_24/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_24/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_24/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/meta-llama/Llama-2-13b-hf/layer_24/mlp.down_proj/compressed.pt'}
/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/checkpoints.yaml
perplexity_inference_command:
 python -u perplexity_eval.py --base_model meta-llama/Llama-2-13b-hf --seqlen 4096 --checkpoint_list_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/checkpoints.yaml --log_wandb --wandb_project compression_no_finetune --wandb_id deaztxbx
running: nohup python -u perplexity_eval.py --base_model meta-llama/Llama-2-13b-hf --seqlen 4096 --checkpoint_list_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/checkpoints.yaml --log_wandb --wandb_project compression_no_finetune --wandb_id deaztxbx --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/smart-sea-68/ppl_eval.log 2>&1 &
eval is done
dict_keys([])
wandb run_id deaztxbx
wandb_project compression_no_finetune
done
[1;34mwandb[0m: üöÄ View run [33msmart-sea-68[0m at: [34mhttps://wandb.ai/m6481/compression_no_finetune/runs/deaztxbx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250106_011752-deaztxbx/logs[0m
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 280/280 [7:53:58<00:00, 101.56s/it]
