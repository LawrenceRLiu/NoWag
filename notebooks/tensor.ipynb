{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "data = torch.load(\"/data/lliu/huffman/test/weights_hessian.pt\")\n",
    "data.keys()\n",
    "\n",
    "\n",
    "W = data[\"weights\"].to(device)\n",
    "H = data[\"hessian\"].to(device)\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W = torch.randn((4096,14336))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 16, 16] 1 square\n"
     ]
    }
   ],
   "source": [
    "#config\n",
    "\n",
    "N_qubits = 3\n",
    "N_gates = int(sp.special.comb(N_qubits, 2))\n",
    "d_out, d_in = W.shape\n",
    "\n",
    "from sympy import factorint\n",
    "\n",
    "def get_qubit_dimensions(d, N_qubits):\n",
    "\n",
    "    #we assume that d is some power of 2 times \n",
    "\n",
    "\n",
    "\n",
    "    factors_raw = factorint(d)\n",
    "    factors = []\n",
    "    for k, v in factors_raw.items():\n",
    "        factors += [k]*v\n",
    "    factors = sorted(factors, reverse=True)\n",
    "    # print(factors)\n",
    "    dimensions = [1]*N_qubits\n",
    "    i1= 0\n",
    "    i2 = len(factors)-1\n",
    "    \n",
    "    i = 0\n",
    "    while i1 <= i2:\n",
    "        if i % (N_qubits*2) < N_qubits:\n",
    "            dimensions[i % N_qubits] *= factors[i]\n",
    "            i1 += 1\n",
    "        else:\n",
    "            dimensions[i % N_qubits] *= factors[i]\n",
    "            i2 -= 1\n",
    "        i += 1\n",
    "    # print(dimensions)\n",
    "    assert np.prod(dimensions) == d\n",
    "    return dimensions\n",
    "\n",
    "if d_in > d_out:\n",
    "    layer_type = \"compress\"\n",
    "    qubit_dimensions = get_qubit_dimensions(d_out, N_qubits)\n",
    "    k_factor = int(d_in/(np.prod(qubit_dimensions[1:]))) \n",
    "    assert d_in == k_factor*np.prod(qubit_dimensions[1:])\n",
    "elif d_in < d_out:\n",
    "    layer_type = \"expand\"\n",
    "    qubit_dimensions = get_qubit_dimensions(d_in, N_qubits)\n",
    "    k_factor = int(d_out/(np.prod(qubit_dimensions[1:]))) \n",
    "    assert d_out == k_factor*np.prod(qubit_dimensions[1:])\n",
    "else:\n",
    "    layer_type = \"square\"\n",
    "    qubit_dimensions = get_qubit_dimensions(d_in, N_qubits)\n",
    "    k_factor = 1\n",
    "\n",
    "\n",
    "print(qubit_dimensions, k_factor, layer_type)\n",
    "# qubit_dimensions = [2**int(np.log2(d**(1/N_qubits)))]*N_qubits\n",
    "# print(qubit_dimensions)\n",
    "# print(d/np.prod(qubit_dimensions))\n",
    "# qubit_dimensions[0] *= int(d/np.prod(qubit_dimensions))\n",
    "# assert np.prod(qubit_dimensions) == d\n",
    "# print(qubit_dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'...abc,efbc,diaf,ghde->...ghi'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "import opt_einsum as oe\n",
    "def quanta_apply_einsum_expr(N):\n",
    "    current_symbols_inds = list(range(N))\n",
    "    expr = \"...\"\n",
    "    for i in current_symbols_inds:\n",
    "        expr += oe.get_symbol(i)\n",
    "    for (dim1, dim2) in itertools.combinations(range(-1, -N-1, -1), 2):\n",
    "        symbol_ind1 = current_symbols_inds[dim1]\n",
    "        symbol_ind2 = current_symbols_inds[dim2]\n",
    "        symbol_ind3 = symbol_ind1 + N\n",
    "        symbol_ind4 = symbol_ind2 + N\n",
    "        expr += \",\" + \\\n",
    "            oe.get_symbol(symbol_ind4) + \\\n",
    "            oe.get_symbol(symbol_ind3) + \\\n",
    "            oe.get_symbol(symbol_ind2) + \\\n",
    "            oe.get_symbol(symbol_ind1)\n",
    "        current_symbols_inds[dim1] = symbol_ind3\n",
    "        current_symbols_inds[dim2] = symbol_ind4\n",
    "    expr += \"->...\"\n",
    "    for i in current_symbols_inds:\n",
    "        expr += oe.get_symbol(i)\n",
    "    return expr\n",
    "\n",
    "def quanta_op_einsum_expr(N):\n",
    "    apply_expression = quanta_apply_einsum_expr(N)\n",
    "    initial_term = apply_expression.split(\",\")[0].split(\"...\")[-1]\n",
    "    final_term = apply_expression.split(\"->\")[-1].split(\"...\")[-1]\n",
    "    middle_terms = apply_expression[apply_expression.find(\",\")+1:apply_expression.find(\"->\")]\n",
    "    return f\"{middle_terms}->{final_term}{initial_term}\"   \n",
    "\n",
    "quanta_apply_einsum_expr(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efbc,diaf,ghde->ghiabc\n"
     ]
    }
   ],
   "source": [
    "einsum_expr = quanta_op_einsum_expr(N_qubits)\n",
    "print(einsum_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_0 = torch.linalg.norm(W,dim = 0)\n",
    "W_normalized = W/norm_0.unsqueeze(0)\n",
    "\n",
    "norm_1 = torch.linalg.norm(W_normalized,dim = 1)\n",
    "W_normalized = W_normalized/norm_1.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gate 3 torch.Size([16, 16, 16, 16]), -2, -1\n",
      "gate 2 torch.Size([16, 16, 16, 16]), -3, -1\n",
      "gate 1 torch.Size([16, 16, 16, 16]), -3, -2\n",
      "196608 reduction: 1.17%, bpv 0.1875\n"
     ]
    }
   ],
   "source": [
    "def initialize_gates(N,qubit_dimensions, layer_type, k_factor, W):\n",
    "    gates = []\n",
    "    i = len(qubit_dimensions)\n",
    "    for (dim2,dim1, ) in itertools.combinations(range(-1, -N-1, -1), 2):\n",
    "        if dim1 == -N and dim2 == -1 and layer_type == \"compress\":\n",
    "            new_gate = torch.randn(qubit_dimensions[dim1], qubit_dimensions[dim2], k_factor, qubit_dimensions[dim2]).to(device) * \\\n",
    "                torch.mean(torch.abs(W))**(1/N)/(qubit_dimensions[dim1]*qubit_dimensions[dim2]*k_factor*qubit_dimensions[dim2])**0.25\n",
    "        elif dim1 == -N and dim2 == -N + 1 and layer_type == \"expand\":\n",
    "            new_gate = torch.randn(k_factor, qubit_dimensions[dim2], qubit_dimensions[dim1], qubit_dimensions[dim1]).to(device) * \\\n",
    "                torch.mean(torch.abs(W))**(1/N)/(qubit_dimensions[dim1]*qubit_dimensions[dim2]*k_factor*qubit_dimensions[dim1])**0.25\n",
    "        \n",
    "        else:\n",
    "            new_gate = torch.randn(qubit_dimensions[dim1], qubit_dimensions[dim2], qubit_dimensions[dim1], qubit_dimensions[dim2]).to(device) * \\\n",
    "                    torch.mean(torch.abs(W))**(1/N)/np.sqrt(qubit_dimensions[dim1]*qubit_dimensions[dim2])\n",
    "        gates.append(new_gate)\n",
    "        print(f\"gate {i} {new_gate.shape}, {dim1}, {dim2}\")\n",
    "        i -=1\n",
    "    return gates\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "gates = initialize_gates(N_qubits, qubit_dimensions, layer_type, k_factor, W)\n",
    "\n",
    "n_params = sum([gate.numel() for gate in gates])    \n",
    "print(f\"{n_params} reduction: {round(n_params/W.numel()*100, 2)}%, bpv {n_params*16/W.numel()}\")\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'square'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'...abc,efbc,diaf,ghde->...ghi'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quanta_apply_einsum_expr(N_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'efbc,diaf,ghde->ghiabc'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "einsum_expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([16, 16, 16, 16]), torch.Size([16, 16, 16, 16]), torch.Size([16, 16, 16, 16])]\n"
     ]
    }
   ],
   "source": [
    "print([gate.shape for gate in gates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 16, 16, 16, 16, 16])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum(einsum_expr, *gates).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5607e-04, -1.6371e-04,  3.5334e-05,  ...,  5.0662e-05,\n",
       "          9.9145e-05,  4.0820e-05],\n",
       "        [-2.7871e-06,  8.6832e-05,  1.2173e-04,  ...,  4.9204e-05,\n",
       "         -2.3000e-05,  1.8864e-05],\n",
       "        [-5.8679e-06, -1.3685e-04, -4.1683e-05,  ..., -2.3557e-05,\n",
       "         -1.6948e-05,  1.4832e-04],\n",
       "        ...,\n",
       "        [-6.3560e-05,  5.2123e-05, -1.1675e-04,  ...,  1.1046e-04,\n",
       "         -1.4163e-07,  4.5130e-05],\n",
       "        [-3.0893e-05,  1.7756e-04, -9.4706e-05,  ..., -3.1393e-05,\n",
       "          1.2467e-05, -7.9110e-05],\n",
       "        [-9.9574e-05, -3.4550e-05, -2.1916e-04,  ...,  1.2618e-04,\n",
       "         -2.4452e-04, -4.1142e-05]], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum(einsum_expr, *gates).reshape(W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_0 = nn.Parameter(norm_0, requires_grad = False)\n",
    "norm_1 = nn.Parameter(norm_1, requires_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_top = 0.00\n",
    "if keep_top > 0:\n",
    "    \n",
    "    threshold = torch.quantile(torch.concat([norm_0, norm_1]), 1-keep_top)\n",
    "    print(threshold)\n",
    "\n",
    "    mask_0 = norm_0 > threshold\n",
    "    mask_1 = norm_1 > threshold\n",
    "\n",
    "\n",
    "    W_sparse_0 = W_normalized[:,mask_0]\n",
    "    W_sparse_1 = W_normalized[mask_1,:]\n",
    "\n",
    "    print((W_sparse_0.numel() + W_sparse_1.numel())/W.numel()*16)\n",
    "\n",
    "    W_sparse_0 = nn.Parameter(W_sparse_0, requires_grad = True)\n",
    "    W_sparse_1 = nn.Parameter(W_sparse_1, requires_grad = True)\n",
    "\n",
    "else:\n",
    "\n",
    "    mask_0 = torch.zeros_like(norm_0, dtype = torch.bool)\n",
    "    mask_1 = torch.zeros_like(norm_1, dtype = torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1953125\n"
     ]
    }
   ],
   "source": [
    "total_parameters = sum([gate.numel() for gate in gates]) + norm_0.numel() + norm_1.numel() + ((W_sparse_0.numel() + W_sparse_1.numel()) if keep_top > 0 else 0)\n",
    "print(total_parameters*16/W.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0, average_error 1.0000265836715698, H_error 5312.076171875, lr 0.01\n",
      "iter 100, average_error 1.8040425777435303, H_error 21.460651397705078, lr 0.01\n",
      "iter 200, average_error 1.6660512685775757, H_error 13.505017280578613, lr 0.01\n",
      "iter 300, average_error 1.5730483531951904, H_error 11.725496292114258, lr 0.01\n",
      "iter 400, average_error 1.522792100906372, H_error 10.231886863708496, lr 0.01\n",
      "iter 500, average_error 1.4972412586212158, H_error 9.210708618164062, lr 0.01\n",
      "iter 600, average_error 1.4829257726669312, H_error 15.025548934936523, lr 0.01\n",
      "iter 700, average_error 1.475117802619934, H_error 8.436769485473633, lr 0.01\n",
      "iter 800, average_error 1.4583978652954102, H_error 8.238386154174805, lr 0.01\n",
      "iter 900, average_error 1.4478546380996704, H_error 6.850631237030029, lr 0.003333333333333333\n",
      "iter 1000, average_error 1.4392722845077515, H_error 6.0877909660339355, lr 0.001111111111111111\n",
      "iter 1100, average_error 1.4306544065475464, H_error 5.775102138519287, lr 0.001111111111111111\n",
      "iter 1200, average_error 1.4235215187072754, H_error 5.670886993408203, lr 0.001111111111111111\n",
      "iter 1300, average_error 1.4171572923660278, H_error 5.569825649261475, lr 0.001111111111111111\n",
      "iter 1400, average_error 1.411278247833252, H_error 5.4741339683532715, lr 0.001111111111111111\n",
      "iter 1500, average_error 1.4057403802871704, H_error 5.387725830078125, lr 0.001111111111111111\n",
      "iter 1600, average_error 1.402613878250122, H_error 5.3904523849487305, lr 0.001111111111111111\n",
      "iter 1700, average_error 1.3991920948028564, H_error 5.207042217254639, lr 0.0003703703703703703\n",
      "iter 1800, average_error 1.3940746784210205, H_error 5.141272068023682, lr 0.0003703703703703703\n",
      "iter 1900, average_error 1.3912245035171509, H_error 5.089601516723633, lr 0.0003703703703703703\n",
      "iter 2000, average_error 1.3882946968078613, H_error 5.041293144226074, lr 0.0003703703703703703\n",
      "iter 2100, average_error 1.3853633403778076, H_error 4.994609355926514, lr 0.0003703703703703703\n",
      "iter 2200, average_error 1.3824214935302734, H_error 4.947269916534424, lr 0.0003703703703703703\n",
      "iter 2300, average_error 1.3798933029174805, H_error 4.911514759063721, lr 0.0003703703703703703\n",
      "iter 2400, average_error 1.3779464960098267, H_error 4.874842166900635, lr 0.0003703703703703703\n",
      "iter 2500, average_error 1.3759175539016724, H_error 4.840229511260986, lr 0.0003703703703703703\n",
      "iter 2600, average_error 1.37388014793396, H_error 4.806124687194824, lr 0.0003703703703703703\n",
      "iter 2700, average_error 1.3718618154525757, H_error 4.772767066955566, lr 0.0003703703703703703\n",
      "iter 2800, average_error 1.3701773881912231, H_error 4.7459001541137695, lr 0.0003703703703703703\n",
      "iter 2900, average_error 1.3687934875488281, H_error 4.728242874145508, lr 0.0003703703703703703\n",
      "iter 3000, average_error 1.3674184083938599, H_error 4.702845096588135, lr 0.0003703703703703703\n",
      "iter 3100, average_error 1.36595618724823, H_error 4.677036762237549, lr 0.0003703703703703703\n",
      "iter 3200, average_error 1.3648173809051514, H_error 4.65647554397583, lr 0.0003703703703703703\n",
      "iter 3300, average_error 1.363825798034668, H_error 4.638957977294922, lr 0.0003703703703703703\n",
      "iter 3400, average_error 1.3627597093582153, H_error 4.620477199554443, lr 0.0003703703703703703\n",
      "iter 3500, average_error 1.3616719245910645, H_error 4.601324081420898, lr 0.0003703703703703703\n",
      "iter 3600, average_error 1.3605766296386719, H_error 4.582718849182129, lr 0.0003703703703703703\n",
      "iter 3700, average_error 1.3594757318496704, H_error 4.565450191497803, lr 0.0003703703703703703\n",
      "iter 3800, average_error 1.3583943843841553, H_error 4.58465051651001, lr 0.0003703703703703703\n",
      "iter 3900, average_error 1.3578826189041138, H_error 4.527212142944336, lr 0.00012345679012345677\n",
      "iter 4000, average_error 1.3569833040237427, H_error 4.5062103271484375, lr 0.00012345679012345677\n",
      "iter 4100, average_error 1.3558531999588013, H_error 4.487680435180664, lr 0.00012345679012345677\n",
      "iter 4200, average_error 1.355122447013855, H_error 4.473989009857178, lr 0.00012345679012345677\n",
      "iter 4300, average_error 1.3543601036071777, H_error 4.460352420806885, lr 0.00012345679012345677\n",
      "iter 4400, average_error 1.3535661697387695, H_error 4.446073055267334, lr 0.00012345679012345677\n",
      "iter 4500, average_error 1.3527429103851318, H_error 4.431411266326904, lr 0.00012345679012345677\n",
      "iter 4600, average_error 1.3518905639648438, H_error 4.416229248046875, lr 0.00012345679012345677\n",
      "iter 4700, average_error 1.3511686325073242, H_error 4.4038238525390625, lr 0.00012345679012345677\n",
      "iter 4800, average_error 1.3505887985229492, H_error 4.393435478210449, lr 0.00012345679012345677\n",
      "iter 4900, average_error 1.3499640226364136, H_error 4.38210391998291, lr 0.00012345679012345677\n",
      "iter 5000, average_error 1.3492995500564575, H_error 4.370111465454102, lr 0.00012345679012345677\n",
      "iter 5100, average_error 1.3486073017120361, H_error 4.357578754425049, lr 0.00012345679012345677\n",
      "iter 5200, average_error 1.3479878902435303, H_error 4.346762657165527, lr 0.00012345679012345677\n",
      "iter 5300, average_error 1.347451090812683, H_error 4.337491035461426, lr 0.00012345679012345677\n",
      "iter 5400, average_error 1.346878170967102, H_error 4.326867580413818, lr 0.00012345679012345677\n",
      "iter 5500, average_error 1.3462716341018677, H_error 4.315755844116211, lr 0.00012345679012345677\n",
      "iter 5600, average_error 1.3456408977508545, H_error 4.303937911987305, lr 0.00012345679012345677\n",
      "iter 5700, average_error 1.345210075378418, H_error 4.297170639038086, lr 0.00012345679012345677\n",
      "iter 5800, average_error 1.3447699546813965, H_error 4.288958549499512, lr 0.00012345679012345677\n",
      "iter 5900, average_error 1.3443067073822021, H_error 4.280361175537109, lr 0.00012345679012345677\n",
      "iter 6000, average_error 1.343819260597229, H_error 4.27125883102417, lr 0.00012345679012345677\n",
      "iter 6100, average_error 1.3433152437210083, H_error 4.261949062347412, lr 0.00012345679012345677\n",
      "iter 6200, average_error 1.342915654182434, H_error 4.253750801086426, lr 0.00012345679012345677\n",
      "iter 6300, average_error 1.3425184488296509, H_error 4.246454238891602, lr 0.00012345679012345677\n",
      "iter 6400, average_error 1.3421303033828735, H_error 4.240161895751953, lr 0.00012345679012345677\n",
      "iter 6500, average_error 1.3417694568634033, H_error 4.233089923858643, lr 0.00012345679012345677\n",
      "iter 6600, average_error 1.3413878679275513, H_error 4.225846767425537, lr 0.00012345679012345677\n",
      "iter 6700, average_error 1.3409889936447144, H_error 4.218282222747803, lr 0.00012345679012345677\n",
      "iter 6800, average_error 1.3405765295028687, H_error 4.2104949951171875, lr 0.00012345679012345677\n",
      "iter 6900, average_error 1.3401563167572021, H_error 4.209517955780029, lr 0.00012345679012345677\n",
      "iter 7000, average_error 1.33985435962677, H_error 4.1984639167785645, lr 0.00012345679012345677\n",
      "iter 7100, average_error 1.3395638465881348, H_error 4.1923828125, lr 0.00012345679012345677\n",
      "iter 7200, average_error 1.3392471075057983, H_error 4.186250686645508, lr 0.00012345679012345677\n",
      "iter 7300, average_error 1.338918924331665, H_error 4.179873943328857, lr 0.00012345679012345677\n",
      "iter 7400, average_error 1.3385759592056274, H_error 4.173277378082275, lr 0.00012345679012345677\n",
      "iter 7500, average_error 1.338221549987793, H_error 4.166681289672852, lr 0.00012345679012345677\n",
      "iter 7600, average_error 1.33785879611969, H_error 4.159982204437256, lr 0.00012345679012345677\n",
      "iter 7700, average_error 1.3375890254974365, H_error 4.15534782409668, lr 0.00012345679012345677\n",
      "iter 7800, average_error 1.3372902870178223, H_error 4.150132656097412, lr 0.00012345679012345677\n",
      "iter 7900, average_error 1.3370176553726196, H_error 4.1449713706970215, lr 0.00012345679012345677\n",
      "iter 8000, average_error 1.3367189168930054, H_error 4.139225482940674, lr 0.00012345679012345677\n",
      "iter 8100, average_error 1.3364055156707764, H_error 4.133363723754883, lr 0.00012345679012345677\n",
      "iter 8200, average_error 1.3360799551010132, H_error 4.127176284790039, lr 0.00012345679012345677\n",
      "iter 8300, average_error 1.3357428312301636, H_error 4.120810508728027, lr 0.00012345679012345677\n",
      "iter 8400, average_error 1.3354034423828125, H_error 4.1242756843566895, lr 0.00012345679012345677\n",
      "iter 8500, average_error 1.3351768255233765, H_error 4.110585689544678, lr 0.00012345679012345677\n",
      "iter 8600, average_error 1.3349356651306152, H_error 4.106673240661621, lr 0.00012345679012345677\n",
      "iter 8700, average_error 1.3346774578094482, H_error 4.101311683654785, lr 0.00012345679012345677\n",
      "iter 8800, average_error 1.3344007730484009, H_error 4.0959153175354, lr 0.00012345679012345677\n",
      "iter 8900, average_error 1.3341119289398193, H_error 4.090397834777832, lr 0.00012345679012345677\n",
      "iter 9000, average_error 1.3338130712509155, H_error 4.084820747375488, lr 0.00012345679012345677\n",
      "iter 9100, average_error 1.3335049152374268, H_error 4.079128742218018, lr 0.00012345679012345677\n",
      "iter 9200, average_error 1.3332760334014893, H_error 4.07511043548584, lr 0.00012345679012345677\n",
      "iter 9300, average_error 1.3330342769622803, H_error 4.070683002471924, lr 0.00012345679012345677\n",
      "iter 9400, average_error 1.3327699899673462, H_error 4.065670490264893, lr 0.00012345679012345677\n",
      "iter 9500, average_error 1.332492709159851, H_error 4.0605149269104, lr 0.00012345679012345677\n",
      "iter 9600, average_error 1.3322250843048096, H_error 4.057745933532715, lr 0.00012345679012345677\n",
      "iter 9700, average_error 1.3319957256317139, H_error 4.051444053649902, lr 0.00012345679012345677\n",
      "iter 9800, average_error 1.331749439239502, H_error 4.0467095375061035, lr 0.00012345679012345677\n",
      "iter 9900, average_error 1.3314876556396484, H_error 4.041916370391846, lr 0.00012345679012345677\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD4CAYAAADrRI2NAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAUoElEQVR4nO3df4yd113n8fd3ZmLHSRMaN+OssV0cJLe7SaA/Mso6FK1KQ2tTuiRabbQuKjFSkKUQoLAgZC9/LJWwtqAVqiKa7EalxNlCgxfKxpuSpVm3FUKEuBOa1nEcY0PSeLA3nhTaGtr8sP3dP+5xemfuMzN3xvPL53m/pKv73O99zp1znPjjM+c5997ITCRJ7TGw1B2QJC0ug1+SWsbgl6SWMfglqWUMfklqmaGl7sBMrr766ty4ceNSd0OSLipPPvnkS5k53PTcsg/+jRs3Mjo6utTdkKSLSkR8barnXOqRpJYx+CWpZQx+SWoZg1+SWsbgl6SWMfglqWUMfklqmWqDf89fPs///sqJpe6GJC071Qb/p/7qazz69Mml7oYkLTvVBj+A3zEjSb2qDf4Ig1+SmtQb/MRSd0GSlqVqgx8gccovSZNVG/wu9UhSs2qDX5LUrOrgd8IvSb2qDf6IcKlHkhr0FfwR8XxEHIyIpyJitNRWR8RjEXG03F/Vdf6uiDgWEUciYktX/cbyOsci4p6IWLCtN+7pkaRms5nx/0hmvj0zR8rjncD+zNwE7C+PiYjrgG3A9cBW4N6IGCxt7gN2AJvKbeuFD2E6TvklabILWeq5FdhTjvcAt3XVH8rMVzLzOeAYcFNErAWuzMzHMzOBB7vazDt39UhSs36DP4HPRcSTEbGj1K7JzJMA5X5Nqa8Djne1HSu1deV4cr1HROyIiNGIGB0fH++zi5NfY07NJKl6Q32e967MPBERa4DHIuLZac5titycpt5bzLwfuB9gZGRkzvN2J/yS1KuvGX9mnij3p4A/AW4CXizLN5T7U+X0MWBDV/P1wIlSX99QXxBBkK71SFKPGYM/Ii6PiCvOHwPvA54G9gHby2nbgYfL8T5gW0SsjIhr6VzEPVCWg05HxOaym+eOrjbzzqUeSWrWz1LPNcCflJ2XQ8AfZOb/iYgvAXsj4k7gBeB2gMw8FBF7gWeAM8DdmXm2vNZdwAPAKuDRclswzvclqdeMwZ+Zfwe8raH+deCWKdrsBnY31EeBG2bfzdkL3NUjSU2qfeeuaz2S1Kze4MelHklqUm3wd5Z6jH5Jmqze4HelR5IaVRv8kqRm1Qa/u3okqVm9we9ajyQ1qjb4JUnNDH5Japmqgz/dyS9JPaoNflf4JalZtcEvSWpm8EtSy1Qd/O7jl6Re1Qa/2/glqVm1wS9JambwS1LLVB38rvFLUq9qgz/cyS9JjaoNfklSM4Nfklqm6uD3s3okqVe9we8SvyQ1qjf4JUmNDH5Japmqg999/JLUq9rgd4lfkppVG/ySpGZ9B39EDEbElyPikfJ4dUQ8FhFHy/1VXefuiohjEXEkIrZ01W+MiIPluXsi/AxNSVpss5nxfxg43PV4J7A/MzcB+8tjIuI6YBtwPbAVuDciBkub+4AdwKZy23pBvZ+BS/yS1Kuv4I+I9cCPA5/oKt8K7CnHe4DbuuoPZeYrmfkccAy4KSLWAldm5uOZmcCDXW3mnb9LSFKzfmf8HwN+FTjXVbsmM08ClPs1pb4OON513liprSvHk+s9ImJHRIxGxOj4+HifXZQk9WPG4I+IDwCnMvPJPl+zaa6d09R7i5n3Z+ZIZo4MDw/3+WMlSf0Y6uOcdwE/ERHvBy4FroyITwEvRsTazDxZlnFOlfPHgA1d7dcDJ0p9fUN94bjIL0k9ZpzxZ+auzFyfmRvpXLT9fGZ+CNgHbC+nbQceLsf7gG0RsTIirqVzEfdAWQ46HRGby26eO7razDs/j1+SmvUz45/KR4G9EXEn8AJwO0BmHoqIvcAzwBng7sw8W9rcBTwArAIeLTdJ0iKaVfBn5heBL5bjrwO3THHebmB3Q30UuGG2nZQkzZ+q37nr5/FLUq9qg999/JLUrNrglyQ1M/glqWWqDn4/j1+SelUb/K7xS1KzaoNfktTM4Jeklqk6+F3il6Re1Qa/n9UjSc2qDX5JUjODX5JapurgTzfyS1KPaoPfffyS1Kza4JckNTP4Jallqg5+V/glqVfVwS9J6mXwS1LLGPyS1DJVB7/b+CWpV7XBH27kl6RG1Qa/JKmZwS9JLVN18LvEL0m9qg1+V/glqVm1wS9JambwS1LLzBj8EXFpRByIiK9ExKGI+Eipr46IxyLiaLm/qqvNrog4FhFHImJLV/3GiDhYnrsnFnrPpRv5JalHPzP+V4D3ZObbgLcDWyNiM7AT2J+Zm4D95TERcR2wDbge2ArcGxGD5bXuA3YAm8pt6/wNZSK38UtSsxmDPzv+qTy8pNwSuBXYU+p7gNvK8a3AQ5n5SmY+BxwDboqItcCVmfl4dr4a68GuNpKkRdLXGn9EDEbEU8Ap4LHMfAK4JjNPApT7NeX0dcDxruZjpbauHE+uN/28HRExGhGj4+PjsxiOJGkmfQV/Zp7NzLcD6+nM3m+Y5vSmRZacpt708+7PzJHMHBkeHu6ni5KkPs1qV09mfgP4Ip21+RfL8g3l/lQ5bQzY0NVsPXCi1Nc31BeMl3YlqVc/u3qGI+KN5XgV8KPAs8A+YHs5bTvwcDneB2yLiJURcS2di7gHynLQ6YjYXHbz3NHVZt55bVeSmg31cc5aYE/ZmTMA7M3MRyLicWBvRNwJvADcDpCZhyJiL/AMcAa4OzPPlte6C3gAWAU8Wm6SpEU0Y/Bn5leBdzTUvw7cMkWb3cDuhvooMN31AUnSAqv6nbu+f0uSelUb/H4RiyQ1qzb4JUnNDH5Japmqgz/dyS9JPaoNflf4JalZP/v4L0r7nz0180mS1ELVzvglSc0MfklqGYNfklrG4JekljH4JallDH5JahmDX5JaxuCXpJYx+CWpZQx+SWoZg1+SWsbgl6SWMfglqWUMfklqGYNfklrG4JekljH4JallDH5Japlqg/9Dm9/Mmy5fsdTdkKRlp9rgB8il7oAkLUPVBn8QS90FSVqWZgz+iNgQEV+IiMMRcSgiPlzqqyPisYg4Wu6v6mqzKyKORcSRiNjSVb8xIg6W5+6JCNNZkhZZPzP+M8AvZ+a/AjYDd0fEdcBOYH9mbgL2l8eU57YB1wNbgXsjYrC81n3ADmBTuW2dx7H0yHSxR5ImmzH4M/NkZv51OT4NHAbWAbcCe8ppe4DbyvGtwEOZ+UpmPgccA26KiLXAlZn5eHYS+cGuNvPO3yUkqdms1vgjYiPwDuAJ4JrMPAmdfxyANeW0dcDxrmZjpbauHE+uLxjn+5LUq+/gj4g3AH8M/GJmfmu6UxtqOU296WftiIjRiBgdHx/vt4szdkKS1GfwR8QldEL/9zPzM6X8Ylm+odyfKvUxYENX8/XAiVJf31DvkZn3Z+ZIZo4MDw/3O5aG15lzU0mqVj+7egL4XeBwZv5211P7gO3leDvwcFd9W0SsjIhr6VzEPVCWg05HxObymnd0tZl3bhiSpGZDfZzzLuCngIMR8VSp/Sfgo8DeiLgTeAG4HSAzD0XEXuAZOjuC7s7Ms6XdXcADwCrg0XJbMO7qkaReMwZ/Zv4FUy+Z3zJFm93A7ob6KHDDbDooSZpf1b5zF9zVI0lNqg1+l/glqVm1wS9JalZ38LvWI0k9qg1+P51TkppVG/zghF+SmlQb/F7claRm1QY/+AYuSWpSbfA74ZekZtUGP7jGL0lNqg1+1/glqVm1wQ9+LLMkNak2+P1YZklqVm3wS5KaVR386eVdSepRbfC70CNJzaoNfvDiriQ1qTf4nfJLUqN6gx/fwCVJTaoNfj+WWZKaVRv8gFN+SWpQbfBHuJ1TkppUG/wD4a4eSWpSbfAHwTmTX5J6VBv8A+ESvyQ1qTb4I4JMv4VLkiarOPg79+a+JE1UbfAPlOQ39yVpomqD//zbt7zAK0kTzRj8EfHJiDgVEU931VZHxGMRcbTcX9X13K6IOBYRRyJiS1f9xog4WJ67Jxb4m1IGBsqM39yXpAn6mfE/AGydVNsJ7M/MTcD+8piIuA7YBlxf2twbEYOlzX3ADmBTuU1+zXl1/p8VZ/ySNNGMwZ+Zfw78w6TyrcCecrwHuK2r/lBmvpKZzwHHgJsiYi1wZWY+np1tNg92tVkQ5z+rx9yXpInmusZ/TWaeBCj3a0p9HXC867yxUltXjifXG0XEjogYjYjR8fHxOXVw4PyuHi/vStIE831xt2ndPqepN8rM+zNzJDNHhoeH59aR15d65tRckqo11+B/sSzfUO5PlfoYsKHrvPXAiVJf31BfMK9v53StR5ImmGvw7wO2l+PtwMNd9W0RsTIirqVzEfdAWQ46HRGby26eO7raLChn/JI00dBMJ0TEp4F3A1dHxBjwn4GPAnsj4k7gBeB2gMw8FBF7gWeAM8DdmXm2vNRddHYIrQIeLbcF44xfkprNGPyZ+cEpnrplivN3A7sb6qPADbPq3QUY8CMbJKlRve/cLTN+9/FL0kTVBv93t3NKkrpVG/w445ekRtUG//kZv1N+SZqo4uA/P+Nf4o5I0jJTbfD7scyS1Kza4PeLWCSpWbXB//pn9bjWI0kTVBv8gwPu6pGkJtUH/xln/JI0QfXB71KPJE1Ub/CHM35JalJv8JcZ/1mDX5ImMPglqWXqD3539UjSBPUHvzN+SZrA4Jeklqk3+MPgl6Qm9Qa/M35JamTwS1LLGPyS1DLVBv+Koc7QXj17bol7IknLS7XBf9klQwB8+9WzS9wTSVpeqg3+VSsGAfjOq2eWuCeStLxUG/yXleB3xi9JE1Ub/Ksu6QT/Pxv8kjRBtcE/MBCsvnwF46dfXuquSNKyUm3wA2x802U8/9K3l7obkrSsLHrwR8TWiDgSEcciYudC/qxNa67gK2Pf4PTLr/HxLxzjOy77SBKRi/ixxRExCPwN8F5gDPgS8MHMfGaqNiMjIzk6Ojqnn7f/8Ivcuae37cd/8p18+KEv80vvfQsA737rMMNvWMnZTL71nTP8xbGX+LdvW8t3Xj3Lpw8c58VvvcxP/9BGnjr+Df7dO9fxyFdP8oEfXMvgQPDya+dYffmKOfVPkhZKRDyZmSONzy1y8N8M/HpmbimPdwFk5n+Zqs2FBH9m8gO//jn+6ZWF3dJ5yWCwcmiQCBiIYKDcRwTls+JKfyb0boo6DA0GA6VhV3Oi+8XmyWxeclbn0v/Js3vdWZw7ixee/z/ZBXIRdPQi6CKwMH+f5ttnf+GHWTk0OKe20wX/0AX1avbWAce7Ho8B/3rySRGxA9gB8OY3v3nOPywiePojW3j1zDn+8duv8vJrZ/n4F47xlmuu4Dc+exiA/zCygX/xPZeyasUglw4N8OdHX+Lzz57iV973Fj72f49y5lyy8U2XMXzFSr70/D/y4z+wls8ePMnOH/uXHBz7JodOfJN3v3UNgwPBuUwy4VxmuXX+8en+q9D9/9rEUO/cZ3Y+ZuL8a53X7z/Ps/l3PPt+1Vl0YHanMpuJx+xedxbnzuJ1l9JiTtLmavn3sLhIOjqbCdSsXneRZ/y3A1sy82fK458CbsrMn5+qzYXM+CWpraab8S/2xd0xYEPX4/XAiUXugyS12mIH/5eATRFxbUSsALYB+xa5D5LUaou6xp+ZZyLi54A/AwaBT2bmocXsgyS13WJf3CUz/xT408X+uZKkjqrfuStJ6mXwS1LLGPyS1DIGvyS1zKK+gWsuImIc+Nocm18NvDSP3bkYOOZ2aNuY2zZeuPAxf19mDjc9seyD/0JExOhU71yrlWNuh7aNuW3jhYUds0s9ktQyBr8ktUztwX//UndgCTjmdmjbmNs2XljAMVe9xi9J6lX7jF+SNInBL0ktU2XwL+YXui+0iNgQEV+IiMMRcSgiPlzqqyPisYg4Wu6v6mqzq4z9SERs6arfGBEHy3P3xDL+7rmIGIyIL0fEI+Vx1eMFiIg3RsQfRcSz5b/3zTWPOyJ+qfw//XREfDoiLq1tvBHxyYg4FRFPd9XmbYwRsTIi/rDUn4iIjX11LDOrutH5uOe/Bb4fWAF8Bbhuqft1AeNZC7yzHF9B58vqrwN+C9hZ6juB3yzH15UxrwSuLX8Wg+W5A8DNdL718VHgx5Z6fNOM+z8CfwA8Uh5XPd7S3z3Az5TjFcAbax03na9hfQ5YVR7vBX66tvEC/wZ4J/B0V23exgj8LPDfyvE24A/76tdS/8EswB/0zcCfdT3eBexa6n7N4/geBt4LHAHWltpa4EjTeOl898HN5Zxnu+ofBP77Uo9nijGuB/YD7+G7wV/teEv/rixBGJPqVY6b737/9mo6Hw//CPC+GscLbJwU/PM2xvPnlOMhOu/0jZn6VONST9MXuq9bor7Mq/Jr3DuAJ4BrMvMkQLlfU06bavzryvHk+nL0MeBXgXNdtZrHC53fUMeB3ytLXJ+IiMupdNyZ+ffAfwVeAE4C38zMz1HpeCeZzzG+3iYzzwDfBN40UwdqDP6m9b2Lfs9qRLwB+GPgFzPzW9Od2lDLaerLSkR8ADiVmU/226ShdtGMt8sQnSWB+zLzHcA/01kGmMpFPe6yrn0rnSWN7wUuj4gPTdekoXbRjLdPcxnjnMZfY/BX94XuEXEJndD//cz8TCm/GBFry/NrgVOlPtX4x8rx5Ppy8y7gJyLieeAh4D0R8SnqHe95Y8BYZj5RHv8RnX8Iah33jwLPZeZ4Zr4GfAb4Ieodb7f5HOPrbSJiCPge4B9m6kCNwV/VF7qXq/e/CxzOzN/uemofsL0cb6ez9n++vq1c7b8W2AQcKL9Sno6IzeU17+hqs2xk5q7MXJ+ZG+n8t/t8Zn6ISsd7Xmb+P+B4RLy1lG4BnqHecb8AbI6Iy0o/bwEOU+94u83nGLtf69/T+fsy8288S33hY4Eupryfzu6XvwV+ban7c4Fj+WE6v7p9FXiq3N5PZx1vP3C03K/uavNrZexH6NrhAIwAT5fnfoc+LgIt8djfzXcv7rZhvG8HRst/6/8FXFXzuIGPAM+Wvv4POrtZqhov8Gk61zBeozM7v3M+xwhcCvxP4BidnT/f30+//MgGSWqZGpd6JEnTMPglqWUMfklqGYNfklrG4JekljH4JallDH5Japn/DxGhgC9k1IGGAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gates = [nn.Parameter(gate) for gate in gates]\n",
    "parameters = nn.ParameterList([norm_0, norm_1] + gates + ([W_sparse_0, W_sparse_1] if torch.any(mask_0) or torch.any(mask_1) else []))\n",
    "optimizer = torch.optim.Adam(gates\n",
    "                             , lr=1e-2)\n",
    "# scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, 1/3, 1.0, 10000)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
    "                                                       factor = 1/3,\n",
    "                                                       patience = 100)\n",
    "n_iters = 10000\n",
    "losses = []\n",
    "clip_grad = 0.1\n",
    "for i in range(n_iters):\n",
    "    reconstructed_W = torch.einsum(einsum_expr, *gates).reshape(W.shape)\n",
    "    reconstructed_W *= norm_0.unsqueeze(0)\n",
    "    reconstructed_W *= norm_1.unsqueeze(1)\n",
    "    if torch.any(mask_0) or torch.any(mask_1):\n",
    "        reconstructed_W[:,mask_0] += W_sparse_0\n",
    "        reconstructed_W[mask_1,:] += W_sparse_1\n",
    "    diff = W - reconstructed_W\n",
    "\n",
    "    average_error = torch.sum(torch.abs(diff)**1)/torch.sum(torch.abs(W)**1)\n",
    "\n",
    "    H_error = torch.einsum('ik,kl,il->', diff, H/H.shape[0], diff)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    H_error.backward()\n",
    "    #clip the grad\n",
    "    torch.nn.utils.clip_grad_norm_(parameters, clip_grad)\n",
    "    optimizer.step()\n",
    "    scheduler.step(H_error)\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(f\"iter {i}, average_error {average_error}, H_error {H_error}, lr {optimizer.param_groups[0]['lr']}\")\n",
    "    \n",
    "    losses.append(H_error.item())\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "standard_times = []\n",
    "einsum_times = []\n",
    "\n",
    "reconstructed_W = torch.einsum(einsum_expr, *gates).reshape(W.shape)\n",
    "reconstructed_W *= norm_0.unsqueeze(0)\n",
    "# reconstructed_W *= norm_1.unsqueeze(1)\n",
    "# reconstructed_W = torch.einsum(einsum_expr, *gates).reshape(W.shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(100):\n",
    "        x = torch.randn((1000,d_in)).to(device)\n",
    "        x_reshaped = (x * norm_0.unsqueeze(0)).reshape([1000] + (qubit_dimensions if layer_type !=  \"compress\" else [k_factor] + qubit_dimensions[1:]))\n",
    "        \n",
    "        start = time.time()\n",
    "        x_try = x @ reconstructed_W.T\n",
    "        \n",
    "        # F.linear(x, reconstructed_W)\n",
    "        standard_times.append(time.time()-start)\n",
    "        \n",
    "        start = time.time()\n",
    "        x_try2 = torch.einsum(quanta_apply_einsum_expr(N_qubits), x_reshaped, *gates).reshape(x.shape[:-1] + (d_out,)) #* norm_1.unsqueeze(0)\n",
    "        einsum_times.append(time.time()-start)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4908,  0.6062, -1.4110,  ..., -0.3367,  0.1120,  0.5138],\n",
       "        [ 0.2419,  0.0143,  0.1184,  ..., -0.1812, -0.1033,  0.9553],\n",
       "        [-0.3329, -0.4994,  0.1030,  ...,  1.4877, -0.2371,  0.3535],\n",
       "        ...,\n",
       "        [ 0.6203, -0.5879,  1.7957,  ..., -0.5400,  0.6840, -1.4585],\n",
       "        [-0.4578,  1.6304,  0.3078,  ...,  0.0738,  0.3206, -0.6771],\n",
       "        [ 0.5914, -0.9025,  0.7389,  ...,  0.8147, -0.9273,  0.3088]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_try2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4908,  0.6062, -1.4110,  ..., -0.3367,  0.1120,  0.5138],\n",
       "        [ 0.2419,  0.0143,  0.1184,  ..., -0.1812, -0.1033,  0.9553],\n",
       "        [-0.3329, -0.4994,  0.1030,  ...,  1.4877, -0.2371,  0.3535],\n",
       "        ...,\n",
       "        [ 0.6203, -0.5879,  1.7957,  ..., -0.5400,  0.6840, -1.4585],\n",
       "        [-0.4578,  1.6304,  0.3078,  ...,  0.0738,  0.3206, -0.6771],\n",
       "        [ 0.5914, -0.9025,  0.7389,  ...,  0.8147, -0.9273,  0.3088]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.930149793624878"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
