/data/lliu/huffman
/home/lliu/anaconda3/lib/python3.11/site-packages/torch/jit/annotations.py:389: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn(
2024-12-23 12:55:55.029812: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-12-23 12:55:55.048632: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-12-23 12:55:55.054530: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-12-23 12:55:55.068887: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-12-23 12:55:56.514573: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]Loading checkpoint shards:   3%|▎         | 1/30 [00:00<00:09,  2.99it/s]Loading checkpoint shards:   7%|▋         | 2/30 [00:00<00:08,  3.42it/s]Loading checkpoint shards:  10%|█         | 3/30 [00:00<00:07,  3.63it/s]Loading checkpoint shards:  13%|█▎        | 4/30 [00:01<00:07,  3.42it/s]Loading checkpoint shards:  17%|█▋        | 5/30 [00:01<00:06,  3.63it/s]Loading checkpoint shards:  20%|██        | 6/30 [00:01<00:06,  3.79it/s]Loading checkpoint shards:  23%|██▎       | 7/30 [00:01<00:05,  4.00it/s]Loading checkpoint shards:  27%|██▋       | 8/30 [00:02<00:05,  4.10it/s]Loading checkpoint shards:  30%|███       | 9/30 [00:02<00:05,  4.19it/s]Loading checkpoint shards:  33%|███▎      | 10/30 [00:02<00:04,  4.27it/s]Loading checkpoint shards:  37%|███▋      | 11/30 [00:02<00:04,  4.35it/s]Loading checkpoint shards:  40%|████      | 12/30 [00:03<00:04,  4.41it/s]Loading checkpoint shards:  43%|████▎     | 13/30 [00:03<00:03,  4.28it/s]Loading checkpoint shards:  47%|████▋     | 14/30 [00:03<00:03,  4.36it/s]Loading checkpoint shards:  50%|█████     | 15/30 [00:03<00:03,  4.43it/s]Loading checkpoint shards:  53%|█████▎    | 16/30 [00:03<00:03,  4.49it/s]Loading checkpoint shards:  57%|█████▋    | 17/30 [00:04<00:02,  4.55it/s]Loading checkpoint shards:  60%|██████    | 18/30 [00:04<00:02,  4.65it/s]Loading checkpoint shards:  63%|██████▎   | 19/30 [00:04<00:02,  4.68it/s]Loading checkpoint shards:  67%|██████▋   | 20/30 [00:04<00:02,  4.71it/s]Loading checkpoint shards:  70%|███████   | 21/30 [00:04<00:01,  4.74it/s]Loading checkpoint shards:  73%|███████▎  | 22/30 [00:05<00:01,  4.76it/s]Loading checkpoint shards:  77%|███████▋  | 23/30 [00:05<00:01,  4.75it/s]Loading checkpoint shards:  80%|████████  | 24/30 [00:05<00:01,  4.44it/s]Loading checkpoint shards:  83%|████████▎ | 25/30 [00:05<00:01,  4.39it/s]Loading checkpoint shards:  87%|████████▋ | 26/30 [00:06<00:00,  4.29it/s]Loading checkpoint shards:  90%|█████████ | 27/30 [00:06<00:00,  4.32it/s]Loading checkpoint shards:  93%|█████████▎| 28/30 [00:06<00:00,  4.30it/s]Loading checkpoint shards:  97%|█████████▋| 29/30 [00:06<00:00,  4.37it/s]Loading checkpoint shards: 100%|██████████| 30/30 [00:07<00:00,  4.39it/s]Loading checkpoint shards: 100%|██████████| 30/30 [00:07<00:00,  4.28it/s]
Model loaded. LlamaForCausalLM(
  (model): LlamaModel(
    (embed_tokens): Embedding(128256, 8192)
    (layers): ModuleList(
      (0-79): 80 x LlamaDecoderLayer(
        (self_attn): LlamaSdpaAttention(
          (q_proj): Linear(in_features=8192, out_features=8192, bias=False)
          (k_proj): Linear(in_features=8192, out_features=1024, bias=False)
          (v_proj): Linear(in_features=8192, out_features=1024, bias=False)
          (o_proj): Linear(in_features=8192, out_features=8192, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LlamaMLP(
          (gate_proj): Linear(in_features=8192, out_features=28672, bias=False)
          (up_proj): Linear(in_features=8192, out_features=28672, bias=False)
          (down_proj): Linear(in_features=28672, out_features=8192, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): LlamaRMSNorm((8192,), eps=1e-05)
        (post_attention_layernorm): LlamaRMSNorm((8192,), eps=1e-05)
      )
    )
    (norm): LlamaRMSNorm((8192,), eps=1e-05)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (lm_head): Linear(in_features=8192, out_features=128256, bias=False)
)
Starting...
getting inputs:   0%|          | 0/128 [00:00<?, ?it/s]getting inputs:   1%|          | 1/128 [00:00<01:27,  1.45it/s]getting inputs:   2%|▏         | 3/128 [00:00<00:27,  4.52it/s]getting inputs:   4%|▍         | 5/128 [00:00<00:17,  7.21it/s]getting inputs:   5%|▌         | 7/128 [00:01<00:12,  9.63it/s]getting inputs:   7%|▋         | 9/128 [00:01<00:10, 11.56it/s]getting inputs:   9%|▊         | 11/128 [00:01<00:09, 12.98it/s]getting inputs:  10%|█         | 13/128 [00:01<00:08, 14.24it/s]getting inputs:  12%|█▏        | 15/128 [00:01<00:07, 15.18it/s]getting inputs:  13%|█▎        | 17/128 [00:01<00:07, 15.85it/s]getting inputs:  15%|█▍        | 19/128 [00:01<00:06, 16.20it/s]getting inputs:  16%|█▋        | 21/128 [00:01<00:06, 16.63it/s]getting inputs:  18%|█▊        | 23/128 [00:01<00:06, 16.60it/s]getting inputs:  20%|█▉        | 25/128 [00:02<00:06, 16.29it/s]getting inputs:  21%|██        | 27/128 [00:02<00:06, 15.62it/s]getting inputs:  23%|██▎       | 29/128 [00:02<00:06, 14.89it/s]getting inputs:  24%|██▍       | 31/128 [00:02<00:06, 14.25it/s]getting inputs:  26%|██▌       | 33/128 [00:02<00:06, 14.26it/s]getting inputs:  27%|██▋       | 35/128 [00:02<00:06, 14.12it/s]getting inputs:  29%|██▉       | 37/128 [00:02<00:06, 14.00it/s]getting inputs:  30%|███       | 39/128 [00:03<00:06, 13.71it/s]getting inputs:  32%|███▏      | 41/128 [00:03<00:06, 13.79it/s]getting inputs:  34%|███▎      | 43/128 [00:03<00:06, 13.88it/s]getting inputs:  35%|███▌      | 45/128 [00:03<00:05, 13.99it/s]getting inputs:  37%|███▋      | 47/128 [00:03<00:05, 13.91it/s]getting inputs:  38%|███▊      | 49/128 [00:03<00:05, 13.97it/s]getting inputs:  40%|███▉      | 51/128 [00:03<00:05, 14.06it/s]getting inputs:  41%|████▏     | 53/128 [00:04<00:05, 14.02it/s]getting inputs:  43%|████▎     | 55/128 [00:04<00:05, 13.32it/s]getting inputs:  45%|████▍     | 57/128 [00:04<00:05, 13.33it/s]getting inputs:  46%|████▌     | 59/128 [00:04<00:05, 13.26it/s]getting inputs:  48%|████▊     | 61/128 [00:04<00:05, 12.48it/s]getting inputs:  49%|████▉     | 63/128 [00:04<00:05, 12.70it/s]getting inputs:  51%|█████     | 65/128 [00:05<00:04, 12.84it/s]getting inputs:  52%|█████▏    | 67/128 [00:05<00:04, 13.22it/s]getting inputs:  54%|█████▍    | 69/128 [00:05<00:04, 13.75it/s]getting inputs:  55%|█████▌    | 71/128 [00:05<00:03, 14.36it/s]getting inputs:  57%|█████▋    | 73/128 [00:05<00:03, 14.65it/s]getting inputs:  59%|█████▊    | 75/128 [00:05<00:03, 15.03it/s]getting inputs:  60%|██████    | 77/128 [00:05<00:03, 15.48it/s]getting inputs:  62%|██████▏   | 79/128 [00:05<00:03, 16.28it/s]getting inputs:  63%|██████▎   | 81/128 [00:06<00:02, 16.31it/s]getting inputs:  65%|██████▍   | 83/128 [00:06<00:02, 16.17it/s]getting inputs:  66%|██████▋   | 85/128 [00:06<00:02, 15.91it/s]getting inputs:  68%|██████▊   | 87/128 [00:06<00:02, 16.18it/s]getting inputs:  70%|██████▉   | 89/128 [00:06<00:02, 15.79it/s]getting inputs:  71%|███████   | 91/128 [00:06<00:02, 16.04it/s]getting inputs:  73%|███████▎  | 93/128 [00:06<00:02, 16.15it/s]getting inputs:  74%|███████▍  | 95/128 [00:06<00:02, 16.30it/s]getting inputs:  76%|███████▌  | 97/128 [00:07<00:01, 16.13it/s]getting inputs:  77%|███████▋  | 99/128 [00:07<00:01, 16.29it/s]getting inputs:  79%|███████▉  | 101/128 [00:07<00:01, 16.19it/s]getting inputs:  80%|████████  | 103/128 [00:07<00:01, 15.95it/s]getting inputs:  82%|████████▏ | 105/128 [00:07<00:01, 16.04it/s]getting inputs:  84%|████████▎ | 107/128 [00:07<00:01, 15.89it/s]getting inputs:  85%|████████▌ | 109/128 [00:07<00:01, 16.03it/s]getting inputs:  87%|████████▋ | 111/128 [00:07<00:01, 16.49it/s]getting inputs:  88%|████████▊ | 113/128 [00:08<00:00, 15.92it/s]getting inputs:  90%|████████▉ | 115/128 [00:08<00:00, 16.17it/s]getting inputs:  91%|█████████▏| 117/128 [00:08<00:00, 16.25it/s]getting inputs:  93%|█████████▎| 119/128 [00:08<00:00, 16.35it/s]getting inputs:  95%|█████████▍| 121/128 [00:08<00:00, 16.33it/s]getting inputs:  96%|█████████▌| 123/128 [00:08<00:00, 16.72it/s]getting inputs:  98%|█████████▊| 125/128 [00:08<00:00, 16.78it/s]getting inputs:  99%|█████████▉| 127/128 [00:08<00:00, 16.76it/s]getting inputs: 100%|██████████| 128/128 [00:08<00:00, 14.27it/s]
48323 MiB free out of 48676 MiB total
Ready.
layer original dtype torch.bfloat16
skipping layer 0
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:20,  1.48it/s]Inference:   6%|▋         | 2/32 [00:01<00:18,  1.61it/s]Inference:   9%|▉         | 3/32 [00:01<00:16,  1.80it/s]Inference:  12%|█▎        | 4/32 [00:02<00:15,  1.79it/s]Inference:  16%|█▌        | 5/32 [00:02<00:15,  1.79it/s]Inference:  19%|█▉        | 6/32 [00:03<00:14,  1.79it/s]Inference:  22%|██▏       | 7/32 [00:03<00:13,  1.79it/s]Inference:  25%|██▌       | 8/32 [00:04<00:13,  1.80it/s]Inference:  28%|██▊       | 9/32 [00:05<00:12,  1.80it/s]Inference:  31%|███▏      | 10/32 [00:05<00:12,  1.80it/s]Inference:  34%|███▍      | 11/32 [00:06<00:11,  1.79it/s]Inference:  38%|███▊      | 12/32 [00:06<00:11,  1.79it/s]Inference:  41%|████      | 13/32 [00:07<00:10,  1.78it/s]Inference:  44%|████▍     | 14/32 [00:07<00:10,  1.79it/s]Inference:  47%|████▋     | 15/32 [00:08<00:09,  1.77it/s]Inference:  50%|█████     | 16/32 [00:09<00:08,  1.78it/s]Inference:  53%|█████▎    | 17/32 [00:09<00:08,  1.78it/s]Inference:  56%|█████▋    | 18/32 [00:10<00:07,  1.79it/s]Inference:  59%|█████▉    | 19/32 [00:10<00:07,  1.79it/s]Inference:  62%|██████▎   | 20/32 [00:11<00:06,  1.79it/s]Inference:  66%|██████▌   | 21/32 [00:11<00:05,  1.89it/s]Inference:  69%|██████▉   | 22/32 [00:12<00:05,  1.86it/s]Inference:  72%|███████▏  | 23/32 [00:12<00:04,  1.84it/s]Inference:  75%|███████▌  | 24/32 [00:13<00:04,  1.83it/s]Inference:  78%|███████▊  | 25/32 [00:13<00:03,  1.83it/s]Inference:  81%|████████▏ | 26/32 [00:14<00:03,  1.82it/s]Inference:  84%|████████▍ | 27/32 [00:15<00:02,  1.82it/s]Inference:  88%|████████▊ | 28/32 [00:15<00:02,  1.82it/s]Inference:  91%|█████████ | 29/32 [00:16<00:01,  1.91it/s]Inference:  94%|█████████▍| 30/32 [00:16<00:01,  1.86it/s]Inference:  97%|█████████▋| 31/32 [00:17<00:00,  1.87it/s]Inference: 100%|██████████| 32/32 [00:17<00:00,  1.87it/s]Inference: 100%|██████████| 32/32 [00:17<00:00,  1.81it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 0
48317 MiB free out of 48676 MiB total
Done with layer 0 total_time elapsed: 32 estimated time left: 2528
layer original dtype torch.bfloat16
skipping layer 1
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:14,  2.15it/s]Inference:   6%|▋         | 2/32 [00:00<00:14,  2.06it/s]Inference:   9%|▉         | 3/32 [00:01<00:14,  2.03it/s]Inference:  12%|█▎        | 4/32 [00:01<00:14,  1.98it/s]Inference:  16%|█▌        | 5/32 [00:02<00:14,  1.90it/s]Inference:  19%|█▉        | 6/32 [00:03<00:13,  1.87it/s]Inference:  22%|██▏       | 7/32 [00:03<00:13,  1.86it/s]Inference:  25%|██▌       | 8/32 [00:04<00:12,  1.86it/s]Inference:  28%|██▊       | 9/32 [00:04<00:12,  1.90it/s]Inference:  31%|███▏      | 10/32 [00:05<00:11,  1.93it/s]Inference:  34%|███▍      | 11/32 [00:05<00:11,  1.88it/s]Inference:  38%|███▊      | 12/32 [00:06<00:10,  1.85it/s]Inference:  41%|████      | 13/32 [00:06<00:10,  1.83it/s]Inference:  44%|████▍     | 14/32 [00:07<00:09,  1.80it/s]Inference:  47%|████▋     | 15/32 [00:07<00:09,  1.80it/s]Inference:  50%|█████     | 16/32 [00:08<00:08,  1.81it/s]Inference:  53%|█████▎    | 17/32 [00:09<00:08,  1.81it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:07,  1.81it/s]Inference:  59%|█████▉    | 19/32 [00:10<00:07,  1.80it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.78it/s]Inference:  66%|██████▌   | 21/32 [00:11<00:06,  1.73it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.75it/s]Inference:  72%|███████▏  | 23/32 [00:12<00:05,  1.76it/s]Inference:  75%|███████▌  | 24/32 [00:13<00:04,  1.80it/s]Inference:  78%|███████▊  | 25/32 [00:13<00:03,  1.81it/s]Inference:  81%|████████▏ | 26/32 [00:14<00:03,  1.82it/s]Inference:  84%|████████▍ | 27/32 [00:14<00:02,  1.85it/s]Inference:  88%|████████▊ | 28/32 [00:15<00:02,  1.92it/s]Inference:  91%|█████████ | 29/32 [00:15<00:01,  1.87it/s]Inference:  94%|█████████▍| 30/32 [00:16<00:01,  1.85it/s]Inference:  97%|█████████▋| 31/32 [00:16<00:00,  1.82it/s]Inference: 100%|██████████| 32/32 [00:17<00:00,  1.77it/s]Inference: 100%|██████████| 32/32 [00:17<00:00,  1.84it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 1
48317 MiB free out of 48676 MiB total
Done with layer 1 total_time elapsed: 51 estimated time left: 1993
layer original dtype torch.bfloat16
skipping layer 2
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:14,  2.13it/s]Inference:   6%|▋         | 2/32 [00:01<00:16,  1.86it/s]Inference:   9%|▉         | 3/32 [00:01<00:15,  1.81it/s]Inference:  12%|█▎        | 4/32 [00:02<00:15,  1.86it/s]Inference:  16%|█▌        | 5/32 [00:02<00:14,  1.90it/s]Inference:  19%|█▉        | 6/32 [00:03<00:14,  1.75it/s]Inference:  22%|██▏       | 7/32 [00:04<00:16,  1.50it/s]Inference:  25%|██▌       | 8/32 [00:04<00:14,  1.61it/s]Inference:  28%|██▊       | 9/32 [00:05<00:13,  1.70it/s]Inference:  31%|███▏      | 10/32 [00:05<00:12,  1.78it/s]Inference:  34%|███▍      | 11/32 [00:06<00:11,  1.82it/s]Inference:  38%|███▊      | 12/32 [00:06<00:10,  1.86it/s]Inference:  41%|████      | 13/32 [00:07<00:09,  1.91it/s]Inference:  44%|████▍     | 14/32 [00:07<00:09,  1.94it/s]Inference:  47%|████▋     | 15/32 [00:08<00:08,  1.96it/s]Inference:  50%|█████     | 16/32 [00:08<00:08,  1.97it/s]Inference:  53%|█████▎    | 17/32 [00:09<00:07,  1.96it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:07,  1.97it/s]Inference:  59%|█████▉    | 19/32 [00:10<00:06,  1.97it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.96it/s]Inference:  66%|██████▌   | 21/32 [00:11<00:05,  1.95it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.95it/s]Inference:  72%|███████▏  | 23/32 [00:12<00:04,  1.95it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:04,  1.94it/s]Inference:  78%|███████▊  | 25/32 [00:13<00:03,  1.90it/s]Inference:  81%|████████▏ | 26/32 [00:14<00:03,  1.79it/s]Inference:  84%|████████▍ | 27/32 [00:14<00:02,  1.86it/s]Inference:  88%|████████▊ | 28/32 [00:15<00:02,  1.89it/s]Inference:  91%|█████████ | 29/32 [00:15<00:01,  1.94it/s]Inference:  94%|█████████▍| 30/32 [00:15<00:01,  1.98it/s]Inference:  97%|█████████▋| 31/32 [00:16<00:00,  2.00it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  2.00it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.89it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 2
48317 MiB free out of 48676 MiB total
Done with layer 2 total_time elapsed: 70 estimated time left: 1788
layer original dtype torch.bfloat16
skipping layer 3
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:14,  2.09it/s]Inference:   6%|▋         | 2/32 [00:00<00:14,  2.08it/s]Inference:   9%|▉         | 3/32 [00:01<00:14,  2.01it/s]Inference:  12%|█▎        | 4/32 [00:01<00:14,  1.99it/s]Inference:  16%|█▌        | 5/32 [00:02<00:13,  1.98it/s]Inference:  19%|█▉        | 6/32 [00:02<00:13,  1.99it/s]Inference:  22%|██▏       | 7/32 [00:03<00:12,  2.00it/s]Inference:  25%|██▌       | 8/32 [00:03<00:11,  2.00it/s]Inference:  28%|██▊       | 9/32 [00:04<00:11,  2.02it/s]Inference:  31%|███▏      | 10/32 [00:04<00:10,  2.03it/s]Inference:  34%|███▍      | 11/32 [00:05<00:10,  2.04it/s]Inference:  38%|███▊      | 12/32 [00:05<00:09,  2.04it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  2.04it/s]Inference:  44%|████▍     | 14/32 [00:06<00:08,  2.03it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  2.04it/s]Inference:  50%|█████     | 16/32 [00:07<00:08,  1.96it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  1.94it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:07,  1.92it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  1.91it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.88it/s]Inference:  66%|██████▌   | 21/32 [00:10<00:05,  1.90it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.92it/s]Inference:  72%|███████▏  | 23/32 [00:11<00:04,  1.91it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:04,  1.93it/s]Inference:  78%|███████▊  | 25/32 [00:12<00:03,  1.97it/s]Inference:  81%|████████▏ | 26/32 [00:13<00:03,  2.00it/s]Inference:  84%|████████▍ | 27/32 [00:13<00:02,  2.02it/s]Inference:  88%|████████▊ | 28/32 [00:14<00:01,  2.05it/s]Inference:  91%|█████████ | 29/32 [00:14<00:01,  2.07it/s]Inference:  94%|█████████▍| 30/32 [00:15<00:00,  2.05it/s]Inference:  97%|█████████▋| 31/32 [00:15<00:00,  2.05it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  2.04it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.99it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 3
48317 MiB free out of 48676 MiB total
Done with layer 3 total_time elapsed: 87 estimated time left: 1659
layer original dtype torch.bfloat16
skipping layer 4
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:17,  1.78it/s]Inference:   6%|▋         | 2/32 [00:01<00:17,  1.76it/s]Inference:   9%|▉         | 3/32 [00:01<00:16,  1.76it/s]Inference:  12%|█▎        | 4/32 [00:02<00:15,  1.78it/s]Inference:  16%|█▌        | 5/32 [00:02<00:15,  1.78it/s]Inference:  19%|█▉        | 6/32 [00:03<00:14,  1.78it/s]Inference:  22%|██▏       | 7/32 [00:03<00:14,  1.78it/s]Inference:  25%|██▌       | 8/32 [00:04<00:13,  1.78it/s]Inference:  28%|██▊       | 9/32 [00:05<00:12,  1.78it/s]Inference:  31%|███▏      | 10/32 [00:05<00:12,  1.77it/s]Inference:  34%|███▍      | 11/32 [00:06<00:11,  1.75it/s]Inference:  38%|███▊      | 12/32 [00:06<00:11,  1.77it/s]Inference:  41%|████      | 13/32 [00:07<00:10,  1.77it/s]Inference:  44%|████▍     | 14/32 [00:07<00:10,  1.75it/s]Inference:  47%|████▋     | 15/32 [00:08<00:09,  1.77it/s]Inference:  50%|█████     | 16/32 [00:09<00:09,  1.77it/s]Inference:  53%|█████▎    | 17/32 [00:09<00:08,  1.77it/s]Inference:  56%|█████▋    | 18/32 [00:10<00:07,  1.76it/s]Inference:  59%|█████▉    | 19/32 [00:10<00:07,  1.74it/s]Inference:  62%|██████▎   | 20/32 [00:11<00:06,  1.74it/s]Inference:  66%|██████▌   | 21/32 [00:11<00:06,  1.75it/s]Inference:  69%|██████▉   | 22/32 [00:12<00:05,  1.75it/s]Inference:  72%|███████▏  | 23/32 [00:13<00:05,  1.74it/s]Inference:  75%|███████▌  | 24/32 [00:13<00:04,  1.75it/s]Inference:  78%|███████▊  | 25/32 [00:14<00:04,  1.73it/s]Inference:  81%|████████▏ | 26/32 [00:14<00:03,  1.74it/s]Inference:  84%|████████▍ | 27/32 [00:15<00:02,  1.70it/s]Inference:  88%|████████▊ | 28/32 [00:15<00:02,  1.73it/s]Inference:  91%|█████████ | 29/32 [00:16<00:01,  1.73it/s]Inference:  94%|█████████▍| 30/32 [00:17<00:01,  1.75it/s]Inference:  97%|█████████▋| 31/32 [00:17<00:00,  1.76it/s]Inference: 100%|██████████| 32/32 [00:18<00:00,  1.77it/s]Inference: 100%|██████████| 32/32 [00:18<00:00,  1.76it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 4
48317 MiB free out of 48676 MiB total
Done with layer 4 total_time elapsed: 107 estimated time left: 1609
layer original dtype torch.bfloat16
skipping layer 5
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:17,  1.73it/s]Inference:   6%|▋         | 2/32 [00:01<00:17,  1.70it/s]Inference:   9%|▉         | 3/32 [00:01<00:17,  1.66it/s]Inference:  12%|█▎        | 4/32 [00:02<00:17,  1.62it/s]Inference:  16%|█▌        | 5/32 [00:03<00:16,  1.62it/s]Inference:  19%|█▉        | 6/32 [00:03<00:15,  1.65it/s]Inference:  22%|██▏       | 7/32 [00:04<00:14,  1.68it/s]Inference:  25%|██▌       | 8/32 [00:04<00:14,  1.68it/s]Inference:  28%|██▊       | 9/32 [00:05<00:13,  1.70it/s]Inference:  31%|███▏      | 10/32 [00:05<00:12,  1.71it/s]Inference:  34%|███▍      | 11/32 [00:06<00:12,  1.73it/s]Inference:  38%|███▊      | 12/32 [00:07<00:11,  1.74it/s]Inference:  41%|████      | 13/32 [00:07<00:10,  1.74it/s]Inference:  44%|████▍     | 14/32 [00:08<00:10,  1.73it/s]Inference:  47%|████▋     | 15/32 [00:08<00:09,  1.74it/s]Inference:  50%|█████     | 16/32 [00:09<00:09,  1.74it/s]Inference:  53%|█████▎    | 17/32 [00:09<00:08,  1.75it/s]Inference:  56%|█████▋    | 18/32 [00:10<00:08,  1.74it/s]Inference:  59%|█████▉    | 19/32 [00:11<00:07,  1.74it/s]Inference:  62%|██████▎   | 20/32 [00:11<00:06,  1.72it/s]Inference:  66%|██████▌   | 21/32 [00:12<00:06,  1.67it/s]Inference:  69%|██████▉   | 22/32 [00:12<00:05,  1.68it/s]Inference:  72%|███████▏  | 23/32 [00:13<00:05,  1.71it/s]Inference:  75%|███████▌  | 24/32 [00:14<00:04,  1.72it/s]Inference:  78%|███████▊  | 25/32 [00:14<00:04,  1.74it/s]Inference:  81%|████████▏ | 26/32 [00:15<00:03,  1.75it/s]Inference:  84%|████████▍ | 27/32 [00:15<00:02,  1.74it/s]Inference:  88%|████████▊ | 28/32 [00:16<00:02,  1.73it/s]Inference:  91%|█████████ | 29/32 [00:16<00:01,  1.75it/s]Inference:  94%|█████████▍| 30/32 [00:17<00:01,  1.76it/s]Inference:  97%|█████████▋| 31/32 [00:18<00:00,  1.77it/s]Inference: 100%|██████████| 32/32 [00:18<00:00,  1.77it/s]Inference: 100%|██████████| 32/32 [00:18<00:00,  1.72it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 5
48317 MiB free out of 48676 MiB total
Done with layer 5 total_time elapsed: 127 estimated time left: 1572
layer original dtype torch.bfloat16
skipping layer 6
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:14,  2.10it/s]Inference:   6%|▋         | 2/32 [00:00<00:14,  2.09it/s]Inference:   9%|▉         | 3/32 [00:01<00:13,  2.09it/s]Inference:  12%|█▎        | 4/32 [00:01<00:13,  2.09it/s]Inference:  16%|█▌        | 5/32 [00:02<00:12,  2.10it/s]Inference:  19%|█▉        | 6/32 [00:02<00:12,  2.10it/s]Inference:  22%|██▏       | 7/32 [00:03<00:12,  1.95it/s]Inference:  25%|██▌       | 8/32 [00:03<00:12,  1.99it/s]Inference:  28%|██▊       | 9/32 [00:04<00:11,  2.01it/s]Inference:  31%|███▏      | 10/32 [00:04<00:10,  2.03it/s]Inference:  34%|███▍      | 11/32 [00:05<00:10,  2.05it/s]Inference:  38%|███▊      | 12/32 [00:05<00:09,  2.06it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  2.07it/s]Inference:  44%|████▍     | 14/32 [00:06<00:08,  2.07it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  2.07it/s]Inference:  50%|█████     | 16/32 [00:07<00:07,  2.07it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  2.07it/s]Inference:  56%|█████▋    | 18/32 [00:08<00:06,  2.07it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  2.07it/s]Inference:  62%|██████▎   | 20/32 [00:09<00:05,  2.08it/s]Inference:  66%|██████▌   | 21/32 [00:10<00:05,  2.08it/s]Inference:  69%|██████▉   | 22/32 [00:10<00:04,  2.08it/s]Inference:  72%|███████▏  | 23/32 [00:11<00:04,  2.04it/s]Inference:  75%|███████▌  | 24/32 [00:11<00:03,  2.05it/s]Inference:  78%|███████▊  | 25/32 [00:12<00:03,  2.03it/s]Inference:  81%|████████▏ | 26/32 [00:12<00:02,  2.02it/s]Inference:  84%|████████▍ | 27/32 [00:13<00:02,  2.01it/s]Inference:  88%|████████▊ | 28/32 [00:13<00:01,  2.01it/s]Inference:  91%|█████████ | 29/32 [00:14<00:01,  2.00it/s]Inference:  94%|█████████▍| 30/32 [00:14<00:00,  2.00it/s]Inference:  97%|█████████▋| 31/32 [00:15<00:00,  1.97it/s]Inference: 100%|██████████| 32/32 [00:15<00:00,  2.00it/s]Inference: 100%|██████████| 32/32 [00:15<00:00,  2.04it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 6
48317 MiB free out of 48676 MiB total
Done with layer 6 total_time elapsed: 145 estimated time left: 1510
layer original dtype torch.bfloat16
skipping layer 7
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:17,  1.74it/s]Inference:   6%|▋         | 2/32 [00:01<00:16,  1.83it/s]Inference:   9%|▉         | 3/32 [00:01<00:15,  1.89it/s]Inference:  12%|█▎        | 4/32 [00:02<00:14,  1.91it/s]Inference:  16%|█▌        | 5/32 [00:02<00:13,  1.95it/s]Inference:  19%|█▉        | 6/32 [00:03<00:13,  1.97it/s]Inference:  22%|██▏       | 7/32 [00:03<00:12,  2.00it/s]Inference:  25%|██▌       | 8/32 [00:04<00:12,  1.99it/s]Inference:  28%|██▊       | 9/32 [00:04<00:11,  2.01it/s]Inference:  31%|███▏      | 10/32 [00:05<00:10,  2.03it/s]Inference:  34%|███▍      | 11/32 [00:05<00:10,  2.05it/s]Inference:  38%|███▊      | 12/32 [00:06<00:09,  2.05it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  2.07it/s]Inference:  44%|████▍     | 14/32 [00:06<00:08,  2.07it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  2.07it/s]Inference:  50%|█████     | 16/32 [00:07<00:07,  2.04it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  2.06it/s]Inference:  56%|█████▋    | 18/32 [00:08<00:06,  2.05it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  2.04it/s]Inference:  62%|██████▎   | 20/32 [00:09<00:06,  1.99it/s]Inference:  66%|██████▌   | 21/32 [00:10<00:05,  1.99it/s]Inference:  69%|██████▉   | 22/32 [00:10<00:04,  2.03it/s]Inference:  72%|███████▏  | 23/32 [00:11<00:04,  2.01it/s]Inference:  75%|███████▌  | 24/32 [00:11<00:04,  1.98it/s]Inference:  78%|███████▊  | 25/32 [00:12<00:03,  2.00it/s]Inference:  81%|████████▏ | 26/32 [00:12<00:02,  2.01it/s]Inference:  84%|████████▍ | 27/32 [00:13<00:02,  2.01it/s]Inference:  88%|████████▊ | 28/32 [00:13<00:01,  2.04it/s]Inference:  91%|█████████ | 29/32 [00:14<00:01,  2.04it/s]Inference:  94%|█████████▍| 30/32 [00:14<00:00,  2.07it/s]Inference:  97%|█████████▋| 31/32 [00:15<00:00,  2.07it/s]Inference: 100%|██████████| 32/32 [00:15<00:00,  2.07it/s]Inference: 100%|██████████| 32/32 [00:15<00:00,  2.02it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 7
48317 MiB free out of 48676 MiB total
Done with layer 7 total_time elapsed: 162 estimated time left: 1461
layer original dtype torch.bfloat16
skipping layer 8
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:15,  1.99it/s]Inference:   6%|▋         | 2/32 [00:00<00:14,  2.03it/s]Inference:   9%|▉         | 3/32 [00:01<00:14,  2.02it/s]Inference:  12%|█▎        | 4/32 [00:01<00:13,  2.02it/s]Inference:  16%|█▌        | 5/32 [00:02<00:13,  2.05it/s]Inference:  19%|█▉        | 6/32 [00:02<00:12,  2.05it/s]Inference:  22%|██▏       | 7/32 [00:03<00:12,  2.05it/s]Inference:  25%|██▌       | 8/32 [00:03<00:11,  2.05it/s]Inference:  28%|██▊       | 9/32 [00:04<00:11,  2.01it/s]Inference:  31%|███▏      | 10/32 [00:04<00:10,  2.03it/s]Inference:  34%|███▍      | 11/32 [00:05<00:10,  2.04it/s]Inference:  38%|███▊      | 12/32 [00:05<00:09,  2.05it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  2.03it/s]Inference:  44%|████▍     | 14/32 [00:06<00:08,  2.04it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  2.06it/s]Inference:  50%|█████     | 16/32 [00:07<00:07,  2.05it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  2.05it/s]Inference:  56%|█████▋    | 18/32 [00:08<00:06,  2.04it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  2.05it/s]Inference:  62%|██████▎   | 20/32 [00:09<00:05,  2.05it/s]Inference:  66%|██████▌   | 21/32 [00:10<00:05,  2.06it/s]Inference:  69%|██████▉   | 22/32 [00:10<00:04,  2.03it/s]Inference:  72%|███████▏  | 23/32 [00:11<00:04,  2.02it/s]Inference:  75%|███████▌  | 24/32 [00:11<00:03,  2.01it/s]Inference:  78%|███████▊  | 25/32 [00:12<00:03,  2.02it/s]Inference:  81%|████████▏ | 26/32 [00:12<00:03,  2.00it/s]Inference:  84%|████████▍ | 27/32 [00:13<00:02,  2.02it/s]Inference:  88%|████████▊ | 28/32 [00:13<00:01,  2.03it/s]Inference:  91%|█████████ | 29/32 [00:14<00:01,  2.02it/s]Inference:  94%|█████████▍| 30/32 [00:14<00:00,  2.04it/s]Inference:  97%|█████████▋| 31/32 [00:15<00:00,  2.05it/s]Inference: 100%|██████████| 32/32 [00:15<00:00,  2.03it/s]Inference: 100%|██████████| 32/32 [00:15<00:00,  2.03it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 8
48317 MiB free out of 48676 MiB total
Done with layer 8 total_time elapsed: 180 estimated time left: 1416
layer original dtype torch.bfloat16
skipping layer 9
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:15,  2.04it/s]Inference:   6%|▋         | 2/32 [00:00<00:14,  2.04it/s]Inference:   9%|▉         | 3/32 [00:01<00:14,  1.98it/s]Inference:  12%|█▎        | 4/32 [00:01<00:14,  2.00it/s]Inference:  16%|█▌        | 5/32 [00:02<00:13,  2.01it/s]Inference:  19%|█▉        | 6/32 [00:02<00:12,  2.01it/s]Inference:  22%|██▏       | 7/32 [00:03<00:12,  2.01it/s]Inference:  25%|██▌       | 8/32 [00:03<00:11,  2.03it/s]Inference:  28%|██▊       | 9/32 [00:04<00:11,  2.05it/s]Inference:  31%|███▏      | 10/32 [00:04<00:10,  2.02it/s]Inference:  34%|███▍      | 11/32 [00:05<00:10,  2.01it/s]Inference:  38%|███▊      | 12/32 [00:05<00:09,  2.03it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  2.04it/s]Inference:  44%|████▍     | 14/32 [00:06<00:08,  2.04it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  2.03it/s]Inference:  50%|█████     | 16/32 [00:07<00:07,  2.03it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  2.05it/s]Inference:  56%|█████▋    | 18/32 [00:08<00:06,  2.04it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  2.02it/s]Inference:  62%|██████▎   | 20/32 [00:09<00:05,  2.02it/s]Inference:  66%|██████▌   | 21/32 [00:10<00:05,  2.04it/s]Inference:  69%|██████▉   | 22/32 [00:10<00:04,  2.05it/s]Inference:  72%|███████▏  | 23/32 [00:11<00:04,  1.98it/s]Inference:  75%|███████▌  | 24/32 [00:11<00:04,  1.94it/s]Inference:  78%|███████▊  | 25/32 [00:12<00:03,  1.98it/s]Inference:  81%|████████▏ | 26/32 [00:12<00:03,  1.95it/s]Inference:  84%|████████▍ | 27/32 [00:13<00:02,  1.96it/s]Inference:  88%|████████▊ | 28/32 [00:13<00:02,  1.98it/s]Inference:  91%|█████████ | 29/32 [00:14<00:01,  2.01it/s]Inference:  94%|█████████▍| 30/32 [00:14<00:00,  2.02it/s]Inference:  97%|█████████▋| 31/32 [00:15<00:00,  2.02it/s]Inference: 100%|██████████| 32/32 [00:15<00:00,  2.02it/s]Inference: 100%|██████████| 32/32 [00:15<00:00,  2.01it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 9
48317 MiB free out of 48676 MiB total
Done with layer 9 total_time elapsed: 197 estimated time left: 1380
layer original dtype torch.bfloat16
skipping layer 10
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:14,  2.09it/s]Inference:   6%|▋         | 2/32 [00:00<00:14,  2.05it/s]Inference:   9%|▉         | 3/32 [00:01<00:14,  2.05it/s]Inference:  12%|█▎        | 4/32 [00:01<00:13,  2.08it/s]Inference:  16%|█▌        | 5/32 [00:02<00:13,  2.06it/s]Inference:  19%|█▉        | 6/32 [00:02<00:12,  2.08it/s]Inference:  22%|██▏       | 7/32 [00:03<00:12,  2.08it/s]Inference:  25%|██▌       | 8/32 [00:03<00:11,  2.08it/s]Inference:  28%|██▊       | 9/32 [00:04<00:11,  2.07it/s]Inference:  31%|███▏      | 10/32 [00:04<00:10,  2.07it/s]Inference:  34%|███▍      | 11/32 [00:05<00:10,  2.09it/s]Inference:  38%|███▊      | 12/32 [00:05<00:09,  2.08it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  2.08it/s]Inference:  44%|████▍     | 14/32 [00:06<00:08,  2.09it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  2.10it/s]Inference:  50%|█████     | 16/32 [00:07<00:07,  2.10it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  2.06it/s]Inference:  56%|█████▋    | 18/32 [00:08<00:06,  2.07it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  2.09it/s]Inference:  62%|██████▎   | 20/32 [00:09<00:05,  2.09it/s]Inference:  66%|██████▌   | 21/32 [00:10<00:05,  2.10it/s]Inference:  69%|██████▉   | 22/32 [00:10<00:04,  2.10it/s]Inference:  72%|███████▏  | 23/32 [00:11<00:04,  2.10it/s]Inference:  75%|███████▌  | 24/32 [00:11<00:03,  2.10it/s]Inference:  78%|███████▊  | 25/32 [00:12<00:03,  2.07it/s]Inference:  81%|████████▏ | 26/32 [00:12<00:02,  2.08it/s]Inference:  84%|████████▍ | 27/32 [00:12<00:02,  2.07it/s]Inference:  88%|████████▊ | 28/32 [00:13<00:01,  2.04it/s]Inference:  91%|█████████ | 29/32 [00:13<00:01,  2.02it/s]Inference:  94%|█████████▍| 30/32 [00:14<00:00,  2.01it/s]Inference:  97%|█████████▋| 31/32 [00:14<00:00,  2.01it/s]Inference: 100%|██████████| 32/32 [00:15<00:00,  2.02it/s]Inference: 100%|██████████| 32/32 [00:15<00:00,  2.07it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 10
48317 MiB free out of 48676 MiB total
Done with layer 10 total_time elapsed: 214 estimated time left: 1344
layer original dtype torch.bfloat16
skipping layer 11
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:14,  2.09it/s]Inference:   6%|▋         | 2/32 [00:00<00:14,  2.06it/s]Inference:   9%|▉         | 3/32 [00:01<00:14,  2.04it/s]Inference:  12%|█▎        | 4/32 [00:01<00:13,  2.04it/s]Inference:  16%|█▌        | 5/32 [00:02<00:13,  2.03it/s]Inference:  19%|█▉        | 6/32 [00:02<00:12,  2.04it/s]Inference:  22%|██▏       | 7/32 [00:03<00:12,  2.06it/s]Inference:  25%|██▌       | 8/32 [00:03<00:11,  2.03it/s]Inference:  28%|██▊       | 9/32 [00:04<00:11,  2.06it/s]Inference:  31%|███▏      | 10/32 [00:04<00:10,  2.04it/s]Inference:  34%|███▍      | 11/32 [00:05<00:10,  2.04it/s]Inference:  38%|███▊      | 12/32 [00:05<00:09,  2.03it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  2.03it/s]Inference:  44%|████▍     | 14/32 [00:06<00:08,  2.03it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  2.02it/s]Inference:  50%|█████     | 16/32 [00:07<00:07,  2.02it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  2.02it/s]Inference:  56%|█████▋    | 18/32 [00:08<00:06,  2.02it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  2.02it/s]Inference:  62%|██████▎   | 20/32 [00:09<00:05,  2.03it/s]Inference:  66%|██████▌   | 21/32 [00:10<00:05,  2.05it/s]Inference:  69%|██████▉   | 22/32 [00:10<00:04,  2.04it/s]Inference:  72%|███████▏  | 23/32 [00:11<00:04,  2.02it/s]Inference:  75%|███████▌  | 24/32 [00:11<00:03,  2.02it/s]Inference:  78%|███████▊  | 25/32 [00:12<00:03,  2.00it/s]Inference:  81%|████████▏ | 26/32 [00:12<00:03,  2.00it/s]Inference:  84%|████████▍ | 27/32 [00:13<00:02,  1.99it/s]Inference:  88%|████████▊ | 28/32 [00:13<00:01,  2.03it/s]Inference:  91%|█████████ | 29/32 [00:14<00:01,  2.03it/s]Inference:  94%|█████████▍| 30/32 [00:14<00:00,  2.02it/s]Inference:  97%|█████████▋| 31/32 [00:15<00:00,  2.04it/s]Inference: 100%|██████████| 32/32 [00:15<00:00,  2.00it/s]Inference: 100%|██████████| 32/32 [00:15<00:00,  2.03it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 11
48317 MiB free out of 48676 MiB total
Done with layer 11 total_time elapsed: 231 estimated time left: 1312
layer original dtype torch.bfloat16
skipping layer 12
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:14,  2.10it/s]Inference:   6%|▋         | 2/32 [00:00<00:14,  2.05it/s]Inference:   9%|▉         | 3/32 [00:01<00:14,  2.06it/s]Inference:  12%|█▎        | 4/32 [00:01<00:13,  2.07it/s]Inference:  16%|█▌        | 5/32 [00:02<00:13,  2.06it/s]Inference:  19%|█▉        | 6/32 [00:02<00:12,  2.04it/s]Inference:  22%|██▏       | 7/32 [00:03<00:12,  2.06it/s]Inference:  25%|██▌       | 8/32 [00:03<00:11,  2.06it/s]Inference:  28%|██▊       | 9/32 [00:04<00:11,  2.06it/s]Inference:  31%|███▏      | 10/32 [00:04<00:10,  2.04it/s]Inference:  34%|███▍      | 11/32 [00:05<00:10,  2.04it/s]Inference:  38%|███▊      | 12/32 [00:05<00:09,  2.02it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  2.04it/s]Inference:  44%|████▍     | 14/32 [00:06<00:08,  2.05it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  2.05it/s]Inference:  50%|█████     | 16/32 [00:07<00:07,  2.04it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  2.05it/s]Inference:  56%|█████▋    | 18/32 [00:08<00:06,  2.05it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  2.05it/s]Inference:  62%|██████▎   | 20/32 [00:09<00:05,  2.06it/s]Inference:  66%|██████▌   | 21/32 [00:10<00:05,  2.06it/s]Inference:  69%|██████▉   | 22/32 [00:10<00:04,  2.06it/s]Inference:  72%|███████▏  | 23/32 [00:11<00:04,  2.03it/s]Inference:  75%|███████▌  | 24/32 [00:11<00:03,  2.02it/s]Inference:  78%|███████▊  | 25/32 [00:12<00:03,  2.03it/s]Inference:  81%|████████▏ | 26/32 [00:12<00:02,  2.02it/s]Inference:  84%|████████▍ | 27/32 [00:13<00:02,  2.03it/s]Inference:  88%|████████▊ | 28/32 [00:13<00:01,  2.02it/s]Inference:  91%|█████████ | 29/32 [00:14<00:01,  2.02it/s]Inference:  94%|█████████▍| 30/32 [00:14<00:00,  2.05it/s]Inference:  97%|█████████▋| 31/32 [00:15<00:00,  2.05it/s]Inference: 100%|██████████| 32/32 [00:15<00:00,  2.02it/s]Inference: 100%|██████████| 32/32 [00:15<00:00,  2.04it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 12
48317 MiB free out of 48676 MiB total
Done with layer 12 total_time elapsed: 249 estimated time left: 1283
layer original dtype torch.bfloat16
skipping layer 13
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:14,  2.12it/s]Inference:   6%|▋         | 2/32 [00:00<00:14,  2.12it/s]Inference:   9%|▉         | 3/32 [00:01<00:13,  2.07it/s]Inference:  12%|█▎        | 4/32 [00:01<00:13,  2.07it/s]Inference:  16%|█▌        | 5/32 [00:02<00:13,  2.02it/s]Inference:  19%|█▉        | 6/32 [00:02<00:13,  2.00it/s]Inference:  22%|██▏       | 7/32 [00:03<00:12,  2.03it/s]Inference:  25%|██▌       | 8/32 [00:03<00:11,  2.05it/s]Inference:  28%|██▊       | 9/32 [00:04<00:11,  2.06it/s]Inference:  31%|███▏      | 10/32 [00:04<00:10,  2.05it/s]Inference:  34%|███▍      | 11/32 [00:05<00:10,  2.07it/s]Inference:  38%|███▊      | 12/32 [00:05<00:09,  2.07it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  2.08it/s]Inference:  44%|████▍     | 14/32 [00:06<00:08,  2.05it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  2.06it/s]Inference:  50%|█████     | 16/32 [00:07<00:07,  2.06it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  2.01it/s]Inference:  56%|█████▋    | 18/32 [00:08<00:06,  2.00it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  2.00it/s]Inference:  62%|██████▎   | 20/32 [00:09<00:06,  1.98it/s]Inference:  66%|██████▌   | 21/32 [00:10<00:05,  1.98it/s]Inference:  69%|██████▉   | 22/32 [00:10<00:05,  1.97it/s]Inference:  72%|███████▏  | 23/32 [00:11<00:04,  1.98it/s]Inference:  75%|███████▌  | 24/32 [00:11<00:03,  2.02it/s]Inference:  78%|███████▊  | 25/32 [00:12<00:03,  2.02it/s]Inference:  81%|████████▏ | 26/32 [00:12<00:02,  2.01it/s]Inference:  84%|████████▍ | 27/32 [00:13<00:02,  1.99it/s]Inference:  88%|████████▊ | 28/32 [00:13<00:02,  1.98it/s]Inference:  91%|█████████ | 29/32 [00:14<00:01,  1.99it/s]Inference:  94%|█████████▍| 30/32 [00:14<00:01,  1.97it/s]Inference:  97%|█████████▋| 31/32 [00:15<00:00,  2.02it/s]Inference: 100%|██████████| 32/32 [00:15<00:00,  1.97it/s]Inference: 100%|██████████| 32/32 [00:15<00:00,  2.02it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 13
48317 MiB free out of 48676 MiB total
Done with layer 13 total_time elapsed: 266 estimated time left: 1255
layer original dtype torch.bfloat16
skipping layer 14
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:15,  2.01it/s]Inference:   6%|▋         | 2/32 [00:00<00:15,  2.00it/s]Inference:   9%|▉         | 3/32 [00:01<00:14,  2.02it/s]Inference:  12%|█▎        | 4/32 [00:01<00:14,  2.00it/s]Inference:  16%|█▌        | 5/32 [00:02<00:13,  2.01it/s]Inference:  19%|█▉        | 6/32 [00:02<00:12,  2.01it/s]Inference:  22%|██▏       | 7/32 [00:03<00:12,  2.02it/s]Inference:  25%|██▌       | 8/32 [00:03<00:11,  2.03it/s]Inference:  28%|██▊       | 9/32 [00:04<00:11,  2.03it/s]Inference:  31%|███▏      | 10/32 [00:04<00:10,  2.03it/s]Inference:  34%|███▍      | 11/32 [00:05<00:10,  2.04it/s]Inference:  38%|███▊      | 12/32 [00:05<00:09,  2.03it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  2.03it/s]Inference:  44%|████▍     | 14/32 [00:06<00:08,  2.03it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  2.02it/s]Inference:  50%|█████     | 16/32 [00:07<00:08,  2.00it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  1.99it/s]Inference:  56%|█████▋    | 18/32 [00:08<00:07,  1.98it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  1.96it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.94it/s]Inference:  66%|██████▌   | 21/32 [00:10<00:05,  1.93it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.94it/s]Inference:  72%|███████▏  | 23/32 [00:11<00:04,  1.99it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:04,  1.99it/s]Inference:  78%|███████▊  | 25/32 [00:12<00:03,  2.02it/s]Inference:  81%|████████▏ | 26/32 [00:12<00:02,  2.04it/s]Inference:  84%|████████▍ | 27/32 [00:13<00:02,  2.03it/s]Inference:  88%|████████▊ | 28/32 [00:13<00:01,  2.00it/s]Inference:  91%|█████████ | 29/32 [00:14<00:01,  1.98it/s]Inference:  94%|█████████▍| 30/32 [00:14<00:01,  2.00it/s]Inference:  97%|█████████▋| 31/32 [00:15<00:00,  1.97it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.94it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.99it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 14
48317 MiB free out of 48676 MiB total
Done with layer 14 total_time elapsed: 284 estimated time left: 1230
layer original dtype torch.bfloat16
skipping layer 15
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:18,  1.71it/s]Inference:   6%|▋         | 2/32 [00:01<00:17,  1.68it/s]Inference:   9%|▉         | 3/32 [00:01<00:17,  1.69it/s]Inference:  12%|█▎        | 4/32 [00:02<00:16,  1.68it/s]Inference:  16%|█▌        | 5/32 [00:02<00:16,  1.67it/s]Inference:  19%|█▉        | 6/32 [00:03<00:15,  1.69it/s]Inference:  22%|██▏       | 7/32 [00:04<00:15,  1.65it/s]Inference:  25%|██▌       | 8/32 [00:04<00:14,  1.64it/s]Inference:  28%|██▊       | 9/32 [00:05<00:13,  1.65it/s]Inference:  31%|███▏      | 10/32 [00:05<00:13,  1.67it/s]Inference:  34%|███▍      | 11/32 [00:06<00:12,  1.66it/s]Inference:  38%|███▊      | 12/32 [00:07<00:12,  1.66it/s]Inference:  41%|████      | 13/32 [00:07<00:11,  1.68it/s]Inference:  44%|████▍     | 14/32 [00:08<00:10,  1.69it/s]Inference:  47%|████▋     | 15/32 [00:08<00:10,  1.69it/s]Inference:  50%|█████     | 16/32 [00:09<00:09,  1.69it/s]Inference:  53%|█████▎    | 17/32 [00:10<00:08,  1.70it/s]Inference:  56%|█████▋    | 18/32 [00:10<00:08,  1.71it/s]Inference:  59%|█████▉    | 19/32 [00:11<00:07,  1.71it/s]Inference:  62%|██████▎   | 20/32 [00:11<00:06,  1.72it/s]Inference:  66%|██████▌   | 21/32 [00:12<00:06,  1.73it/s]Inference:  69%|██████▉   | 22/32 [00:13<00:05,  1.73it/s]Inference:  72%|███████▏  | 23/32 [00:13<00:05,  1.70it/s]Inference:  75%|███████▌  | 24/32 [00:14<00:04,  1.69it/s]Inference:  78%|███████▊  | 25/32 [00:14<00:04,  1.69it/s]Inference:  81%|████████▏ | 26/32 [00:15<00:03,  1.70it/s]Inference:  84%|████████▍ | 27/32 [00:15<00:02,  1.69it/s]Inference:  88%|████████▊ | 28/32 [00:16<00:02,  1.71it/s]Inference:  91%|█████████ | 29/32 [00:17<00:01,  1.71it/s]Inference:  94%|█████████▍| 30/32 [00:17<00:01,  1.73it/s]Inference:  97%|█████████▋| 31/32 [00:18<00:00,  1.78it/s]Inference: 100%|██████████| 32/32 [00:18<00:00,  1.81it/s]Inference: 100%|██████████| 32/32 [00:18<00:00,  1.71it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 15
48317 MiB free out of 48676 MiB total
Done with layer 15 total_time elapsed: 304 estimated time left: 1217
layer original dtype torch.bfloat16
skipping layer 16
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:14,  2.10it/s]Inference:   6%|▋         | 2/32 [00:00<00:14,  2.06it/s]Inference:   9%|▉         | 3/32 [00:01<00:14,  2.00it/s]Inference:  12%|█▎        | 4/32 [00:01<00:13,  2.04it/s]Inference:  16%|█▌        | 5/32 [00:02<00:13,  2.02it/s]Inference:  19%|█▉        | 6/32 [00:02<00:12,  2.05it/s]Inference:  22%|██▏       | 7/32 [00:03<00:12,  2.06it/s]Inference:  25%|██▌       | 8/32 [00:03<00:11,  2.01it/s]Inference:  28%|██▊       | 9/32 [00:04<00:11,  2.03it/s]Inference:  31%|███▏      | 10/32 [00:04<00:10,  2.04it/s]Inference:  34%|███▍      | 11/32 [00:05<00:10,  1.99it/s]Inference:  38%|███▊      | 12/32 [00:05<00:09,  2.02it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  2.02it/s]Inference:  44%|████▍     | 14/32 [00:06<00:08,  2.05it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  2.03it/s]Inference:  50%|█████     | 16/32 [00:07<00:07,  2.02it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  2.02it/s]Inference:  56%|█████▋    | 18/32 [00:08<00:06,  2.01it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  2.02it/s]Inference:  62%|██████▎   | 20/32 [00:09<00:05,  2.00it/s]Inference:  66%|██████▌   | 21/32 [00:10<00:05,  2.02it/s]Inference:  69%|██████▉   | 22/32 [00:10<00:04,  2.02it/s]Inference:  72%|███████▏  | 23/32 [00:11<00:04,  1.99it/s]Inference:  75%|███████▌  | 24/32 [00:11<00:03,  2.03it/s]Inference:  78%|███████▊  | 25/32 [00:12<00:03,  2.05it/s]Inference:  81%|████████▏ | 26/32 [00:12<00:02,  2.06it/s]Inference:  84%|████████▍ | 27/32 [00:13<00:02,  2.05it/s]Inference:  88%|████████▊ | 28/32 [00:13<00:01,  2.01it/s]Inference:  91%|█████████ | 29/32 [00:14<00:01,  2.02it/s]Inference:  94%|█████████▍| 30/32 [00:14<00:00,  2.03it/s]Inference:  97%|█████████▋| 31/32 [00:15<00:00,  2.05it/s]Inference: 100%|██████████| 32/32 [00:15<00:00,  2.03it/s]Inference: 100%|██████████| 32/32 [00:15<00:00,  2.03it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 16
48317 MiB free out of 48676 MiB total
Done with layer 16 total_time elapsed: 322 estimated time left: 1192
layer original dtype torch.bfloat16
skipping layer 17
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:14,  2.09it/s]Inference:   6%|▋         | 2/32 [00:01<00:15,  1.98it/s]Inference:   9%|▉         | 3/32 [00:01<00:14,  2.03it/s]Inference:  12%|█▎        | 4/32 [00:01<00:14,  2.00it/s]Inference:  16%|█▌        | 5/32 [00:02<00:13,  1.97it/s]Inference:  19%|█▉        | 6/32 [00:02<00:12,  2.01it/s]Inference:  22%|██▏       | 7/32 [00:03<00:12,  2.01it/s]Inference:  25%|██▌       | 8/32 [00:04<00:12,  1.97it/s]Inference:  28%|██▊       | 9/32 [00:04<00:11,  2.01it/s]Inference:  31%|███▏      | 10/32 [00:04<00:10,  2.02it/s]Inference:  34%|███▍      | 11/32 [00:05<00:10,  2.00it/s]Inference:  38%|███▊      | 12/32 [00:05<00:09,  2.03it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  2.01it/s]Inference:  44%|████▍     | 14/32 [00:06<00:08,  2.04it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  2.06it/s]Inference:  50%|█████     | 16/32 [00:07<00:07,  2.01it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  2.04it/s]Inference:  56%|█████▋    | 18/32 [00:08<00:06,  2.02it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  1.96it/s]Inference:  62%|██████▎   | 20/32 [00:09<00:06,  1.98it/s]Inference:  66%|██████▌   | 21/32 [00:10<00:05,  2.01it/s]Inference:  69%|██████▉   | 22/32 [00:10<00:05,  2.00it/s]Inference:  72%|███████▏  | 23/32 [00:11<00:04,  2.04it/s]Inference:  75%|███████▌  | 24/32 [00:11<00:03,  2.06it/s]Inference:  78%|███████▊  | 25/32 [00:12<00:03,  2.05it/s]Inference:  81%|████████▏ | 26/32 [00:12<00:02,  2.03it/s]Inference:  84%|████████▍ | 27/32 [00:13<00:02,  2.02it/s]Inference:  88%|████████▊ | 28/32 [00:13<00:01,  2.05it/s]Inference:  91%|█████████ | 29/32 [00:14<00:01,  2.07it/s]Inference:  94%|█████████▍| 30/32 [00:14<00:00,  2.05it/s]Inference:  97%|█████████▋| 31/32 [00:15<00:00,  2.02it/s]Inference: 100%|██████████| 32/32 [00:15<00:00,  2.02it/s]Inference: 100%|██████████| 32/32 [00:15<00:00,  2.02it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 17
48317 MiB free out of 48676 MiB total
Done with layer 17 total_time elapsed: 339 estimated time left: 1168
layer original dtype torch.bfloat16
skipping layer 18
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:15,  2.06it/s]Inference:   6%|▋         | 2/32 [00:00<00:14,  2.00it/s]Inference:   9%|▉         | 3/32 [00:01<00:14,  2.00it/s]Inference:  12%|█▎        | 4/32 [00:01<00:13,  2.00it/s]Inference:  16%|█▌        | 5/32 [00:02<00:13,  2.01it/s]Inference:  19%|█▉        | 6/32 [00:02<00:12,  2.01it/s]Inference:  22%|██▏       | 7/32 [00:03<00:12,  2.01it/s]Inference:  25%|██▌       | 8/32 [00:03<00:11,  2.03it/s]Inference:  28%|██▊       | 9/32 [00:04<00:11,  2.03it/s]Inference:  31%|███▏      | 10/32 [00:04<00:10,  2.01it/s]Inference:  34%|███▍      | 11/32 [00:05<00:10,  1.99it/s]Inference:  38%|███▊      | 12/32 [00:05<00:09,  2.01it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  2.02it/s]Inference:  44%|████▍     | 14/32 [00:06<00:08,  2.00it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  1.99it/s]Inference:  50%|█████     | 16/32 [00:07<00:08,  1.97it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  1.99it/s]Inference:  56%|█████▋    | 18/32 [00:08<00:07,  1.98it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  1.96it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.96it/s]Inference:  66%|██████▌   | 21/32 [00:10<00:05,  1.99it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.98it/s]Inference:  72%|███████▏  | 23/32 [00:11<00:04,  1.98it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:04,  1.96it/s]Inference:  78%|███████▊  | 25/32 [00:12<00:03,  1.97it/s]Inference:  81%|████████▏ | 26/32 [00:13<00:03,  1.96it/s]Inference:  84%|████████▍ | 27/32 [00:13<00:02,  1.98it/s]Inference:  88%|████████▊ | 28/32 [00:14<00:01,  2.01it/s]Inference:  91%|█████████ | 29/32 [00:14<00:01,  2.01it/s]Inference:  94%|█████████▍| 30/32 [00:15<00:00,  2.01it/s]Inference:  97%|█████████▋| 31/32 [00:15<00:00,  2.00it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  2.00it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.99it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 18
48317 MiB free out of 48676 MiB total
Done with layer 18 total_time elapsed: 357 estimated time left: 1145
layer original dtype torch.bfloat16
skipping layer 19
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:15,  2.06it/s]Inference:   6%|▋         | 2/32 [00:00<00:15,  2.00it/s]Inference:   9%|▉         | 3/32 [00:01<00:14,  1.98it/s]Inference:  12%|█▎        | 4/32 [00:02<00:14,  1.94it/s]Inference:  16%|█▌        | 5/32 [00:02<00:13,  1.96it/s]Inference:  19%|█▉        | 6/32 [00:03<00:13,  1.94it/s]Inference:  22%|██▏       | 7/32 [00:03<00:12,  1.93it/s]Inference:  25%|██▌       | 8/32 [00:04<00:12,  1.90it/s]Inference:  28%|██▊       | 9/32 [00:04<00:12,  1.91it/s]Inference:  31%|███▏      | 10/32 [00:05<00:11,  1.94it/s]Inference:  34%|███▍      | 11/32 [00:05<00:10,  1.97it/s]Inference:  38%|███▊      | 12/32 [00:06<00:10,  1.98it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  2.00it/s]Inference:  44%|████▍     | 14/32 [00:07<00:09,  2.00it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  2.01it/s]Inference:  50%|█████     | 16/32 [00:08<00:08,  1.99it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  2.01it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:06,  2.01it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  1.98it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.97it/s]Inference:  66%|██████▌   | 21/32 [00:10<00:05,  1.94it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.95it/s]Inference:  72%|███████▏  | 23/32 [00:11<00:04,  1.95it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:04,  1.97it/s]Inference:  78%|███████▊  | 25/32 [00:12<00:03,  1.93it/s]Inference:  81%|████████▏ | 26/32 [00:13<00:03,  1.94it/s]Inference:  84%|████████▍ | 27/32 [00:13<00:02,  1.97it/s]Inference:  88%|████████▊ | 28/32 [00:14<00:02,  1.98it/s]Inference:  91%|█████████ | 29/32 [00:14<00:01,  1.98it/s]Inference:  94%|█████████▍| 30/32 [00:15<00:01,  1.99it/s]Inference:  97%|█████████▋| 31/32 [00:15<00:00,  2.00it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.98it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.97it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 19
48317 MiB free out of 48676 MiB total
Done with layer 19 total_time elapsed: 375 estimated time left: 1124
layer original dtype torch.bfloat16
skipping layer 20
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:15,  1.99it/s]Inference:   6%|▋         | 2/32 [00:01<00:15,  1.96it/s]Inference:   9%|▉         | 3/32 [00:01<00:14,  1.95it/s]Inference:  12%|█▎        | 4/32 [00:02<00:13,  2.01it/s]Inference:  16%|█▌        | 5/32 [00:02<00:13,  1.97it/s]Inference:  19%|█▉        | 6/32 [00:03<00:13,  1.92it/s]Inference:  22%|██▏       | 7/32 [00:03<00:13,  1.90it/s]Inference:  25%|██▌       | 8/32 [00:04<00:12,  1.88it/s]Inference:  28%|██▊       | 9/32 [00:04<00:12,  1.86it/s]Inference:  31%|███▏      | 10/32 [00:05<00:11,  1.88it/s]Inference:  34%|███▍      | 11/32 [00:05<00:10,  1.94it/s]Inference:  38%|███▊      | 12/32 [00:06<00:10,  1.91it/s]Inference:  41%|████      | 13/32 [00:06<00:10,  1.86it/s]Inference:  44%|████▍     | 14/32 [00:07<00:09,  1.87it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  1.92it/s]Inference:  50%|█████     | 16/32 [00:08<00:08,  1.87it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:08,  1.87it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:07,  1.87it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  1.92it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.87it/s]Inference:  66%|██████▌   | 21/32 [00:11<00:05,  1.85it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.82it/s]Inference:  72%|███████▏  | 23/32 [00:12<00:04,  1.89it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:04,  1.86it/s]Inference:  78%|███████▊  | 25/32 [00:13<00:03,  1.84it/s]Inference:  81%|████████▏ | 26/32 [00:13<00:03,  1.83it/s]Inference:  84%|████████▍ | 27/32 [00:14<00:02,  1.88it/s]Inference:  88%|████████▊ | 28/32 [00:14<00:02,  1.85it/s]Inference:  91%|█████████ | 29/32 [00:15<00:01,  1.83it/s]Inference:  94%|█████████▍| 30/32 [00:15<00:01,  1.83it/s]Inference:  97%|█████████▋| 31/32 [00:16<00:00,  1.89it/s]Inference: 100%|██████████| 32/32 [00:17<00:00,  1.86it/s]Inference: 100%|██████████| 32/32 [00:17<00:00,  1.88it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 20
48317 MiB free out of 48676 MiB total
Done with layer 20 total_time elapsed: 393 estimated time left: 1104
layer original dtype torch.bfloat16
skipping layer 21
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:14,  2.08it/s]Inference:   6%|▋         | 2/32 [00:01<00:15,  1.91it/s]Inference:   9%|▉         | 3/32 [00:01<00:14,  1.98it/s]Inference:  12%|█▎        | 4/32 [00:02<00:14,  1.98it/s]Inference:  16%|█▌        | 5/32 [00:02<00:14,  1.91it/s]Inference:  19%|█▉        | 6/32 [00:03<00:14,  1.85it/s]Inference:  22%|██▏       | 7/32 [00:03<00:13,  1.87it/s]Inference:  25%|██▌       | 8/32 [00:04<00:12,  1.92it/s]Inference:  28%|██▊       | 9/32 [00:04<00:11,  1.95it/s]Inference:  31%|███▏      | 10/32 [00:05<00:11,  1.88it/s]Inference:  34%|███▍      | 11/32 [00:05<00:11,  1.85it/s]Inference:  38%|███▊      | 12/32 [00:06<00:10,  1.86it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  1.92it/s]Inference:  44%|████▍     | 14/32 [00:07<00:09,  1.88it/s]Inference:  47%|████▋     | 15/32 [00:07<00:09,  1.85it/s]Inference:  50%|█████     | 16/32 [00:08<00:08,  1.83it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  1.88it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:07,  1.84it/s]Inference:  59%|█████▉    | 19/32 [00:10<00:07,  1.83it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.82it/s]Inference:  66%|██████▌   | 21/32 [00:11<00:05,  1.87it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.82it/s]Inference:  72%|███████▏  | 23/32 [00:12<00:04,  1.83it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:04,  1.82it/s]Inference:  78%|███████▊  | 25/32 [00:13<00:03,  1.87it/s]Inference:  81%|████████▏ | 26/32 [00:13<00:03,  1.84it/s]Inference:  84%|████████▍ | 27/32 [00:14<00:02,  1.82it/s]Inference:  88%|████████▊ | 28/32 [00:15<00:02,  1.81it/s]Inference:  91%|█████████ | 29/32 [00:15<00:01,  1.83it/s]Inference:  94%|█████████▍| 30/32 [00:16<00:01,  1.83it/s]Inference:  97%|█████████▋| 31/32 [00:16<00:00,  1.84it/s]Inference: 100%|██████████| 32/32 [00:17<00:00,  1.82it/s]Inference: 100%|██████████| 32/32 [00:17<00:00,  1.86it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 21
48317 MiB free out of 48676 MiB total
Done with layer 21 total_time elapsed: 412 estimated time left: 1086
layer original dtype torch.bfloat16
skipping layer 22
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:15,  2.04it/s]Inference:   6%|▋         | 2/32 [00:01<00:15,  1.89it/s]Inference:   9%|▉         | 3/32 [00:01<00:14,  1.95it/s]Inference:  12%|█▎        | 4/32 [00:02<00:14,  1.88it/s]Inference:  16%|█▌        | 5/32 [00:02<00:14,  1.85it/s]Inference:  19%|█▉        | 6/32 [00:03<00:14,  1.82it/s]Inference:  22%|██▏       | 7/32 [00:03<00:13,  1.88it/s]Inference:  25%|██▌       | 8/32 [00:04<00:12,  1.85it/s]Inference:  28%|██▊       | 9/32 [00:04<00:12,  1.83it/s]Inference:  31%|███▏      | 10/32 [00:05<00:12,  1.82it/s]Inference:  34%|███▍      | 11/32 [00:05<00:11,  1.86it/s]Inference:  38%|███▊      | 12/32 [00:06<00:10,  1.83it/s]Inference:  41%|████      | 13/32 [00:06<00:10,  1.90it/s]Inference:  44%|████▍     | 14/32 [00:07<00:09,  1.86it/s]Inference:  47%|████▋     | 15/32 [00:08<00:08,  1.89it/s]Inference:  50%|█████     | 16/32 [00:08<00:08,  1.93it/s]Inference:  53%|█████▎    | 17/32 [00:09<00:07,  1.89it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:07,  1.87it/s]Inference:  59%|█████▉    | 19/32 [00:10<00:06,  1.87it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.91it/s]Inference:  66%|██████▌   | 21/32 [00:11<00:05,  1.87it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.84it/s]Inference:  72%|███████▏  | 23/32 [00:12<00:04,  1.81it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:04,  1.85it/s]Inference:  78%|███████▊  | 25/32 [00:13<00:03,  1.82it/s]Inference:  81%|████████▏ | 26/32 [00:13<00:03,  1.81it/s]Inference:  84%|████████▍ | 27/32 [00:14<00:02,  1.81it/s]Inference:  88%|████████▊ | 28/32 [00:15<00:02,  1.86it/s]Inference:  91%|█████████ | 29/32 [00:15<00:01,  1.83it/s]Inference:  94%|█████████▍| 30/32 [00:16<00:01,  1.82it/s]Inference:  97%|█████████▋| 31/32 [00:16<00:00,  1.81it/s]Inference: 100%|██████████| 32/32 [00:17<00:00,  1.88it/s]Inference: 100%|██████████| 32/32 [00:17<00:00,  1.86it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 22
48317 MiB free out of 48676 MiB total
Done with layer 22 total_time elapsed: 431 estimated time left: 1067
layer original dtype torch.bfloat16
skipping layer 23
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:16,  1.91it/s]Inference:   6%|▋         | 2/32 [00:01<00:16,  1.82it/s]Inference:   9%|▉         | 3/32 [00:01<00:14,  1.95it/s]Inference:  12%|█▎        | 4/32 [00:02<00:14,  1.89it/s]Inference:  16%|█▌        | 5/32 [00:02<00:14,  1.89it/s]Inference:  19%|█▉        | 6/32 [00:03<00:14,  1.86it/s]Inference:  22%|██▏       | 7/32 [00:03<00:13,  1.84it/s]Inference:  25%|██▌       | 8/32 [00:04<00:13,  1.82it/s]Inference:  28%|██▊       | 9/32 [00:04<00:12,  1.85it/s]Inference:  31%|███▏      | 10/32 [00:05<00:11,  1.91it/s]Inference:  34%|███▍      | 11/32 [00:05<00:11,  1.87it/s]Inference:  38%|███▊      | 12/32 [00:06<00:10,  1.84it/s]Inference:  41%|████      | 13/32 [00:06<00:10,  1.83it/s]Inference:  44%|████▍     | 14/32 [00:07<00:09,  1.90it/s]Inference:  47%|████▋     | 15/32 [00:08<00:09,  1.88it/s]Inference:  50%|█████     | 16/32 [00:08<00:08,  1.86it/s]Inference:  53%|█████▎    | 17/32 [00:09<00:07,  1.92it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:07,  1.90it/s]Inference:  59%|█████▉    | 19/32 [00:10<00:06,  1.87it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.84it/s]Inference:  66%|██████▌   | 21/32 [00:11<00:06,  1.82it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.83it/s]Inference:  72%|███████▏  | 23/32 [00:12<00:04,  1.89it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:04,  1.85it/s]Inference:  78%|███████▊  | 25/32 [00:13<00:03,  1.84it/s]Inference:  81%|████████▏ | 26/32 [00:13<00:03,  1.83it/s]Inference:  84%|████████▍ | 27/32 [00:14<00:02,  1.89it/s]Inference:  88%|████████▊ | 28/32 [00:15<00:02,  1.85it/s]Inference:  91%|█████████ | 29/32 [00:15<00:01,  1.83it/s]Inference:  94%|█████████▍| 30/32 [00:16<00:01,  1.81it/s]Inference:  97%|█████████▋| 31/32 [00:16<00:00,  1.83it/s]Inference: 100%|██████████| 32/32 [00:17<00:00,  1.81it/s]Inference: 100%|██████████| 32/32 [00:17<00:00,  1.85it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 23
48317 MiB free out of 48676 MiB total
Done with layer 23 total_time elapsed: 450 estimated time left: 1049
layer original dtype torch.bfloat16
skipping layer 24
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:15,  2.01it/s]Inference:   6%|▋         | 2/32 [00:01<00:15,  1.89it/s]Inference:   9%|▉         | 3/32 [00:01<00:15,  1.90it/s]Inference:  12%|█▎        | 4/32 [00:02<00:15,  1.86it/s]Inference:  16%|█▌        | 5/32 [00:02<00:14,  1.86it/s]Inference:  19%|█▉        | 6/32 [00:03<00:13,  1.86it/s]Inference:  22%|██▏       | 7/32 [00:03<00:13,  1.84it/s]Inference:  25%|██▌       | 8/32 [00:04<00:13,  1.82it/s]Inference:  28%|██▊       | 9/32 [00:04<00:12,  1.83it/s]Inference:  31%|███▏      | 10/32 [00:05<00:11,  1.86it/s]Inference:  34%|███▍      | 11/32 [00:05<00:11,  1.86it/s]Inference:  38%|███▊      | 12/32 [00:06<00:10,  1.85it/s]Inference:  41%|████      | 13/32 [00:06<00:10,  1.87it/s]Inference:  44%|████▍     | 14/32 [00:07<00:09,  1.89it/s]Inference:  47%|████▋     | 15/32 [00:08<00:08,  1.90it/s]Inference:  50%|█████     | 16/32 [00:08<00:08,  1.93it/s]Inference:  53%|█████▎    | 17/32 [00:09<00:07,  1.91it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:07,  1.89it/s]Inference:  59%|█████▉    | 19/32 [00:10<00:06,  1.88it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.87it/s]Inference:  66%|██████▌   | 21/32 [00:11<00:05,  1.87it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.87it/s]Inference:  72%|███████▏  | 23/32 [00:12<00:04,  1.88it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:04,  1.87it/s]Inference:  78%|███████▊  | 25/32 [00:13<00:03,  1.90it/s]Inference:  81%|████████▏ | 26/32 [00:13<00:03,  1.89it/s]Inference:  84%|████████▍ | 27/32 [00:14<00:02,  1.87it/s]Inference:  88%|████████▊ | 28/32 [00:14<00:02,  1.85it/s]Inference:  91%|█████████ | 29/32 [00:15<00:01,  1.84it/s]Inference:  94%|█████████▍| 30/32 [00:16<00:01,  1.82it/s]Inference:  97%|█████████▋| 31/32 [00:16<00:00,  1.87it/s]Inference: 100%|██████████| 32/32 [00:17<00:00,  1.85it/s]Inference: 100%|██████████| 32/32 [00:17<00:00,  1.87it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 24
48317 MiB free out of 48676 MiB total
Done with layer 24 total_time elapsed: 468 estimated time left: 1030
layer original dtype torch.bfloat16
skipping layer 25
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:15,  2.02it/s]Inference:   6%|▋         | 2/32 [00:00<00:14,  2.03it/s]Inference:   9%|▉         | 3/32 [00:01<00:15,  1.90it/s]Inference:  12%|█▎        | 4/32 [00:02<00:14,  1.87it/s]Inference:  16%|█▌        | 5/32 [00:02<00:13,  1.94it/s]Inference:  19%|█▉        | 6/32 [00:03<00:13,  1.89it/s]Inference:  22%|██▏       | 7/32 [00:03<00:13,  1.85it/s]Inference:  25%|██▌       | 8/32 [00:04<00:13,  1.84it/s]Inference:  28%|██▊       | 9/32 [00:04<00:12,  1.87it/s]Inference:  31%|███▏      | 10/32 [00:05<00:11,  1.87it/s]Inference:  34%|███▍      | 11/32 [00:05<00:11,  1.86it/s]Inference:  38%|███▊      | 12/32 [00:06<00:10,  1.91it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  1.94it/s]Inference:  44%|████▍     | 14/32 [00:07<00:09,  1.96it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  1.90it/s]Inference:  50%|█████     | 16/32 [00:08<00:08,  1.95it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  1.90it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:07,  1.91it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  1.88it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.87it/s]Inference:  66%|██████▌   | 21/32 [00:11<00:05,  1.85it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.86it/s]Inference:  72%|███████▏  | 23/32 [00:12<00:04,  1.88it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:04,  1.85it/s]Inference:  78%|███████▊  | 25/32 [00:13<00:03,  1.83it/s]Inference:  81%|████████▏ | 26/32 [00:13<00:03,  1.84it/s]Inference:  84%|████████▍ | 27/32 [00:14<00:02,  1.90it/s]Inference:  88%|████████▊ | 28/32 [00:14<00:02,  1.86it/s]Inference:  91%|█████████ | 29/32 [00:15<00:01,  1.84it/s]Inference:  94%|█████████▍| 30/32 [00:15<00:01,  1.89it/s]Inference:  97%|█████████▋| 31/32 [00:16<00:00,  1.93it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.89it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.89it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 25
48317 MiB free out of 48676 MiB total
Done with layer 25 total_time elapsed: 487 estimated time left: 1011
layer original dtype torch.bfloat16
skipping layer 26
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:15,  2.05it/s]Inference:   6%|▋         | 2/32 [00:00<00:14,  2.05it/s]Inference:   9%|▉         | 3/32 [00:01<00:14,  1.94it/s]Inference:  12%|█▎        | 4/32 [00:02<00:14,  1.96it/s]Inference:  16%|█▌        | 5/32 [00:02<00:14,  1.91it/s]Inference:  19%|█▉        | 6/32 [00:03<00:13,  1.95it/s]Inference:  22%|██▏       | 7/32 [00:03<00:12,  1.97it/s]Inference:  25%|██▌       | 8/32 [00:04<00:12,  1.95it/s]Inference:  28%|██▊       | 9/32 [00:04<00:11,  1.98it/s]Inference:  31%|███▏      | 10/32 [00:05<00:11,  1.94it/s]Inference:  34%|███▍      | 11/32 [00:05<00:11,  1.90it/s]Inference:  38%|███▊      | 12/32 [00:06<00:10,  1.88it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  1.93it/s]Inference:  44%|████▍     | 14/32 [00:07<00:09,  1.90it/s]Inference:  47%|████▋     | 15/32 [00:07<00:09,  1.88it/s]Inference:  50%|█████     | 16/32 [00:08<00:08,  1.84it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  1.90it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:07,  1.88it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  1.86it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.84it/s]Inference:  66%|██████▌   | 21/32 [00:11<00:05,  1.88it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.88it/s]Inference:  72%|███████▏  | 23/32 [00:12<00:04,  1.92it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:04,  1.89it/s]Inference:  78%|███████▊  | 25/32 [00:13<00:03,  1.88it/s]Inference:  81%|████████▏ | 26/32 [00:13<00:03,  1.91it/s]Inference:  84%|████████▍ | 27/32 [00:14<00:02,  1.88it/s]Inference:  88%|████████▊ | 28/32 [00:14<00:02,  1.86it/s]Inference:  91%|█████████ | 29/32 [00:15<00:01,  1.76it/s]Inference:  94%|█████████▍| 30/32 [00:16<00:01,  1.66it/s]Inference:  97%|█████████▋| 31/32 [00:16<00:00,  1.58it/s]Inference: 100%|██████████| 32/32 [00:17<00:00,  1.51it/s]Inference: 100%|██████████| 32/32 [00:17<00:00,  1.83it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 26
48317 MiB free out of 48676 MiB total
Done with layer 26 total_time elapsed: 506 estimated time left: 993
layer original dtype torch.bfloat16
skipping layer 27
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:15,  2.01it/s]Inference:   6%|▋         | 2/32 [00:00<00:14,  2.01it/s]Inference:   9%|▉         | 3/32 [00:01<00:15,  1.85it/s]Inference:  12%|█▎        | 4/32 [00:02<00:15,  1.83it/s]Inference:  16%|█▌        | 5/32 [00:02<00:14,  1.80it/s]Inference:  19%|█▉        | 6/32 [00:03<00:13,  1.86it/s]Inference:  22%|██▏       | 7/32 [00:03<00:13,  1.84it/s]Inference:  25%|██▌       | 8/32 [00:04<00:13,  1.83it/s]Inference:  28%|██▊       | 9/32 [00:04<00:12,  1.81it/s]Inference:  31%|███▏      | 10/32 [00:05<00:11,  1.84it/s]Inference:  34%|███▍      | 11/32 [00:05<00:11,  1.90it/s]Inference:  38%|███▊      | 12/32 [00:06<00:10,  1.88it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  1.93it/s]Inference:  44%|████▍     | 14/32 [00:07<00:09,  1.88it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  1.92it/s]Inference:  50%|█████     | 16/32 [00:08<00:08,  1.95it/s]Inference:  53%|█████▎    | 17/32 [00:09<00:07,  1.89it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:07,  1.86it/s]Inference:  59%|█████▉    | 19/32 [00:10<00:06,  1.92it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.89it/s]Inference:  66%|██████▌   | 21/32 [00:11<00:05,  1.86it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.83it/s]Inference:  72%|███████▏  | 23/32 [00:12<00:04,  1.86it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:04,  1.92it/s]Inference:  78%|███████▊  | 25/32 [00:13<00:03,  1.89it/s]Inference:  81%|████████▏ | 26/32 [00:13<00:03,  1.87it/s]Inference:  84%|████████▍ | 27/32 [00:14<00:02,  1.89it/s]Inference:  88%|████████▊ | 28/32 [00:14<00:02,  1.88it/s]Inference:  91%|█████████ | 29/32 [00:15<00:01,  1.87it/s]Inference:  94%|█████████▍| 30/32 [00:16<00:01,  1.84it/s]Inference:  97%|█████████▋| 31/32 [00:16<00:00,  1.85it/s]Inference: 100%|██████████| 32/32 [00:17<00:00,  1.90it/s]Inference: 100%|██████████| 32/32 [00:17<00:00,  1.88it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 27
48317 MiB free out of 48676 MiB total
Done with layer 27 total_time elapsed: 524 estimated time left: 974
layer original dtype torch.bfloat16
skipping layer 28
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:15,  1.99it/s]Inference:   6%|▋         | 2/32 [00:01<00:15,  1.89it/s]Inference:   9%|▉         | 3/32 [00:01<00:15,  1.85it/s]Inference:  12%|█▎        | 4/32 [00:02<00:15,  1.84it/s]Inference:  16%|█▌        | 5/32 [00:02<00:15,  1.79it/s]Inference:  19%|█▉        | 6/32 [00:03<00:13,  1.86it/s]Inference:  22%|██▏       | 7/32 [00:03<00:13,  1.85it/s]Inference:  25%|██▌       | 8/32 [00:04<00:13,  1.84it/s]Inference:  28%|██▊       | 9/32 [00:04<00:12,  1.79it/s]Inference:  31%|███▏      | 10/32 [00:05<00:12,  1.82it/s]Inference:  34%|███▍      | 11/32 [00:06<00:11,  1.82it/s]Inference:  38%|███▊      | 12/32 [00:06<00:11,  1.82it/s]Inference:  41%|████      | 13/32 [00:07<00:10,  1.89it/s]Inference:  44%|████▍     | 14/32 [00:07<00:09,  1.87it/s]Inference:  47%|████▋     | 15/32 [00:08<00:09,  1.82it/s]Inference:  50%|█████     | 16/32 [00:08<00:09,  1.77it/s]Inference:  53%|█████▎    | 17/32 [00:09<00:08,  1.67it/s]Inference:  56%|█████▋    | 18/32 [00:10<00:08,  1.61it/s]Inference:  59%|█████▉    | 19/32 [00:10<00:08,  1.55it/s]Inference:  62%|██████▎   | 20/32 [00:11<00:08,  1.49it/s]Inference:  66%|██████▌   | 21/32 [00:12<00:07,  1.46it/s]Inference:  69%|██████▉   | 22/32 [00:12<00:06,  1.49it/s]Inference:  72%|███████▏  | 23/32 [00:13<00:06,  1.48it/s]Inference:  75%|███████▌  | 24/32 [00:14<00:05,  1.47it/s]Inference:  78%|███████▊  | 25/32 [00:14<00:04,  1.46it/s]Inference:  81%|████████▏ | 26/32 [00:15<00:04,  1.45it/s]Inference:  84%|████████▍ | 27/32 [00:16<00:03,  1.46it/s]Inference:  88%|████████▊ | 28/32 [00:17<00:02,  1.45it/s]Inference:  91%|█████████ | 29/32 [00:17<00:02,  1.48it/s]Inference:  94%|█████████▍| 30/32 [00:18<00:01,  1.53it/s]Inference:  97%|█████████▋| 31/32 [00:18<00:00,  1.56it/s]Inference: 100%|██████████| 32/32 [00:19<00:00,  1.58it/s]Inference: 100%|██████████| 32/32 [00:19<00:00,  1.64it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 28
48317 MiB free out of 48676 MiB total
Done with layer 28 total_time elapsed: 546 estimated time left: 959
layer original dtype torch.bfloat16
skipping layer 29
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:15,  2.03it/s]Inference:   6%|▋         | 2/32 [00:01<00:15,  1.90it/s]Inference:   9%|▉         | 3/32 [00:01<00:15,  1.84it/s]Inference:  12%|█▎        | 4/32 [00:02<00:15,  1.83it/s]Inference:  16%|█▌        | 5/32 [00:02<00:14,  1.82it/s]Inference:  19%|█▉        | 6/32 [00:03<00:14,  1.82it/s]Inference:  22%|██▏       | 7/32 [00:03<00:13,  1.83it/s]Inference:  25%|██▌       | 8/32 [00:04<00:12,  1.87it/s]Inference:  28%|██▊       | 9/32 [00:04<00:12,  1.88it/s]Inference:  31%|███▏      | 10/32 [00:05<00:11,  1.85it/s]Inference:  34%|███▍      | 11/32 [00:05<00:11,  1.82it/s]Inference:  38%|███▊      | 12/32 [00:06<00:11,  1.80it/s]Inference:  41%|████      | 13/32 [00:07<00:10,  1.82it/s]Inference:  44%|████▍     | 14/32 [00:07<00:09,  1.81it/s]Inference:  47%|████▋     | 15/32 [00:08<00:09,  1.79it/s]Inference:  50%|█████     | 16/32 [00:08<00:08,  1.78it/s]Inference:  53%|█████▎    | 17/32 [00:09<00:08,  1.79it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:07,  1.83it/s]Inference:  59%|█████▉    | 19/32 [00:10<00:07,  1.74it/s]Inference:  62%|██████▎   | 20/32 [00:11<00:07,  1.62it/s]Inference:  66%|██████▌   | 21/32 [00:11<00:06,  1.58it/s]Inference:  69%|██████▉   | 22/32 [00:12<00:06,  1.55it/s]Inference:  72%|███████▏  | 23/32 [00:13<00:05,  1.51it/s]Inference:  75%|███████▌  | 24/32 [00:13<00:05,  1.48it/s]Inference:  78%|███████▊  | 25/32 [00:14<00:04,  1.51it/s]Inference:  81%|████████▏ | 26/32 [00:15<00:04,  1.48it/s]Inference:  84%|████████▍ | 27/32 [00:15<00:03,  1.46it/s]Inference:  88%|████████▊ | 28/32 [00:16<00:02,  1.49it/s]Inference:  91%|█████████ | 29/32 [00:17<00:02,  1.48it/s]Inference:  94%|█████████▍| 30/32 [00:18<00:01,  1.46it/s]Inference:  97%|█████████▋| 31/32 [00:18<00:00,  1.46it/s]Inference: 100%|██████████| 32/32 [00:19<00:00,  1.49it/s]Inference: 100%|██████████| 32/32 [00:19<00:00,  1.65it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 29
48317 MiB free out of 48676 MiB total
Done with layer 29 total_time elapsed: 567 estimated time left: 945
layer original dtype torch.bfloat16
skipping layer 30
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:20,  1.49it/s]Inference:   6%|▋         | 2/32 [00:01<00:21,  1.40it/s]Inference:   9%|▉         | 3/32 [00:02<00:20,  1.41it/s]Inference:  12%|█▎        | 4/32 [00:02<00:19,  1.44it/s]Inference:  16%|█▌        | 5/32 [00:03<00:18,  1.44it/s]Inference:  19%|█▉        | 6/32 [00:04<00:18,  1.42it/s]Inference:  22%|██▏       | 7/32 [00:04<00:17,  1.42it/s]Inference:  25%|██▌       | 8/32 [00:05<00:16,  1.46it/s]Inference:  28%|██▊       | 9/32 [00:06<00:16,  1.43it/s]Inference:  31%|███▏      | 10/32 [00:06<00:15,  1.42it/s]Inference:  34%|███▍      | 11/32 [00:07<00:14,  1.43it/s]Inference:  38%|███▊      | 12/32 [00:08<00:13,  1.44it/s]Inference:  41%|████      | 13/32 [00:09<00:13,  1.43it/s]Inference:  44%|████▍     | 14/32 [00:09<00:12,  1.44it/s]Inference:  47%|████▋     | 15/32 [00:10<00:11,  1.47it/s]Inference:  50%|█████     | 16/32 [00:11<00:10,  1.49it/s]Inference:  53%|█████▎    | 17/32 [00:11<00:09,  1.53it/s]Inference:  56%|█████▋    | 18/32 [00:12<00:08,  1.57it/s]Inference:  59%|█████▉    | 19/32 [00:12<00:08,  1.55it/s]Inference:  62%|██████▎   | 20/32 [00:13<00:07,  1.56it/s]Inference:  66%|██████▌   | 21/32 [00:14<00:07,  1.57it/s]Inference:  69%|██████▉   | 22/32 [00:14<00:06,  1.61it/s]Inference:  72%|███████▏  | 23/32 [00:15<00:05,  1.59it/s]Inference:  75%|███████▌  | 24/32 [00:16<00:05,  1.59it/s]Inference:  78%|███████▊  | 25/32 [00:16<00:04,  1.58it/s]Inference:  81%|████████▏ | 26/32 [00:17<00:03,  1.61it/s]Inference:  84%|████████▍ | 27/32 [00:17<00:03,  1.58it/s]Inference:  88%|████████▊ | 28/32 [00:18<00:02,  1.57it/s]Inference:  91%|█████████ | 29/32 [00:19<00:01,  1.60it/s]Inference:  94%|█████████▍| 30/32 [00:19<00:01,  1.64it/s]Inference:  97%|█████████▋| 31/32 [00:20<00:00,  1.62it/s]Inference: 100%|██████████| 32/32 [00:21<00:00,  1.59it/s]Inference: 100%|██████████| 32/32 [00:21<00:00,  1.52it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 30
48317 MiB free out of 48676 MiB total
Done with layer 30 total_time elapsed: 589 estimated time left: 932
layer original dtype torch.bfloat16
skipping layer 31
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:20,  1.53it/s]Inference:   6%|▋         | 2/32 [00:01<00:20,  1.49it/s]Inference:   9%|▉         | 3/32 [00:02<00:19,  1.45it/s]Inference:  12%|█▎        | 4/32 [00:02<00:19,  1.43it/s]Inference:  16%|█▌        | 5/32 [00:03<00:18,  1.43it/s]Inference:  19%|█▉        | 6/32 [00:04<00:17,  1.48it/s]Inference:  22%|██▏       | 7/32 [00:04<00:17,  1.46it/s]Inference:  25%|██▌       | 8/32 [00:05<00:16,  1.45it/s]Inference:  28%|██▊       | 9/32 [00:06<00:15,  1.46it/s]Inference:  31%|███▏      | 10/32 [00:06<00:15,  1.45it/s]Inference:  34%|███▍      | 11/32 [00:07<00:14,  1.45it/s]Inference:  38%|███▊      | 12/32 [00:08<00:13,  1.44it/s]Inference:  41%|████      | 13/32 [00:08<00:12,  1.48it/s]Inference:  44%|████▍     | 14/32 [00:09<00:12,  1.45it/s]Inference:  47%|████▋     | 15/32 [00:10<00:11,  1.43it/s]Inference:  50%|█████     | 16/32 [00:11<00:11,  1.45it/s]Inference:  53%|█████▎    | 17/32 [00:11<00:10,  1.45it/s]Inference:  56%|█████▋    | 18/32 [00:12<00:09,  1.43it/s]Inference:  59%|█████▉    | 19/32 [00:13<00:08,  1.46it/s]Inference:  62%|██████▎   | 20/32 [00:13<00:08,  1.49it/s]Inference:  66%|██████▌   | 21/32 [00:14<00:07,  1.51it/s]Inference:  69%|██████▉   | 22/32 [00:15<00:06,  1.50it/s]Inference:  72%|███████▏  | 23/32 [00:15<00:05,  1.54it/s]Inference:  75%|███████▌  | 24/32 [00:16<00:05,  1.53it/s]Inference:  78%|███████▊  | 25/32 [00:16<00:04,  1.53it/s]Inference:  81%|████████▏ | 26/32 [00:17<00:03,  1.53it/s]Inference:  84%|████████▍ | 27/32 [00:18<00:03,  1.59it/s]Inference:  88%|████████▊ | 28/32 [00:18<00:02,  1.56it/s]Inference:  91%|█████████ | 29/32 [00:19<00:01,  1.55it/s]Inference:  94%|█████████▍| 30/32 [00:20<00:01,  1.55it/s]Inference:  97%|█████████▋| 31/32 [00:20<00:00,  1.58it/s]Inference: 100%|██████████| 32/32 [00:21<00:00,  1.60it/s]Inference: 100%|██████████| 32/32 [00:21<00:00,  1.50it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 31
48317 MiB free out of 48676 MiB total
Done with layer 31 total_time elapsed: 612 estimated time left: 918
layer original dtype torch.bfloat16
skipping layer 32
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:18,  1.64it/s]Inference:   6%|▋         | 2/32 [00:01<00:17,  1.68it/s]Inference:   9%|▉         | 3/32 [00:01<00:17,  1.69it/s]Inference:  12%|█▎        | 4/32 [00:02<00:16,  1.65it/s]Inference:  16%|█▌        | 5/32 [00:03<00:16,  1.62it/s]Inference:  19%|█▉        | 6/32 [00:03<00:16,  1.59it/s]Inference:  22%|██▏       | 7/32 [00:04<00:15,  1.63it/s]Inference:  25%|██▌       | 8/32 [00:04<00:14,  1.61it/s]Inference:  28%|██▊       | 9/32 [00:05<00:14,  1.64it/s]Inference:  31%|███▏      | 10/32 [00:06<00:13,  1.59it/s]Inference:  34%|███▍      | 11/32 [00:06<00:12,  1.62it/s]Inference:  38%|███▊      | 12/32 [00:07<00:12,  1.61it/s]Inference:  41%|████      | 13/32 [00:08<00:11,  1.60it/s]Inference:  44%|████▍     | 14/32 [00:08<00:11,  1.58it/s]Inference:  47%|████▋     | 15/32 [00:09<00:10,  1.59it/s]Inference:  50%|█████     | 16/32 [00:09<00:10,  1.56it/s]Inference:  53%|█████▎    | 17/32 [00:10<00:09,  1.52it/s]Inference:  56%|█████▋    | 18/32 [00:11<00:09,  1.51it/s]Inference:  59%|█████▉    | 19/32 [00:11<00:08,  1.51it/s]Inference:  62%|██████▎   | 20/32 [00:12<00:08,  1.48it/s]Inference:  66%|██████▌   | 21/32 [00:13<00:07,  1.45it/s]Inference:  69%|██████▉   | 22/32 [00:14<00:06,  1.48it/s]Inference:  72%|███████▏  | 23/32 [00:14<00:06,  1.48it/s]Inference:  75%|███████▌  | 24/32 [00:15<00:05,  1.48it/s]Inference:  78%|███████▊  | 25/32 [00:16<00:04,  1.49it/s]Inference:  81%|████████▏ | 26/32 [00:16<00:04,  1.49it/s]Inference:  84%|████████▍ | 27/32 [00:17<00:03,  1.49it/s]Inference:  88%|████████▊ | 28/32 [00:18<00:02,  1.48it/s]Inference:  91%|█████████ | 29/32 [00:18<00:02,  1.45it/s]Inference:  94%|█████████▍| 30/32 [00:19<00:01,  1.46it/s]Inference:  97%|█████████▋| 31/32 [00:20<00:00,  1.46it/s]Inference: 100%|██████████| 32/32 [00:20<00:00,  1.47it/s]Inference: 100%|██████████| 32/32 [00:20<00:00,  1.53it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 32
48317 MiB free out of 48676 MiB total
Done with layer 32 total_time elapsed: 635 estimated time left: 904
layer original dtype torch.bfloat16
skipping layer 33
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:18,  1.69it/s]Inference:   6%|▋         | 2/32 [00:01<00:18,  1.59it/s]Inference:   9%|▉         | 3/32 [00:01<00:17,  1.62it/s]Inference:  12%|█▎        | 4/32 [00:02<00:16,  1.66it/s]Inference:  16%|█▌        | 5/32 [00:03<00:16,  1.64it/s]Inference:  19%|█▉        | 6/32 [00:03<00:15,  1.63it/s]Inference:  22%|██▏       | 7/32 [00:04<00:15,  1.62it/s]Inference:  25%|██▌       | 8/32 [00:04<00:14,  1.64it/s]Inference:  28%|██▊       | 9/32 [00:05<00:14,  1.63it/s]Inference:  31%|███▏      | 10/32 [00:06<00:13,  1.62it/s]Inference:  34%|███▍      | 11/32 [00:06<00:13,  1.61it/s]Inference:  38%|███▊      | 12/32 [00:07<00:12,  1.61it/s]Inference:  41%|████      | 13/32 [00:07<00:11,  1.62it/s]Inference:  44%|████▍     | 14/32 [00:08<00:11,  1.63it/s]Inference:  47%|████▋     | 15/32 [00:09<00:10,  1.64it/s]Inference:  50%|█████     | 16/32 [00:09<00:09,  1.66it/s]Inference:  53%|█████▎    | 17/32 [00:10<00:09,  1.65it/s]Inference:  56%|█████▋    | 18/32 [00:11<00:08,  1.64it/s]Inference:  59%|█████▉    | 19/32 [00:11<00:07,  1.66it/s]Inference:  62%|██████▎   | 20/32 [00:12<00:07,  1.66it/s]Inference:  66%|██████▌   | 21/32 [00:12<00:06,  1.65it/s]Inference:  69%|██████▉   | 22/32 [00:13<00:06,  1.64it/s]Inference:  72%|███████▏  | 23/32 [00:14<00:05,  1.66it/s]Inference:  75%|███████▌  | 24/32 [00:14<00:04,  1.64it/s]Inference:  78%|███████▊  | 25/32 [00:15<00:04,  1.66it/s]Inference:  81%|████████▏ | 26/32 [00:15<00:03,  1.61it/s]Inference:  84%|████████▍ | 27/32 [00:16<00:03,  1.62it/s]Inference:  88%|████████▊ | 28/32 [00:17<00:02,  1.59it/s]Inference:  91%|█████████ | 29/32 [00:17<00:01,  1.57it/s]Inference:  94%|█████████▍| 30/32 [00:18<00:01,  1.59it/s]Inference:  97%|█████████▋| 31/32 [00:19<00:00,  1.63it/s]Inference: 100%|██████████| 32/32 [00:19<00:00,  1.67it/s]Inference: 100%|██████████| 32/32 [00:19<00:00,  1.63it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 33
48317 MiB free out of 48676 MiB total
Done with layer 33 total_time elapsed: 656 estimated time left: 888
layer original dtype torch.bfloat16
skipping layer 34
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:16,  1.89it/s]Inference:   6%|▋         | 2/32 [00:01<00:17,  1.76it/s]Inference:   9%|▉         | 3/32 [00:01<00:15,  1.86it/s]Inference:  12%|█▎        | 4/32 [00:02<00:15,  1.80it/s]Inference:  16%|█▌        | 5/32 [00:02<00:15,  1.79it/s]Inference:  19%|█▉        | 6/32 [00:03<00:14,  1.78it/s]Inference:  22%|██▏       | 7/32 [00:03<00:13,  1.84it/s]Inference:  25%|██▌       | 8/32 [00:04<00:13,  1.80it/s]Inference:  28%|██▊       | 9/32 [00:04<00:12,  1.80it/s]Inference:  31%|███▏      | 10/32 [00:05<00:12,  1.79it/s]Inference:  34%|███▍      | 11/32 [00:06<00:11,  1.84it/s]Inference:  38%|███▊      | 12/32 [00:06<00:11,  1.81it/s]Inference:  41%|████      | 13/32 [00:07<00:10,  1.80it/s]Inference:  44%|████▍     | 14/32 [00:07<00:10,  1.71it/s]Inference:  47%|████▋     | 15/32 [00:08<00:10,  1.69it/s]Inference:  50%|█████     | 16/32 [00:09<00:10,  1.59it/s]Inference:  53%|█████▎    | 17/32 [00:09<00:09,  1.57it/s]Inference:  56%|█████▋    | 18/32 [00:10<00:08,  1.57it/s]Inference:  59%|█████▉    | 19/32 [00:11<00:08,  1.61it/s]Inference:  62%|██████▎   | 20/32 [00:11<00:07,  1.58it/s]Inference:  66%|██████▌   | 21/32 [00:12<00:07,  1.55it/s]Inference:  69%|██████▉   | 22/32 [00:12<00:06,  1.60it/s]Inference:  72%|███████▏  | 23/32 [00:13<00:05,  1.63it/s]Inference:  75%|███████▌  | 24/32 [00:14<00:04,  1.64it/s]Inference:  78%|███████▊  | 25/32 [00:14<00:04,  1.62it/s]Inference:  81%|████████▏ | 26/32 [00:15<00:03,  1.64it/s]Inference:  84%|████████▍ | 27/32 [00:16<00:03,  1.61it/s]Inference:  88%|████████▊ | 28/32 [00:16<00:02,  1.57it/s]Inference:  91%|█████████ | 29/32 [00:17<00:01,  1.61it/s]Inference:  94%|█████████▍| 30/32 [00:17<00:01,  1.57it/s]Inference:  97%|█████████▋| 31/32 [00:18<00:00,  1.61it/s]Inference: 100%|██████████| 32/32 [00:19<00:00,  1.59it/s]Inference: 100%|██████████| 32/32 [00:19<00:00,  1.67it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 34
48317 MiB free out of 48676 MiB total
Done with layer 34 total_time elapsed: 677 estimated time left: 870
layer original dtype torch.bfloat16
skipping layer 35
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:20,  1.48it/s]Inference:   6%|▋         | 2/32 [00:01<00:19,  1.54it/s]Inference:   9%|▉         | 3/32 [00:01<00:19,  1.52it/s]Inference:  12%|█▎        | 4/32 [00:02<00:17,  1.60it/s]Inference:  16%|█▌        | 5/32 [00:03<00:16,  1.65it/s]Inference:  19%|█▉        | 6/32 [00:03<00:16,  1.61it/s]Inference:  22%|██▏       | 7/32 [00:04<00:15,  1.59it/s]Inference:  25%|██▌       | 8/32 [00:05<00:15,  1.59it/s]Inference:  28%|██▊       | 9/32 [00:05<00:14,  1.63it/s]Inference:  31%|███▏      | 10/32 [00:06<00:13,  1.59it/s]Inference:  34%|███▍      | 11/32 [00:06<00:13,  1.57it/s]Inference:  38%|███▊      | 12/32 [00:07<00:12,  1.61it/s]Inference:  41%|████      | 13/32 [00:08<00:11,  1.59it/s]Inference:  44%|████▍     | 14/32 [00:08<00:11,  1.58it/s]Inference:  47%|████▋     | 15/32 [00:09<00:10,  1.59it/s]Inference:  50%|█████     | 16/32 [00:10<00:09,  1.60it/s]Inference:  53%|█████▎    | 17/32 [00:10<00:09,  1.56it/s]Inference:  56%|█████▋    | 18/32 [00:11<00:09,  1.55it/s]Inference:  59%|█████▉    | 19/32 [00:11<00:08,  1.60it/s]Inference:  62%|██████▎   | 20/32 [00:12<00:07,  1.57it/s]Inference:  66%|██████▌   | 21/32 [00:13<00:07,  1.57it/s]Inference:  69%|██████▉   | 22/32 [00:13<00:06,  1.59it/s]Inference:  72%|███████▏  | 23/32 [00:14<00:05,  1.58it/s]Inference:  75%|███████▌  | 24/32 [00:15<00:05,  1.56it/s]Inference:  78%|███████▊  | 25/32 [00:15<00:04,  1.63it/s]Inference:  81%|████████▏ | 26/32 [00:16<00:03,  1.66it/s]Inference:  84%|████████▍ | 27/32 [00:17<00:03,  1.60it/s]Inference:  88%|████████▊ | 28/32 [00:17<00:02,  1.59it/s]Inference:  91%|█████████ | 29/32 [00:18<00:01,  1.62it/s]Inference:  94%|█████████▍| 30/32 [00:18<00:01,  1.65it/s]Inference:  97%|█████████▋| 31/32 [00:19<00:00,  1.55it/s]Inference: 100%|██████████| 32/32 [00:20<00:00,  1.55it/s]Inference: 100%|██████████| 32/32 [00:20<00:00,  1.59it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 35
48317 MiB free out of 48676 MiB total
Done with layer 35 total_time elapsed: 699 estimated time left: 854
layer original dtype torch.bfloat16
skipping layer 36
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:17,  1.77it/s]Inference:   6%|▋         | 2/32 [00:01<00:18,  1.58it/s]Inference:   9%|▉         | 3/32 [00:01<00:18,  1.57it/s]Inference:  12%|█▎        | 4/32 [00:02<00:18,  1.53it/s]Inference:  16%|█▌        | 5/32 [00:03<00:18,  1.49it/s]Inference:  19%|█▉        | 6/32 [00:03<00:17,  1.46it/s]Inference:  22%|██▏       | 7/32 [00:04<00:17,  1.44it/s]Inference:  25%|██▌       | 8/32 [00:05<00:16,  1.46it/s]Inference:  28%|██▊       | 9/32 [00:06<00:15,  1.47it/s]Inference:  31%|███▏      | 10/32 [00:06<00:15,  1.45it/s]Inference:  34%|███▍      | 11/32 [00:07<00:14,  1.45it/s]Inference:  38%|███▊      | 12/32 [00:08<00:13,  1.46it/s]Inference:  41%|████      | 13/32 [00:08<00:13,  1.46it/s]Inference:  44%|████▍     | 14/32 [00:09<00:12,  1.47it/s]Inference:  47%|████▋     | 15/32 [00:10<00:11,  1.53it/s]Inference:  50%|█████     | 16/32 [00:10<00:10,  1.55it/s]Inference:  53%|█████▎    | 17/32 [00:11<00:09,  1.55it/s]Inference:  56%|█████▋    | 18/32 [00:11<00:08,  1.56it/s]Inference:  59%|█████▉    | 19/32 [00:12<00:08,  1.60it/s]Inference:  62%|██████▎   | 20/32 [00:13<00:07,  1.61it/s]Inference:  66%|██████▌   | 21/32 [00:13<00:06,  1.63it/s]Inference:  69%|██████▉   | 22/32 [00:14<00:06,  1.64it/s]Inference:  72%|███████▏  | 23/32 [00:14<00:05,  1.66it/s]Inference:  75%|███████▌  | 24/32 [00:15<00:04,  1.68it/s]Inference:  78%|███████▊  | 25/32 [00:16<00:04,  1.64it/s]Inference:  81%|████████▏ | 26/32 [00:16<00:03,  1.65it/s]Inference:  84%|████████▍ | 27/32 [00:17<00:03,  1.66it/s]Inference:  88%|████████▊ | 28/32 [00:17<00:02,  1.67it/s]Inference:  91%|█████████ | 29/32 [00:18<00:01,  1.68it/s]Inference:  94%|█████████▍| 30/32 [00:19<00:01,  1.69it/s]Inference:  97%|█████████▋| 31/32 [00:19<00:00,  1.77it/s]Inference: 100%|██████████| 32/32 [00:20<00:00,  1.80it/s]Inference: 100%|██████████| 32/32 [00:20<00:00,  1.59it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 36
48317 MiB free out of 48676 MiB total
Done with layer 36 total_time elapsed: 720 estimated time left: 837
layer original dtype torch.bfloat16
skipping layer 37
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:17,  1.76it/s]Inference:   6%|▋         | 2/32 [00:01<00:17,  1.70it/s]Inference:   9%|▉         | 3/32 [00:01<00:17,  1.70it/s]Inference:  12%|█▎        | 4/32 [00:02<00:16,  1.71it/s]Inference:  16%|█▌        | 5/32 [00:02<00:15,  1.70it/s]Inference:  19%|█▉        | 6/32 [00:03<00:15,  1.70it/s]Inference:  22%|██▏       | 7/32 [00:04<00:15,  1.66it/s]Inference:  25%|██▌       | 8/32 [00:04<00:14,  1.64it/s]Inference:  28%|██▊       | 9/32 [00:05<00:14,  1.62it/s]Inference:  31%|███▏      | 10/32 [00:05<00:13,  1.66it/s]Inference:  34%|███▍      | 11/32 [00:06<00:12,  1.63it/s]Inference:  38%|███▊      | 12/32 [00:07<00:12,  1.61it/s]Inference:  41%|████      | 13/32 [00:07<00:11,  1.64it/s]Inference:  44%|████▍     | 14/32 [00:08<00:11,  1.61it/s]Inference:  47%|████▋     | 15/32 [00:09<00:10,  1.61it/s]Inference:  50%|█████     | 16/32 [00:09<00:10,  1.58it/s]Inference:  53%|█████▎    | 17/32 [00:10<00:09,  1.62it/s]Inference:  56%|█████▋    | 18/32 [00:10<00:08,  1.60it/s]Inference:  59%|█████▉    | 19/32 [00:11<00:08,  1.60it/s]Inference:  62%|██████▎   | 20/32 [00:12<00:07,  1.64it/s]Inference:  66%|██████▌   | 21/32 [00:12<00:06,  1.73it/s]Inference:  69%|██████▉   | 22/32 [00:13<00:05,  1.75it/s]Inference:  72%|███████▏  | 23/32 [00:13<00:05,  1.77it/s]Inference:  75%|███████▌  | 24/32 [00:14<00:04,  1.78it/s]Inference:  78%|███████▊  | 25/32 [00:14<00:03,  1.85it/s]Inference:  81%|████████▏ | 26/32 [00:15<00:03,  1.82it/s]Inference:  84%|████████▍ | 27/32 [00:15<00:02,  1.82it/s]Inference:  88%|████████▊ | 28/32 [00:16<00:02,  1.81it/s]Inference:  91%|█████████ | 29/32 [00:17<00:01,  1.86it/s]Inference:  94%|█████████▍| 30/32 [00:17<00:01,  1.84it/s]Inference:  97%|█████████▋| 31/32 [00:18<00:00,  1.83it/s]Inference: 100%|██████████| 32/32 [00:18<00:00,  1.82it/s]Inference: 100%|██████████| 32/32 [00:18<00:00,  1.71it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 37
48317 MiB free out of 48676 MiB total
Done with layer 37 total_time elapsed: 741 estimated time left: 819
layer original dtype torch.bfloat16
skipping layer 38
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:15,  2.00it/s]Inference:   6%|▋         | 2/32 [00:01<00:15,  1.94it/s]Inference:   9%|▉         | 3/32 [00:01<00:14,  1.99it/s]Inference:  12%|█▎        | 4/32 [00:02<00:14,  1.91it/s]Inference:  16%|█▌        | 5/32 [00:02<00:14,  1.85it/s]Inference:  19%|█▉        | 6/32 [00:03<00:14,  1.85it/s]Inference:  22%|██▏       | 7/32 [00:03<00:13,  1.88it/s]Inference:  25%|██▌       | 8/32 [00:04<00:12,  1.86it/s]Inference:  28%|██▊       | 9/32 [00:04<00:12,  1.84it/s]Inference:  31%|███▏      | 10/32 [00:05<00:12,  1.83it/s]Inference:  34%|███▍      | 11/32 [00:05<00:11,  1.86it/s]Inference:  38%|███▊      | 12/32 [00:06<00:10,  1.83it/s]Inference:  41%|████      | 13/32 [00:06<00:10,  1.83it/s]Inference:  44%|████▍     | 14/32 [00:07<00:09,  1.81it/s]Inference:  47%|████▋     | 15/32 [00:08<00:09,  1.85it/s]Inference:  50%|█████     | 16/32 [00:08<00:08,  1.84it/s]Inference:  53%|█████▎    | 17/32 [00:09<00:08,  1.82it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:07,  1.80it/s]Inference:  59%|█████▉    | 19/32 [00:10<00:07,  1.84it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.84it/s]Inference:  66%|██████▌   | 21/32 [00:11<00:06,  1.80it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.80it/s]Inference:  72%|███████▏  | 23/32 [00:12<00:04,  1.87it/s]Inference:  75%|███████▌  | 24/32 [00:13<00:04,  1.83it/s]Inference:  78%|███████▊  | 25/32 [00:13<00:03,  1.88it/s]Inference:  81%|████████▏ | 26/32 [00:13<00:03,  1.94it/s]Inference:  84%|████████▍ | 27/32 [00:14<00:02,  1.97it/s]Inference:  88%|████████▊ | 28/32 [00:15<00:02,  1.92it/s]Inference:  91%|█████████ | 29/32 [00:15<00:01,  1.89it/s]Inference:  94%|█████████▍| 30/32 [00:16<00:01,  1.87it/s]Inference:  97%|█████████▋| 31/32 [00:16<00:00,  1.88it/s]Inference: 100%|██████████| 32/32 [00:17<00:00,  1.84it/s]Inference: 100%|██████████| 32/32 [00:17<00:00,  1.86it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 38
48317 MiB free out of 48676 MiB total
Done with layer 38 total_time elapsed: 760 estimated time left: 799
layer original dtype torch.bfloat16
skipping layer 39
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:14,  2.07it/s]Inference:   6%|▋         | 2/32 [00:01<00:15,  1.91it/s]Inference:   9%|▉         | 3/32 [00:01<00:15,  1.88it/s]Inference:  12%|█▎        | 4/32 [00:02<00:15,  1.83it/s]Inference:  16%|█▌        | 5/32 [00:02<00:14,  1.89it/s]Inference:  19%|█▉        | 6/32 [00:03<00:14,  1.86it/s]Inference:  22%|██▏       | 7/32 [00:03<00:13,  1.81it/s]Inference:  25%|██▌       | 8/32 [00:04<00:13,  1.79it/s]Inference:  28%|██▊       | 9/32 [00:04<00:12,  1.86it/s]Inference:  31%|███▏      | 10/32 [00:05<00:11,  1.84it/s]Inference:  34%|███▍      | 11/32 [00:06<00:11,  1.77it/s]Inference:  38%|███▊      | 12/32 [00:06<00:11,  1.75it/s]Inference:  41%|████      | 13/32 [00:07<00:10,  1.83it/s]Inference:  44%|████▍     | 14/32 [00:07<00:09,  1.80it/s]Inference:  47%|████▋     | 15/32 [00:08<00:09,  1.79it/s]Inference:  50%|█████     | 16/32 [00:08<00:09,  1.77it/s]Inference:  53%|█████▎    | 17/32 [00:09<00:08,  1.85it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:07,  1.82it/s]Inference:  59%|█████▉    | 19/32 [00:10<00:07,  1.80it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.80it/s]Inference:  66%|██████▌   | 21/32 [00:11<00:05,  1.86it/s]Inference:  69%|██████▉   | 22/32 [00:12<00:05,  1.84it/s]Inference:  72%|███████▏  | 23/32 [00:12<00:04,  1.80it/s]Inference:  75%|███████▌  | 24/32 [00:13<00:04,  1.81it/s]Inference:  78%|███████▊  | 25/32 [00:13<00:03,  1.86it/s]Inference:  81%|████████▏ | 26/32 [00:14<00:03,  1.86it/s]Inference:  84%|████████▍ | 27/32 [00:14<00:02,  1.85it/s]Inference:  88%|████████▊ | 28/32 [00:15<00:02,  1.84it/s]Inference:  91%|█████████ | 29/32 [00:15<00:01,  1.88it/s]Inference:  94%|█████████▍| 30/32 [00:16<00:01,  1.86it/s]Inference:  97%|█████████▋| 31/32 [00:16<00:00,  1.82it/s]Inference: 100%|██████████| 32/32 [00:17<00:00,  1.80it/s]Inference: 100%|██████████| 32/32 [00:17<00:00,  1.83it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 39
48317 MiB free out of 48676 MiB total
Done with layer 39 total_time elapsed: 779 estimated time left: 779
layer original dtype torch.bfloat16
skipping layer 40
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:14,  2.10it/s]Inference:   6%|▋         | 2/32 [00:00<00:14,  2.00it/s]Inference:   9%|▉         | 3/32 [00:01<00:15,  1.93it/s]Inference:  12%|█▎        | 4/32 [00:02<00:14,  1.88it/s]Inference:  16%|█▌        | 5/32 [00:02<00:14,  1.87it/s]Inference:  19%|█▉        | 6/32 [00:03<00:13,  1.88it/s]Inference:  22%|██▏       | 7/32 [00:03<00:13,  1.85it/s]Inference:  25%|██▌       | 8/32 [00:04<00:13,  1.84it/s]Inference:  28%|██▊       | 9/32 [00:04<00:12,  1.84it/s]Inference:  31%|███▏      | 10/32 [00:05<00:11,  1.84it/s]Inference:  34%|███▍      | 11/32 [00:05<00:10,  1.92it/s]Inference:  38%|███▊      | 12/32 [00:06<00:10,  1.89it/s]Inference:  41%|████      | 13/32 [00:06<00:10,  1.87it/s]Inference:  44%|████▍     | 14/32 [00:07<00:09,  1.84it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  1.92it/s]Inference:  50%|█████     | 16/32 [00:08<00:08,  1.88it/s]Inference:  53%|█████▎    | 17/32 [00:09<00:08,  1.84it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:07,  1.83it/s]Inference:  59%|█████▉    | 19/32 [00:10<00:06,  1.90it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.92it/s]Inference:  66%|██████▌   | 21/32 [00:11<00:05,  1.85it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.85it/s]Inference:  72%|███████▏  | 23/32 [00:12<00:04,  1.91it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:04,  1.88it/s]Inference:  78%|███████▊  | 25/32 [00:13<00:03,  1.86it/s]Inference:  81%|████████▏ | 26/32 [00:13<00:03,  1.85it/s]Inference:  84%|████████▍ | 27/32 [00:14<00:02,  1.89it/s]Inference:  88%|████████▊ | 28/32 [00:14<00:02,  1.87it/s]Inference:  91%|█████████ | 29/32 [00:15<00:01,  1.84it/s]Inference:  94%|█████████▍| 30/32 [00:16<00:01,  1.84it/s]Inference:  97%|█████████▋| 31/32 [00:16<00:00,  1.86it/s]Inference: 100%|██████████| 32/32 [00:17<00:00,  1.85it/s]Inference: 100%|██████████| 32/32 [00:17<00:00,  1.87it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 40
48317 MiB free out of 48676 MiB total
Done with layer 40 total_time elapsed: 798 estimated time left: 759
layer original dtype torch.bfloat16
skipping layer 41
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:17,  1.77it/s]Inference:   6%|▋         | 2/32 [00:01<00:17,  1.72it/s]Inference:   9%|▉         | 3/32 [00:01<00:16,  1.71it/s]Inference:  12%|█▎        | 4/32 [00:02<00:16,  1.72it/s]Inference:  16%|█▌        | 5/32 [00:02<00:15,  1.71it/s]Inference:  19%|█▉        | 6/32 [00:03<00:15,  1.70it/s]Inference:  22%|██▏       | 7/32 [00:04<00:14,  1.68it/s]Inference:  25%|██▌       | 8/32 [00:04<00:14,  1.67it/s]Inference:  28%|██▊       | 9/32 [00:05<00:13,  1.70it/s]Inference:  31%|███▏      | 10/32 [00:05<00:12,  1.70it/s]Inference:  34%|███▍      | 11/32 [00:06<00:12,  1.72it/s]Inference:  38%|███▊      | 12/32 [00:07<00:11,  1.72it/s]Inference:  41%|████      | 13/32 [00:07<00:11,  1.71it/s]Inference:  44%|████▍     | 14/32 [00:08<00:10,  1.70it/s]Inference:  47%|████▋     | 15/32 [00:08<00:09,  1.71it/s]Inference:  50%|█████     | 16/32 [00:09<00:09,  1.70it/s]Inference:  53%|█████▎    | 17/32 [00:09<00:08,  1.71it/s]Inference:  56%|█████▋    | 18/32 [00:10<00:08,  1.73it/s]Inference:  59%|█████▉    | 19/32 [00:11<00:07,  1.70it/s]Inference:  62%|██████▎   | 20/32 [00:11<00:07,  1.71it/s]Inference:  66%|██████▌   | 21/32 [00:12<00:06,  1.71it/s]Inference:  69%|██████▉   | 22/32 [00:12<00:05,  1.71it/s]Inference:  72%|███████▏  | 23/32 [00:13<00:05,  1.65it/s]Inference:  75%|███████▌  | 24/32 [00:14<00:04,  1.62it/s]Inference:  78%|███████▊  | 25/32 [00:14<00:04,  1.59it/s]Inference:  81%|████████▏ | 26/32 [00:15<00:03,  1.64it/s]Inference:  84%|████████▍ | 27/32 [00:16<00:03,  1.61it/s]Inference:  88%|████████▊ | 28/32 [00:16<00:02,  1.60it/s]Inference:  91%|█████████ | 29/32 [00:17<00:01,  1.61it/s]Inference:  94%|█████████▍| 30/32 [00:17<00:01,  1.59it/s]Inference:  97%|█████████▋| 31/32 [00:18<00:00,  1.58it/s]Inference: 100%|██████████| 32/32 [00:19<00:00,  1.58it/s]Inference: 100%|██████████| 32/32 [00:19<00:00,  1.66it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 41
48317 MiB free out of 48676 MiB total
Done with layer 41 total_time elapsed: 819 estimated time left: 741
layer original dtype torch.bfloat16
skipping layer 42
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:18,  1.68it/s]Inference:   6%|▋         | 2/32 [00:01<00:18,  1.64it/s]Inference:   9%|▉         | 3/32 [00:01<00:17,  1.66it/s]Inference:  12%|█▎        | 4/32 [00:02<00:17,  1.61it/s]Inference:  16%|█▌        | 5/32 [00:03<00:17,  1.59it/s]Inference:  19%|█▉        | 6/32 [00:03<00:16,  1.61it/s]Inference:  22%|██▏       | 7/32 [00:04<00:15,  1.60it/s]Inference:  25%|██▌       | 8/32 [00:04<00:15,  1.58it/s]Inference:  28%|██▊       | 9/32 [00:05<00:14,  1.57it/s]Inference:  31%|███▏      | 10/32 [00:06<00:13,  1.61it/s]Inference:  34%|███▍      | 11/32 [00:06<00:13,  1.59it/s]Inference:  38%|███▊      | 12/32 [00:07<00:12,  1.59it/s]Inference:  41%|████      | 13/32 [00:08<00:11,  1.61it/s]Inference:  44%|████▍     | 14/32 [00:08<00:11,  1.63it/s]Inference:  47%|████▋     | 15/32 [00:09<00:10,  1.60it/s]Inference:  50%|█████     | 16/32 [00:09<00:09,  1.60it/s]Inference:  53%|█████▎    | 17/32 [00:10<00:09,  1.64it/s]Inference:  56%|█████▋    | 18/32 [00:11<00:08,  1.63it/s]Inference:  59%|█████▉    | 19/32 [00:11<00:08,  1.61it/s]Inference:  62%|██████▎   | 20/32 [00:12<00:07,  1.61it/s]Inference:  66%|██████▌   | 21/32 [00:12<00:06,  1.65it/s]Inference:  69%|██████▉   | 22/32 [00:13<00:06,  1.63it/s]Inference:  72%|███████▏  | 23/32 [00:14<00:05,  1.61it/s]Inference:  75%|███████▌  | 24/32 [00:14<00:04,  1.61it/s]Inference:  78%|███████▊  | 25/32 [00:15<00:04,  1.66it/s]Inference:  81%|████████▏ | 26/32 [00:16<00:03,  1.64it/s]Inference:  84%|████████▍ | 27/32 [00:16<00:03,  1.61it/s]Inference:  88%|████████▊ | 28/32 [00:17<00:02,  1.64it/s]Inference:  91%|█████████ | 29/32 [00:17<00:01,  1.63it/s]Inference:  94%|█████████▍| 30/32 [00:18<00:01,  1.62it/s]Inference:  97%|█████████▋| 31/32 [00:19<00:00,  1.59it/s]Inference: 100%|██████████| 32/32 [00:19<00:00,  1.63it/s]Inference: 100%|██████████| 32/32 [00:19<00:00,  1.62it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 42
48317 MiB free out of 48676 MiB total
Done with layer 42 total_time elapsed: 840 estimated time left: 723
layer original dtype torch.bfloat16
skipping layer 43
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:14,  2.08it/s]Inference:   6%|▋         | 2/32 [00:00<00:14,  2.05it/s]Inference:   9%|▉         | 3/32 [00:01<00:15,  1.92it/s]Inference:  12%|█▎        | 4/32 [00:02<00:14,  1.89it/s]Inference:  16%|█▌        | 5/32 [00:02<00:14,  1.92it/s]Inference:  19%|█▉        | 6/32 [00:03<00:13,  1.94it/s]Inference:  22%|██▏       | 7/32 [00:03<00:13,  1.90it/s]Inference:  25%|██▌       | 8/32 [00:04<00:12,  1.86it/s]Inference:  28%|██▊       | 9/32 [00:04<00:12,  1.86it/s]Inference:  31%|███▏      | 10/32 [00:05<00:11,  1.92it/s]Inference:  34%|███▍      | 11/32 [00:05<00:11,  1.90it/s]Inference:  38%|███▊      | 12/32 [00:06<00:10,  1.88it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  1.92it/s]Inference:  44%|████▍     | 14/32 [00:07<00:09,  1.92it/s]Inference:  47%|████▋     | 15/32 [00:07<00:09,  1.89it/s]Inference:  50%|█████     | 16/32 [00:08<00:08,  1.94it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  1.90it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:07,  1.89it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  1.92it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.89it/s]Inference:  66%|██████▌   | 21/32 [00:11<00:05,  1.88it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.87it/s]Inference:  72%|███████▏  | 23/32 [00:12<00:04,  1.93it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:04,  1.89it/s]Inference:  78%|███████▊  | 25/32 [00:13<00:03,  1.87it/s]Inference:  81%|████████▏ | 26/32 [00:13<00:03,  1.85it/s]Inference:  84%|████████▍ | 27/32 [00:14<00:02,  1.90it/s]Inference:  88%|████████▊ | 28/32 [00:14<00:02,  1.86it/s]Inference:  91%|█████████ | 29/32 [00:15<00:01,  1.93it/s]Inference:  94%|█████████▍| 30/32 [00:15<00:01,  1.89it/s]Inference:  97%|█████████▋| 31/32 [00:16<00:00,  1.89it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.93it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.90it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 43
48317 MiB free out of 48676 MiB total
Done with layer 43 total_time elapsed: 858 estimated time left: 702
layer original dtype torch.bfloat16
skipping layer 44
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:14,  2.08it/s]Inference:   6%|▋         | 2/32 [00:01<00:15,  1.89it/s]Inference:   9%|▉         | 3/32 [00:01<00:15,  1.84it/s]Inference:  12%|█▎        | 4/32 [00:02<00:15,  1.81it/s]Inference:  16%|█▌        | 5/32 [00:02<00:14,  1.87it/s]Inference:  19%|█▉        | 6/32 [00:03<00:14,  1.85it/s]Inference:  22%|██▏       | 7/32 [00:03<00:13,  1.83it/s]Inference:  25%|██▌       | 8/32 [00:04<00:13,  1.83it/s]Inference:  28%|██▊       | 9/32 [00:04<00:12,  1.83it/s]Inference:  31%|███▏      | 10/32 [00:05<00:11,  1.90it/s]Inference:  34%|███▍      | 11/32 [00:05<00:11,  1.86it/s]Inference:  38%|███▊      | 12/32 [00:06<00:10,  1.83it/s]Inference:  41%|████      | 13/32 [00:07<00:10,  1.82it/s]Inference:  44%|████▍     | 14/32 [00:07<00:09,  1.89it/s]Inference:  47%|████▋     | 15/32 [00:08<00:09,  1.83it/s]Inference:  50%|█████     | 16/32 [00:08<00:08,  1.85it/s]Inference:  53%|█████▎    | 17/32 [00:09<00:08,  1.83it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:07,  1.88it/s]Inference:  59%|█████▉    | 19/32 [00:10<00:07,  1.84it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.88it/s]Inference:  66%|██████▌   | 21/32 [00:11<00:05,  1.88it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.89it/s]Inference:  72%|███████▏  | 23/32 [00:12<00:04,  1.93it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:04,  1.88it/s]Inference:  78%|███████▊  | 25/32 [00:13<00:03,  1.86it/s]Inference:  81%|████████▏ | 26/32 [00:14<00:03,  1.83it/s]Inference:  84%|████████▍ | 27/32 [00:14<00:02,  1.90it/s]Inference:  88%|████████▊ | 28/32 [00:15<00:02,  1.86it/s]Inference:  91%|█████████ | 29/32 [00:15<00:01,  1.84it/s]Inference:  94%|█████████▍| 30/32 [00:16<00:01,  1.82it/s]Inference:  97%|█████████▋| 31/32 [00:16<00:00,  1.89it/s]Inference: 100%|██████████| 32/32 [00:17<00:00,  1.87it/s]Inference: 100%|██████████| 32/32 [00:17<00:00,  1.86it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 44
48317 MiB free out of 48676 MiB total
Done with layer 44 total_time elapsed: 877 estimated time left: 682
layer original dtype torch.bfloat16
skipping layer 45
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:14,  2.07it/s]Inference:   6%|▋         | 2/32 [00:01<00:15,  1.95it/s]Inference:   9%|▉         | 3/32 [00:01<00:15,  1.88it/s]Inference:  12%|█▎        | 4/32 [00:02<00:14,  1.89it/s]Inference:  16%|█▌        | 5/32 [00:02<00:14,  1.91it/s]Inference:  19%|█▉        | 6/32 [00:03<00:13,  1.86it/s]Inference:  22%|██▏       | 7/32 [00:03<00:13,  1.82it/s]Inference:  25%|██▌       | 8/32 [00:04<00:13,  1.83it/s]Inference:  28%|██▊       | 9/32 [00:04<00:12,  1.90it/s]Inference:  31%|███▏      | 10/32 [00:05<00:11,  1.86it/s]Inference:  34%|███▍      | 11/32 [00:05<00:10,  1.92it/s]Inference:  38%|███▊      | 12/32 [00:06<00:10,  1.86it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  1.91it/s]Inference:  44%|████▍     | 14/32 [00:07<00:09,  1.94it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  1.96it/s]Inference:  50%|█████     | 16/32 [00:08<00:08,  1.96it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  1.97it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:07,  1.97it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  1.96it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.95it/s]Inference:  66%|██████▌   | 21/32 [00:10<00:05,  1.98it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.95it/s]Inference:  72%|███████▏  | 23/32 [00:11<00:04,  1.94it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:04,  1.97it/s]Inference:  78%|███████▊  | 25/32 [00:13<00:03,  1.92it/s]Inference:  81%|████████▏ | 26/32 [00:13<00:03,  1.87it/s]Inference:  84%|████████▍ | 27/32 [00:14<00:02,  1.85it/s]Inference:  88%|████████▊ | 28/32 [00:14<00:02,  1.81it/s]Inference:  91%|█████████ | 29/32 [00:15<00:01,  1.77it/s]Inference:  94%|█████████▍| 30/32 [00:15<00:01,  1.79it/s]Inference:  97%|█████████▋| 31/32 [00:16<00:00,  1.75it/s]Inference: 100%|██████████| 32/32 [00:17<00:00,  1.76it/s]Inference: 100%|██████████| 32/32 [00:17<00:00,  1.88it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 45
48317 MiB free out of 48676 MiB total
Done with layer 45 total_time elapsed: 896 estimated time left: 662
layer original dtype torch.bfloat16
skipping layer 46
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:14,  2.12it/s]Inference:   6%|▋         | 2/32 [00:00<00:14,  2.12it/s]Inference:   9%|▉         | 3/32 [00:01<00:14,  2.01it/s]Inference:  12%|█▎        | 4/32 [00:01<00:13,  2.01it/s]Inference:  16%|█▌        | 5/32 [00:02<00:13,  2.02it/s]Inference:  19%|█▉        | 6/32 [00:02<00:12,  2.02it/s]Inference:  22%|██▏       | 7/32 [00:03<00:12,  2.02it/s]Inference:  25%|██▌       | 8/32 [00:03<00:11,  2.01it/s]Inference:  28%|██▊       | 9/32 [00:04<00:12,  1.84it/s]Inference:  31%|███▏      | 10/32 [00:05<00:12,  1.78it/s]Inference:  34%|███▍      | 11/32 [00:05<00:12,  1.74it/s]Inference:  38%|███▊      | 12/32 [00:06<00:11,  1.77it/s]Inference:  41%|████      | 13/32 [00:06<00:11,  1.70it/s]Inference:  44%|████▍     | 14/32 [00:07<00:11,  1.60it/s]Inference:  47%|████▋     | 15/32 [00:08<00:10,  1.63it/s]Inference:  50%|█████     | 16/32 [00:08<00:09,  1.62it/s]Inference:  53%|█████▎    | 17/32 [00:09<00:09,  1.61it/s]Inference:  56%|█████▋    | 18/32 [00:10<00:08,  1.59it/s]Inference:  59%|█████▉    | 19/32 [00:10<00:07,  1.63it/s]Inference:  62%|██████▎   | 20/32 [00:11<00:07,  1.62it/s]Inference:  66%|██████▌   | 21/32 [00:12<00:06,  1.60it/s]Inference:  69%|██████▉   | 22/32 [00:12<00:06,  1.62it/s]Inference:  72%|███████▏  | 23/32 [00:13<00:05,  1.66it/s]Inference:  75%|███████▌  | 24/32 [00:13<00:04,  1.65it/s]Inference:  78%|███████▊  | 25/32 [00:14<00:04,  1.62it/s]Inference:  81%|████████▏ | 26/32 [00:15<00:03,  1.65it/s]Inference:  84%|████████▍ | 27/32 [00:15<00:03,  1.63it/s]Inference:  88%|████████▊ | 28/32 [00:16<00:02,  1.60it/s]Inference:  91%|█████████ | 29/32 [00:16<00:01,  1.57it/s]Inference:  94%|█████████▍| 30/32 [00:17<00:01,  1.63it/s]Inference:  97%|█████████▋| 31/32 [00:18<00:00,  1.57it/s]Inference: 100%|██████████| 32/32 [00:18<00:00,  1.54it/s]Inference: 100%|██████████| 32/32 [00:18<00:00,  1.69it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 46
48317 MiB free out of 48676 MiB total
Done with layer 46 total_time elapsed: 916 estimated time left: 643
layer original dtype torch.bfloat16
skipping layer 47
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:14,  2.11it/s]Inference:   6%|▋         | 2/32 [00:00<00:14,  2.09it/s]Inference:   9%|▉         | 3/32 [00:01<00:13,  2.12it/s]Inference:  12%|█▎        | 4/32 [00:01<00:13,  2.02it/s]Inference:  16%|█▌        | 5/32 [00:02<00:13,  1.95it/s]Inference:  19%|█▉        | 6/32 [00:03<00:13,  1.92it/s]Inference:  22%|██▏       | 7/32 [00:03<00:12,  1.95it/s]Inference:  25%|██▌       | 8/32 [00:04<00:12,  1.91it/s]Inference:  28%|██▊       | 9/32 [00:04<00:11,  1.97it/s]Inference:  31%|███▏      | 10/32 [00:05<00:11,  1.93it/s]Inference:  34%|███▍      | 11/32 [00:05<00:10,  1.94it/s]Inference:  38%|███▊      | 12/32 [00:06<00:10,  1.97it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  1.93it/s]Inference:  44%|████▍     | 14/32 [00:07<00:09,  1.92it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  1.90it/s]Inference:  50%|█████     | 16/32 [00:08<00:08,  1.95it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  1.98it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:07,  1.90it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  1.93it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.92it/s]Inference:  66%|██████▌   | 21/32 [00:10<00:05,  1.93it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.97it/s]Inference:  72%|███████▏  | 23/32 [00:11<00:04,  1.96it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:04,  1.95it/s]Inference:  78%|███████▊  | 25/32 [00:12<00:03,  1.98it/s]Inference:  81%|████████▏ | 26/32 [00:13<00:03,  1.94it/s]Inference:  84%|████████▍ | 27/32 [00:13<00:02,  1.93it/s]Inference:  88%|████████▊ | 28/32 [00:14<00:02,  1.93it/s]Inference:  91%|█████████ | 29/32 [00:14<00:01,  1.94it/s]Inference:  94%|█████████▍| 30/32 [00:15<00:01,  1.90it/s]Inference:  97%|█████████▋| 31/32 [00:15<00:00,  1.87it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.90it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.94it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 47
48317 MiB free out of 48676 MiB total
Done with layer 47 total_time elapsed: 934 estimated time left: 623
layer original dtype torch.bfloat16
skipping layer 48
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:14,  2.10it/s]Inference:   6%|▋         | 2/32 [00:01<00:15,  1.93it/s]Inference:   9%|▉         | 3/32 [00:01<00:14,  2.01it/s]Inference:  12%|█▎        | 4/32 [00:02<00:14,  1.89it/s]Inference:  16%|█▌        | 5/32 [00:02<00:14,  1.87it/s]Inference:  19%|█▉        | 6/32 [00:03<00:14,  1.85it/s]Inference:  22%|██▏       | 7/32 [00:03<00:12,  1.92it/s]Inference:  25%|██▌       | 8/32 [00:04<00:12,  1.88it/s]Inference:  28%|██▊       | 9/32 [00:04<00:12,  1.84it/s]Inference:  31%|███▏      | 10/32 [00:05<00:12,  1.83it/s]Inference:  34%|███▍      | 11/32 [00:05<00:11,  1.89it/s]Inference:  38%|███▊      | 12/32 [00:06<00:10,  1.87it/s]Inference:  41%|████      | 13/32 [00:06<00:10,  1.89it/s]Inference:  44%|████▍     | 14/32 [00:07<00:09,  1.87it/s]Inference:  47%|████▋     | 15/32 [00:07<00:09,  1.88it/s]Inference:  50%|█████     | 16/32 [00:08<00:08,  1.94it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  1.90it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:07,  1.84it/s]Inference:  59%|█████▉    | 19/32 [00:10<00:07,  1.85it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.92it/s]Inference:  66%|██████▌   | 21/32 [00:11<00:05,  1.88it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.86it/s]Inference:  72%|███████▏  | 23/32 [00:12<00:04,  1.86it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:04,  1.93it/s]Inference:  78%|███████▊  | 25/32 [00:13<00:03,  1.89it/s]Inference:  81%|████████▏ | 26/32 [00:13<00:03,  1.87it/s]Inference:  84%|████████▍ | 27/32 [00:14<00:02,  1.84it/s]Inference:  88%|████████▊ | 28/32 [00:14<00:02,  1.89it/s]Inference:  91%|█████████ | 29/32 [00:15<00:01,  1.93it/s]Inference:  94%|█████████▍| 30/32 [00:15<00:01,  1.87it/s]Inference:  97%|█████████▋| 31/32 [00:16<00:00,  1.86it/s]Inference: 100%|██████████| 32/32 [00:17<00:00,  1.84it/s]Inference: 100%|██████████| 32/32 [00:17<00:00,  1.88it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 48
48317 MiB free out of 48676 MiB total
Done with layer 48 total_time elapsed: 952 estimated time left: 603
layer original dtype torch.bfloat16
skipping layer 49
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:15,  2.04it/s]Inference:   6%|▋         | 2/32 [00:00<00:14,  2.06it/s]Inference:   9%|▉         | 3/32 [00:01<00:14,  1.95it/s]Inference:  12%|█▎        | 4/32 [00:02<00:14,  1.95it/s]Inference:  16%|█▌        | 5/32 [00:02<00:13,  1.98it/s]Inference:  19%|█▉        | 6/32 [00:03<00:13,  1.97it/s]Inference:  22%|██▏       | 7/32 [00:03<00:13,  1.92it/s]Inference:  25%|██▌       | 8/32 [00:04<00:12,  1.88it/s]Inference:  28%|██▊       | 9/32 [00:04<00:12,  1.87it/s]Inference:  31%|███▏      | 10/32 [00:05<00:11,  1.90it/s]Inference:  34%|███▍      | 11/32 [00:05<00:10,  1.91it/s]Inference:  38%|███▊      | 12/32 [00:06<00:10,  1.90it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  1.91it/s]Inference:  44%|████▍     | 14/32 [00:07<00:09,  1.87it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  1.92it/s]Inference:  50%|█████     | 16/32 [00:08<00:08,  1.89it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:08,  1.87it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:07,  1.86it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  1.91it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.87it/s]Inference:  66%|██████▌   | 21/32 [00:11<00:05,  1.85it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.86it/s]Inference:  72%|███████▏  | 23/32 [00:12<00:04,  1.89it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:04,  1.86it/s]Inference:  78%|███████▊  | 25/32 [00:13<00:03,  1.84it/s]Inference:  81%|████████▏ | 26/32 [00:13<00:03,  1.82it/s]Inference:  84%|████████▍ | 27/32 [00:14<00:02,  1.85it/s]Inference:  88%|████████▊ | 28/32 [00:14<00:02,  1.84it/s]Inference:  91%|█████████ | 29/32 [00:15<00:01,  1.84it/s]Inference:  94%|█████████▍| 30/32 [00:15<00:01,  1.84it/s]Inference:  97%|█████████▋| 31/32 [00:16<00:00,  1.85it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.90it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.89it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 49
48317 MiB free out of 48676 MiB total
Done with layer 49 total_time elapsed: 971 estimated time left: 583
layer original dtype torch.bfloat16
skipping layer 50
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:15,  2.05it/s]Inference:   6%|▋         | 2/32 [00:01<00:15,  1.96it/s]Inference:   9%|▉         | 3/32 [00:01<00:15,  1.91it/s]Inference:  12%|█▎        | 4/32 [00:02<00:14,  1.89it/s]Inference:  16%|█▌        | 5/32 [00:02<00:13,  1.93it/s]Inference:  19%|█▉        | 6/32 [00:03<00:13,  1.96it/s]Inference:  22%|██▏       | 7/32 [00:03<00:12,  1.94it/s]Inference:  25%|██▌       | 8/32 [00:04<00:12,  1.96it/s]Inference:  28%|██▊       | 9/32 [00:04<00:11,  1.99it/s]Inference:  31%|███▏      | 10/32 [00:05<00:11,  1.97it/s]Inference:  34%|███▍      | 11/32 [00:05<00:10,  1.98it/s]Inference:  38%|███▊      | 12/32 [00:06<00:10,  1.99it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  1.99it/s]Inference:  44%|████▍     | 14/32 [00:07<00:09,  1.97it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  2.01it/s]Inference:  50%|█████     | 16/32 [00:08<00:08,  1.98it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  2.03it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:06,  2.01it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  2.02it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:05,  2.03it/s]Inference:  66%|██████▌   | 21/32 [00:10<00:05,  2.04it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:04,  2.03it/s]Inference:  72%|███████▏  | 23/32 [00:11<00:04,  2.05it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:03,  2.04it/s]Inference:  78%|███████▊  | 25/32 [00:12<00:03,  2.06it/s]Inference:  81%|████████▏ | 26/32 [00:12<00:02,  2.05it/s]Inference:  84%|████████▍ | 27/32 [00:13<00:02,  2.04it/s]Inference:  88%|████████▊ | 28/32 [00:13<00:01,  2.02it/s]Inference:  91%|█████████ | 29/32 [00:14<00:01,  2.02it/s]Inference:  94%|█████████▍| 30/32 [00:14<00:00,  2.01it/s]Inference:  97%|█████████▋| 31/32 [00:15<00:00,  1.99it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.93it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.99it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 50
48317 MiB free out of 48676 MiB total
Done with layer 50 total_time elapsed: 989 estimated time left: 562
layer original dtype torch.bfloat16
skipping layer 51
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:14,  2.09it/s]Inference:   6%|▋         | 2/32 [00:01<00:15,  1.93it/s]Inference:   9%|▉         | 3/32 [00:01<00:15,  1.90it/s]Inference:  12%|█▎        | 4/32 [00:02<00:14,  1.91it/s]Inference:  16%|█▌        | 5/32 [00:02<00:14,  1.87it/s]Inference:  19%|█▉        | 6/32 [00:03<00:14,  1.84it/s]Inference:  22%|██▏       | 7/32 [00:03<00:13,  1.83it/s]Inference:  25%|██▌       | 8/32 [00:04<00:12,  1.86it/s]Inference:  28%|██▊       | 9/32 [00:04<00:11,  1.92it/s]Inference:  31%|███▏      | 10/32 [00:05<00:11,  1.88it/s]Inference:  34%|███▍      | 11/32 [00:05<00:11,  1.88it/s]Inference:  38%|███▊      | 12/32 [00:06<00:10,  1.87it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  1.93it/s]Inference:  44%|████▍     | 14/32 [00:07<00:09,  1.91it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  1.90it/s]Inference:  50%|█████     | 16/32 [00:08<00:08,  1.89it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  1.92it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:07,  1.97it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  2.01it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.95it/s]Inference:  66%|██████▌   | 21/32 [00:11<00:05,  1.92it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.96it/s]Inference:  72%|███████▏  | 23/32 [00:12<00:04,  1.90it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:04,  1.89it/s]Inference:  78%|███████▊  | 25/32 [00:13<00:03,  1.88it/s]Inference:  81%|████████▏ | 26/32 [00:13<00:03,  1.92it/s]Inference:  84%|████████▍ | 27/32 [00:14<00:02,  1.97it/s]Inference:  88%|████████▊ | 28/32 [00:14<00:02,  1.99it/s]Inference:  91%|█████████ | 29/32 [00:15<00:01,  2.00it/s]Inference:  94%|█████████▍| 30/32 [00:15<00:00,  2.00it/s]Inference:  97%|█████████▋| 31/32 [00:16<00:00,  2.02it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  2.00it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.93it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 51
48317 MiB free out of 48676 MiB total
Done with layer 51 total_time elapsed: 1007 estimated time left: 542
layer original dtype torch.bfloat16
skipping layer 52
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:14,  2.13it/s]Inference:   6%|▋         | 2/32 [00:00<00:14,  2.02it/s]Inference:   9%|▉         | 3/32 [00:01<00:14,  2.00it/s]Inference:  12%|█▎        | 4/32 [00:01<00:14,  1.99it/s]Inference:  16%|█▌        | 5/32 [00:02<00:13,  2.04it/s]Inference:  19%|█▉        | 6/32 [00:02<00:13,  2.00it/s]Inference:  22%|██▏       | 7/32 [00:03<00:12,  2.00it/s]Inference:  25%|██▌       | 8/32 [00:03<00:11,  2.05it/s]Inference:  28%|██▊       | 9/32 [00:04<00:11,  2.07it/s]Inference:  31%|███▏      | 10/32 [00:04<00:10,  2.09it/s]Inference:  34%|███▍      | 11/32 [00:05<00:10,  2.09it/s]Inference:  38%|███▊      | 12/32 [00:05<00:09,  2.06it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  2.03it/s]Inference:  44%|████▍     | 14/32 [00:06<00:08,  2.05it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  2.02it/s]Inference:  50%|█████     | 16/32 [00:07<00:07,  2.01it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  2.00it/s]Inference:  56%|█████▋    | 18/32 [00:08<00:06,  2.00it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  2.04it/s]Inference:  62%|██████▎   | 20/32 [00:09<00:05,  2.03it/s]Inference:  66%|██████▌   | 21/32 [00:10<00:05,  2.01it/s]Inference:  69%|██████▉   | 22/32 [00:10<00:05,  1.99it/s]Inference:  72%|███████▏  | 23/32 [00:11<00:04,  2.01it/s]Inference:  75%|███████▌  | 24/32 [00:11<00:03,  2.00it/s]Inference:  78%|███████▊  | 25/32 [00:12<00:03,  2.00it/s]Inference:  81%|████████▏ | 26/32 [00:12<00:03,  1.98it/s]Inference:  84%|████████▍ | 27/32 [00:13<00:02,  1.95it/s]Inference:  88%|████████▊ | 28/32 [00:13<00:02,  2.00it/s]Inference:  91%|█████████ | 29/32 [00:14<00:01,  1.99it/s]Inference:  94%|█████████▍| 30/32 [00:14<00:01,  1.98it/s]Inference:  97%|█████████▋| 31/32 [00:15<00:00,  1.98it/s]Inference: 100%|██████████| 32/32 [00:15<00:00,  2.01it/s]Inference: 100%|██████████| 32/32 [00:15<00:00,  2.02it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 52
48317 MiB free out of 48676 MiB total
Done with layer 52 total_time elapsed: 1024 estimated time left: 522
layer original dtype torch.bfloat16
skipping layer 53
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:15,  1.99it/s]Inference:   6%|▋         | 2/32 [00:00<00:14,  2.06it/s]Inference:   9%|▉         | 3/32 [00:01<00:14,  2.01it/s]Inference:  12%|█▎        | 4/32 [00:01<00:13,  2.05it/s]Inference:  16%|█▌        | 5/32 [00:02<00:13,  2.03it/s]Inference:  19%|█▉        | 6/32 [00:02<00:12,  2.04it/s]Inference:  22%|██▏       | 7/32 [00:03<00:12,  2.02it/s]Inference:  25%|██▌       | 8/32 [00:03<00:12,  1.99it/s]Inference:  28%|██▊       | 9/32 [00:04<00:11,  1.99it/s]Inference:  31%|███▏      | 10/32 [00:04<00:11,  1.96it/s]Inference:  34%|███▍      | 11/32 [00:05<00:10,  2.01it/s]Inference:  38%|███▊      | 12/32 [00:05<00:10,  1.98it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  1.99it/s]Inference:  44%|████▍     | 14/32 [00:06<00:09,  1.99it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  1.97it/s]Inference:  50%|█████     | 16/32 [00:08<00:08,  1.93it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  1.95it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:07,  1.95it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  1.95it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.99it/s]Inference:  66%|██████▌   | 21/32 [00:10<00:05,  1.97it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.97it/s]Inference:  72%|███████▏  | 23/32 [00:11<00:04,  1.97it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:04,  1.99it/s]Inference:  78%|███████▊  | 25/32 [00:12<00:03,  1.99it/s]Inference:  81%|████████▏ | 26/32 [00:13<00:03,  1.98it/s]Inference:  84%|████████▍ | 27/32 [00:13<00:02,  1.98it/s]Inference:  88%|████████▊ | 28/32 [00:14<00:02,  1.97it/s]Inference:  91%|█████████ | 29/32 [00:14<00:01,  2.01it/s]Inference:  94%|█████████▍| 30/32 [00:15<00:00,  2.01it/s]Inference:  97%|█████████▋| 31/32 [00:15<00:00,  2.00it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.98it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.99it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 53
48317 MiB free out of 48676 MiB total
Done with layer 53 total_time elapsed: 1042 estimated time left: 502
layer original dtype torch.bfloat16
skipping layer 54
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:14,  2.11it/s]Inference:   6%|▋         | 2/32 [00:00<00:14,  2.13it/s]Inference:   9%|▉         | 3/32 [00:01<00:13,  2.12it/s]Inference:  12%|█▎        | 4/32 [00:01<00:13,  2.04it/s]Inference:  16%|█▌        | 5/32 [00:02<00:13,  2.00it/s]Inference:  19%|█▉        | 6/32 [00:02<00:13,  1.98it/s]Inference:  22%|██▏       | 7/32 [00:03<00:12,  2.03it/s]Inference:  25%|██▌       | 8/32 [00:03<00:11,  2.00it/s]Inference:  28%|██▊       | 9/32 [00:04<00:11,  1.98it/s]Inference:  31%|███▏      | 10/32 [00:04<00:11,  1.97it/s]Inference:  34%|███▍      | 11/32 [00:05<00:10,  2.02it/s]Inference:  38%|███▊      | 12/32 [00:05<00:09,  2.01it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  1.99it/s]Inference:  44%|████▍     | 14/32 [00:06<00:09,  1.97it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  1.96it/s]Inference:  50%|█████     | 16/32 [00:07<00:07,  2.00it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  1.98it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:07,  1.96it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  1.98it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.97it/s]Inference:  66%|██████▌   | 21/32 [00:10<00:05,  1.97it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.95it/s]Inference:  72%|███████▏  | 23/32 [00:11<00:04,  1.95it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:04,  1.93it/s]Inference:  78%|███████▊  | 25/32 [00:12<00:03,  1.98it/s]Inference:  81%|████████▏ | 26/32 [00:13<00:03,  1.96it/s]Inference:  84%|████████▍ | 27/32 [00:13<00:02,  1.95it/s]Inference:  88%|████████▊ | 28/32 [00:14<00:02,  1.93it/s]Inference:  91%|█████████ | 29/32 [00:14<00:01,  1.96it/s]Inference:  94%|█████████▍| 30/32 [00:15<00:01,  1.95it/s]Inference:  97%|█████████▋| 31/32 [00:15<00:00,  1.94it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.91it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.97it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 54
48317 MiB free out of 48676 MiB total
Done with layer 54 total_time elapsed: 1060 estimated time left: 482
layer original dtype torch.bfloat16
skipping layer 55
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:15,  2.06it/s]Inference:   6%|▋         | 2/32 [00:00<00:14,  2.04it/s]Inference:   9%|▉         | 3/32 [00:01<00:14,  2.03it/s]Inference:  12%|█▎        | 4/32 [00:01<00:13,  2.01it/s]Inference:  16%|█▌        | 5/32 [00:02<00:13,  1.99it/s]Inference:  19%|█▉        | 6/32 [00:02<00:12,  2.01it/s]Inference:  22%|██▏       | 7/32 [00:03<00:12,  2.00it/s]Inference:  25%|██▌       | 8/32 [00:03<00:12,  1.99it/s]Inference:  28%|██▊       | 9/32 [00:04<00:11,  2.00it/s]Inference:  31%|███▏      | 10/32 [00:04<00:10,  2.01it/s]Inference:  34%|███▍      | 11/32 [00:05<00:10,  2.01it/s]Inference:  38%|███▊      | 12/32 [00:05<00:10,  1.99it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  1.96it/s]Inference:  44%|████▍     | 14/32 [00:06<00:09,  2.00it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  1.99it/s]Inference:  50%|█████     | 16/32 [00:07<00:07,  2.01it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  2.02it/s]Inference:  56%|█████▋    | 18/32 [00:08<00:06,  2.04it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  2.04it/s]Inference:  62%|██████▎   | 20/32 [00:09<00:05,  2.04it/s]Inference:  66%|██████▌   | 21/32 [00:10<00:05,  2.04it/s]Inference:  69%|██████▉   | 22/32 [00:10<00:04,  2.03it/s]Inference:  72%|███████▏  | 23/32 [00:11<00:04,  2.00it/s]Inference:  75%|███████▌  | 24/32 [00:11<00:03,  2.01it/s]Inference:  78%|███████▊  | 25/32 [00:12<00:03,  2.01it/s]Inference:  81%|████████▏ | 26/32 [00:12<00:02,  2.01it/s]Inference:  84%|████████▍ | 27/32 [00:13<00:02,  2.02it/s]Inference:  88%|████████▊ | 28/32 [00:13<00:01,  2.03it/s]Inference:  91%|█████████ | 29/32 [00:14<00:01,  2.02it/s]Inference:  94%|█████████▍| 30/32 [00:14<00:00,  2.00it/s]Inference:  97%|█████████▋| 31/32 [00:15<00:00,  1.96it/s]Inference: 100%|██████████| 32/32 [00:15<00:00,  1.93it/s]Inference: 100%|██████████| 32/32 [00:15<00:00,  2.00it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 55
48317 MiB free out of 48676 MiB total
Done with layer 55 total_time elapsed: 1077 estimated time left: 462
layer original dtype torch.bfloat16
skipping layer 56
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:14,  2.09it/s]Inference:   6%|▋         | 2/32 [00:01<00:15,  1.96it/s]Inference:   9%|▉         | 3/32 [00:01<00:14,  2.01it/s]Inference:  12%|█▎        | 4/32 [00:02<00:14,  1.96it/s]Inference:  16%|█▌        | 5/32 [00:02<00:13,  1.94it/s]Inference:  19%|█▉        | 6/32 [00:03<00:13,  1.92it/s]Inference:  22%|██▏       | 7/32 [00:03<00:12,  1.93it/s]Inference:  25%|██▌       | 8/32 [00:04<00:12,  1.99it/s]Inference:  28%|██▊       | 9/32 [00:04<00:11,  1.96it/s]Inference:  31%|███▏      | 10/32 [00:05<00:11,  1.92it/s]Inference:  34%|███▍      | 11/32 [00:05<00:11,  1.91it/s]Inference:  38%|███▊      | 12/32 [00:06<00:10,  1.97it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  1.95it/s]Inference:  44%|████▍     | 14/32 [00:07<00:09,  1.92it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  1.92it/s]Inference:  50%|█████     | 16/32 [00:08<00:08,  1.94it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  1.99it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:07,  1.94it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  1.92it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.91it/s]Inference:  66%|██████▌   | 21/32 [00:10<00:05,  1.97it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.94it/s]Inference:  72%|███████▏  | 23/32 [00:11<00:04,  1.96it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:03,  2.01it/s]Inference:  78%|███████▊  | 25/32 [00:12<00:03,  2.02it/s]Inference:  81%|████████▏ | 26/32 [00:13<00:02,  2.05it/s]Inference:  84%|████████▍ | 27/32 [00:13<00:02,  2.01it/s]Inference:  88%|████████▊ | 28/32 [00:14<00:02,  1.95it/s]Inference:  91%|█████████ | 29/32 [00:14<00:01,  1.97it/s]Inference:  94%|█████████▍| 30/32 [00:15<00:00,  2.02it/s]Inference:  97%|█████████▋| 31/32 [00:15<00:00,  1.97it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.96it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.96it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 56
48317 MiB free out of 48676 MiB total
Done with layer 56 total_time elapsed: 1095 estimated time left: 442
layer original dtype torch.bfloat16
skipping layer 57
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:14,  2.09it/s]Inference:   6%|▋         | 2/32 [00:01<00:15,  1.95it/s]Inference:   9%|▉         | 3/32 [00:01<00:14,  2.03it/s]Inference:  12%|█▎        | 4/32 [00:02<00:14,  1.93it/s]Inference:  16%|█▌        | 5/32 [00:02<00:14,  1.92it/s]Inference:  19%|█▉        | 6/32 [00:03<00:13,  1.94it/s]Inference:  22%|██▏       | 7/32 [00:03<00:12,  1.98it/s]Inference:  25%|██▌       | 8/32 [00:04<00:11,  2.01it/s]Inference:  28%|██▊       | 9/32 [00:04<00:11,  1.96it/s]Inference:  31%|███▏      | 10/32 [00:05<00:11,  1.93it/s]Inference:  34%|███▍      | 11/32 [00:05<00:10,  1.94it/s]Inference:  38%|███▊      | 12/32 [00:06<00:10,  1.99it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  1.94it/s]Inference:  44%|████▍     | 14/32 [00:07<00:09,  1.92it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  1.90it/s]Inference:  50%|█████     | 16/32 [00:08<00:08,  1.96it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  1.96it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:07,  1.94it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  1.98it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:05,  2.01it/s]Inference:  66%|██████▌   | 21/32 [00:10<00:05,  1.94it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.92it/s]Inference:  72%|███████▏  | 23/32 [00:11<00:04,  1.91it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:04,  1.93it/s]Inference:  78%|███████▊  | 25/32 [00:12<00:03,  1.98it/s]Inference:  81%|████████▏ | 26/32 [00:13<00:03,  1.94it/s]Inference:  84%|████████▍ | 27/32 [00:13<00:02,  1.91it/s]Inference:  88%|████████▊ | 28/32 [00:14<00:02,  1.90it/s]Inference:  91%|█████████ | 29/32 [00:14<00:01,  1.96it/s]Inference:  94%|█████████▍| 30/32 [00:15<00:01,  1.93it/s]Inference:  97%|█████████▋| 31/32 [00:15<00:00,  1.90it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.89it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.94it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 57
48317 MiB free out of 48676 MiB total
Done with layer 57 total_time elapsed: 1114 estimated time left: 422
layer original dtype torch.bfloat16
skipping layer 58
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:14,  2.11it/s]Inference:   6%|▋         | 2/32 [00:00<00:14,  2.02it/s]Inference:   9%|▉         | 3/32 [00:01<00:14,  2.05it/s]Inference:  12%|█▎        | 4/32 [00:02<00:14,  1.96it/s]Inference:  16%|█▌        | 5/32 [00:02<00:14,  1.91it/s]Inference:  19%|█▉        | 6/32 [00:03<00:13,  1.89it/s]Inference:  22%|██▏       | 7/32 [00:03<00:12,  1.93it/s]Inference:  25%|██▌       | 8/32 [00:04<00:12,  1.98it/s]Inference:  28%|██▊       | 9/32 [00:04<00:11,  1.94it/s]Inference:  31%|███▏      | 10/32 [00:05<00:11,  1.89it/s]Inference:  34%|███▍      | 11/32 [00:05<00:10,  1.95it/s]Inference:  38%|███▊      | 12/32 [00:06<00:10,  1.92it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  1.91it/s]Inference:  44%|████▍     | 14/32 [00:07<00:09,  1.97it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  1.95it/s]Inference:  50%|█████     | 16/32 [00:08<00:08,  1.92it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  1.89it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:07,  1.85it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  1.87it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.94it/s]Inference:  66%|██████▌   | 21/32 [00:10<00:05,  1.91it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.90it/s]Inference:  72%|███████▏  | 23/32 [00:11<00:04,  1.89it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:04,  1.94it/s]Inference:  78%|███████▊  | 25/32 [00:12<00:03,  1.91it/s]Inference:  81%|████████▏ | 26/32 [00:13<00:03,  1.88it/s]Inference:  84%|████████▍ | 27/32 [00:14<00:02,  1.88it/s]Inference:  88%|████████▊ | 28/32 [00:14<00:02,  1.92it/s]Inference:  91%|█████████ | 29/32 [00:15<00:01,  1.93it/s]Inference:  94%|█████████▍| 30/32 [00:15<00:01,  1.90it/s]Inference:  97%|█████████▋| 31/32 [00:16<00:00,  1.88it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.89it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.92it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 58
48317 MiB free out of 48676 MiB total
Done with layer 58 total_time elapsed: 1132 estimated time left: 403
layer original dtype torch.bfloat16
skipping layer 59
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:14,  2.10it/s]Inference:   6%|▋         | 2/32 [00:00<00:14,  2.01it/s]Inference:   9%|▉         | 3/32 [00:01<00:14,  2.05it/s]Inference:  12%|█▎        | 4/32 [00:01<00:14,  1.98it/s]Inference:  16%|█▌        | 5/32 [00:02<00:13,  1.94it/s]Inference:  19%|█▉        | 6/32 [00:03<00:13,  1.92it/s]Inference:  22%|██▏       | 7/32 [00:03<00:12,  1.97it/s]Inference:  25%|██▌       | 8/32 [00:04<00:12,  1.94it/s]Inference:  28%|██▊       | 9/32 [00:04<00:11,  1.92it/s]Inference:  31%|███▏      | 10/32 [00:05<00:11,  1.91it/s]Inference:  34%|███▍      | 11/32 [00:05<00:11,  1.91it/s]Inference:  38%|███▊      | 12/32 [00:06<00:10,  1.96it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  1.90it/s]Inference:  44%|████▍     | 14/32 [00:07<00:09,  1.89it/s]Inference:  47%|████▋     | 15/32 [00:07<00:09,  1.89it/s]Inference:  50%|█████     | 16/32 [00:08<00:08,  1.93it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  1.93it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:07,  1.91it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  1.89it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.89it/s]Inference:  66%|██████▌   | 21/32 [00:10<00:05,  1.95it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.92it/s]Inference:  72%|███████▏  | 23/32 [00:11<00:04,  1.89it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:04,  1.85it/s]Inference:  78%|███████▊  | 25/32 [00:12<00:03,  1.91it/s]Inference:  81%|████████▏ | 26/32 [00:13<00:03,  1.89it/s]Inference:  84%|████████▍ | 27/32 [00:14<00:02,  1.88it/s]Inference:  88%|████████▊ | 28/32 [00:14<00:02,  1.86it/s]Inference:  91%|█████████ | 29/32 [00:15<00:01,  1.90it/s]Inference:  94%|█████████▍| 30/32 [00:15<00:01,  1.91it/s]Inference:  97%|█████████▋| 31/32 [00:16<00:00,  1.94it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.95it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.92it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 59
48317 MiB free out of 48676 MiB total
Done with layer 59 total_time elapsed: 1150 estimated time left: 383
layer original dtype torch.bfloat16
skipping layer 60
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:14,  2.07it/s]Inference:   6%|▋         | 2/32 [00:01<00:16,  1.87it/s]Inference:   9%|▉         | 3/32 [00:01<00:14,  1.94it/s]Inference:  12%|█▎        | 4/32 [00:02<00:14,  1.96it/s]Inference:  16%|█▌        | 5/32 [00:02<00:13,  2.00it/s]Inference:  19%|█▉        | 6/32 [00:03<00:12,  2.04it/s]Inference:  22%|██▏       | 7/32 [00:03<00:12,  1.99it/s]Inference:  25%|██▌       | 8/32 [00:04<00:12,  2.00it/s]Inference:  28%|██▊       | 9/32 [00:04<00:11,  2.02it/s]Inference:  31%|███▏      | 10/32 [00:05<00:11,  1.98it/s]Inference:  34%|███▍      | 11/32 [00:05<00:10,  1.97it/s]Inference:  38%|███▊      | 12/32 [00:06<00:10,  1.99it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  2.04it/s]Inference:  44%|████▍     | 14/32 [00:06<00:08,  2.03it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  2.06it/s]Inference:  50%|█████     | 16/32 [00:07<00:07,  2.04it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  2.05it/s]Inference:  56%|█████▋    | 18/32 [00:08<00:06,  2.05it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  2.04it/s]Inference:  62%|██████▎   | 20/32 [00:09<00:05,  2.02it/s]Inference:  66%|██████▌   | 21/32 [00:10<00:05,  2.03it/s]Inference:  69%|██████▉   | 22/32 [00:10<00:04,  2.03it/s]Inference:  72%|███████▏  | 23/32 [00:11<00:04,  2.02it/s]Inference:  75%|███████▌  | 24/32 [00:11<00:03,  2.02it/s]Inference:  78%|███████▊  | 25/32 [00:12<00:03,  2.05it/s]Inference:  81%|████████▏ | 26/32 [00:12<00:03,  1.99it/s]Inference:  84%|████████▍ | 27/32 [00:13<00:02,  1.95it/s]Inference:  88%|████████▊ | 28/32 [00:13<00:02,  1.92it/s]Inference:  91%|█████████ | 29/32 [00:14<00:01,  1.92it/s]Inference:  94%|█████████▍| 30/32 [00:15<00:01,  1.96it/s]Inference:  97%|█████████▋| 31/32 [00:15<00:00,  1.92it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.89it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.99it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 60
48317 MiB free out of 48676 MiB total
Done with layer 60 total_time elapsed: 1168 estimated time left: 364
layer original dtype torch.bfloat16
skipping layer 61
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:14,  2.07it/s]Inference:   6%|▋         | 2/32 [00:01<00:15,  1.94it/s]Inference:   9%|▉         | 3/32 [00:01<00:14,  2.01it/s]Inference:  12%|█▎        | 4/32 [00:02<00:14,  1.94it/s]Inference:  16%|█▌        | 5/32 [00:02<00:14,  1.91it/s]Inference:  19%|█▉        | 6/32 [00:03<00:13,  1.90it/s]Inference:  22%|██▏       | 7/32 [00:03<00:12,  1.94it/s]Inference:  25%|██▌       | 8/32 [00:04<00:12,  1.98it/s]Inference:  28%|██▊       | 9/32 [00:04<00:11,  1.95it/s]Inference:  31%|███▏      | 10/32 [00:05<00:11,  1.93it/s]Inference:  34%|███▍      | 11/32 [00:05<00:10,  1.92it/s]Inference:  38%|███▊      | 12/32 [00:06<00:10,  1.98it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  1.94it/s]Inference:  44%|████▍     | 14/32 [00:07<00:09,  1.91it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  1.90it/s]Inference:  50%|█████     | 16/32 [00:08<00:08,  1.92it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  1.90it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:07,  1.97it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  1.94it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.92it/s]Inference:  66%|██████▌   | 21/32 [00:10<00:05,  1.97it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.94it/s]Inference:  72%|███████▏  | 23/32 [00:11<00:04,  1.91it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:04,  1.90it/s]Inference:  78%|███████▊  | 25/32 [00:12<00:03,  1.96it/s]Inference:  81%|████████▏ | 26/32 [00:13<00:03,  1.93it/s]Inference:  84%|████████▍ | 27/32 [00:13<00:02,  1.91it/s]Inference:  88%|████████▊ | 28/32 [00:14<00:02,  1.90it/s]Inference:  91%|█████████ | 29/32 [00:15<00:01,  1.93it/s]Inference:  94%|█████████▍| 30/32 [00:15<00:01,  1.98it/s]Inference:  97%|█████████▋| 31/32 [00:16<00:00,  1.94it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.92it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.93it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 61
48317 MiB free out of 48676 MiB total
Done with layer 61 total_time elapsed: 1186 estimated time left: 344
layer original dtype torch.bfloat16
skipping layer 62
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:14,  2.09it/s]Inference:   6%|▋         | 2/32 [00:00<00:14,  2.03it/s]Inference:   9%|▉         | 3/32 [00:01<00:14,  2.05it/s]Inference:  12%|█▎        | 4/32 [00:02<00:14,  1.93it/s]Inference:  16%|█▌        | 5/32 [00:02<00:14,  1.92it/s]Inference:  19%|█▉        | 6/32 [00:03<00:13,  1.98it/s]Inference:  22%|██▏       | 7/32 [00:03<00:12,  2.02it/s]Inference:  25%|██▌       | 8/32 [00:03<00:11,  2.05it/s]Inference:  28%|██▊       | 9/32 [00:04<00:11,  2.00it/s]Inference:  31%|███▏      | 10/32 [00:05<00:11,  1.97it/s]Inference:  34%|███▍      | 11/32 [00:05<00:10,  2.03it/s]Inference:  38%|███▊      | 12/32 [00:05<00:09,  2.01it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  2.05it/s]Inference:  44%|████▍     | 14/32 [00:06<00:09,  1.99it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  1.96it/s]Inference:  50%|█████     | 16/32 [00:08<00:08,  1.95it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  2.01it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:07,  1.96it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  1.94it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.94it/s]Inference:  66%|██████▌   | 21/32 [00:10<00:05,  1.98it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.96it/s]Inference:  72%|███████▏  | 23/32 [00:11<00:04,  1.95it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:04,  1.93it/s]Inference:  78%|███████▊  | 25/32 [00:12<00:03,  1.95it/s]Inference:  81%|████████▏ | 26/32 [00:13<00:03,  1.98it/s]Inference:  84%|████████▍ | 27/32 [00:13<00:02,  1.96it/s]Inference:  88%|████████▊ | 28/32 [00:14<00:02,  1.94it/s]Inference:  91%|█████████ | 29/32 [00:14<00:01,  1.95it/s]Inference:  94%|█████████▍| 30/32 [00:15<00:01,  1.99it/s]Inference:  97%|█████████▋| 31/32 [00:15<00:00,  1.96it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.94it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.97it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 62
48317 MiB free out of 48676 MiB total
Done with layer 62 total_time elapsed: 1204 estimated time left: 325
layer original dtype torch.bfloat16
skipping layer 63
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:15,  2.06it/s]Inference:   6%|▋         | 2/32 [00:01<00:15,  1.96it/s]Inference:   9%|▉         | 3/32 [00:01<00:14,  1.95it/s]Inference:  12%|█▎        | 4/32 [00:02<00:13,  2.01it/s]Inference:  16%|█▌        | 5/32 [00:02<00:13,  1.97it/s]Inference:  19%|█▉        | 6/32 [00:03<00:13,  1.94it/s]Inference:  22%|██▏       | 7/32 [00:03<00:12,  1.93it/s]Inference:  25%|██▌       | 8/32 [00:04<00:12,  1.95it/s]Inference:  28%|██▊       | 9/32 [00:04<00:11,  1.93it/s]Inference:  31%|███▏      | 10/32 [00:05<00:11,  1.92it/s]Inference:  34%|███▍      | 11/32 [00:05<00:10,  1.94it/s]Inference:  38%|███▊      | 12/32 [00:06<00:10,  1.94it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  1.99it/s]Inference:  44%|████▍     | 14/32 [00:07<00:09,  1.92it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  1.91it/s]Inference:  50%|█████     | 16/32 [00:08<00:08,  1.89it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  1.96it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:07,  1.93it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  1.92it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.89it/s]Inference:  66%|██████▌   | 21/32 [00:10<00:05,  1.93it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.97it/s]Inference:  72%|███████▏  | 23/32 [00:11<00:04,  1.94it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:04,  1.91it/s]Inference:  78%|███████▊  | 25/32 [00:12<00:03,  1.90it/s]Inference:  81%|████████▏ | 26/32 [00:13<00:03,  1.95it/s]Inference:  84%|████████▍ | 27/32 [00:13<00:02,  1.93it/s]Inference:  88%|████████▊ | 28/32 [00:14<00:02,  1.91it/s]Inference:  91%|█████████ | 29/32 [00:15<00:01,  1.90it/s]Inference:  94%|█████████▍| 30/32 [00:15<00:01,  1.94it/s]Inference:  97%|█████████▋| 31/32 [00:16<00:00,  1.91it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.89it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.93it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 63
48317 MiB free out of 48676 MiB total
Done with layer 63 total_time elapsed: 1222 estimated time left: 306
layer original dtype torch.bfloat16
skipping layer 64
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:15,  1.97it/s]Inference:   6%|▋         | 2/32 [00:01<00:15,  1.88it/s]Inference:   9%|▉         | 3/32 [00:01<00:15,  1.88it/s]Inference:  12%|█▎        | 4/32 [00:02<00:14,  1.95it/s]Inference:  16%|█▌        | 5/32 [00:02<00:14,  1.92it/s]Inference:  19%|█▉        | 6/32 [00:03<00:13,  1.88it/s]Inference:  22%|██▏       | 7/32 [00:03<00:13,  1.88it/s]Inference:  25%|██▌       | 8/32 [00:04<00:12,  1.93it/s]Inference:  28%|██▊       | 9/32 [00:04<00:12,  1.88it/s]Inference:  31%|███▏      | 10/32 [00:05<00:11,  1.86it/s]Inference:  34%|███▍      | 11/32 [00:05<00:11,  1.86it/s]Inference:  38%|███▊      | 12/32 [00:06<00:10,  1.88it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  1.94it/s]Inference:  44%|████▍     | 14/32 [00:07<00:09,  1.91it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  1.89it/s]Inference:  50%|█████     | 16/32 [00:08<00:08,  1.85it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  1.92it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:07,  1.90it/s]Inference:  59%|█████▉    | 19/32 [00:10<00:06,  1.88it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.88it/s]Inference:  66%|██████▌   | 21/32 [00:11<00:05,  1.94it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.92it/s]Inference:  72%|███████▏  | 23/32 [00:12<00:04,  1.90it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:04,  1.87it/s]Inference:  78%|███████▊  | 25/32 [00:13<00:03,  1.91it/s]Inference:  81%|████████▏ | 26/32 [00:13<00:03,  1.93it/s]Inference:  84%|████████▍ | 27/32 [00:14<00:02,  1.96it/s]Inference:  88%|████████▊ | 28/32 [00:14<00:02,  1.96it/s]Inference:  91%|█████████ | 29/32 [00:15<00:01,  1.99it/s]Inference:  94%|█████████▍| 30/32 [00:15<00:00,  2.01it/s]Inference:  97%|█████████▋| 31/32 [00:16<00:00,  1.99it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  2.00it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.92it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 64
48317 MiB free out of 48676 MiB total
Done with layer 64 total_time elapsed: 1240 estimated time left: 286
layer original dtype torch.bfloat16
skipping layer 65
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:14,  2.07it/s]Inference:   6%|▋         | 2/32 [00:00<00:14,  2.10it/s]Inference:   9%|▉         | 3/32 [00:01<00:14,  2.04it/s]Inference:  12%|█▎        | 4/32 [00:01<00:13,  2.01it/s]Inference:  16%|█▌        | 5/32 [00:02<00:13,  2.01it/s]Inference:  19%|█▉        | 6/32 [00:02<00:13,  1.99it/s]Inference:  22%|██▏       | 7/32 [00:03<00:12,  1.99it/s]Inference:  25%|██▌       | 8/32 [00:04<00:12,  1.93it/s]Inference:  28%|██▊       | 9/32 [00:04<00:11,  1.97it/s]Inference:  31%|███▏      | 10/32 [00:05<00:11,  1.94it/s]Inference:  34%|███▍      | 11/32 [00:05<00:10,  1.96it/s]Inference:  38%|███▊      | 12/32 [00:06<00:10,  1.96it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  1.93it/s]Inference:  44%|████▍     | 14/32 [00:07<00:09,  1.89it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  1.90it/s]Inference:  50%|█████     | 16/32 [00:08<00:08,  1.92it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  1.93it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:07,  1.96it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  1.92it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.94it/s]Inference:  66%|██████▌   | 21/32 [00:10<00:05,  1.95it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.95it/s]Inference:  72%|███████▏  | 23/32 [00:11<00:04,  1.93it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:04,  1.90it/s]Inference:  78%|███████▊  | 25/32 [00:12<00:03,  1.85it/s]Inference:  81%|████████▏ | 26/32 [00:13<00:03,  1.91it/s]Inference:  84%|████████▍ | 27/32 [00:13<00:02,  1.87it/s]Inference:  88%|████████▊ | 28/32 [00:14<00:02,  1.85it/s]Inference:  91%|█████████ | 29/32 [00:15<00:01,  1.83it/s]Inference:  94%|█████████▍| 30/32 [00:15<00:01,  1.87it/s]Inference:  97%|█████████▋| 31/32 [00:16<00:00,  1.85it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.85it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.92it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 65
48317 MiB free out of 48676 MiB total
Done with layer 65 total_time elapsed: 1259 estimated time left: 267
layer original dtype torch.bfloat16
skipping layer 66
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:14,  2.08it/s]Inference:   6%|▋         | 2/32 [00:01<00:15,  1.92it/s]Inference:   9%|▉         | 3/32 [00:01<00:14,  1.99it/s]Inference:  12%|█▎        | 4/32 [00:02<00:14,  1.98it/s]Inference:  16%|█▌        | 5/32 [00:02<00:14,  1.92it/s]Inference:  19%|█▉        | 6/32 [00:03<00:13,  1.94it/s]Inference:  22%|██▏       | 7/32 [00:03<00:13,  1.91it/s]Inference:  25%|██▌       | 8/32 [00:04<00:12,  1.90it/s]Inference:  28%|██▊       | 9/32 [00:04<00:11,  1.96it/s]Inference:  31%|███▏      | 10/32 [00:05<00:11,  1.92it/s]Inference:  34%|███▍      | 11/32 [00:05<00:11,  1.89it/s]Inference:  38%|███▊      | 12/32 [00:06<00:10,  1.88it/s]Inference:  41%|████      | 13/32 [00:06<00:10,  1.89it/s]Inference:  44%|████▍     | 14/32 [00:07<00:09,  1.87it/s]Inference:  47%|████▋     | 15/32 [00:07<00:09,  1.86it/s]Inference:  50%|█████     | 16/32 [00:08<00:08,  1.86it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:08,  1.86it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:07,  1.90it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  1.88it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.86it/s]Inference:  66%|██████▌   | 21/32 [00:11<00:05,  1.84it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.90it/s]Inference:  72%|███████▏  | 23/32 [00:12<00:04,  1.88it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:04,  1.85it/s]Inference:  78%|███████▊  | 25/32 [00:13<00:03,  1.86it/s]Inference:  81%|████████▏ | 26/32 [00:13<00:03,  1.87it/s]Inference:  84%|████████▍ | 27/32 [00:14<00:02,  1.93it/s]Inference:  88%|████████▊ | 28/32 [00:14<00:02,  1.98it/s]Inference:  91%|█████████ | 29/32 [00:15<00:01,  1.96it/s]Inference:  94%|█████████▍| 30/32 [00:15<00:01,  1.91it/s]Inference:  97%|█████████▋| 31/32 [00:16<00:00,  1.91it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.90it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.90it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 66
48317 MiB free out of 48676 MiB total
Done with layer 66 total_time elapsed: 1277 estimated time left: 248
layer original dtype torch.bfloat16
skipping layer 67
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:14,  2.10it/s]Inference:   6%|▋         | 2/32 [00:01<00:15,  1.94it/s]Inference:   9%|▉         | 3/32 [00:01<00:15,  1.90it/s]Inference:  12%|█▎        | 4/32 [00:02<00:14,  1.92it/s]Inference:  16%|█▌        | 5/32 [00:02<00:14,  1.92it/s]Inference:  19%|█▉        | 6/32 [00:03<00:13,  1.95it/s]Inference:  22%|██▏       | 7/32 [00:03<00:13,  1.91it/s]Inference:  25%|██▌       | 8/32 [00:04<00:12,  1.94it/s]Inference:  28%|██▊       | 9/32 [00:04<00:11,  1.97it/s]Inference:  31%|███▏      | 10/32 [00:05<00:11,  2.00it/s]Inference:  34%|███▍      | 11/32 [00:05<00:10,  1.97it/s]Inference:  38%|███▊      | 12/32 [00:06<00:10,  1.92it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  1.90it/s]Inference:  44%|████▍     | 14/32 [00:07<00:09,  1.90it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  1.95it/s]Inference:  50%|█████     | 16/32 [00:08<00:08,  1.92it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  1.89it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:07,  1.87it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  1.92it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.90it/s]Inference:  66%|██████▌   | 21/32 [00:10<00:05,  1.86it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.85it/s]Inference:  72%|███████▏  | 23/32 [00:12<00:04,  1.85it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:04,  1.90it/s]Inference:  78%|███████▊  | 25/32 [00:13<00:03,  1.88it/s]Inference:  81%|████████▏ | 26/32 [00:13<00:03,  1.86it/s]Inference:  84%|████████▍ | 27/32 [00:14<00:02,  1.86it/s]Inference:  88%|████████▊ | 28/32 [00:14<00:02,  1.91it/s]Inference:  91%|█████████ | 29/32 [00:15<00:01,  1.84it/s]Inference:  94%|█████████▍| 30/32 [00:15<00:01,  1.85it/s]Inference:  97%|█████████▋| 31/32 [00:16<00:00,  1.83it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.83it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.89it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 67
48317 MiB free out of 48676 MiB total
Done with layer 67 total_time elapsed: 1295 estimated time left: 229
layer original dtype torch.bfloat16
skipping layer 68
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:14,  2.10it/s]Inference:   6%|▋         | 2/32 [00:00<00:14,  2.12it/s]Inference:   9%|▉         | 3/32 [00:01<00:14,  1.96it/s]Inference:  12%|█▎        | 4/32 [00:02<00:14,  1.90it/s]Inference:  16%|█▌        | 5/32 [00:02<00:14,  1.88it/s]Inference:  19%|█▉        | 6/32 [00:03<00:13,  1.92it/s]Inference:  22%|██▏       | 7/32 [00:03<00:12,  1.98it/s]Inference:  25%|██▌       | 8/32 [00:04<00:12,  1.94it/s]Inference:  28%|██▊       | 9/32 [00:04<00:12,  1.88it/s]Inference:  31%|███▏      | 10/32 [00:05<00:11,  1.87it/s]Inference:  34%|███▍      | 11/32 [00:05<00:10,  1.94it/s]Inference:  38%|███▊      | 12/32 [00:06<00:10,  1.95it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  1.92it/s]Inference:  44%|████▍     | 14/32 [00:07<00:09,  1.89it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  1.90it/s]Inference:  50%|█████     | 16/32 [00:08<00:08,  1.94it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  1.99it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:07,  1.96it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  2.00it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.98it/s]Inference:  66%|██████▌   | 21/32 [00:10<00:05,  2.00it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.98it/s]Inference:  72%|███████▏  | 23/32 [00:11<00:04,  1.95it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:04,  1.91it/s]Inference:  78%|███████▊  | 25/32 [00:12<00:03,  1.94it/s]Inference:  81%|████████▏ | 26/32 [00:13<00:03,  1.92it/s]Inference:  84%|████████▍ | 27/32 [00:13<00:02,  1.90it/s]Inference:  88%|████████▊ | 28/32 [00:14<00:02,  1.88it/s]Inference:  91%|█████████ | 29/32 [00:15<00:01,  1.87it/s]Inference:  94%|█████████▍| 30/32 [00:15<00:01,  1.94it/s]Inference:  97%|█████████▋| 31/32 [00:16<00:00,  1.93it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.91it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.93it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 68
48317 MiB free out of 48676 MiB total
Done with layer 68 total_time elapsed: 1314 estimated time left: 209
layer original dtype torch.bfloat16
skipping layer 69
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:14,  2.10it/s]Inference:   6%|▋         | 2/32 [00:01<00:15,  1.93it/s]Inference:   9%|▉         | 3/32 [00:01<00:15,  1.89it/s]Inference:  12%|█▎        | 4/32 [00:02<00:14,  1.91it/s]Inference:  16%|█▌        | 5/32 [00:02<00:14,  1.91it/s]Inference:  19%|█▉        | 6/32 [00:03<00:13,  1.89it/s]Inference:  22%|██▏       | 7/32 [00:03<00:13,  1.88it/s]Inference:  25%|██▌       | 8/32 [00:04<00:13,  1.80it/s]Inference:  28%|██▊       | 9/32 [00:04<00:12,  1.88it/s]Inference:  31%|███▏      | 10/32 [00:05<00:11,  1.87it/s]Inference:  34%|███▍      | 11/32 [00:05<00:11,  1.86it/s]Inference:  38%|███▊      | 12/32 [00:06<00:10,  1.86it/s]Inference:  41%|████      | 13/32 [00:06<00:10,  1.88it/s]Inference:  44%|████▍     | 14/32 [00:07<00:09,  1.86it/s]Inference:  47%|████▋     | 15/32 [00:08<00:09,  1.85it/s]Inference:  50%|█████     | 16/32 [00:08<00:08,  1.85it/s]Inference:  53%|█████▎    | 17/32 [00:09<00:08,  1.87it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:07,  1.93it/s]Inference:  59%|█████▉    | 19/32 [00:10<00:06,  1.90it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.89it/s]Inference:  66%|██████▌   | 21/32 [00:11<00:05,  1.88it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.91it/s]Inference:  72%|███████▏  | 23/32 [00:12<00:04,  1.90it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:04,  1.89it/s]Inference:  78%|███████▊  | 25/32 [00:13<00:03,  1.88it/s]Inference:  81%|████████▏ | 26/32 [00:13<00:03,  1.89it/s]Inference:  84%|████████▍ | 27/32 [00:14<00:02,  1.93it/s]Inference:  88%|████████▊ | 28/32 [00:14<00:02,  1.95it/s]Inference:  91%|█████████ | 29/32 [00:15<00:01,  1.94it/s]Inference:  94%|█████████▍| 30/32 [00:15<00:01,  1.97it/s]Inference:  97%|█████████▋| 31/32 [00:16<00:00,  2.00it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  2.00it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.91it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 69
48317 MiB free out of 48676 MiB total
Done with layer 69 total_time elapsed: 1332 estimated time left: 190
layer original dtype torch.bfloat16
skipping layer 70
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:15,  1.96it/s]Inference:   6%|▋         | 2/32 [00:01<00:16,  1.80it/s]Inference:   9%|▉         | 3/32 [00:01<00:15,  1.85it/s]Inference:  12%|█▎        | 4/32 [00:02<00:14,  1.94it/s]Inference:  16%|█▌        | 5/32 [00:02<00:13,  1.97it/s]Inference:  19%|█▉        | 6/32 [00:03<00:13,  1.96it/s]Inference:  22%|██▏       | 7/32 [00:03<00:12,  1.95it/s]Inference:  25%|██▌       | 8/32 [00:04<00:12,  1.96it/s]Inference:  28%|██▊       | 9/32 [00:04<00:11,  1.96it/s]Inference:  31%|███▏      | 10/32 [00:05<00:11,  1.96it/s]Inference:  34%|███▍      | 11/32 [00:05<00:10,  1.98it/s]Inference:  38%|███▊      | 12/32 [00:06<00:10,  1.98it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  1.99it/s]Inference:  44%|████▍     | 14/32 [00:07<00:09,  1.98it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  1.97it/s]Inference:  50%|█████     | 16/32 [00:08<00:08,  1.96it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  1.96it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:07,  1.99it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  1.99it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.96it/s]Inference:  66%|██████▌   | 21/32 [00:10<00:05,  1.94it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.91it/s]Inference:  72%|███████▏  | 23/32 [00:11<00:04,  1.96it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:04,  1.93it/s]Inference:  78%|███████▊  | 25/32 [00:12<00:03,  1.92it/s]Inference:  81%|████████▏ | 26/32 [00:13<00:03,  1.90it/s]Inference:  84%|████████▍ | 27/32 [00:13<00:02,  1.93it/s]Inference:  88%|████████▊ | 28/32 [00:14<00:02,  1.93it/s]Inference:  91%|█████████ | 29/32 [00:14<00:01,  1.92it/s]Inference:  94%|█████████▍| 30/32 [00:15<00:01,  1.90it/s]Inference:  97%|█████████▋| 31/32 [00:15<00:00,  1.97it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.93it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.94it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 70
48317 MiB free out of 48676 MiB total
Done with layer 70 total_time elapsed: 1350 estimated time left: 171
layer original dtype torch.bfloat16
skipping layer 71
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:00<00:14,  2.13it/s]Inference:   6%|▋         | 2/32 [00:01<00:15,  1.98it/s]Inference:   9%|▉         | 3/32 [00:01<00:14,  1.95it/s]Inference:  12%|█▎        | 4/32 [00:02<00:14,  1.98it/s]Inference:  16%|█▌        | 5/32 [00:02<00:13,  2.03it/s]Inference:  19%|█▉        | 6/32 [00:03<00:13,  1.97it/s]Inference:  22%|██▏       | 7/32 [00:03<00:12,  1.95it/s]Inference:  25%|██▌       | 8/32 [00:04<00:12,  1.94it/s]Inference:  28%|██▊       | 9/32 [00:04<00:11,  2.00it/s]Inference:  31%|███▏      | 10/32 [00:05<00:11,  1.95it/s]Inference:  34%|███▍      | 11/32 [00:05<00:10,  1.94it/s]Inference:  38%|███▊      | 12/32 [00:06<00:10,  1.93it/s]Inference:  41%|████      | 13/32 [00:06<00:09,  1.98it/s]Inference:  44%|████▍     | 14/32 [00:07<00:08,  2.02it/s]Inference:  47%|████▋     | 15/32 [00:07<00:08,  1.99it/s]Inference:  50%|█████     | 16/32 [00:08<00:08,  1.96it/s]Inference:  53%|█████▎    | 17/32 [00:08<00:07,  1.98it/s]Inference:  56%|█████▋    | 18/32 [00:09<00:06,  2.02it/s]Inference:  59%|█████▉    | 19/32 [00:09<00:06,  1.98it/s]Inference:  62%|██████▎   | 20/32 [00:10<00:06,  1.96it/s]Inference:  66%|██████▌   | 21/32 [00:10<00:05,  1.94it/s]Inference:  69%|██████▉   | 22/32 [00:11<00:05,  1.99it/s]Inference:  72%|███████▏  | 23/32 [00:11<00:04,  2.02it/s]Inference:  75%|███████▌  | 24/32 [00:12<00:04,  1.98it/s]Inference:  78%|███████▊  | 25/32 [00:12<00:03,  1.95it/s]Inference:  81%|████████▏ | 26/32 [00:13<00:03,  2.00it/s]Inference:  84%|████████▍ | 27/32 [00:13<00:02,  1.97it/s]Inference:  88%|████████▊ | 28/32 [00:14<00:02,  1.95it/s]Inference:  91%|█████████ | 29/32 [00:14<00:01,  1.90it/s]Inference:  94%|█████████▍| 30/32 [00:15<00:01,  1.91it/s]Inference:  97%|█████████▋| 31/32 [00:15<00:00,  1.91it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.91it/s]Inference: 100%|██████████| 32/32 [00:16<00:00,  1.96it/s]
41693 MiB free out of 48676 MiB total
after cleaning up 71
48317 MiB free out of 48676 MiB total
Done with layer 71 total_time elapsed: 1368 estimated time left: 152
layer original dtype torch.bfloat16
sublayer Linear(in_features=8192, out_features=8192, bias=False)
sublayer Linear(in_features=8192, out_features=1024, bias=False)
sublayer Linear(in_features=8192, out_features=1024, bias=False)
sublayer Linear(in_features=8192, out_features=8192, bias=False)
sublayer Linear(in_features=8192, out_features=28672, bias=False)
sublayer Linear(in_features=8192, out_features=28672, bias=False)
sublayer Linear(in_features=28672, out_features=8192, bias=False)
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:02<01:05,  2.12s/it]Inference:   6%|▋         | 2/32 [00:04<01:02,  2.09s/it]Inference:   9%|▉         | 3/32 [00:06<01:01,  2.13s/it]Inference:  12%|█▎        | 4/32 [00:08<01:00,  2.14s/it]Inference:  16%|█▌        | 5/32 [00:10<00:57,  2.15s/it]Inference:  19%|█▉        | 6/32 [00:12<00:55,  2.14s/it]Inference:  22%|██▏       | 7/32 [00:14<00:53,  2.14s/it]Inference:  25%|██▌       | 8/32 [00:16<00:50,  2.11s/it]Inference:  28%|██▊       | 9/32 [00:19<00:48,  2.12s/it]Inference:  31%|███▏      | 10/32 [00:21<00:46,  2.13s/it]Inference:  34%|███▍      | 11/32 [00:23<00:45,  2.14s/it]Inference:  38%|███▊      | 12/32 [00:25<00:42,  2.14s/it]Inference:  41%|████      | 13/32 [00:27<00:40,  2.16s/it]Inference:  44%|████▍     | 14/32 [00:29<00:38,  2.16s/it]Inference:  47%|████▋     | 15/32 [00:32<00:36,  2.15s/it]Inference:  50%|█████     | 16/32 [00:34<00:34,  2.15s/it]Inference:  53%|█████▎    | 17/32 [00:36<00:32,  2.15s/it]Inference:  56%|█████▋    | 18/32 [00:38<00:29,  2.14s/it]Inference:  59%|█████▉    | 19/32 [00:40<00:27,  2.15s/it]Inference:  62%|██████▎   | 20/32 [00:42<00:25,  2.14s/it]Inference:  66%|██████▌   | 21/32 [00:44<00:23,  2.14s/it]Inference:  69%|██████▉   | 22/32 [00:47<00:21,  2.15s/it]Inference:  72%|███████▏  | 23/32 [00:49<00:19,  2.15s/it]Inference:  75%|███████▌  | 24/32 [00:51<00:17,  2.18s/it]Inference:  78%|███████▊  | 25/32 [00:53<00:15,  2.17s/it]Inference:  81%|████████▏ | 26/32 [00:55<00:12,  2.15s/it]Inference:  84%|████████▍ | 27/32 [00:57<00:10,  2.15s/it]Inference:  88%|████████▊ | 28/32 [01:00<00:08,  2.16s/it]Inference:  91%|█████████ | 29/32 [01:02<00:06,  2.15s/it]Inference:  94%|█████████▍| 30/32 [01:04<00:04,  2.14s/it]Inference:  97%|█████████▋| 31/32 [01:06<00:02,  2.14s/it]Inference: 100%|██████████| 32/32 [01:08<00:00,  2.12s/it]Inference: 100%|██████████| 32/32 [01:08<00:00,  2.14s/it]
45053 MiB free out of 48676 MiB total
after cleaning up 72
45053 MiB free out of 48676 MiB total
Done with layer 72 total_time elapsed: 1453 estimated time left: 139
layer original dtype torch.bfloat16
sublayer Linear(in_features=8192, out_features=8192, bias=False)
sublayer Linear(in_features=8192, out_features=1024, bias=False)
sublayer Linear(in_features=8192, out_features=1024, bias=False)
sublayer Linear(in_features=8192, out_features=8192, bias=False)
sublayer Linear(in_features=8192, out_features=28672, bias=False)
sublayer Linear(in_features=8192, out_features=28672, bias=False)
sublayer Linear(in_features=28672, out_features=8192, bias=False)
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:02<01:07,  2.19s/it]Inference:   6%|▋         | 2/32 [00:04<01:04,  2.14s/it]Inference:   9%|▉         | 3/32 [00:06<01:02,  2.16s/it]Inference:  12%|█▎        | 4/32 [00:08<01:00,  2.16s/it]Inference:  16%|█▌        | 5/32 [00:10<00:58,  2.16s/it]Inference:  19%|█▉        | 6/32 [00:12<00:55,  2.15s/it]Inference:  22%|██▏       | 7/32 [00:15<00:53,  2.15s/it]Inference:  25%|██▌       | 8/32 [00:17<00:51,  2.13s/it]Inference:  28%|██▊       | 9/32 [00:19<00:49,  2.14s/it]Inference:  31%|███▏      | 10/32 [00:21<00:47,  2.14s/it]Inference:  34%|███▍      | 11/32 [00:23<00:44,  2.14s/it]Inference:  38%|███▊      | 12/32 [00:25<00:42,  2.14s/it]Inference:  41%|████      | 13/32 [00:27<00:40,  2.14s/it]Inference:  44%|████▍     | 14/32 [00:30<00:38,  2.14s/it]Inference:  47%|████▋     | 15/32 [00:32<00:36,  2.15s/it]Inference:  50%|█████     | 16/32 [00:34<00:34,  2.14s/it]Inference:  53%|█████▎    | 17/32 [00:36<00:32,  2.15s/it]Inference:  56%|█████▋    | 18/32 [00:38<00:30,  2.15s/it]Inference:  59%|█████▉    | 19/32 [00:40<00:27,  2.14s/it]Inference:  62%|██████▎   | 20/32 [00:42<00:25,  2.14s/it]Inference:  66%|██████▌   | 21/32 [00:45<00:23,  2.13s/it]Inference:  69%|██████▉   | 22/32 [00:47<00:21,  2.15s/it]Inference:  72%|███████▏  | 23/32 [00:49<00:19,  2.15s/it]Inference:  75%|███████▌  | 24/32 [00:51<00:17,  2.15s/it]Inference:  78%|███████▊  | 25/32 [00:53<00:15,  2.15s/it]Inference:  81%|████████▏ | 26/32 [00:55<00:12,  2.15s/it]Inference:  84%|████████▍ | 27/32 [00:57<00:10,  2.14s/it]Inference:  88%|████████▊ | 28/32 [01:00<00:08,  2.15s/it]Inference:  91%|█████████ | 29/32 [01:02<00:06,  2.14s/it]Inference:  94%|█████████▍| 30/32 [01:04<00:04,  2.16s/it]Inference:  97%|█████████▋| 31/32 [01:06<00:02,  2.16s/it]Inference: 100%|██████████| 32/32 [01:08<00:00,  2.13s/it]Inference: 100%|██████████| 32/32 [01:08<00:00,  2.14s/it]
43421 MiB free out of 48676 MiB total
after cleaning up 73
43421 MiB free out of 48676 MiB total
Done with layer 73 total_time elapsed: 1537 estimated time left: 125
layer original dtype torch.bfloat16
sublayer Linear(in_features=8192, out_features=8192, bias=False)
sublayer Linear(in_features=8192, out_features=1024, bias=False)
sublayer Linear(in_features=8192, out_features=1024, bias=False)
sublayer Linear(in_features=8192, out_features=8192, bias=False)
sublayer Linear(in_features=8192, out_features=28672, bias=False)
sublayer Linear(in_features=8192, out_features=28672, bias=False)
sublayer Linear(in_features=28672, out_features=8192, bias=False)
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:02<01:10,  2.26s/it]Inference:   6%|▋         | 2/32 [00:04<01:04,  2.14s/it]Inference:   9%|▉         | 3/32 [00:06<01:02,  2.15s/it]Inference:  12%|█▎        | 4/32 [00:08<01:00,  2.15s/it]Inference:  16%|█▌        | 5/32 [00:10<00:57,  2.14s/it]Inference:  19%|█▉        | 6/32 [00:12<00:55,  2.15s/it]Inference:  22%|██▏       | 7/32 [00:15<00:53,  2.15s/it]Inference:  25%|██▌       | 8/32 [00:17<00:50,  2.12s/it]Inference:  28%|██▊       | 9/32 [00:19<00:48,  2.13s/it]Inference:  31%|███▏      | 10/32 [00:21<00:46,  2.13s/it]Inference:  34%|███▍      | 11/32 [00:23<00:44,  2.13s/it]Inference:  38%|███▊      | 12/32 [00:25<00:42,  2.13s/it]Inference:  41%|████      | 13/32 [00:27<00:40,  2.13s/it]Inference:  44%|████▍     | 14/32 [00:29<00:38,  2.13s/it]Inference:  47%|████▋     | 15/32 [00:32<00:36,  2.13s/it]Inference:  50%|█████     | 16/32 [00:34<00:34,  2.14s/it]Inference:  53%|█████▎    | 17/32 [00:36<00:32,  2.14s/it]Inference:  56%|█████▋    | 18/32 [00:38<00:29,  2.13s/it]Inference:  59%|█████▉    | 19/32 [00:40<00:27,  2.14s/it]Inference:  62%|██████▎   | 20/32 [00:42<00:25,  2.14s/it]Inference:  66%|██████▌   | 21/32 [00:44<00:23,  2.15s/it]Inference:  69%|██████▉   | 22/32 [00:47<00:21,  2.14s/it]Inference:  72%|███████▏  | 23/32 [00:49<00:19,  2.14s/it]Inference:  75%|███████▌  | 24/32 [00:51<00:17,  2.14s/it]Inference:  78%|███████▊  | 25/32 [00:53<00:15,  2.14s/it]Inference:  81%|████████▏ | 26/32 [00:55<00:12,  2.14s/it]Inference:  84%|████████▍ | 27/32 [00:57<00:10,  2.14s/it]Inference:  88%|████████▊ | 28/32 [00:59<00:08,  2.14s/it]Inference:  91%|█████████ | 29/32 [01:02<00:06,  2.15s/it]Inference:  94%|█████████▍| 30/32 [01:04<00:04,  2.15s/it]Inference:  97%|█████████▋| 31/32 [01:06<00:02,  2.15s/it]Inference: 100%|██████████| 32/32 [01:08<00:00,  2.13s/it]Inference: 100%|██████████| 32/32 [01:08<00:00,  2.14s/it]
41789 MiB free out of 48676 MiB total
after cleaning up 74
41789 MiB free out of 48676 MiB total
Done with layer 74 total_time elapsed: 1622 estimated time left: 108
layer original dtype torch.bfloat16
sublayer Linear(in_features=8192, out_features=8192, bias=False)
sublayer Linear(in_features=8192, out_features=1024, bias=False)
sublayer Linear(in_features=8192, out_features=1024, bias=False)
sublayer Linear(in_features=8192, out_features=8192, bias=False)
sublayer Linear(in_features=8192, out_features=28672, bias=False)
sublayer Linear(in_features=8192, out_features=28672, bias=False)
sublayer Linear(in_features=28672, out_features=8192, bias=False)
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:02<01:08,  2.22s/it]Inference:   6%|▋         | 2/32 [00:04<01:04,  2.14s/it]Inference:   9%|▉         | 3/32 [00:06<01:02,  2.15s/it]Inference:  12%|█▎        | 4/32 [00:08<01:00,  2.16s/it]Inference:  16%|█▌        | 5/32 [00:10<00:58,  2.15s/it]Inference:  19%|█▉        | 6/32 [00:12<00:56,  2.16s/it]Inference:  22%|██▏       | 7/32 [00:15<00:54,  2.17s/it]Inference:  25%|██▌       | 8/32 [00:17<00:51,  2.14s/it]Inference:  28%|██▊       | 9/32 [00:19<00:49,  2.14s/it]Inference:  31%|███▏      | 10/32 [00:21<00:46,  2.13s/it]Inference:  34%|███▍      | 11/32 [00:23<00:44,  2.13s/it]Inference:  38%|███▊      | 12/32 [00:25<00:42,  2.14s/it]Inference:  41%|████      | 13/32 [00:27<00:40,  2.13s/it]Inference:  44%|████▍     | 14/32 [00:30<00:38,  2.14s/it]Inference:  47%|████▋     | 15/32 [00:32<00:36,  2.15s/it]Inference:  50%|█████     | 16/32 [00:34<00:34,  2.14s/it]Inference:  53%|█████▎    | 17/32 [00:36<00:32,  2.14s/it]Inference:  56%|█████▋    | 18/32 [00:38<00:29,  2.13s/it]Inference:  59%|█████▉    | 19/32 [00:40<00:27,  2.13s/it]Inference:  62%|██████▎   | 20/32 [00:42<00:25,  2.13s/it]Inference:  66%|██████▌   | 21/32 [00:44<00:23,  2.13s/it]Inference:  69%|██████▉   | 22/32 [00:47<00:21,  2.14s/it]Inference:  72%|███████▏  | 23/32 [00:49<00:19,  2.13s/it]Inference:  75%|███████▌  | 24/32 [00:51<00:17,  2.13s/it]Inference:  78%|███████▊  | 25/32 [00:53<00:14,  2.14s/it]Inference:  81%|████████▏ | 26/32 [00:55<00:12,  2.14s/it]Inference:  84%|████████▍ | 27/32 [00:57<00:10,  2.15s/it]Inference:  88%|████████▊ | 28/32 [01:00<00:08,  2.15s/it]Inference:  91%|█████████ | 29/32 [01:02<00:06,  2.15s/it]Inference:  94%|█████████▍| 30/32 [01:04<00:04,  2.14s/it]Inference:  97%|█████████▋| 31/32 [01:06<00:02,  2.15s/it]Inference: 100%|██████████| 32/32 [01:08<00:00,  2.12s/it]Inference: 100%|██████████| 32/32 [01:08<00:00,  2.14s/it]
40157 MiB free out of 48676 MiB total
after cleaning up 75
40157 MiB free out of 48676 MiB total
Done with layer 75 total_time elapsed: 1707 estimated time left: 90
layer original dtype torch.bfloat16
sublayer Linear(in_features=8192, out_features=8192, bias=False)
sublayer Linear(in_features=8192, out_features=1024, bias=False)
sublayer Linear(in_features=8192, out_features=1024, bias=False)
sublayer Linear(in_features=8192, out_features=8192, bias=False)
sublayer Linear(in_features=8192, out_features=28672, bias=False)
sublayer Linear(in_features=8192, out_features=28672, bias=False)
sublayer Linear(in_features=28672, out_features=8192, bias=False)
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:02<01:13,  2.36s/it]Inference:   6%|▋         | 2/32 [00:04<01:09,  2.31s/it]Inference:   9%|▉         | 3/32 [00:06<01:06,  2.28s/it]Inference:  12%|█▎        | 4/32 [00:09<01:03,  2.26s/it]Inference:  16%|█▌        | 5/32 [00:11<01:00,  2.25s/it]Inference:  19%|█▉        | 6/32 [00:13<00:58,  2.24s/it]Inference:  22%|██▏       | 7/32 [00:15<00:55,  2.24s/it]Inference:  25%|██▌       | 8/32 [00:17<00:52,  2.20s/it]Inference:  28%|██▊       | 9/32 [00:20<00:50,  2.21s/it]Inference:  31%|███▏      | 10/32 [00:22<00:48,  2.20s/it]Inference:  34%|███▍      | 11/32 [00:24<00:45,  2.18s/it]Inference:  38%|███▊      | 12/32 [00:26<00:43,  2.19s/it]Inference:  41%|████      | 13/32 [00:28<00:41,  2.19s/it]Inference:  44%|████▍     | 14/32 [00:31<00:39,  2.21s/it]Inference:  47%|████▋     | 15/32 [00:33<00:37,  2.23s/it]Inference:  50%|█████     | 16/32 [00:35<00:35,  2.25s/it]Inference:  53%|█████▎    | 17/32 [00:37<00:33,  2.25s/it]Inference:  56%|█████▋    | 18/32 [00:40<00:31,  2.24s/it]Inference:  59%|█████▉    | 19/32 [00:42<00:28,  2.22s/it]Inference:  62%|██████▎   | 20/32 [00:44<00:26,  2.21s/it]Inference:  66%|██████▌   | 21/32 [00:46<00:24,  2.20s/it]Inference:  69%|██████▉   | 22/32 [00:48<00:22,  2.21s/it]Inference:  72%|███████▏  | 23/32 [00:51<00:19,  2.22s/it]Inference:  75%|███████▌  | 24/32 [00:53<00:17,  2.23s/it]Inference:  78%|███████▊  | 25/32 [00:55<00:15,  2.24s/it]Inference:  81%|████████▏ | 26/32 [00:57<00:13,  2.25s/it]Inference:  84%|████████▍ | 27/32 [01:00<00:11,  2.25s/it]Inference:  88%|████████▊ | 28/32 [01:02<00:09,  2.26s/it]Inference:  91%|█████████ | 29/32 [01:04<00:06,  2.25s/it]Inference:  94%|█████████▍| 30/32 [01:06<00:04,  2.26s/it]Inference:  97%|█████████▋| 31/32 [01:09<00:02,  2.26s/it]Inference: 100%|██████████| 32/32 [01:11<00:00,  2.21s/it]Inference: 100%|██████████| 32/32 [01:11<00:00,  2.23s/it]
38525 MiB free out of 48676 MiB total
after cleaning up 76
38525 MiB free out of 48676 MiB total
Done with layer 76 total_time elapsed: 1793 estimated time left: 70
layer original dtype torch.bfloat16
sublayer Linear(in_features=8192, out_features=8192, bias=False)
sublayer Linear(in_features=8192, out_features=1024, bias=False)
sublayer Linear(in_features=8192, out_features=1024, bias=False)
sublayer Linear(in_features=8192, out_features=8192, bias=False)
sublayer Linear(in_features=8192, out_features=28672, bias=False)
sublayer Linear(in_features=8192, out_features=28672, bias=False)
sublayer Linear(in_features=28672, out_features=8192, bias=False)
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:02<01:08,  2.20s/it]Inference:   6%|▋         | 2/32 [00:04<01:03,  2.13s/it]Inference:   9%|▉         | 3/32 [00:06<01:03,  2.19s/it]Inference:  12%|█▎        | 4/32 [00:08<01:01,  2.21s/it]Inference:  16%|█▌        | 5/32 [00:11<01:00,  2.23s/it]Inference:  19%|█▉        | 6/32 [00:13<00:57,  2.23s/it]Inference:  22%|██▏       | 7/32 [00:15<00:55,  2.23s/it]Inference:  25%|██▌       | 8/32 [00:17<00:52,  2.19s/it]Inference:  28%|██▊       | 9/32 [00:19<00:50,  2.19s/it]Inference:  31%|███▏      | 10/32 [00:21<00:47,  2.18s/it]Inference:  34%|███▍      | 11/32 [00:24<00:45,  2.19s/it]Inference:  38%|███▊      | 12/32 [00:26<00:43,  2.20s/it]Inference:  41%|████      | 13/32 [00:28<00:41,  2.20s/it]Inference:  44%|████▍     | 14/32 [00:30<00:39,  2.19s/it]Inference:  47%|████▋     | 15/32 [00:32<00:37,  2.19s/it]Inference:  50%|█████     | 16/32 [00:35<00:34,  2.18s/it]Inference:  53%|█████▎    | 17/32 [00:37<00:32,  2.18s/it]Inference:  56%|█████▋    | 18/32 [00:39<00:30,  2.18s/it]Inference:  59%|█████▉    | 19/32 [00:41<00:28,  2.20s/it]Inference:  62%|██████▎   | 20/32 [00:43<00:26,  2.20s/it]Inference:  66%|██████▌   | 21/32 [00:46<00:24,  2.21s/it]Inference:  69%|██████▉   | 22/32 [00:48<00:22,  2.21s/it]Inference:  72%|███████▏  | 23/32 [00:50<00:19,  2.21s/it]Inference:  75%|███████▌  | 24/32 [00:52<00:17,  2.19s/it]Inference:  78%|███████▊  | 25/32 [00:54<00:15,  2.19s/it]Inference:  81%|████████▏ | 26/32 [00:57<00:13,  2.20s/it]Inference:  84%|████████▍ | 27/32 [00:59<00:11,  2.21s/it]Inference:  88%|████████▊ | 28/32 [01:01<00:08,  2.21s/it]Inference:  91%|█████████ | 29/32 [01:03<00:06,  2.21s/it]Inference:  94%|█████████▍| 30/32 [01:05<00:04,  2.21s/it]Inference:  97%|█████████▋| 31/32 [01:08<00:02,  2.22s/it]Inference: 100%|██████████| 32/32 [01:10<00:00,  2.19s/it]Inference: 100%|██████████| 32/32 [01:10<00:00,  2.20s/it]
36893 MiB free out of 48676 MiB total
after cleaning up 77
36893 MiB free out of 48676 MiB total
Done with layer 77 total_time elapsed: 1878 estimated time left: 48
layer original dtype torch.bfloat16
sublayer Linear(in_features=8192, out_features=8192, bias=False)
sublayer Linear(in_features=8192, out_features=1024, bias=False)
sublayer Linear(in_features=8192, out_features=1024, bias=False)
sublayer Linear(in_features=8192, out_features=8192, bias=False)
sublayer Linear(in_features=8192, out_features=28672, bias=False)
sublayer Linear(in_features=8192, out_features=28672, bias=False)
sublayer Linear(in_features=28672, out_features=8192, bias=False)
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:02<01:08,  2.22s/it]Inference:   6%|▋         | 2/32 [00:04<01:05,  2.19s/it]Inference:   9%|▉         | 3/32 [00:06<01:02,  2.17s/it]Inference:  12%|█▎        | 4/32 [00:08<01:00,  2.18s/it]Inference:  16%|█▌        | 5/32 [00:10<00:58,  2.18s/it]Inference:  19%|█▉        | 6/32 [00:13<00:57,  2.20s/it]Inference:  22%|██▏       | 7/32 [00:15<00:55,  2.22s/it]Inference:  25%|██▌       | 8/32 [00:17<00:52,  2.19s/it]Inference:  28%|██▊       | 9/32 [00:19<00:50,  2.20s/it]Inference:  31%|███▏      | 10/32 [00:22<00:48,  2.22s/it]Inference:  34%|███▍      | 11/32 [00:24<00:46,  2.21s/it]Inference:  38%|███▊      | 12/32 [00:26<00:43,  2.20s/it]Inference:  41%|████      | 13/32 [00:28<00:41,  2.20s/it]Inference:  44%|████▍     | 14/32 [00:30<00:39,  2.19s/it]Inference:  47%|████▋     | 15/32 [00:33<00:37,  2.21s/it]Inference:  50%|█████     | 16/32 [00:35<00:35,  2.22s/it]Inference:  53%|█████▎    | 17/32 [00:37<00:33,  2.24s/it]Inference:  56%|█████▋    | 18/32 [00:39<00:30,  2.21s/it]Inference:  59%|█████▉    | 19/32 [00:41<00:28,  2.21s/it]Inference:  62%|██████▎   | 20/32 [00:44<00:26,  2.22s/it]Inference:  66%|██████▌   | 21/32 [00:46<00:24,  2.20s/it]Inference:  69%|██████▉   | 22/32 [00:48<00:21,  2.19s/it]Inference:  72%|███████▏  | 23/32 [00:50<00:19,  2.20s/it]Inference:  75%|███████▌  | 24/32 [00:52<00:17,  2.21s/it]Inference:  78%|███████▊  | 25/32 [00:55<00:15,  2.23s/it]Inference:  81%|████████▏ | 26/32 [00:57<00:13,  2.23s/it]Inference:  84%|████████▍ | 27/32 [00:59<00:11,  2.24s/it]Inference:  88%|████████▊ | 28/32 [01:01<00:08,  2.25s/it]Inference:  91%|█████████ | 29/32 [01:04<00:06,  2.23s/it]Inference:  94%|█████████▍| 30/32 [01:06<00:04,  2.21s/it]Inference:  97%|█████████▋| 31/32 [01:08<00:02,  2.21s/it]Inference: 100%|██████████| 32/32 [01:10<00:00,  2.20s/it]Inference: 100%|██████████| 32/32 [01:10<00:00,  2.21s/it]
35261 MiB free out of 48676 MiB total
after cleaning up 78
35261 MiB free out of 48676 MiB total
Done with layer 78 total_time elapsed: 1965 estimated time left: 25
layer original dtype torch.bfloat16
sublayer Linear(in_features=8192, out_features=8192, bias=False)
sublayer Linear(in_features=8192, out_features=1024, bias=False)
sublayer Linear(in_features=8192, out_features=1024, bias=False)
sublayer Linear(in_features=8192, out_features=8192, bias=False)
sublayer Linear(in_features=8192, out_features=28672, bias=False)
sublayer Linear(in_features=8192, out_features=28672, bias=False)
sublayer Linear(in_features=28672, out_features=8192, bias=False)
Inference:   0%|          | 0/32 [00:00<?, ?it/s]Inference:   3%|▎         | 1/32 [00:02<01:07,  2.16s/it]Inference:   6%|▋         | 2/32 [00:04<01:03,  2.13s/it]Inference:   9%|▉         | 3/32 [00:06<01:02,  2.14s/it]Inference:  12%|█▎        | 4/32 [00:08<01:00,  2.16s/it]Inference:  16%|█▌        | 5/32 [00:10<00:58,  2.16s/it]Inference:  19%|█▉        | 6/32 [00:12<00:56,  2.16s/it]Inference:  22%|██▏       | 7/32 [00:15<00:54,  2.20s/it]Inference:  25%|██▌       | 8/32 [00:17<00:51,  2.16s/it]Inference:  28%|██▊       | 9/32 [00:19<00:49,  2.16s/it]Inference:  31%|███▏      | 10/32 [00:21<00:47,  2.16s/it]Inference:  34%|███▍      | 11/32 [00:23<00:45,  2.17s/it]Inference:  38%|███▊      | 12/32 [00:26<00:43,  2.20s/it]Inference:  41%|████      | 13/32 [00:28<00:41,  2.21s/it]Inference:  44%|████▍     | 14/32 [00:30<00:39,  2.20s/it]Inference:  47%|████▋     | 15/32 [00:32<00:37,  2.20s/it]Inference:  50%|█████     | 16/32 [00:34<00:35,  2.19s/it]Inference:  53%|█████▎    | 17/32 [00:37<00:32,  2.19s/it]Inference:  56%|█████▋    | 18/32 [00:39<00:30,  2.19s/it]Inference:  59%|█████▉    | 19/32 [00:41<00:28,  2.19s/it]Inference:  62%|██████▎   | 20/32 [00:43<00:26,  2.18s/it]Inference:  66%|██████▌   | 21/32 [00:45<00:24,  2.19s/it]Inference:  69%|██████▉   | 22/32 [00:47<00:21,  2.20s/it]Inference:  72%|███████▏  | 23/32 [00:50<00:19,  2.21s/it]Inference:  75%|███████▌  | 24/32 [00:52<00:17,  2.20s/it]Inference:  78%|███████▊  | 25/32 [00:54<00:15,  2.20s/it]Inference:  81%|████████▏ | 26/32 [00:56<00:13,  2.21s/it]Inference:  84%|████████▍ | 27/32 [00:59<00:11,  2.21s/it]Inference:  88%|████████▊ | 28/32 [01:01<00:08,  2.22s/it]Inference:  91%|█████████ | 29/32 [01:03<00:06,  2.21s/it]Inference:  94%|█████████▍| 30/32 [01:05<00:04,  2.21s/it]Inference:  97%|█████████▋| 31/32 [01:07<00:02,  2.22s/it]Inference: 100%|██████████| 32/32 [01:10<00:00,  2.18s/it]Inference: 100%|██████████| 32/32 [01:10<00:00,  2.19s/it]
33629 MiB free out of 48676 MiB total
after cleaning up 79
33629 MiB free out of 48676 MiB total
Done with layer 79 total_time elapsed: 2049 estimated time left: 0
Total bits: 0 Total params: 0
Traceback (most recent call last):
  File "/data/lliu/huffman/scripts/generate_hessians.py", line 366, in <module>
    generate_hessians(model, train_loader, val_loader, args.device)
  File "/home/lliu/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/lliu/huffman/scripts/generate_hessians.py", line 274, in generate_hessians
    print("average bits per value:", total_bits / total_params)
                                     ~~~~~~~~~~~^~~~~~~~~~~~~~
ZeroDivisionError: division by zero
