Namespace(models_to_compress=['meta-llama/Llama-2-7b-hf', 'meta-llama/Llama-2-13b-hf', 'meta-llama/Llama-2-70b-hf', 'meta-llama/Meta-Llama-3-8B'], seqlens=[4096, 4096, 4096, 8192], batch_size=1, hessian_path='/data/lliu/huffman/models/{model_name}/hessians_new/seed_0/pajama/128', discrete_update_hessian_path=None, weights_path='/data/lliu/huffman/models/{model_name}/original_weights', save_path='/data/lliu/huffman/models/{model_name}/compressed', self_attn_compression_algorithm='quantize', mlp_compression_algorithm='quantize', devices=['cuda:6', 'cuda:5', 'cuda:4', 'cuda:3', 'cuda:2'], yaml_path='/data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml', self_attn_yaml_path=None, mlp_yaml_path=None, use_already_done=False, use_wandb=True, resume_wandb=False, wandb_id=None, wandb_project='compression_no_finetune', run_name=None, no_config_update=False, ppl_eval=True)
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: m6481. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /data/lliu/huffman/wandb/run-20250111_123209-8nvg37wl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-resonance-101
wandb: ‚≠êÔ∏è View project at https://wandb.ai/m6481/compression_no_finetune
wandb: üöÄ View run at https://wandb.ai/m6481/compression_no_finetune/runs/8nvg37wl
  0%|          | 0/1288 [00:00<?, ?it/s]n_commands 1288
sample command python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_3/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_3/mlp.gate_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_3/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_3/mlp.gate_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_3/mlp.gate_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_3/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_3/mlp.up_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_3/mlp.up_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_3/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_3/self_attn.q_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_3/self_attn.q_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_3/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_3/self_attn.k_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_3/self_attn.k_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_3/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_3/self_attn.o_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_3/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_3/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_3/self_attn.q_proj/compressed.log
best_loss 119.84557342529297 running bpv: 2.040043
  0%|          | 1/1288 [04:40<100:09:01, 280.14s/it]COMMANDS_FINISHED 1 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_3/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_3/mlp.down_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_3/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_3/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_3/self_attn.k_proj/compressed.log
best_loss 135.93609619140625 running bpv: 2.040043
  0%|          | 2/1288 [04:46<42:28:07, 118.89s/it] COMMANDS_FINISHED 2 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_3/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_3/self_attn.v_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_3/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_3/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_3/self_attn.o_proj/compressed.log
best_loss 0.24297833442687988 running bpv: 2.040043
  0%|          | 3/1288 [04:54<24:21:49, 68.26s/it] COMMANDS_FINISHED 3 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_5/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_5/mlp.gate_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_5/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_3/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_3/self_attn.v_proj/compressed.log
best_loss 30.8930721282959 running bpv: 2.040043
  0%|          | 4/1288 [09:16<51:38:37, 144.80s/it]COMMANDS_FINISHED 4 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_5/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_5/mlp.up_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_5/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_3/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_3/mlp.gate_proj/compressed.log
best_loss 48.00326156616211 running bpv: 2.032156
  0%|          | 5/1288 [10:30<42:30:35, 119.28s/it]COMMANDS_FINISHED 5 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_5/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_5/self_attn.q_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_5/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_3/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_3/mlp.up_proj/compressed.log
best_loss 40.44489288330078 running bpv: 2.028792
  0%|          | 6/1288 [10:36<28:45:42, 80.77s/it] COMMANDS_FINISHED 6 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_5/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_5/self_attn.k_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_5/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_3/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_3/mlp.down_proj/compressed.log
best_loss 0.8194230794906616 running bpv: 2.026789
  1%|          | 7/1288 [14:56<49:36:06, 139.40s/it]COMMANDS_FINISHED 7 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_5/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_5/self_attn.o_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_5/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_5/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_5/self_attn.q_proj/compressed.log
best_loss 126.84709167480469 running bpv: 2.027804
  1%|          | 8/1288 [15:02<34:27:51, 96.93s/it] COMMANDS_FINISHED 8 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_5/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_5/mlp.down_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_5/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_5/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_5/self_attn.k_proj/compressed.log
best_loss 144.71115112304688 running bpv: 2.028674
  1%|          | 9/1288 [15:08<24:20:19, 68.51s/it]COMMANDS_FINISHED 9 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_5/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_5/self_attn.v_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_5/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_5/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_5/mlp.gate_proj/compressed.log
best_loss 85.82488250732422 running bpv: 2.02735
  1%|          | 10/1288 [15:26<18:47:08, 52.92s/it]COMMANDS_FINISHED 10 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_8/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_8/mlp.gate_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_8/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_5/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_5/self_attn.o_proj/compressed.log
best_loss 0.8817993998527527 running bpv: 2.028065
  1%|          | 11/1288 [19:27<39:12:03, 110.51s/it]COMMANDS_FINISHED 11 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_8/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_8/mlp.up_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_8/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_5/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_5/self_attn.v_proj/compressed.log
best_loss 35.34905242919922 running bpv: 2.028704
  1%|          | 12/1288 [19:40<28:39:24, 80.85s/it] COMMANDS_FINISHED 12 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_8/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_8/self_attn.q_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_8/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_5/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_5/mlp.up_proj/compressed.log
best_loss 67.51312255859375 running bpv: 2.027665
  1%|          | 13/1288 [19:46<20:36:15, 58.18s/it]COMMANDS_FINISHED 13 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_8/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_8/self_attn.k_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_8/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_8/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_8/self_attn.q_proj/compressed.log
best_loss 200.81752014160156 running bpv: 2.028217
  1%|          | 14/1288 [24:10<42:35:59, 120.38s/it]COMMANDS_FINISHED 14 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_8/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_8/self_attn.o_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_8/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_8/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_8/self_attn.k_proj/compressed.log
best_loss 207.37185668945312 running bpv: 2.028721
  1%|          | 15/1288 [24:22<31:00:55, 87.71s/it] COMMANDS_FINISHED 15 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_8/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_8/mlp.down_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_8/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_5/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_5/mlp.down_proj/compressed.log
best_loss 2.2289490699768066 running bpv: 2.027804
  1%|          | 16/1288 [25:17<27:30:53, 77.87s/it]COMMANDS_FINISHED 16 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_8/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_8/self_attn.v_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_8/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_8/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_8/mlp.gate_proj/compressed.log
best_loss 128.0747528076172 running bpv: 2.027115
  1%|‚ñè         | 17/1288 [26:00<23:47:37, 67.39s/it]COMMANDS_FINISHED 17 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_12/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_12/mlp.gate_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_12/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_8/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_8/self_attn.o_proj/compressed.log
best_loss 2.9614758491516113 running bpv: 2.027549
  1%|‚ñè         | 18/1288 [28:39<33:29:38, 94.94s/it]COMMANDS_FINISHED 18 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_12/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_12/mlp.up_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_12/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_8/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_8/self_attn.v_proj/compressed.log
best_loss 57.85379409790039 running bpv: 2.027954
  1%|‚ñè         | 19/1288 [29:49<30:49:51, 87.46s/it]COMMANDS_FINISHED 19 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_12/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_12/self_attn.q_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_12/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_8/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_8/mlp.up_proj/compressed.log
best_loss 103.32672882080078 running bpv: 2.02735
  2%|‚ñè         | 20/1288 [29:58<22:30:35, 63.91s/it]COMMANDS_FINISHED 20 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_12/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_12/self_attn.k_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_12/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_12/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_12/self_attn.q_proj/compressed.log
best_loss 247.73342895507812 running bpv: 2.027718
  2%|‚ñè         | 21/1288 [34:22<43:38:39, 124.01s/it]COMMANDS_FINISHED 21 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_12/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_12/self_attn.o_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_12/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_12/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_12/self_attn.k_proj/compressed.log
best_loss 270.71356201171875 running bpv: 2.028065
  2%|‚ñè         | 22/1288 [34:31<31:28:20, 89.49s/it] COMMANDS_FINISHED 22 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_12/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_12/mlp.down_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_12/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_8/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_8/mlp.down_proj/compressed.log
best_loss 5.4195451736450195 running bpv: 2.027484
  2%|‚ñè         | 23/1288 [34:39<22:51:17, 65.04s/it]COMMANDS_FINISHED 23 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_12/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_12/self_attn.v_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_12/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_12/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_12/mlp.gate_proj/compressed.log
best_loss 159.07901000976562 running bpv: 2.027019
  2%|‚ñè         | 24/1288 [36:30<27:34:40, 78.54s/it]COMMANDS_FINISHED 24 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_1/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_1/mlp.gate_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_1/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_12/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_12/self_attn.o_proj/compressed.log
best_loss 6.863934516906738 running bpv: 2.02733
  2%|‚ñè         | 25/1288 [38:58<34:52:24, 99.40s/it]COMMANDS_FINISHED 25 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_1/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_1/mlp.up_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_1/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_12/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_12/mlp.up_proj/compressed.log
best_loss 144.47352600097656 running bpv: 2.026913
  2%|‚ñè         | 26/1288 [39:07<25:20:18, 72.28s/it]COMMANDS_FINISHED 26 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_1/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_1/self_attn.q_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_1/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_12/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_12/self_attn.v_proj/compressed.log
best_loss 83.34698486328125 running bpv: 2.027201
  2%|‚ñè         | 27/1288 [39:13<18:21:13, 52.40s/it]COMMANDS_FINISHED 27 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_1/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_1/self_attn.k_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_1/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_1/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_1/self_attn.q_proj/compressed.log
best_loss 10.839945793151855 running bpv: 2.027477
  2%|‚ñè         | 28/1288 [43:37<40:34:24, 115.92s/it]COMMANDS_FINISHED 28 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_1/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_1/self_attn.o_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_1/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_1/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_1/self_attn.k_proj/compressed.log
best_loss 11.169244766235352 running bpv: 2.027741
  2%|‚ñè         | 29/1288 [43:47<29:25:43, 84.15s/it] COMMANDS_FINISHED 29 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_1/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_1/mlp.down_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_1/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_12/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_12/mlp.down_proj/compressed.log
best_loss 9.811717987060547 running bpv: 2.027317
  2%|‚ñè         | 30/1288 [44:48<26:58:56, 77.21s/it]COMMANDS_FINISHED 30 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_1/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_1/self_attn.v_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_1/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_1/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_1/mlp.gate_proj/compressed.log
best_loss 13.426972389221191 running bpv: 2.026967
  2%|‚ñè         | 31/1288 [46:58<32:29:46, 93.07s/it]COMMANDS_FINISHED 31 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_7/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_7/mlp.gate_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_7/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_1/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_1/self_attn.o_proj/compressed.log
best_loss 0.06460008770227432 running bpv: 2.027209
  2%|‚ñè         | 32/1288 [48:07<29:57:15, 85.86s/it]COMMANDS_FINISHED 32 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_7/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_7/mlp.up_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_7/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_1/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_1/self_attn.v_proj/compressed.log
best_loss 0.7376424074172974 running bpv: 2.027443
  3%|‚ñé         | 33/1288 [49:20<28:35:20, 82.01s/it]COMMANDS_FINISHED 33 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_7/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_7/self_attn.q_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_7/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_1/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_1/mlp.up_proj/compressed.log
best_loss 11.241580963134766 running bpv: 2.027115
  3%|‚ñé         | 34/1288 [49:27<20:43:42, 59.51s/it]COMMANDS_FINISHED 34 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_7/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_7/self_attn.k_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_7/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_7/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_7/self_attn.q_proj/compressed.log
best_loss 207.85960388183594 running bpv: 2.027336
  3%|‚ñé         | 35/1288 [53:55<42:29:47, 122.10s/it]COMMANDS_FINISHED 35 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_7/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_7/self_attn.o_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_7/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_7/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_7/self_attn.k_proj/compressed.log
best_loss 214.99855041503906 running bpv: 2.027549
  3%|‚ñé         | 36/1288 [54:01<30:21:01, 87.27s/it] COMMANDS_FINISHED 36 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_7/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_7/mlp.down_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_7/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_1/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_1/mlp.down_proj/compressed.log
best_loss 0.19723767042160034 running bpv: 2.027215
  3%|‚ñé         | 37/1288 [54:07<21:51:15, 62.89s/it]COMMANDS_FINISHED 37 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_7/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_7/self_attn.v_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_7/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_7/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_7/mlp.gate_proj/compressed.log
best_loss 123.23406982421875 running bpv: 2.026934
  3%|‚ñé         | 38/1288 [57:30<36:26:30, 104.95s/it]COMMANDS_FINISHED 38 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_0/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_0/mlp.gate_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_0/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_7/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_7/self_attn.o_proj/compressed.log
best_loss 1.9078752994537354 running bpv: 2.027132
  3%|‚ñé         | 39/1288 [58:27<31:25:28, 90.57s/it] COMMANDS_FINISHED 39 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_0/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_0/mlp.up_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_0/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_7/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_7/mlp.up_proj/compressed.log
best_loss 93.88176727294922 running bpv: 2.02687
  3%|‚ñé         | 40/1288 [58:34<22:42:29, 65.50s/it]COMMANDS_FINISHED 40 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_0/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_0/self_attn.q_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_0/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_7/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_7/self_attn.v_proj/compressed.log
best_loss 56.31377410888672 running bpv: 2.027059
  3%|‚ñé         | 41/1288 [58:40<16:30:25, 47.66s/it]COMMANDS_FINISHED 41 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_0/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_0/self_attn.k_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_0/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_0/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_0/self_attn.q_proj/compressed.log
best_loss 0.6414870619773865 running bpv: 2.027242
  3%|‚ñé         | 42/1288 [1:03:04<38:58:11, 112.59s/it]COMMANDS_FINISHED 42 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_0/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_0/self_attn.o_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_0/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_0/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_0/self_attn.k_proj/compressed.log
best_loss 0.37701618671417236 running bpv: 2.027421
  3%|‚ñé         | 43/1288 [1:03:11<27:59:01, 80.92s/it] COMMANDS_FINISHED 43 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_0/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_0/mlp.down_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_0/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_7/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_7/mlp.down_proj/compressed.log
best_loss 4.390452861785889 running bpv: 2.027146
  3%|‚ñé         | 44/1288 [1:04:19<26:37:30, 77.05s/it]COMMANDS_FINISHED 44 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_0/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_0/self_attn.v_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_0/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_0/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_0/self_attn.o_proj/compressed.log
best_loss 0.00646075839176774 running bpv: 2.027317
  3%|‚ñé         | 45/1288 [1:07:34<38:49:51, 112.46s/it]COMMANDS_FINISHED 45 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_31/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_31/mlp.gate_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_31/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_0/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_0/mlp.gate_proj/compressed.log
best_loss 3.3426597118377686 running bpv: 2.027079
  4%|‚ñé         | 46/1288 [1:08:01<29:57:21, 86.83s/it] COMMANDS_FINISHED 46 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_31/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_31/mlp.up_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_31/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_0/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_0/self_attn.v_proj/compressed.log
best_loss 0.06628772616386414 running bpv: 2.027243
  4%|‚ñé         | 47/1288 [1:08:50<26:01:19, 75.49s/it]COMMANDS_FINISHED 47 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_31/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_31/self_attn.q_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_31/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_0/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_0/mlp.up_proj/compressed.log
best_loss 2.9650635719299316 running bpv: 2.027019
  4%|‚ñé         | 48/1288 [1:09:03<19:26:29, 56.44s/it]COMMANDS_FINISHED 48 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_31/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_31/self_attn.k_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_31/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_31/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_31/self_attn.q_proj/compressed.log
best_loss 313.8927917480469 running bpv: 2.027176
  4%|‚ñç         | 49/1288 [1:13:23<40:27:14, 117.54s/it]COMMANDS_FINISHED 49 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_31/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_31/self_attn.o_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_31/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_0/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_0/mlp.down_proj/compressed.log
best_loss 0.026178160682320595 running bpv: 2.026944
  4%|‚ñç         | 50/1288 [1:13:29<28:54:52, 84.08s/it] COMMANDS_FINISHED 50 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_31/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_31/mlp.down_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_31/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_31/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_31/self_attn.k_proj/compressed.log
best_loss 366.3060302734375 running bpv: 2.027096
  4%|‚ñç         | 51/1288 [1:13:35<20:50:34, 60.66s/it]COMMANDS_FINISHED 51 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_31/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_31/self_attn.v_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_31/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_31/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_31/self_attn.o_proj/compressed.log
best_loss 58.9236946105957 running bpv: 2.027244
  4%|‚ñç         | 52/1288 [1:17:54<41:16:03, 120.20s/it]COMMANDS_FINISHED 52 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_21/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_21/mlp.gate_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_21/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_31/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_31/mlp.gate_proj/compressed.log
best_loss 667.9314575195312 running bpv: 2.027041
  4%|‚ñç         | 53/1288 [1:18:02<29:41:17, 86.54s/it] COMMANDS_FINISHED 53 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_21/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_21/mlp.up_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_21/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_31/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_31/self_attn.v_proj/compressed.log
best_loss 194.41598510742188 running bpv: 2.027183
  4%|‚ñç         | 54/1288 [1:18:08<21:22:57, 62.38s/it]COMMANDS_FINISHED 54 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_21/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_21/self_attn.q_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_21/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_31/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_31/mlp.up_proj/compressed.log
best_loss 655.209228515625 running bpv: 2.026989
  4%|‚ñç         | 55/1288 [1:18:30<17:13:02, 50.27s/it]COMMANDS_FINISHED 55 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_21/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_21/self_attn.k_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_21/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_21/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_21/self_attn.q_proj/compressed.log
best_loss 318.5999755859375 running bpv: 2.027127
  4%|‚ñç         | 56/1288 [1:22:37<37:24:42, 109.32s/it]COMMANDS_FINISHED 56 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_21/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_21/self_attn.o_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_21/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_21/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_21/self_attn.k_proj/compressed.log
best_loss 333.29803466796875 running bpv: 2.027262
  4%|‚ñç         | 57/1288 [1:23:07<29:14:46, 85.53s/it] COMMANDS_FINISHED 57 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_21/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_21/mlp.down_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_21/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_31/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_31/mlp.down_proj/compressed.log
best_loss 304.15423583984375 running bpv: 2.027058
  5%|‚ñç         | 58/1288 [1:23:50<24:51:55, 72.78s/it]COMMANDS_FINISHED 58 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_21/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_21/self_attn.v_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_21/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_21/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_21/self_attn.o_proj/compressed.log
best_loss 11.99828815460205 running bpv: 2.027189
  5%|‚ñç         | 59/1288 [1:27:07<37:34:34, 110.07s/it]COMMANDS_FINISHED 59 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_26/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_26/mlp.gate_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_26/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_21/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_21/self_attn.v_proj/compressed.log
best_loss 186.59913635253906 running bpv: 2.027317
  5%|‚ñç         | 60/1288 [1:28:23<34:03:46, 99.86s/it] COMMANDS_FINISHED 60 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_26/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_26/mlp.up_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_26/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_21/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_21/mlp.gate_proj/compressed.log
best_loss 388.98486328125 running bpv: 2.027137
  5%|‚ñç         | 61/1288 [1:28:29<24:26:19, 71.70s/it]COMMANDS_FINISHED 61 n_commands 1288
meta-llama/Llama-2-7b-hf/layer_21/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_21/mlp.up_proj/compressed.log
best_loss 332.1181640625 running bpv: 2.026967
COMMANDS_FINISHED 62 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_26/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_26/self_attn.q_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_26/self_attn.q_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_26/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_26/self_attn.k_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_26/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_26/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_26/self_attn.q_proj/compressed.log
best_loss 373.28424072265625 running bpv: 2.027089
  5%|‚ñç         | 63/1288 [1:33:03<34:39:47, 101.87s/it]COMMANDS_FINISHED 63 n_commands 1288
meta-llama/Llama-2-7b-hf/layer_26/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_26/self_attn.k_proj/compressed.log
best_loss 388.5416259765625 running bpv: 2.027209
COMMANDS_FINISHED 64 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_26/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_26/self_attn.o_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_26/self_attn.o_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_26/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_26/mlp.down_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_26/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_21/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_21/mlp.down_proj/compressed.log
best_loss 41.59030532836914 running bpv: 2.027029
  5%|‚ñå         | 65/1288 [1:33:24<22:16:26, 65.57s/it] COMMANDS_FINISHED 65 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_26/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_26/self_attn.v_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_26/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_26/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_26/self_attn.o_proj/compressed.log
best_loss 32.7528190612793 running bpv: 2.027146
  5%|‚ñå         | 66/1288 [1:37:37<36:19:46, 107.03s/it]COMMANDS_FINISHED 66 n_commands 1288
meta-llama/Llama-2-7b-hf/layer_26/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_26/mlp.gate_proj/compressed.log
best_loss 528.4825439453125 running bpv: 2.026988
COMMANDS_FINISHED 67 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_14/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_14/mlp.gate_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_14/mlp.gate_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_14/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_14/mlp.up_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_14/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_26/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_26/self_attn.v_proj/compressed.log
best_loss 277.5832824707031 running bpv: 2.027101
  5%|‚ñå         | 68/1288 [1:37:57<23:32:31, 69.47s/it] COMMANDS_FINISHED 68 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_14/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_14/self_attn.q_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_14/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_26/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_26/mlp.up_proj/compressed.log
best_loss 450.98199462890625 running bpv: 2.026949
  5%|‚ñå         | 69/1288 [1:38:57<22:49:48, 67.42s/it]COMMANDS_FINISHED 69 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_14/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_14/self_attn.k_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_14/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_14/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_14/self_attn.q_proj/compressed.log
best_loss 266.5088195800781 running bpv: 2.027059
  5%|‚ñå         | 70/1288 [1:42:30<34:27:29, 101.85s/it]COMMANDS_FINISHED 70 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_14/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_14/self_attn.o_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_14/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_26/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_26/mlp.down_proj/compressed.log
best_loss 62.18516540527344 running bpv: 2.026898
  6%|‚ñå         | 71/1288 [1:43:21<30:05:35, 89.02s/it] COMMANDS_FINISHED 71 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_14/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_14/mlp.down_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_14/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_14/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_14/self_attn.k_proj/compressed.log
best_loss 288.3487548828125 running bpv: 2.027006
  6%|‚ñå         | 72/1288 [1:43:30<22:54:22, 67.81s/it]COMMANDS_FINISHED 72 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_14/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_14/self_attn.v_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_14/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_14/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_14/self_attn.o_proj/compressed.log
best_loss 9.466745376586914 running bpv: 2.027111
  6%|‚ñå         | 73/1288 [1:47:03<36:15:32, 107.43s/it]COMMANDS_FINISHED 73 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_15/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_15/mlp.gate_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_15/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_14/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_14/self_attn.v_proj/compressed.log
best_loss 93.62350463867188 running bpv: 2.027215
  6%|‚ñå         | 74/1288 [1:48:06<32:00:34, 94.92s/it] COMMANDS_FINISHED 74 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_15/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_15/mlp.up_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_15/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_14/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_14/mlp.gate_proj/compressed.log
best_loss 184.3971710205078 running bpv: 2.027071
  6%|‚ñå         | 75/1288 [1:48:12<23:23:04, 69.40s/it]COMMANDS_FINISHED 75 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_15/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_15/self_attn.q_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_15/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_14/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_14/mlp.up_proj/compressed.log
best_loss 172.872314453125 running bpv: 2.026934
  6%|‚ñå         | 76/1288 [1:48:18<17:09:32, 50.97s/it]COMMANDS_FINISHED 76 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_15/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_15/self_attn.k_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_15/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_15/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_15/self_attn.q_proj/compressed.log
best_loss 250.01702880859375 running bpv: 2.027034
  6%|‚ñå         | 77/1288 [1:52:47<38:41:00, 115.00s/it]COMMANDS_FINISHED 77 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_15/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_15/self_attn.o_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_15/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_15/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_15/self_attn.k_proj/compressed.log
best_loss 279.31939697265625 running bpv: 2.027132
  6%|‚ñå         | 78/1288 [1:52:53<27:49:47, 82.80s/it] COMMANDS_FINISHED 78 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_15/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_15/mlp.down_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_15/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_14/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_14/mlp.down_proj/compressed.log
best_loss 14.038110733032227 running bpv: 2.026986
  6%|‚ñå         | 79/1288 [1:53:41<24:20:26, 72.48s/it]COMMANDS_FINISHED 79 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_15/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_15/self_attn.v_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_15/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_15/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_15/self_attn.o_proj/compressed.log
best_loss 10.016554832458496 running bpv: 2.027082
  6%|‚ñå         | 80/1288 [1:57:20<38:58:04, 116.13s/it]COMMANDS_FINISHED 80 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_4/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_4/mlp.gate_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_4/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_15/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_15/mlp.gate_proj/compressed.log
best_loss 203.93994140625 running bpv: 2.026953
  6%|‚ñã         | 81/1288 [1:57:32<28:31:06, 85.06s/it] COMMANDS_FINISHED 81 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_4/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_4/mlp.up_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_4/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_15/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_15/self_attn.v_proj/compressed.log
best_loss 97.74845123291016 running bpv: 2.027047
  6%|‚ñã         | 82/1288 [1:58:13<24:05:08, 71.90s/it]COMMANDS_FINISHED 82 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_4/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_4/self_attn.q_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_4/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_15/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_15/mlp.up_proj/compressed.log
best_loss 190.86941528320312 running bpv: 2.026921
  6%|‚ñã         | 83/1288 [1:58:36<19:10:10, 57.27s/it]COMMANDS_FINISHED 83 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_4/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_4/self_attn.k_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_4/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_4/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_4/self_attn.q_proj/compressed.log
best_loss 111.02044677734375 running bpv: 2.027013
  7%|‚ñã         | 84/1288 [2:02:44<38:16:01, 114.42s/it]COMMANDS_FINISHED 84 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_4/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_4/self_attn.o_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_4/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_15/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_15/mlp.down_proj/compressed.log
best_loss 17.627866744995117 running bpv: 2.02688
  7%|‚ñã         | 85/1288 [2:03:08<29:11:00, 87.33s/it] COMMANDS_FINISHED 85 n_commands 1288
meta-llama/Llama-2-7b-hf/layer_4/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_4/self_attn.k_proj/compressed.log
best_loss 120.13555908203125 running bpv: 2.02697
COMMANDS_FINISHED 86 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_4/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_4/mlp.down_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_4/mlp.down_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_4/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_4/self_attn.v_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_4/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_4/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_4/self_attn.o_proj/compressed.log
best_loss 0.5510374307632446 running bpv: 2.027058
  7%|‚ñã         | 87/1288 [2:07:19<35:00:58, 104.96s/it]COMMANDS_FINISHED 87 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_27/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_27/mlp.gate_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_27/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_4/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_4/self_attn.v_proj/compressed.log
best_loss 30.193233489990234 running bpv: 2.027146
  7%|‚ñã         | 88/1288 [2:07:43<28:18:02, 84.90s/it] COMMANDS_FINISHED 88 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_27/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_27/mlp.up_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_27/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_4/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_4/mlp.gate_proj/compressed.log
best_loss 67.49626922607422 running bpv: 2.027026
  7%|‚ñã         | 89/1288 [2:07:49<21:24:25, 64.27s/it]COMMANDS_FINISHED 89 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_27/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_27/self_attn.q_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_27/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_4/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_4/mlp.up_proj/compressed.log
best_loss 53.710750579833984 running bpv: 2.026911
  7%|‚ñã         | 90/1288 [2:08:01<16:39:34, 50.06s/it]COMMANDS_FINISHED 90 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_27/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_27/self_attn.k_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_27/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_27/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_27/self_attn.q_proj/compressed.log
best_loss 424.3494567871094 running bpv: 2.026996
  7%|‚ñã         | 91/1288 [2:12:24<36:27:54, 109.67s/it]COMMANDS_FINISHED 91 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_27/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_27/self_attn.o_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_27/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_27/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_27/self_attn.k_proj/compressed.log
best_loss 444.86273193359375 running bpv: 2.027079
  7%|‚ñã         | 92/1288 [2:12:32<26:47:24, 80.64s/it] COMMANDS_FINISHED 92 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_27/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_27/mlp.down_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_27/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_4/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_4/mlp.down_proj/compressed.log
best_loss 1.5177809000015259 running bpv: 2.026956
  7%|‚ñã         | 93/1288 [2:13:29<24:29:47, 73.80s/it]COMMANDS_FINISHED 93 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_27/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_27/self_attn.v_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_27/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_27/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_27/self_attn.o_proj/compressed.log
best_loss 19.884979248046875 running bpv: 2.027038
  7%|‚ñã         | 94/1288 [2:16:55<37:19:12, 112.52s/it]COMMANDS_FINISHED 94 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_2/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_2/mlp.gate_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_2/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_27/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_27/mlp.gate_proj/compressed.log
best_loss 566.478515625 running bpv: 2.026929
  7%|‚ñã         | 95/1288 [2:17:48<31:28:28, 94.98s/it] COMMANDS_FINISHED 95 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_2/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_2/mlp.up_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_2/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_27/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_27/self_attn.v_proj/compressed.log
best_loss 289.585205078125 running bpv: 2.027009
  7%|‚ñã         | 96/1288 [2:18:00<23:18:19, 70.39s/it]COMMANDS_FINISHED 96 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_2/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_2/self_attn.q_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_2/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_27/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_27/mlp.up_proj/compressed.log
best_loss 488.0482482910156 running bpv: 2.026902
  8%|‚ñä         | 97/1288 [2:18:12<17:32:26, 53.02s/it]COMMANDS_FINISHED 97 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_2/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_2/self_attn.k_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_2/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_2/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_2/self_attn.q_proj/compressed.log
best_loss 49.4848518371582 running bpv: 2.026981
  8%|‚ñä         | 98/1288 [2:22:31<37:44:43, 114.19s/it]COMMANDS_FINISHED 98 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_2/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_2/self_attn.o_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_2/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_2/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_2/self_attn.k_proj/compressed.log
best_loss 57.37301254272461 running bpv: 2.027059
  8%|‚ñä         | 99/1288 [2:22:46<27:55:39, 84.56s/it] COMMANDS_FINISHED 99 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_2/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_2/mlp.down_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_2/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_27/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_27/mlp.down_proj/compressed.log
best_loss 71.16854858398438 running bpv: 2.026944
  8%|‚ñä         | 100/1288 [2:22:52<20:09:00, 61.06s/it]COMMANDS_FINISHED 100 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_2/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_2/self_attn.v_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_2/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_2/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_2/self_attn.o_proj/compressed.log
best_loss 0.1462545543909073 running bpv: 2.027021
  8%|‚ñä         | 101/1288 [2:27:01<38:41:43, 117.36s/it]COMMANDS_FINISHED 101 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_28/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_28/mlp.gate_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_28/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_2/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_2/self_attn.v_proj/compressed.log
best_loss 11.821826934814453 running bpv: 2.027096
  8%|‚ñä         | 102/1288 [2:27:22<29:09:15, 88.50s/it] COMMANDS_FINISHED 102 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_28/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_28/mlp.up_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_28/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_2/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_2/mlp.gate_proj/compressed.log
best_loss 28.76287841796875 running bpv: 2.026994
  8%|‚ñä         | 103/1288 [2:27:28<20:59:31, 63.77s/it]COMMANDS_FINISHED 103 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_28/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_28/self_attn.q_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_28/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_2/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_2/mlp.up_proj/compressed.log
best_loss 24.514911651611328 running bpv: 2.026895
  8%|‚ñä         | 104/1288 [2:28:17<19:31:12, 59.35s/it]COMMANDS_FINISHED 104 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_28/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_28/self_attn.k_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_28/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_28/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_28/self_attn.q_proj/compressed.log
best_loss 418.000732421875 running bpv: 2.026968
  8%|‚ñä         | 105/1288 [2:32:02<35:50:02, 109.05s/it]COMMANDS_FINISHED 105 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_28/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_28/self_attn.o_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_28/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_28/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_28/self_attn.k_proj/compressed.log
best_loss 441.675537109375 running bpv: 2.027041
  8%|‚ñä         | 106/1288 [2:32:49<29:41:48, 90.45s/it] COMMANDS_FINISHED 106 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_28/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_28/mlp.down_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_28/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_2/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_2/mlp.down_proj/compressed.log
best_loss 0.4039464592933655 running bpv: 2.026934
  8%|‚ñä         | 107/1288 [2:33:07<22:32:41, 68.72s/it]COMMANDS_FINISHED 107 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_28/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_28/self_attn.v_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_28/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_28/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_28/self_attn.o_proj/compressed.log
best_loss 27.06995391845703 running bpv: 2.027006
  8%|‚ñä         | 108/1288 [2:36:33<36:01:58, 109.93s/it]COMMANDS_FINISHED 108 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_18/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_18/mlp.gate_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_18/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_28/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_28/mlp.gate_proj/compressed.log
best_loss 593.7869873046875 running bpv: 2.026911
  8%|‚ñä         | 109/1288 [2:37:29<30:42:25, 93.76s/it] COMMANDS_FINISHED 109 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_18/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_18/mlp.up_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_18/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_28/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_28/self_attn.v_proj/compressed.log
best_loss 320.49371337890625 running bpv: 2.026981
  9%|‚ñä         | 110/1288 [2:37:40<22:33:29, 68.94s/it]COMMANDS_FINISHED 110 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_18/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_18/self_attn.q_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_18/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_28/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_28/mlp.up_proj/compressed.log
best_loss 531.3165283203125 running bpv: 2.026888
  9%|‚ñä         | 111/1288 [2:37:52<16:57:19, 51.86s/it]COMMANDS_FINISHED 111 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_18/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_18/self_attn.k_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_18/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_18/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_18/self_attn.q_proj/compressed.log
best_loss 301.7868347167969 running bpv: 2.026957
  9%|‚ñä         | 112/1288 [2:42:10<37:09:08, 113.73s/it]COMMANDS_FINISHED 112 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_18/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_18/self_attn.o_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_18/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_18/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_18/self_attn.k_proj/compressed.log
best_loss 327.0965270996094 running bpv: 2.027025
  9%|‚ñâ         | 113/1288 [2:42:22<27:09:38, 83.22s/it] COMMANDS_FINISHED 113 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_18/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_18/mlp.down_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_18/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_28/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_28/mlp.down_proj/compressed.log
best_loss 86.48280334472656 running bpv: 2.026925
  9%|‚ñâ         | 114/1288 [2:43:04<23:06:26, 70.86s/it]COMMANDS_FINISHED 114 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_18/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_18/self_attn.v_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_18/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_18/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_18/self_attn.o_proj/compressed.log
best_loss 10.332781791687012 running bpv: 2.026992
  9%|‚ñâ         | 115/1288 [2:46:40<37:17:00, 114.42s/it]COMMANDS_FINISHED 115 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_25/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_25/mlp.gate_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_25/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_18/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_18/mlp.gate_proj/compressed.log
best_loss 310.40484619140625 running bpv: 2.026903
  9%|‚ñâ         | 116/1288 [2:47:02<28:13:33, 86.70s/it] COMMANDS_FINISHED 116 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_25/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_25/mlp.up_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_25/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_18/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_18/self_attn.v_proj/compressed.log
best_loss 147.5670623779297 running bpv: 2.026969
  9%|‚ñâ         | 117/1288 [2:47:38<23:15:22, 71.50s/it]COMMANDS_FINISHED 117 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_25/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_25/self_attn.q_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_25/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_18/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_18/mlp.up_proj/compressed.log
best_loss 273.1237487792969 running bpv: 2.026882
  9%|‚ñâ         | 118/1288 [2:48:04<18:48:06, 57.85s/it]COMMANDS_FINISHED 118 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_25/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_25/self_attn.k_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_25/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_25/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_25/self_attn.q_proj/compressed.log
best_loss 395.3919372558594 running bpv: 2.026947
  9%|‚ñâ         | 119/1288 [2:52:08<36:55:43, 113.72s/it]COMMANDS_FINISHED 119 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_25/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_25/self_attn.o_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_25/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_25/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_25/self_attn.k_proj/compressed.log
best_loss 404.2434387207031 running bpv: 2.027011
  9%|‚ñâ         | 120/1288 [2:52:36<28:33:17, 88.01s/it] COMMANDS_FINISHED 120 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_25/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_25/mlp.down_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_25/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_18/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_18/mlp.down_proj/compressed.log
best_loss 30.48630142211914 running bpv: 2.026917
  9%|‚ñâ         | 121/1288 [2:52:42<20:33:19, 63.41s/it]COMMANDS_FINISHED 121 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_25/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_25/self_attn.v_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_25/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_25/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_25/self_attn.o_proj/compressed.log
best_loss 12.649624824523926 running bpv: 2.02698
  9%|‚ñâ         | 122/1288 [2:56:40<37:30:44, 115.82s/it]COMMANDS_FINISHED 122 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_30/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_30/mlp.gate_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_30/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_25/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_25/mlp.gate_proj/compressed.log
best_loss 494.4622802734375 running bpv: 2.026897
 10%|‚ñâ         | 123/1288 [2:57:08<28:57:22, 89.48s/it] COMMANDS_FINISHED 123 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_30/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_30/mlp.up_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_30/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_25/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_25/self_attn.v_proj/compressed.log
best_loss 281.55279541015625 running bpv: 2.026959
 10%|‚ñâ         | 124/1288 [2:57:14<20:50:04, 64.44s/it]COMMANDS_FINISHED 124 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_30/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_30/self_attn.q_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_30/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_25/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_25/mlp.up_proj/compressed.log
best_loss 421.6818542480469 running bpv: 2.026877
 10%|‚ñâ         | 125/1288 [2:57:31<16:13:13, 50.21s/it]COMMANDS_FINISHED 125 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_30/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_30/self_attn.k_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_30/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_30/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_30/self_attn.q_proj/compressed.log
best_loss 419.5884094238281 running bpv: 2.026938
 10%|‚ñâ         | 126/1288 [3:01:45<35:51:17, 111.08s/it]COMMANDS_FINISHED 126 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_30/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_30/self_attn.o_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_30/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_30/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_30/self_attn.k_proj/compressed.log
best_loss 444.22308349609375 running bpv: 2.026999
 10%|‚ñâ         | 127/1288 [3:02:03<26:49:09, 83.16s/it] COMMANDS_FINISHED 127 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_30/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_30/mlp.down_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_30/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_25/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_25/mlp.down_proj/compressed.log
best_loss 55.9825325012207 running bpv: 2.02691
 10%|‚ñâ         | 128/1288 [3:02:57<23:58:47, 74.42s/it]COMMANDS_FINISHED 128 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_30/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_30/self_attn.v_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_30/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_30/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_30/self_attn.o_proj/compressed.log
best_loss 37.7338752746582 running bpv: 2.02697
 10%|‚ñà         | 129/1288 [3:06:17<36:05:51, 112.12s/it]COMMANDS_FINISHED 129 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_29/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_29/mlp.gate_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_29/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_30/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_30/mlp.gate_proj/compressed.log
best_loss 688.44921875 running bpv: 2.026891
 10%|‚ñà         | 130/1288 [3:07:10<30:21:48, 94.39s/it] COMMANDS_FINISHED 130 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_29/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_29/mlp.up_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_29/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_30/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_30/self_attn.v_proj/compressed.log
best_loss 341.4005126953125 running bpv: 2.02695
 10%|‚ñà         | 131/1288 [3:07:33<23:27:17, 72.98s/it]COMMANDS_FINISHED 131 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_29/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_29/self_attn.q_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_29/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_30/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_30/mlp.up_proj/compressed.log
best_loss 643.8733520507812 running bpv: 2.026872
 10%|‚ñà         | 132/1288 [3:07:39<16:58:57, 52.89s/it]COMMANDS_FINISHED 132 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_29/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_29/self_attn.k_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_29/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_29/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_29/self_attn.q_proj/compressed.log
best_loss 379.5313720703125 running bpv: 2.02693
 10%|‚ñà         | 133/1288 [3:12:05<37:29:34, 116.86s/it]COMMANDS_FINISHED 133 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_29/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_29/self_attn.o_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_29/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_29/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_29/self_attn.k_proj/compressed.log
best_loss 404.81103515625 running bpv: 2.026988
 10%|‚ñà         | 134/1288 [3:12:12<26:53:45, 83.90s/it] COMMANDS_FINISHED 134 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_29/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_29/mlp.down_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_29/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_30/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_30/mlp.down_proj/compressed.log
best_loss 148.77560424804688 running bpv: 2.026904
 10%|‚ñà         | 135/1288 [3:12:21<19:40:34, 61.44s/it]COMMANDS_FINISHED 135 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_29/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_29/self_attn.v_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_29/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_29/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_29/self_attn.o_proj/compressed.log
best_loss 28.18730926513672 running bpv: 2.026961
 11%|‚ñà         | 136/1288 [3:16:38<38:26:45, 120.14s/it]COMMANDS_FINISHED 136 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_16/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_16/mlp.gate_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_16/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_29/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_29/mlp.gate_proj/compressed.log
best_loss 626.60693359375 running bpv: 2.026886
 11%|‚ñà         | 137/1288 [3:16:52<28:13:58, 88.30s/it] COMMANDS_FINISHED 137 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_16/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_16/mlp.up_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_16/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_29/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_29/self_attn.v_proj/compressed.log
best_loss 300.8134765625 running bpv: 2.026942
 11%|‚ñà         | 138/1288 [3:16:58<20:19:17, 63.62s/it]COMMANDS_FINISHED 138 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_16/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_16/self_attn.q_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_16/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_29/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_29/mlp.up_proj/compressed.log
best_loss 575.589599609375 running bpv: 2.026868
 11%|‚ñà         | 139/1288 [3:17:36<17:51:11, 55.94s/it]COMMANDS_FINISHED 139 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_16/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_16/self_attn.k_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_16/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_16/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_16/self_attn.q_proj/compressed.log
best_loss 265.46466064453125 running bpv: 2.026923
 11%|‚ñà         | 140/1288 [3:21:32<35:04:29, 109.99s/it]COMMANDS_FINISHED 140 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_16/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_16/self_attn.o_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_16/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_16/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_16/self_attn.k_proj/compressed.log
best_loss 293.8986511230469 running bpv: 2.026978
 11%|‚ñà         | 141/1288 [3:22:06<27:46:57, 87.20s/it] COMMANDS_FINISHED 141 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_16/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_16/mlp.down_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_16/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_29/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_29/mlp.down_proj/compressed.log
best_loss 104.84065246582031 running bpv: 2.026898
 11%|‚ñà         | 142/1288 [3:22:32<21:54:55, 68.84s/it]COMMANDS_FINISHED 142 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_16/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_16/self_attn.v_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_16/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_16/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_16/self_attn.o_proj/compressed.log
best_loss 13.217436790466309 running bpv: 2.026952
 11%|‚ñà         | 143/1288 [3:26:06<35:45:25, 112.42s/it]COMMANDS_FINISHED 143 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_13/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_13/mlp.gate_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_13/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_16/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_16/self_attn.v_proj/compressed.log
best_loss 112.34247589111328 running bpv: 2.027006
 11%|‚ñà         | 144/1288 [3:27:05<30:38:06, 96.40s/it] COMMANDS_FINISHED 144 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_13/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_13/mlp.up_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_13/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_16/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_16/mlp.gate_proj/compressed.log
best_loss 238.94546508789062 running bpv: 2.026934
 11%|‚ñà‚ñè        | 145/1288 [3:27:11<21:59:52, 69.29s/it]COMMANDS_FINISHED 145 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_13/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_13/self_attn.q_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_13/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_16/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_16/mlp.up_proj/compressed.log
best_loss 220.02455139160156 running bpv: 2.026864
 11%|‚ñà‚ñè        | 146/1288 [3:27:24<16:37:23, 52.40s/it]COMMANDS_FINISHED 146 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_13/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_13/self_attn.k_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_13/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_13/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_13/self_attn.q_proj/compressed.log
best_loss 253.03074645996094 running bpv: 2.026917
 11%|‚ñà‚ñè        | 147/1288 [3:31:45<36:21:34, 114.72s/it]COMMANDS_FINISHED 147 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_13/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_13/self_attn.o_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_13/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_13/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_13/self_attn.k_proj/compressed.log
best_loss 270.00579833984375 running bpv: 2.026969
 11%|‚ñà‚ñè        | 148/1288 [3:31:58<26:39:55, 84.21s/it] COMMANDS_FINISHED 148 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_13/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_13/mlp.down_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_13/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_16/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_16/mlp.down_proj/compressed.log
best_loss 23.643081665039062 running bpv: 2.026893
 12%|‚ñà‚ñè        | 149/1288 [3:32:19<20:38:38, 65.25s/it]COMMANDS_FINISHED 149 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_13/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_13/self_attn.v_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_13/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_13/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_13/self_attn.o_proj/compressed.log
best_loss 7.685151100158691 running bpv: 2.026944
 12%|‚ñà‚ñè        | 150/1288 [3:36:17<37:01:03, 117.10s/it]COMMANDS_FINISHED 150 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_10/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_10/mlp.gate_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_10/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_13/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_13/mlp.gate_proj/compressed.log
best_loss 169.55148315429688 running bpv: 2.026877
 12%|‚ñà‚ñè        | 151/1288 [3:36:39<27:58:31, 88.58s/it] COMMANDS_FINISHED 151 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_10/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_10/mlp.up_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_10/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_13/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_13/self_attn.v_proj/compressed.log
best_loss 92.85099792480469 running bpv: 2.026927
 12%|‚ñà‚ñè        | 152/1288 [3:36:49<20:30:46, 65.01s/it]COMMANDS_FINISHED 152 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_10/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_10/self_attn.q_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_10/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_13/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_13/mlp.up_proj/compressed.log
best_loss 157.89306640625 running bpv: 2.026861
 12%|‚ñà‚ñè        | 153/1288 [3:37:37<18:53:20, 59.91s/it]COMMANDS_FINISHED 153 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_10/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_10/self_attn.k_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_10/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_10/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_10/self_attn.q_proj/compressed.log
best_loss 212.9708251953125 running bpv: 2.026911
 12%|‚ñà‚ñè        | 154/1288 [3:41:19<34:11:55, 108.57s/it]COMMANDS_FINISHED 154 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_10/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_10/self_attn.o_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_10/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_10/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_10/self_attn.k_proj/compressed.log
best_loss 232.51174926757812 running bpv: 2.02696
 12%|‚ñà‚ñè        | 155/1288 [3:42:10<28:44:09, 91.31s/it] COMMANDS_FINISHED 155 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_10/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_10/mlp.down_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_10/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_13/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_13/mlp.down_proj/compressed.log
best_loss 12.211995124816895 running bpv: 2.026889
 12%|‚ñà‚ñè        | 156/1288 [3:42:19<20:56:49, 66.62s/it]COMMANDS_FINISHED 156 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_10/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_10/self_attn.v_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_10/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_10/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_10/self_attn.o_proj/compressed.log
best_loss 6.029052257537842 running bpv: 2.026938
 12%|‚ñà‚ñè        | 157/1288 [3:45:48<34:21:23, 109.36s/it]COMMANDS_FINISHED 157 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_19/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_19/mlp.gate_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_19/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_10/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_10/mlp.gate_proj/compressed.log
best_loss 141.24742126464844 running bpv: 2.026873
 12%|‚ñà‚ñè        | 158/1288 [3:46:46<29:29:34, 93.96s/it] COMMANDS_FINISHED 158 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_19/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_19/mlp.up_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_19/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_10/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_10/self_attn.v_proj/compressed.log
best_loss 63.53646469116211 running bpv: 2.026921
 12%|‚ñà‚ñè        | 159/1288 [3:46:55<21:28:26, 68.47s/it]COMMANDS_FINISHED 159 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_19/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_19/self_attn.q_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_19/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_10/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_10/mlp.up_proj/compressed.log
best_loss 120.93706512451172 running bpv: 2.026858
 12%|‚ñà‚ñè        | 160/1288 [3:47:09<16:20:07, 52.13s/it]COMMANDS_FINISHED 160 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_19/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_19/self_attn.k_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_19/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_19/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_19/self_attn.q_proj/compressed.log
best_loss 291.687744140625 running bpv: 2.026906
 12%|‚ñà‚ñé        | 161/1288 [3:51:27<35:39:50, 113.92s/it]COMMANDS_FINISHED 161 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_19/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_19/self_attn.o_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_19/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_19/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_19/self_attn.k_proj/compressed.log
best_loss 313.6986083984375 running bpv: 2.026953
 13%|‚ñà‚ñé        | 162/1288 [3:51:40<26:09:48, 83.65s/it] COMMANDS_FINISHED 162 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_19/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_19/mlp.down_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_19/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_10/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_10/mlp.down_proj/compressed.log
best_loss 7.548906326293945 running bpv: 2.026884
 13%|‚ñà‚ñé        | 163/1288 [3:52:28<22:48:02, 72.96s/it]COMMANDS_FINISHED 163 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_19/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_19/self_attn.v_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_19/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_19/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_19/self_attn.o_proj/compressed.log
best_loss 9.813072204589844 running bpv: 2.026931
 13%|‚ñà‚ñé        | 164/1288 [3:56:00<35:48:47, 114.70s/it]COMMANDS_FINISHED 164 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_6/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_6/mlp.gate_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_6/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_19/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_19/mlp.gate_proj/compressed.log
best_loss 333.95379638671875 running bpv: 2.026869
 13%|‚ñà‚ñé        | 165/1288 [3:56:15<26:27:05, 84.80s/it] COMMANDS_FINISHED 165 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_6/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_6/mlp.up_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_6/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_19/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_19/self_attn.v_proj/compressed.log
best_loss 149.9930877685547 running bpv: 2.026916
 13%|‚ñà‚ñé        | 166/1288 [3:57:01<22:48:11, 73.17s/it]COMMANDS_FINISHED 166 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_6/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_6/self_attn.q_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_6/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_19/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_19/mlp.up_proj/compressed.log
best_loss 292.6923522949219 running bpv: 2.026855
 13%|‚ñà‚ñé        | 167/1288 [3:57:16<17:21:00, 55.72s/it]COMMANDS_FINISHED 167 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_6/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_6/self_attn.k_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_6/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_6/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_6/self_attn.q_proj/compressed.log
best_loss 191.06961059570312 running bpv: 2.026901
 13%|‚ñà‚ñé        | 168/1288 [4:01:31<35:56:35, 115.53s/it]COMMANDS_FINISHED 168 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_6/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_6/self_attn.o_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_6/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_6/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_6/self_attn.k_proj/compressed.log
best_loss 203.90846252441406 running bpv: 2.026946
 13%|‚ñà‚ñé        | 169/1288 [4:01:47<26:37:51, 85.68s/it] COMMANDS_FINISHED 169 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_6/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_6/mlp.down_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_6/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_19/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_19/mlp.down_proj/compressed.log
best_loss 33.62782287597656 running bpv: 2.02688
 13%|‚ñà‚ñé        | 170/1288 [4:01:58<19:39:02, 63.28s/it]COMMANDS_FINISHED 170 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_6/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_6/self_attn.v_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_6/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_6/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_6/self_attn.o_proj/compressed.log
best_loss 1.2358226776123047 running bpv: 2.026925
 13%|‚ñà‚ñé        | 171/1288 [4:06:04<36:39:01, 118.12s/it]COMMANDS_FINISHED 171 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_11/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_11/mlp.gate_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_11/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_6/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_6/self_attn.v_proj/compressed.log
best_loss 50.08827590942383 running bpv: 2.02697
 13%|‚ñà‚ñé        | 172/1288 [4:06:31<28:08:40, 90.79s/it] COMMANDS_FINISHED 172 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_11/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_11/mlp.up_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_11/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_6/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_6/mlp.gate_proj/compressed.log
best_loss 107.6581039428711 running bpv: 2.026911
 13%|‚ñà‚ñé        | 173/1288 [4:06:37<20:14:29, 65.35s/it]COMMANDS_FINISHED 173 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_11/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_11/self_attn.q_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_11/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_6/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_6/mlp.up_proj/compressed.log
best_loss 81.1401138305664 running bpv: 2.026852
 14%|‚ñà‚ñé        | 174/1288 [4:06:43<14:42:50, 47.55s/it]COMMANDS_FINISHED 174 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_11/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_11/self_attn.k_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_11/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_11/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_11/self_attn.q_proj/compressed.log
best_loss 238.9290008544922 running bpv: 2.026896
 14%|‚ñà‚ñé        | 175/1288 [4:11:11<35:03:51, 113.42s/it]COMMANDS_FINISHED 175 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_11/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_11/self_attn.o_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_11/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_11/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_11/self_attn.k_proj/compressed.log
best_loss 244.97515869140625 running bpv: 2.02694
 14%|‚ñà‚ñé        | 176/1288 [4:11:17<25:04:46, 81.19s/it] COMMANDS_FINISHED 176 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_11/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_11/mlp.down_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_11/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_6/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_6/mlp.down_proj/compressed.log
best_loss 3.292673349380493 running bpv: 2.026877
 14%|‚ñà‚ñé        | 177/1288 [4:12:03<21:48:02, 70.64s/it]COMMANDS_FINISHED 177 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_11/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_11/self_attn.v_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_11/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_11/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_11/self_attn.o_proj/compressed.log
best_loss 6.474165916442871 running bpv: 2.02692
 14%|‚ñà‚ñç        | 178/1288 [4:15:43<35:36:25, 115.48s/it]COMMANDS_FINISHED 178 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_20/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_20/mlp.gate_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_20/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_11/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_11/self_attn.v_proj/compressed.log
best_loss 85.5790023803711 running bpv: 2.026963
 14%|‚ñà‚ñç        | 179/1288 [4:16:34<29:37:06, 96.15s/it] COMMANDS_FINISHED 179 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_20/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_20/mlp.up_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_20/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_11/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_11/mlp.gate_proj/compressed.log
best_loss 150.88955688476562 running bpv: 2.026906
 14%|‚ñà‚ñç        | 180/1288 [4:16:40<21:16:07, 69.10s/it]COMMANDS_FINISHED 180 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_20/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_20/self_attn.q_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_20/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_11/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_11/mlp.up_proj/compressed.log
best_loss 132.68170166015625 running bpv: 2.02685
 14%|‚ñà‚ñç        | 181/1288 [4:17:01<16:48:47, 54.68s/it]COMMANDS_FINISHED 181 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_20/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_20/self_attn.k_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_20/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_20/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_20/self_attn.q_proj/compressed.log
best_loss 299.6741943359375 running bpv: 2.026892
 14%|‚ñà‚ñç        | 182/1288 [4:21:13<34:59:45, 113.91s/it]COMMANDS_FINISHED 182 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_20/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_20/self_attn.o_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_20/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_11/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_11/mlp.down_proj/compressed.log
best_loss 8.54656982421875 running bpv: 2.026831
 14%|‚ñà‚ñç        | 183/1288 [4:21:30<26:02:29, 84.84s/it] COMMANDS_FINISHED 183 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_20/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_20/mlp.down_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_20/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_20/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_20/self_attn.k_proj/compressed.log
best_loss 321.3870849609375 running bpv: 2.026873
 14%|‚ñà‚ñç        | 184/1288 [4:21:36<18:45:54, 61.19s/it]COMMANDS_FINISHED 184 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_20/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_20/self_attn.v_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_20/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_20/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_20/self_attn.o_proj/compressed.log
best_loss 15.899857521057129 running bpv: 2.026915
 14%|‚ñà‚ñç        | 185/1288 [4:25:46<36:06:52, 117.87s/it]COMMANDS_FINISHED 185 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_23/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_23/mlp.gate_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_23/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_20/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_20/self_attn.v_proj/compressed.log
best_loss 156.20608520507812 running bpv: 2.026956
 14%|‚ñà‚ñç        | 186/1288 [4:26:11<27:33:16, 90.01s/it] COMMANDS_FINISHED 186 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_23/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_23/mlp.up_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_23/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_20/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_20/mlp.gate_proj/compressed.log
best_loss 362.7336120605469 running bpv: 2.026901
 15%|‚ñà‚ñç        | 187/1288 [4:26:17<19:49:18, 64.81s/it]COMMANDS_FINISHED 187 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_23/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_23/self_attn.q_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_23/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_20/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_20/mlp.up_proj/compressed.log
best_loss 314.2409362792969 running bpv: 2.026847
 15%|‚ñà‚ñç        | 188/1288 [4:27:03<18:04:53, 59.18s/it]COMMANDS_FINISHED 188 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_23/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_23/self_attn.k_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_23/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_23/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_23/self_attn.q_proj/compressed.log
best_loss 370.15838623046875 running bpv: 2.026888
 15%|‚ñà‚ñç        | 189/1288 [4:30:50<33:26:43, 109.56s/it]COMMANDS_FINISHED 189 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_23/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_23/self_attn.o_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_23/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_23/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_23/self_attn.k_proj/compressed.log
best_loss 383.09735107421875 running bpv: 2.026929
 15%|‚ñà‚ñç        | 190/1288 [4:31:36<27:36:06, 90.50s/it] COMMANDS_FINISHED 190 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_23/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_23/mlp.down_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_23/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_20/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_20/mlp.down_proj/compressed.log
best_loss 40.27881622314453 running bpv: 2.02687
 15%|‚ñà‚ñç        | 191/1288 [4:31:42<19:51:10, 65.15s/it]COMMANDS_FINISHED 191 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_23/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_23/self_attn.v_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_23/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_23/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_23/self_attn.o_proj/compressed.log
best_loss 14.151421546936035 running bpv: 2.02691
 15%|‚ñà‚ñç        | 192/1288 [4:35:23<34:04:46, 111.94s/it]COMMANDS_FINISHED 192 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_17/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_17/mlp.gate_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_17/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_23/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_23/self_attn.v_proj/compressed.log
best_loss 238.01536560058594 running bpv: 2.02695
 15%|‚ñà‚ñç        | 193/1288 [4:36:12<28:18:26, 93.06s/it] COMMANDS_FINISHED 193 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_17/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_17/mlp.up_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_17/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_23/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_23/mlp.gate_proj/compressed.log
best_loss 439.31561279296875 running bpv: 2.026897
 15%|‚ñà‚ñå        | 194/1288 [4:36:18<20:20:40, 66.95s/it]COMMANDS_FINISHED 194 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_17/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_17/self_attn.q_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_17/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_23/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_23/mlp.up_proj/compressed.log
best_loss 374.05853271484375 running bpv: 2.026845
 15%|‚ñà‚ñå        | 195/1288 [4:36:44<16:35:51, 54.67s/it]COMMANDS_FINISHED 195 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_17/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_17/self_attn.k_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_17/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_17/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_17/self_attn.q_proj/compressed.log
best_loss 283.731201171875 running bpv: 2.026885
 15%|‚ñà‚ñå        | 196/1288 [4:40:49<33:54:49, 111.80s/it]COMMANDS_FINISHED 196 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_17/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_17/self_attn.o_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_17/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_17/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_17/self_attn.k_proj/compressed.log
best_loss 305.3692626953125 running bpv: 2.026924
 15%|‚ñà‚ñå        | 197/1288 [4:41:20<26:26:47, 87.27s/it] COMMANDS_FINISHED 197 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_17/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_17/mlp.down_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_17/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_23/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_23/mlp.down_proj/compressed.log
best_loss 49.73297119140625 running bpv: 2.026867
 15%|‚ñà‚ñå        | 198/1288 [4:41:54<21:35:07, 71.29s/it]COMMANDS_FINISHED 198 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_17/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_17/self_attn.v_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_17/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_17/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_17/self_attn.o_proj/compressed.log
best_loss 9.80501651763916 running bpv: 2.026906
 15%|‚ñà‚ñå        | 199/1288 [4:45:21<33:53:25, 112.03s/it]COMMANDS_FINISHED 199 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_9/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_9/mlp.gate_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_9/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_17/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_17/mlp.gate_proj/compressed.log
best_loss 272.3961486816406 running bpv: 2.026855
 16%|‚ñà‚ñå        | 200/1288 [4:45:55<26:47:08, 88.63s/it] COMMANDS_FINISHED 200 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_9/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_9/mlp.up_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_9/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_17/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_17/self_attn.v_proj/compressed.log
best_loss 120.54969787597656 running bpv: 2.026894
 16%|‚ñà‚ñå        | 201/1288 [4:46:29<21:48:50, 72.25s/it]COMMANDS_FINISHED 201 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_9/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_9/self_attn.q_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_9/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_17/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_17/mlp.up_proj/compressed.log
best_loss 245.10513305664062 running bpv: 2.026843
 16%|‚ñà‚ñå        | 202/1288 [4:46:39<16:09:40, 53.57s/it]COMMANDS_FINISHED 202 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_9/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_9/self_attn.k_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_9/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_9/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_9/self_attn.q_proj/compressed.log
best_loss 208.13746643066406 running bpv: 2.026881
 16%|‚ñà‚ñå        | 203/1288 [4:51:01<35:00:10, 116.14s/it]COMMANDS_FINISHED 203 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_9/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_9/self_attn.o_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_9/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_9/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_9/self_attn.k_proj/compressed.log
best_loss 224.77882385253906 running bpv: 2.026919
 16%|‚ñà‚ñå        | 204/1288 [4:51:11<25:23:00, 84.30s/it] COMMANDS_FINISHED 204 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_9/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_9/mlp.down_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_9/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_17/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_17/mlp.down_proj/compressed.log
best_loss 25.995859146118164 running bpv: 2.026865
 16%|‚ñà‚ñå        | 205/1288 [4:51:39<20:16:48, 67.41s/it]COMMANDS_FINISHED 205 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_9/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_9/self_attn.v_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_9/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_9/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_9/self_attn.o_proj/compressed.log
best_loss 4.098062038421631 running bpv: 2.026902
 16%|‚ñà‚ñå        | 206/1288 [4:55:36<35:33:47, 118.32s/it]COMMANDS_FINISHED 206 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_22/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_22/mlp.gate_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_22/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_9/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_9/mlp.gate_proj/compressed.log
best_loss 135.22703552246094 running bpv: 2.026853
 16%|‚ñà‚ñå        | 207/1288 [4:55:50<26:07:59, 87.03s/it] COMMANDS_FINISHED 207 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_22/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_22/mlp.up_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_22/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_9/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_9/self_attn.v_proj/compressed.log
best_loss 63.11085891723633 running bpv: 2.02689
 16%|‚ñà‚ñå        | 208/1288 [4:56:10<20:04:39, 66.93s/it]COMMANDS_FINISHED 208 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_22/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_22/self_attn.q_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_22/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_9/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_9/mlp.up_proj/compressed.log
best_loss 112.94261932373047 running bpv: 2.026842
 16%|‚ñà‚ñå        | 209/1288 [4:56:24<15:18:03, 51.05s/it]COMMANDS_FINISHED 209 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_22/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_22/self_attn.k_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_22/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_22/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_22/self_attn.q_proj/compressed.log
best_loss 339.22271728515625 running bpv: 2.026878
 16%|‚ñà‚ñã        | 210/1288 [5:00:41<33:47:56, 112.87s/it]COMMANDS_FINISHED 210 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_22/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_22/self_attn.o_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_22/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_22/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_22/self_attn.k_proj/compressed.log
best_loss 357.204345703125 running bpv: 2.026915
 16%|‚ñà‚ñã        | 211/1288 [5:00:55<24:53:40, 83.21s/it] COMMANDS_FINISHED 211 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_22/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_22/mlp.down_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_22/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_9/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_9/mlp.down_proj/compressed.log
best_loss 6.4519243240356445 running bpv: 2.026862
 16%|‚ñà‚ñã        | 212/1288 [5:01:25<20:06:05, 67.25s/it]COMMANDS_FINISHED 212 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_22/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_22/self_attn.v_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_22/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_22/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_22/self_attn.o_proj/compressed.log
best_loss 30.6275634765625 running bpv: 2.026898
 17%|‚ñà‚ñã        | 213/1288 [5:05:15<34:40:19, 116.11s/it]COMMANDS_FINISHED 213 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_24/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_24/mlp.gate_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_24/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_22/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_22/self_attn.v_proj/compressed.log
best_loss 193.725341796875 running bpv: 2.026934
 17%|‚ñà‚ñã        | 214/1288 [5:05:57<28:00:31, 93.88s/it] COMMANDS_FINISHED 214 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_24/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_24/mlp.up_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_24/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_22/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_22/mlp.gate_proj/compressed.log
best_loss 416.5081787109375 running bpv: 2.026887
 17%|‚ñà‚ñã        | 215/1288 [5:06:05<20:18:14, 68.12s/it]COMMANDS_FINISHED 215 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_24/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_24/self_attn.q_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_24/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_22/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_22/mlp.up_proj/compressed.log
best_loss 350.99151611328125 running bpv: 2.02684
 17%|‚ñà‚ñã        | 216/1288 [5:06:21<15:37:47, 52.49s/it]COMMANDS_FINISHED 216 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_24/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_24/self_attn.k_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_24/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_24/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_24/self_attn.q_proj/compressed.log
best_loss 337.32440185546875 running bpv: 2.026875
 17%|‚ñà‚ñã        | 217/1288 [5:10:35<33:36:33, 112.97s/it]COMMANDS_FINISHED 217 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_24/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_24/self_attn.o_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_24/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_24/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_24/self_attn.k_proj/compressed.log
best_loss 350.1551208496094 running bpv: 2.026911
 17%|‚ñà‚ñã        | 218/1288 [5:10:54<25:11:58, 84.78s/it] COMMANDS_FINISHED 218 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_24/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_24/mlp.down_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_24/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_22/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_22/mlp.down_proj/compressed.log
best_loss 47.174041748046875 running bpv: 2.02686
 17%|‚ñà‚ñã        | 219/1288 [5:11:13<19:19:00, 65.05s/it]COMMANDS_FINISHED 219 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_24/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_24/self_attn.v_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_24/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_24/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_24/self_attn.o_proj/compressed.log
best_loss 22.625782012939453 running bpv: 2.026895
 17%|‚ñà‚ñã        | 220/1288 [5:15:05<34:09:56, 115.17s/it]COMMANDS_FINISHED 220 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_3/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_3/mlp.gate_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_3/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_24/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_24/mlp.gate_proj/compressed.log
best_loss 464.0127868652344 running bpv: 2.026849
 17%|‚ñà‚ñã        | 221/1288 [5:15:48<27:37:48, 93.22s/it] COMMANDS_FINISHED 221 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_3/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_3/mlp.up_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_3/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_24/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_24/self_attn.v_proj/compressed.log
best_loss 225.36375427246094 running bpv: 2.026884
 17%|‚ñà‚ñã        | 222/1288 [5:15:54<19:51:23, 67.06s/it]COMMANDS_FINISHED 222 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_3/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_3/self_attn.q_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_3/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_24/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_24/mlp.up_proj/compressed.log
best_loss 394.5099182128906 running bpv: 2.026838
 17%|‚ñà‚ñã        | 223/1288 [5:16:28<16:54:19, 57.14s/it]COMMANDS_FINISHED 223 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_3/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_3/self_attn.k_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_3/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_24/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_24/mlp.down_proj/compressed.log
best_loss 52.8035888671875 running bpv: 2.026789
 17%|‚ñà‚ñã        | 224/1288 [5:21:13<37:06:08, 125.53s/it]COMMANDS_FINISHED 224 n_commands 1288
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_3/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_3/self_attn.o_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_3/self_attn.o_proj/compressed.log 2>&1 &
done with meta-llama/Llama-2-7b-hf
done with {'meta-llama/Llama-2-7b-hf/layer_3/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_3/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_3/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_3/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_3/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_3/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_3/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_3/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_3/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_3/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_3/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_3/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_3/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_3/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_5/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_5/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_5/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_5/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_5/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_5/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_5/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_5/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_5/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_5/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_5/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_5/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_8/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_8/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_8/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_8/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_5/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_5/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_8/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_8/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_8/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_8/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_8/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_8/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_8/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_8/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_12/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_12/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_12/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_12/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_8/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_8/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_12/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_12/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_12/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_12/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_12/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_12/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_12/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_12/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_1/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_1/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_1/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_1/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_12/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_12/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_1/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_1/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_1/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_1/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_1/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_1/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_1/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_1/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_7/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_7/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_7/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_7/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_1/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_1/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_7/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_7/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_7/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_7/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_7/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_7/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_7/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_7/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_0/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_0/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_0/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_0/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_7/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_7/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_0/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_0/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_0/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_0/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_0/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_0/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_0/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_0/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_31/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_31/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_0/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_0/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_31/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_31/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_31/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_31/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_31/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_31/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_31/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_31/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_31/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_31/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_21/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_21/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_21/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_21/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_31/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_31/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_21/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_21/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_21/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_21/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_21/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_21/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_21/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_21/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_26/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_26/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_26/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_26/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_21/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_21/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_26/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_26/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_26/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_26/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_26/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_26/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_26/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_26/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_14/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_14/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_26/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_26/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_14/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_14/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_14/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_14/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_14/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_14/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_14/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_14/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_14/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_14/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_15/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_15/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_15/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_15/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_14/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_14/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_15/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_15/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_15/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_15/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_15/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_15/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_15/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_15/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_4/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_4/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_15/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_15/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_4/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_4/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_4/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_4/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_4/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_4/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_4/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_4/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_4/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_4/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_27/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_27/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_27/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_27/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_4/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_4/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_27/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_27/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_27/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_27/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_27/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_27/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_27/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_27/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_2/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_2/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_2/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_2/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_27/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_27/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_2/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_2/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_2/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_2/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_2/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_2/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_2/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_2/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_28/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_28/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_28/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_28/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_2/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_2/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_28/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_28/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_28/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_28/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_28/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_28/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_28/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_28/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_18/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_18/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_18/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_18/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_28/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_28/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_18/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_18/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_18/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_18/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_18/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_18/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_18/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_18/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_25/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_25/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_25/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_25/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_18/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_18/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_25/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_25/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_25/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_25/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_25/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_25/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_25/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_25/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_30/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_30/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_30/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_30/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_25/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_25/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_30/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_30/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_30/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_30/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_30/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_30/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_30/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_30/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_29/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_29/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_29/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_29/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_30/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_30/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_29/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_29/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_29/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_29/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_29/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_29/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_29/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_29/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_16/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_16/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_16/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_16/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_29/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_29/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_16/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_16/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_16/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_16/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_16/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_16/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_16/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_16/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_13/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_13/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_13/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_13/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_16/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_16/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_13/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_13/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_13/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_13/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_13/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_13/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_13/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_13/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_10/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_10/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_10/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_10/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_13/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_13/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_10/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_10/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_10/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_10/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_10/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_10/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_10/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_10/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_19/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_19/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_19/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_19/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_10/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_10/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_19/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_19/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_19/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_19/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_19/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_19/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_19/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_19/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_6/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_6/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_6/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_6/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_19/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_19/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_6/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_6/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_6/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_6/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_6/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_6/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_6/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_6/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_11/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_11/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_11/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_11/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_6/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_6/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_11/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_11/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_11/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_11/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_11/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_11/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_11/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_11/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_20/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_20/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_11/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_11/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_20/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_20/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_20/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_20/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_20/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_20/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_20/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_20/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_20/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_20/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_23/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_23/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_23/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_23/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_20/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_20/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_23/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_23/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_23/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_23/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_23/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_23/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_23/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_23/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_17/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_17/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_17/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_17/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_23/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_23/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_17/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_17/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_17/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_17/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_17/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_17/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_17/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_17/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_9/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_9/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_9/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_9/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_17/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_17/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_9/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_9/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_9/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_9/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_9/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_9/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_9/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_9/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_22/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_22/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_22/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_22/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_9/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_9/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_22/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_22/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_22/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_22/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_22/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_22/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_22/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_22/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_24/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_24/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_24/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_24/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_22/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_22/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_24/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_24/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_24/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_24/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_24/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_24/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_24/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_24/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_24/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-7b-hf/layer_24/mlp.down_proj/compressed.pt'}
/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/checkpoints.yaml
perplexity_inference_command:
 python -u perplexity_eval.py --base_model meta-llama/Llama-2-7b-hf --seqlen 4096 --checkpoint_list_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/checkpoints.yaml --seqlen 4096 --log_wandb --wandb_project compression_no_finetune --wandb_id 8nvg37wl
meta-llama/Llama-2-13b-hf/layer_3/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_3/self_attn.q_proj/compressed.log
best_loss 58.90077590942383 running bpv: 2.026799
 17%|‚ñà‚ñã        | 225/1288 [5:22:23<32:09:12, 108.89s/it]COMMANDS_FINISHED 225 n_commands 1289
running: nohup python -u perplexity_eval.py --base_model meta-llama/Llama-2-7b-hf --seqlen 4096 --checkpoint_list_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/checkpoints.yaml --seqlen 4096 --log_wandb --wandb_project compression_no_finetune --wandb_id 8nvg37wl --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/glamorous-resonance-101/ppl_eval.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_3/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_3/self_attn.k_proj/compressed.log
best_loss 67.38566589355469 running bpv: 2.026808
 18%|‚ñà‚ñä        | 226/1288 [5:22:53<25:08:33, 85.23s/it] COMMANDS_FINISHED 226 n_commands 1289
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_3/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_3/mlp.down_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_3/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_3/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_3/self_attn.o_proj/compressed.log
best_loss 0.757061243057251 running bpv: 2.026817
 18%|‚ñà‚ñä        | 227/1288 [5:27:45<43:24:43, 147.30s/it]COMMANDS_FINISHED 227 n_commands 1289
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_3/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_3/self_attn.v_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_3/self_attn.v_proj/compressed.log 2>&1 &
eval is done
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_5/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_5/mlp.gate_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_5/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_3/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_3/mlp.gate_proj/compressed.log
best_loss 53.45655059814453 running bpv: 2.026698
 18%|‚ñà‚ñä        | 228/1288 [5:31:05<48:02:00, 163.13s/it]COMMANDS_FINISHED 229 n_commands 1289
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_5/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_5/mlp.up_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_5/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_3/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_3/mlp.up_proj/compressed.log
best_loss 44.68669891357422 running bpv: 2.026581
 18%|‚ñà‚ñä        | 229/1288 [5:31:45<37:07:23, 126.20s/it]COMMANDS_FINISHED 230 n_commands 1289
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_5/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_5/self_attn.q_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_5/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_3/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_3/self_attn.v_proj/compressed.log
best_loss 16.137592315673828 running bpv: 2.026591
 18%|‚ñà‚ñä        | 230/1288 [5:34:15<39:11:34, 133.36s/it]COMMANDS_FINISHED 231 n_commands 1289
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_5/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_5/self_attn.k_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_5/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_5/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_5/self_attn.q_proj/compressed.log
best_loss 139.9264678955078 running bpv: 2.026601
 18%|‚ñà‚ñä        | 231/1288 [5:38:14<48:28:10, 165.08s/it]COMMANDS_FINISHED 232 n_commands 1289
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_5/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_5/self_attn.o_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_5/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_3/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_3/mlp.down_proj/compressed.log
best_loss 1.7178044319152832 running bpv: 2.026471
 18%|‚ñà‚ñä        | 232/1288 [5:38:29<35:13:03, 120.06s/it]COMMANDS_FINISHED 233 n_commands 1289
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_5/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_5/mlp.down_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_5/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_5/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_5/self_attn.k_proj/compressed.log
best_loss 138.64144897460938 running bpv: 2.026481
 18%|‚ñà‚ñä        | 233/1288 [5:40:43<36:24:55, 124.26s/it]COMMANDS_FINISHED 234 n_commands 1289
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_5/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_5/self_attn.v_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_5/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_5/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_5/self_attn.o_proj/compressed.log
best_loss 1.1260383129119873 running bpv: 2.026491
 18%|‚ñà‚ñä        | 234/1288 [5:44:44<46:38:34, 159.31s/it]COMMANDS_FINISHED 235 n_commands 1289
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_8/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_8/mlp.gate_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_8/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_5/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_5/mlp.gate_proj/compressed.log
best_loss 96.88355255126953 running bpv: 2.026381
 18%|‚ñà‚ñä        | 235/1288 [5:46:56<44:12:23, 151.13s/it]COMMANDS_FINISHED 236 n_commands 1289
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_8/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_8/mlp.up_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_8/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_5/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_5/mlp.up_proj/compressed.log
best_loss 78.95883178710938 running bpv: 2.026273
 18%|‚ñà‚ñä        | 236/1288 [5:47:02<31:26:30, 107.60s/it]COMMANDS_FINISHED 237 n_commands 1289
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_8/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_8/self_attn.q_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_8/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_5/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_5/self_attn.v_proj/compressed.log
best_loss 44.185916900634766 running bpv: 2.026283
 18%|‚ñà‚ñä        | 237/1288 [5:47:13<22:57:08, 78.62s/it] COMMANDS_FINISHED 238 n_commands 1289
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_8/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_8/self_attn.k_proj/compressed.pt --yaml_path tmp/glamorous-resonance-101/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/glamorous-resonance-101/meta-llama/Llama-2-13b-hf/layer_8/self_attn.k_proj/compressed.log 2>&1 &
Traceback (most recent call last):
  File "/data/lliu/huffman/scripts/layer_by_layer_parallel_compress.py", line 353, in <module>
    time.sleep(1)
KeyboardInterrupt
Exception ignored in atexit callback: <function _start_and_connect_service.<locals>.teardown_atexit at 0x70887cd47420>
Traceback (most recent call last):
  File "/home/lliu/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service_connection.py", line 93, in teardown_atexit
    conn.teardown(hooks.exit_code)
  File "/home/lliu/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service_connection.py", line 216, in teardown
    return self._proc.join()
           ^^^^^^^^^^^^^^^^^
  File "/home/lliu/anaconda3/lib/python3.11/site-packages/wandb/sdk/service/service.py", line 241, in join
    ret = self._internal_proc.wait()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lliu/anaconda3/lib/python3.11/subprocess.py", line 1277, in wait
    self._wait(timeout=sigint_timeout)
  File "/home/lliu/anaconda3/lib/python3.11/subprocess.py", line 2040, in _wait
    time.sleep(delay)
KeyboardInterrupt: 
 18%|‚ñà‚ñä        | 237/1288 [5:50:29<25:54:15, 88.73s/it]
[1;34mwandb[0m: üöÄ View run [33mglamorous-resonance-101[0m at: [34mhttps://wandb.ai/m6481/compression_no_finetune/runs/8nvg37wl[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250111_123209-8nvg37wl/logs[0m
