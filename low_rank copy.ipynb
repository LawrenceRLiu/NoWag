{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np \n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:6\")\n",
    "\n",
    "H = torch.load(\"./test/original_weights.pt\")[\"H\"].to(device).float()\n",
    "weights = torch.load(\"./test/original_weights.pt\")[\"weights\"].to(device).float()    \n",
    "\n",
    "# weights = weights[:,:-2]\n",
    "# print(weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_mask.sum() =  tensor(4055, device='cuda:6')\n",
      "column_mask.sum() =  tensor(4055, device='cuda:6')\n"
     ]
    }
   ],
   "source": [
    "torch.random.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "random.seed(0)\n",
    "def create_mask(data:list,percent_top):\n",
    "    \"\"\"\n",
    "    data: list of torch.tensor of shape (n)\n",
    "    percent_top: float, the percentage of the top values to keep\n",
    "    \"\"\"\n",
    "    mask = torch.ones(data[0].shape, dtype = torch.bool, device = data[0].device)\n",
    "\n",
    "    datas_sorted = [torch.sort(data[i], descending = True)[0] for i in range(len(data))]\n",
    "    i = 0\n",
    "    big_i = 0\n",
    "    # print(mask.sum(), (100-percent_top)/100 * mask.numel())\n",
    "    # raise ValueError(\"The mask is not sparse enough\")\n",
    "    while mask.sum() > (100-percent_top)/100 * mask.numel():\n",
    "        # print(mask.sum())\n",
    "        mask &= data[i%len(data)] < datas_sorted[i][big_i]\n",
    "        i += 1\n",
    "        i = i % len(data)\n",
    "        if i == 0:\n",
    "            big_i += 1\n",
    "        # if i==0:\n",
    "        #     raise ValueError(\"The mask is not sparse enough\")\n",
    "    # threshold = torch.quantile(data, 1-percent_top/100)\n",
    "    return mask\n",
    "\n",
    "d = 1\n",
    "percent_dense_rowise = 1\n",
    "percent_dense_columnwise = 1\n",
    "\n",
    "\n",
    "# row_mask = create_mask([torch.norm(weights, dim = 1)], percent_dense_rowise)\n",
    "# column_mask = create_mask([torch.norm(weights, dim = 0),torch.norm(H, dim = 0)], percent_dense_columnwise)\n",
    "\n",
    "# print(\"row_mask.sum() = \", row_mask.sum())\n",
    "# print(\"column_mask.sum() = \", column_mask.sum())\n",
    "\n",
    "\n",
    "def mask_round(mask, d):\n",
    "\n",
    "    while mask.sum() % d != 0:\n",
    "        mask[torch.randint(0, mask.shape[0], (1,))] = False\n",
    "        print(mask.sum())\n",
    "\n",
    "    return mask\n",
    "\n",
    "if percent_dense_columnwise == 0:\n",
    "    column_mask = torch.ones(weights.shape[1], dtype = torch.bool, device = weights.device)\n",
    "else:\n",
    "    column_mask = create_mask([torch.norm(weights, dim = 0)], percent_dense_columnwise)\n",
    "    column_mask = mask_round(column_mask, d)\n",
    "    \n",
    "if percent_dense_rowise == 0:\n",
    "    \n",
    "    row_mask = torch.ones(weights.shape[0], dtype = torch.bool, device = weights.device)    \n",
    "else:\n",
    "    row_mask = create_mask([torch.norm(weights, dim = 1)], percent_dense_rowise)\n",
    "    row_mask = mask_round(row_mask, d)\n",
    "\n",
    "\n",
    "mask = row_mask.unsqueeze(1) & column_mask.unsqueeze(0)\n",
    "\n",
    "print(\"row_mask.sum() = \", row_mask.sum())\n",
    "print(\"column_mask.sum() = \", column_mask.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_adjusted = weights[row_mask,:][:, column_mask]\n",
    "# print()\n",
    "weights_norms_rowwise = torch.norm(weights_adjusted, dim = 0)\n",
    "weights_norms_rowwise[torch.isclose(weights_norms_rowwise, torch.zeros_like(weights_norms_rowwise))] = 1\n",
    "weights_normalized = weights_adjusted / weights_norms_rowwise.unsqueeze(0)\n",
    "# weights_norms_columnwise = torch.norm(weights_normalized, dim = 1)\n",
    "# weights_norms_columnwise[torch.isclose(weights_norms_columnwise, torch.zeros_like(weights_norms_columnwise))] = 1\n",
    "# weights_normalized = weights_normalized / weights_norms_columnwise.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0039, -0.0158,  0.0058,  ...,  0.0090, -0.0031, -0.0219],\n",
       "        [-0.0012, -0.0053,  0.0069,  ...,  0.0074,  0.0025, -0.0062],\n",
       "        [-0.0002,  0.0073, -0.0051,  ..., -0.0042, -0.0043,  0.0087],\n",
       "        ...,\n",
       "        [-0.0044, -0.0032,  0.0212,  ..., -0.0026, -0.0087,  0.0141],\n",
       "        [-0.0043, -0.0112, -0.0089,  ..., -0.0101, -0.0087, -0.0061],\n",
       "        [ 0.0075,  0.0062,  0.0133,  ...,  0.0174, -0.0199, -0.0213]],\n",
       "       device='cuda:6')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4055, 512]) 2076160\n",
      "total_bits =  71784176 bits per weight =  4.278670310974121 lora_overhead =  3.9599609375 sparse_overhead =  0.3187093734741211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1000 [00:00<00:23, 41.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_error =  0.16381524503231049 H_error =  0.6523004770278931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 52/1000 [00:02<00:52, 17.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_error =  0.1645875871181488 H_error =  0.2989295721054077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 104/1000 [00:05<00:36, 24.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_error =  0.1650630086660385 H_error =  0.26863646507263184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 155/1000 [00:07<00:28, 29.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_error =  0.16543282568454742 H_error =  0.2534675896167755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 203/1000 [00:09<00:48, 16.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_error =  0.16573594510555267 H_error =  0.2436908632516861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 257/1000 [00:12<00:22, 32.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_error =  0.165995255112648 H_error =  0.23657332360744476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 301/1000 [00:14<00:37, 18.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_error =  0.16622430086135864 H_error =  0.23101510107517242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 357/1000 [00:17<00:21, 29.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_error =  0.1664314568042755 H_error =  0.22647541761398315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 402/1000 [00:19<00:33, 18.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_error =  0.16662225127220154 H_error =  0.22265151143074036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 456/1000 [00:22<00:23, 23.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_error =  0.1668003499507904 H_error =  0.2193576991558075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 505/1000 [00:24<00:16, 29.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_error =  0.16696839034557343 H_error =  0.2164720892906189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 553/1000 [00:26<00:26, 17.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_error =  0.16712802648544312 H_error =  0.21391038596630096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 605/1000 [00:29<00:16, 23.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_error =  0.16728055477142334 H_error =  0.21161188185214996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 653/1000 [00:31<00:14, 23.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_error =  0.16742698848247528 H_error =  0.20953133702278137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 702/1000 [00:34<00:18, 16.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_error =  0.16756804287433624 H_error =  0.20763421058654785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 752/1000 [00:36<00:15, 16.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_error =  0.1677042841911316 H_error =  0.20589342713356018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 802/1000 [00:40<00:12, 15.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_error =  0.16783617436885834 H_error =  0.20428742468357086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 852/1000 [00:43<00:09, 15.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_error =  0.1679641455411911 H_error =  0.2027987539768219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 902/1000 [00:46<00:06, 15.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_error =  0.16808855533599854 H_error =  0.20141306519508362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 952/1000 [00:49<00:03, 14.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_error =  0.16820964217185974 H_error =  0.20011842250823975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:53<00:00, 18.79it/s]\n"
     ]
    }
   ],
   "source": [
    "#do a svd decomposition\n",
    "U, S, V = torch.svd(weights_normalized)\n",
    "\n",
    "k = 512\n",
    "\n",
    "A = (U[:, :k] @ torch.sqrt(torch.diag(S[:k]))).requires_grad_(True)\n",
    "B = (torch.sqrt(torch.diag(S[:k])) @ V[:, :k].t()).requires_grad_(True)\n",
    "print(A.shape,A.numel())\n",
    "lora_overhead = 16*(A.numel() + B.numel())/(weights.numel())\n",
    "sparse_overhead = 16*(torch.sum(~mask).item())/(weights.numel())\n",
    "total_bits = 16*(A.numel() + B.numel() + torch.sum(~mask).item())\n",
    "print(\"total_bits = \", total_bits, \"bits per weight = \", total_bits/weights.numel(),\n",
    "        \"lora_overhead = \", lora_overhead, \"sparse_overhead = \", sparse_overhead)\n",
    "\n",
    "n_iters = 1000\n",
    "lr = 5e-2\n",
    "grad_clip = 1e-1\n",
    "lr_multiple = 0.9\n",
    "prev_H_error = 1e10\n",
    "losses = []\n",
    "\n",
    "for i in tqdm.tqdm(range(n_iters)):\n",
    "\n",
    "    weights_reconstructed = torch.zeros_like(weights)\n",
    "    weights_reconstructed[mask] = ((A @ B) * weights_norms_rowwise.unsqueeze(0) #* weights_norms_columnwise.unsqueeze(1)\n",
    "                                   ).flatten()\n",
    "    weights_reconstructed[~mask] = weights[~mask]\n",
    "\n",
    "    diff = weights - weights_reconstructed\n",
    "\n",
    "    average_error = torch.sum(torch.abs(diff)**1)/torch.sum(torch.abs(weights)**1)\n",
    "\n",
    "    H_error = torch.einsum('ik,kl,il->', diff, H/H.shape[0], diff)\n",
    "    if H_error < 1e-5:\n",
    "        break\n",
    "    if i % 50 == 0:\n",
    "        print(\"average_error = \", average_error.item(), \"H_error = \", H_error.item())\n",
    "    H_error.backward()\n",
    "    losses.append(H_error.item())\n",
    "\n",
    "    if H_error > prev_H_error:\n",
    "        lr *= lr_multiple\n",
    "    prev_H_error = H_error.item()\n",
    "    with torch.no_grad():\n",
    "        if i % 1 == 0:\n",
    "            #update A\n",
    "            A.grad = A.grad.clamp(-grad_clip, grad_clip)\n",
    "            A -= lr * A.grad\n",
    "            A.grad.zero_()\n",
    "\n",
    "        # else:\n",
    "            #update B\n",
    "            B.grad = B.grad.clamp(-grad_clip, grad_clip)\n",
    "            B -= lr * B.grad\n",
    "            B.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(100,weights.shape[1], device = device)\n",
    "\n",
    "Y_true = torch.nn.functional.linear(X, weights)\n",
    "\n",
    "Y_reconstructed = torch.nn.functional.linear(X, weights_reconstructed)\n",
    "\n",
    "Y_attempt = torch.zeros_like(Y_reconstructed)\n",
    "Y_attempt[...,row_mask] = torch.nn.functional.linear(torch.nn.functional.linear(X[..., column_mask]* weights_norms_rowwise.unsqueeze(0), B), A)\n",
    "Y_attempt[...,row_mask] += torch.nn.functional.linear(X[..., ~column_mask], weights[row_mask][...,~column_mask])\n",
    "Y_attempt[...,~row_mask] = torch.nn.functional.linear(X, weights[~row_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0005, device='cuda:6', grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(torch.abs(Y_attempt - Y_reconstructed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "shape mismatch: indexing tensors could not be broadcast together with shapes [21], [4055]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m weights[\u001b[38;5;241m~\u001b[39mrow_mask,column_mask]\n",
      "\u001b[0;31mIndexError\u001b[0m: shape mismatch: indexing tensors could not be broadcast together with shapes [21], [4055]"
     ]
    }
   ],
   "source": [
    "weights[(~row_mask.unsqueeze(1)) | (~column_mask.unsqueeze(0))]\n",
    "        \n",
    "        column_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4055])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_norms_rowwise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(A.flatten().detach().cpu().numpy(), bins = 100, density=True, alpha = 0.5)\n",
    "plt.hist(B.flatten().detach().cpu().numpy(), bins = 100, density=True, alpha = 0.5)\n",
    "plt.hist(weights.flatten().detach().cpu().numpy(), bins = 100, density=True, alpha = 0.5)\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 0, 0, 0, 1, 0, 1, 1, 1],\n",
      "        [1, 0, 0, 1, 1, 1, 0, 1, 0, 1],\n",
      "        [0, 1, 1, 1, 0, 1, 0, 1, 0, 1],\n",
      "        [1, 1, 0, 0, 1, 1, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 1, 0, 0, 0],\n",
      "        [0, 1, 1, 1, 1, 0, 1, 0, 1, 0],\n",
      "        [1, 1, 1, 1, 0, 1, 1, 0, 1, 1],\n",
      "        [1, 0, 0, 1, 0, 0, 0, 0, 1, 1],\n",
      "        [0, 0, 0, 0, 1, 0, 1, 1, 0, 0]], device='cuda:6')\n",
      "tensor([[1, 0, 0, 0, 0, 1, 0, 1, 1, 1],\n",
      "        [1, 0, 0, 1, 1, 1, 0, 1, 0, 1],\n",
      "        [0, 1, 1, 1, 0, 1, 0, 1, 0, 1],\n",
      "        [1, 1, 0, 0, 1, 1, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 1, 0, 0, 0],\n",
      "        [0, 1, 1, 1, 1, 0, 1, 0, 1, 0],\n",
      "        [1, 1, 1, 1, 0, 1, 1, 0, 1, 1],\n",
      "        [1, 0, 0, 1, 0, 0, 0, 0, 1, 1],\n",
      "        [0, 0, 0, 0, 1, 0, 1, 1, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "\n",
    "device = torch.device(\"cuda:6\")\n",
    "\n",
    "class test(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.A = nn.Parameter(torch.randn(10,10, device = device))\n",
    "        self.register_buffer(\"mask\", torch.randn(10,10, device = device) > 0)\n",
    "        self.register_buffer(\"mask2\", torch.randint(0,2,(10,10), device = device))\n",
    "        \n",
    "t = test()\n",
    "print(t.mask2)\n",
    "t.to(torch.half)\n",
    "t.to(\"cpu\") \n",
    "print(t.mask2)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 10, 25])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.zeros(100,25)\n",
    "indexs = torch.randint(0,10,(100,10))\n",
    "a[indexs].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_round(X,codebook):\n",
    "    \"\"\"\n",
    "    X: torch.tensor of shape (n)\n",
    "    codebook: torch.tensor of shape (m)\n",
    "    \"\"\"\n",
    "\n",
    "    distances = torch.abs(X.reshape(list(X.shape) + [1]) - codebook.reshape([1]*len(X.shape) + list(codebook.shape)))\n",
    "    #for each one select the smallest 2 indices\n",
    "    distance, indices = torch.topk(distances, 2, dim = -1, largest = False)\n",
    "    # print(distance[0])\n",
    "    #randomly choose based on the distance\n",
    "    random_choice = torch.rand_like(X)\n",
    "\n",
    "    probabilities = distance/(distance.sum(-1, keepdim = True) + 1e-10)\n",
    "    # print(probabilities[0])\n",
    "    # print(probabilities.shape, random_choice.shape)\n",
    "    # print((random_choice < probabilities[..., 0])[0])\n",
    "    return torch.where(random_choice < probabilities[..., 0],  indices[..., 1],indices[..., 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantized_low_rank_bits =  0.49871826171875 bits per weight =  0.580780029296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:00<02:13,  7.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_error =  0.5106793642044067 H_error =  23.37791633605957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 51/1000 [00:04<01:16, 12.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_error =  0.39892807602882385 H_error =  10.105695724487305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 101/1000 [00:08<01:12, 12.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_error =  0.3982369601726532 H_error =  10.00516128540039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 148/1000 [00:12<01:10, 12.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_error =  0.3982584476470947 H_error =  10.002592086791992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_bits =  4\n",
    "# A = A.detach().requires_grad_(False)\n",
    "A_codebook = torch.linspace(A.min(), A.max(), 2**n_bits).to(device)\n",
    "errrors = torch.abs(A.unsqueeze(-1) - A_codebook.unsqueeze(0).unsqueeze(0))\n",
    "# assignments_A = stochastic_round(A, A_codebook)\n",
    "# raise ValueError(\"stop\")\n",
    "\n",
    "assignments_A = torch.argmin(torch.abs(A.unsqueeze(-1) - A_codebook.unsqueeze(0).unsqueeze(0)), dim = -1)\n",
    "A_codebook = A_codebook.requires_grad_(True)\n",
    "\n",
    "# B = B.detach().requires_grad_(False)\n",
    "B_codebook = torch.linspace(B.min(), B.max(), 2**n_bits).to(device)\n",
    "# assignments_B = stochastic_round(B, B_codebook)\n",
    "assignments_B = torch.argmin(torch.abs(B.unsqueeze(-1) - B_codebook.unsqueeze(0).unsqueeze(0)), dim = -1)\n",
    "\n",
    "quantized_low_rank_bits = (n_bits*assignments_A.numel() + n_bits*assignments_B.numel())\n",
    "total_bits = 16*(torch.sum(~mask).item()) + 16*(A_codebook.numel() + B_codebook.numel()) + quantized_low_rank_bits\n",
    "\n",
    "print(\"quantized_low_rank_bits = \", quantized_low_rank_bits/weights.numel(), \"bits per weight = \", (total_bits)\n",
    "                                                                                                    /weights.numel())\n",
    "\n",
    "# raise ValueError(\"stop\")\n",
    "B_codebook = B_codebook.requires_grad_(True)\n",
    "\n",
    "n_iters = 1000\n",
    "lr = 1e-1\n",
    "grad_clip = 1e-1\n",
    "lr_multiple = 0.9\n",
    "prev_H_error = 1e10\n",
    "patience = 100\n",
    "patience_used = 0\n",
    "eps = 1e-3\n",
    "\n",
    "for i in tqdm.tqdm(range(n_iters)):\n",
    "    \n",
    "    A_quantized = A_codebook[assignments_A]\n",
    "    B_quantized = B_codebook[assignments_B]\n",
    "    # print(\"A_quantized = \", A_quantized.shape, \"A= \", A.shape)\n",
    "    # print(\"B_quantized = \", B_quantized.shape, \"B= \", B.shape)\n",
    "    # raise ValueError(\"stop\")\n",
    "\n",
    "    weights_reconstructed = torch.zeros_like(weights)\n",
    "    weights_reconstructed[mask] = ((A_quantized @ B_quantized) * weights_norms_rowwise.unsqueeze(0) * weights_norms_columnwise.unsqueeze(1)\n",
    "                                   ).flatten()\n",
    "    weights_reconstructed[~mask] = weights[~mask]\n",
    "\n",
    "    diff = weights - weights_reconstructed\n",
    "\n",
    "    average_error = torch.sum(torch.abs(diff)**1)/torch.sum(torch.abs(weights)**1)\n",
    "\n",
    "    H_error = torch.einsum('ik,kl,il->', diff, H/H.shape[0], diff)\n",
    "    # print(\"average_error = \", average_error.item(), \"H_error = \", H_error.item())\n",
    "    # raise ValueError(\"stop\")\n",
    "    if H_error < 1e-5:\n",
    "        break\n",
    "    if i % 50 == 0:\n",
    "        print(\"average_error = \", average_error.item(), \"H_error = \", H_error.item())\n",
    "    H_error.backward()\n",
    "    losses.append(H_error.item())\n",
    "\n",
    "    if prev_H_error - H_error < eps:\n",
    "        lr *= lr_multiple\n",
    "        # print(\"lr = \", lr)\n",
    "        patience_used += 1\n",
    "        if patience_used > patience:\n",
    "            break\n",
    "    else:\n",
    "        patience_used = 0\n",
    "        prev_H_error = H_error.item()\n",
    "    with torch.no_grad():\n",
    "        if i % 1 == 0:\n",
    "            #update A\n",
    "            A_codebook.grad = A_codebook.grad.clamp(-grad_clip, grad_clip)\n",
    "            A_codebook -= lr * A_codebook.grad\n",
    "            A_codebook.grad.zero_()\n",
    "\n",
    "        # else:\n",
    "            #update B\n",
    "            B_codebook.grad = B_codebook.grad.clamp(-grad_clip, grad_clip)\n",
    "            B_codebook -= lr * B_codebook.grad\n",
    "            B_codebook.grad.zero_()\n",
    "    if i % 10 ==  9:\n",
    "        with torch.no_grad():\n",
    "            assignments_A = torch.argmin(torch.abs(A.unsqueeze(-1) - A_codebook.unsqueeze(0).unsqueeze(0)), dim = -1) #stochastic_round(A, A_codebook)\n",
    "            assignments_B = torch.argmin(torch.abs(B.unsqueeze(-1) - B_codebook.unsqueeze(0).unsqueeze(0)), dim = -1) #stochastic_round(B, B_codebook)\n",
    "\n",
    "print(\"average_error = \", average_error.item(), \"H_error = \", H_error.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.9834, device='cuda:6', grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_error =  tensor(0.5148, device='cuda:6') H_error =  tensor(3955.0728, device='cuda:6')\n"
     ]
    }
   ],
   "source": [
    "diff = weights - weights_reconstructed\n",
    "\n",
    "average_error = torch.sum(torch.abs(diff)**1)/torch.sum(torch.abs(weights)**1)\n",
    "\n",
    "H_error = torch.einsum('ik,kl,il->', diff, H/H.shape[0], diff)\n",
    "\n",
    "print(\"average_error = \", average_error, \"H_error = \", H_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
