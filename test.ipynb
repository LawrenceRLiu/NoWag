{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time the time it takes to do a multiplication with sparse tensors\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "dtype = torch.float16\n",
    "n = 1000\n",
    "x = torch.randn(100, n, n).to(device).to(dtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quantizer3(nn.Module):\n",
    "    def __init__(self, weights, \n",
    "                 mask = None,\n",
    "                 scale_init = None):\n",
    "        super(Quantizer3, self).__init__()\n",
    "        self.weights = weights\n",
    "\n",
    "        if mask is None:\n",
    "            self.mask = torch.ones_like(weights, dtype=torch.bool)\n",
    "        else:\n",
    "            self.mask = mask\n",
    "\n",
    "        #if we do not have a scale we need to find one\n",
    "        #default will be 1/3*range of weights\n",
    "        if scale_init is None:\n",
    "            self.scale = 1/3*(weights.max()-weights.min())\n",
    "        else:\n",
    "            self.scale = scale_init\n",
    "        print(self.scale)\n",
    "        \n",
    "        #set scale to be a parameter\n",
    "        self.scale_activation = F.softplus\n",
    "        self.scale = nn.Parameter(\n",
    "            torch.log(torch.exp(self.scale) - 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # scale = self.scale_activation(self.scale)\n",
    "        scale = self.scale\n",
    "        if torch.all(self.mask):\n",
    "            quantized_weights = torch.clip(torch.round(self.weights/scale), min=-1, max=1)\n",
    "            return x @ self.weights, quantized_weights\n",
    "        quantized_weights = self.weights.clone()\n",
    "        quantized = torch.clip(torch.round(self.weights[self.mask]/scale), min=-1, max=1)\n",
    "        assert ~torch.isnan(quantized).any()\n",
    "        quantized_weights[self.mask] = scale * quantized\n",
    "        return x.reshape(-1, quantized_weights.shape[1]) @ quantized_weights, quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "weights = torch.randn(1000,1000).to(device).to(dtype)\n",
    "mask = torch.randn(1000,1000).to(device).to(dtype) > 0\n",
    "\n",
    "quantizer = Quantizer3(weights, mask,torch.tensor(1))\n",
    "quantizer.to(device).to(dtype)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.SGD(quantizer.parameters(), lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "tensor(0., device='cuda:0', dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "y,_ = quantizer(x)\n",
    "y_actual = x.reshape(-1, weights.shape[1]) @ weights\n",
    "\n",
    "losses = []\n",
    "for i in range(500):\n",
    "    y,q = quantizer(x)\n",
    "    optimizer.zero_grad()\n",
    "    loss = F.mse_loss(y, y_actual)\n",
    "    loss.backward()\n",
    "    #print the gradients\n",
    "    # print(quantizer.scale.grad)\n",
    "    # print(quantizer.scale_activation(quantizer.scale).item())\n",
    "    optimizer.step()\n",
    "    print(quantizer.scale.grad)\n",
    "    # print(quantizer.scale_activation(quantizer.scale).item())\n",
    "    losses.append(loss.item())\n",
    "    # print(quantizer.scale_activation(quantizer.scale))\n",
    "    # print(loss.item(), quantizer.scale_activation(quantizer.scale).item(), loss,torch.any(torch.isnan(q)), torch.any(torch.isnan(y)))\n",
    "    # print()\n",
    "    # raise Exception(\"stop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0,\n",
       " 340.0]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,q = quantizer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.unique(q, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantizer.scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba.cuda\n",
    "import numba as nb\n",
    "\n",
    "threadsperblock = 32\n",
    "blockspergrid = (an_array.size + (threadsperblock - 1)) // threadsperblock\n",
    "increment_by_one[blockspergrid, threadsperblock](an_array)\n",
    "\n",
    "@numba.cuda.jit(device=True)\n",
    "def binary_sparse_matrix_multiplication(x, row_idxs):\n",
    "    #x is a 3d tensor with shape (batch, n, n)\n",
    "    #row idxs is a list of list of booleans, representing the column indicies that are 1 in the sparse matrix\n",
    "    #returns a 3d tensor with shape (batch, n, n)\n",
    "    #both are boolean tensors\n",
    "\n",
    "    y = x.clone()\n",
    "    # return x[:,:,row_idxs].sum(dim=3)\n",
    "\n",
    "    # raise Exception(\"stop\")\n",
    "    for i, row_idx in enumerate(row_idxs):\n",
    "        # for j in range(len(row_idx)):\n",
    "        y[:,:,i] += x[:,:,row_idx].sum(dim=2) \n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_sparse = []\n",
    "times_naive = []\n",
    "sparsities = torch.logspace(-4, -1, 10)\n",
    "with torch.no_grad():\n",
    "    for sparsity in sparsities:\n",
    "        w = torch.zeros_like(x[0])\n",
    "        row,col = torch.randint(0,n, (2, int(n**2*sparsity)))\n",
    "        w[row, col] = 1\n",
    "\n",
    "\n",
    "        row_idxs = []\n",
    "        for i in range(n):\n",
    "            row_idxs.append(w[i]==1)\n",
    "        print(\"here\")\n",
    "        print(row_idxs[0].shape)\n",
    "        # raise Exception(\"stop\")\n",
    "        start = time.time()\n",
    "        y_sparse = binary_sparse_matrix_multiplication(x, row_idxs)\n",
    "        times_sparse.append(time.time()-start)\n",
    "\n",
    "        \n",
    "        start = time.time()\n",
    "        y_naive = F.linear(x, w)\n",
    "        times_naive.append(time.time()-start)\n",
    "\n",
    "        # assert torch.allclose(y_sparse, y_naive, atol=1e-2)\n",
    "\n",
    "        print(f\"sparsity: {sparsity}, sparse: {times_sparse[-1]}, naive: {times_naive[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_sparse = []\n",
    "times_naive = []\n",
    "sparsities = torch.logspace(-4, -1, 10)\n",
    "with torch.no_grad():\n",
    "    for sparsity in sparsities:\n",
    "        w = torch.zeros_like(x[0])\n",
    "        row,col = torch.randint(0,n, (2, int(n**2*sparsity)))\n",
    "        w[row, col] = 1\n",
    "\n",
    "\n",
    "        row_idxs = []\n",
    "        for i in range(n):\n",
    "            row_idxs.append(torch.where(w[i]==1)[0].cpu())\n",
    "        print(\"here\")\n",
    "        # print(row_idxs)\n",
    "        # raise Exception(\"stop\")\n",
    "        start = time.time()\n",
    "        y_sparse = binary_sparse_matrix_multiplication(x, row_idxs)\n",
    "        times_sparse.append(time.time()-start)\n",
    "\n",
    "        \n",
    "        start = time.time()\n",
    "        y_naive = F.linear(x, w)\n",
    "        times_naive.append(time.time()-start)\n",
    "\n",
    "        # assert torch.allclose(y_sparse, y_naive, atol=1e-2)\n",
    "\n",
    "        print(f\"sparsity: {sparsity}, sparse: {times_sparse[-1]}, naive: {times_naive[-1]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(sparsities,times_sparse, label=\"sparse\")\n",
    "plt.plot(sparsities,times_naive, label=\"naive\")\n",
    "plt.xscale(\"log\")\n",
    "plt.ylim(0,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(sparsities,times_sparse, label=\"sparse\")\n",
    "plt.plot(sparsities,times_naive, label=\"naive\")\n",
    "plt.xscale(\"log\")\n",
    "# plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i,j,k = torch.where(~torch.isclose(y_sparse, y_naive, atol=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in range(len(i)):\n",
    "    print(y_naive[i[l],j[l],k[l]].item(), y_sparse[i[l],j[l],k[l]].item())\n",
    "    # print(x[i[l],:,k[l]], w[j[l],:])\n",
    "    print(torch.sum(x[i[l],j[l],:]@w[k[l],:]).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.allclose((x.reshape(-1,n) @ w.T).reshape(-1,n,n), y_naive, atol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(torch.abs(y_sparse[4]-y_naive[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
