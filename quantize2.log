wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: m6481. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /data/lliu/huffman/wandb/run-20250105_010922-ggzzgfuk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-firefly-64
wandb: ‚≠êÔ∏è View project at https://wandb.ai/m6481/compression_no_finetune
wandb: üöÄ View run at https://wandb.ai/m6481/compression_no_finetune/runs/ggzzgfuk
Namespace(models_to_compress=['meta-llama/Llama-2-13b-hf'], seqlens=[4096], batch_size=1, hessian_path='/data/lliu/huffman/models/{model_name}/hessians_new/pajama/2048', save_path='/data/lliu/huffman/models/{model_name}/compressed', self_attn_compression_algorithm='quantize', mlp_compression_algorithm='quantize', devices=['cuda:5', 'cuda:6', 'cuda:7'], yaml_path='/data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml', self_attn_yaml_path=None, mlp_yaml_path=None, use_already_done=False, use_wandb=True, resume_wandb=False, wandb_id=None, wandb_project='compression_no_finetune')
  0%|          | 0/280 [00:00<?, ?it/s]  0%|          | 1/280 [05:35<25:57:54, 335.03s/it]  1%|          | 2/280 [11:00<25:25:01, 329.14s/it]  1%|          | 3/280 [14:25<20:57:52, 272.46s/it]  1%|‚ñè         | 4/280 [14:40<13:05:47, 170.82s/it]  2%|‚ñè         | 5/280 [16:25<11:14:09, 147.09s/it]  2%|‚ñè         | 6/280 [20:10<13:12:42, 173.58s/it]  2%|‚ñé         | 7/280 [30:35<24:21:20, 321.17s/it]n_commands 280
sample command python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_3/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_3/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_3/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_3/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_3/mlp.gate_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_3/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_3/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_3/mlp.up_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_3/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_3/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_3/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_3/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_3/self_attn.q_proj/compressed.log
best_loss 29.5782413482666 running bpv: 2.022815
COMMANDS_FINISHED 1 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_3/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_3/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_3/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_3/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_3/self_attn.k_proj/compressed.log
best_loss 33.48579788208008 running bpv: 2.022815
COMMANDS_FINISHED 2 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_3/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_3/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_3/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_3/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_3/mlp.gate_proj/compressed.log
best_loss 32.92475509643555 running bpv: 2.016258
COMMANDS_FINISHED 3 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_3/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_3/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_3/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_3/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_3/mlp.up_proj/compressed.log
best_loss 28.093936920166016 running bpv: 2.014486
COMMANDS_FINISHED 4 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_3/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_3/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_3/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_3/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_3/self_attn.o_proj/compressed.log
best_loss 0.2718517780303955 running bpv: 2.015478
COMMANDS_FINISHED 5 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_5/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_5/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_5/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_3/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_3/self_attn.v_proj/compressed.log
best_loss 9.304742813110352 running bpv: 2.016258
COMMANDS_FINISHED 6 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_5/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_5/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_5/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_3/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_3/mlp.down_proj/compressed.log
best_loss 0.9916909337043762 running bpv: 2.014826
COMMANDS_FINISHED 7 n_commands 280
  3%|‚ñé         | 8/280 [31:00<17:08:33, 226.89s/it]  3%|‚ñé         | 9/280 [34:45<17:02:08, 226.30s/it]  4%|‚ñé         | 10/280 [36:00<13:28:10, 179.60s/it]  4%|‚ñç         | 11/280 [36:25<9:53:04, 132.28s/it]   4%|‚ñç         | 12/280 [40:10<11:56:52, 160.49s/it]  5%|‚ñç         | 13/280 [41:45<10:25:55, 140.66s/it]  5%|‚ñå         | 14/280 [52:10<21:12:11, 286.96s/it]  5%|‚ñå         | 15/280 [54:35<17:58:25, 244.17s/it]  6%|‚ñå         | 16/280 [56:00<14:23:33, 196.26s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_5/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_5/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_5/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_5/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_5/mlp.gate_proj/compressed.log
best_loss 65.00531005859375 running bpv: 2.014201
COMMANDS_FINISHED 8 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_5/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_5/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_5/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_5/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_5/mlp.up_proj/compressed.log
best_loss 53.70176696777344 running bpv: 2.013769
COMMANDS_FINISHED 9 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_5/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_5/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_5/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_5/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_5/self_attn.q_proj/compressed.log
best_loss 78.71636962890625 running bpv: 2.014258
COMMANDS_FINISHED 10 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_5/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_5/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_5/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_5/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_5/self_attn.k_proj/compressed.log
best_loss 77.20048522949219 running bpv: 2.014697
COMMANDS_FINISHED 11 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_5/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_5/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_5/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_5/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_5/self_attn.o_proj/compressed.log
best_loss 0.7445290088653564 running bpv: 2.015093
COMMANDS_FINISHED 12 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_8/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_8/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_8/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_5/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_5/self_attn.v_proj/compressed.log
best_loss 28.046859741210938 running bpv: 2.015452
COMMANDS_FINISHED 13 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_8/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_8/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_8/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_5/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_5/mlp.down_proj/compressed.log
best_loss 2.6443445682525635 running bpv: 2.014826
COMMANDS_FINISHED 14 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_8/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_8/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_8/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_8/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_8/mlp.gate_proj/compressed.log
best_loss 113.20164489746094 running bpv: 2.014482
COMMANDS_FINISHED 15 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_8/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_8/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_8/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_8/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_8/mlp.up_proj/compressed.log
best_loss 92.80511474609375 running bpv: 2.014201
COMMANDS_FINISHED 16 n_commands 280
  6%|‚ñå         | 17/280 [57:35<12:06:50, 165.82s/it]  6%|‚ñã         | 18/280 [1:00:10<11:49:53, 162.57s/it]  7%|‚ñã         | 19/280 [1:01:25<9:52:46, 136.27s/it]   7%|‚ñã         | 20/280 [1:05:40<12:25:00, 171.92s/it]  8%|‚ñä         | 21/280 [1:13:45<19:07:49, 265.91s/it]  8%|‚ñä         | 22/280 [1:16:10<16:27:23, 229.63s/it]  8%|‚ñä         | 23/280 [1:19:05<15:13:22, 213.24s/it]  9%|‚ñä         | 24/280 [1:20:30<12:25:39, 174.76s/it]  9%|‚ñâ         | 25/280 [1:21:35<10:02:47, 141.83s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_8/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_8/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_8/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_8/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_8/self_attn.q_proj/compressed.log
best_loss 126.31576538085938 running bpv: 2.014482
COMMANDS_FINISHED 17 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_8/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_8/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_8/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_8/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_8/self_attn.k_proj/compressed.log
best_loss 130.3981170654297 running bpv: 2.014746
COMMANDS_FINISHED 18 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_8/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_8/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_8/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_8/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_8/self_attn.o_proj/compressed.log
best_loss 2.5187718868255615 running bpv: 2.014994
COMMANDS_FINISHED 19 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_39/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_39/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_39/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_8/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_8/self_attn.v_proj/compressed.log
best_loss 50.56698989868164 running bpv: 2.015226
COMMANDS_FINISHED 20 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_39/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_39/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_39/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_8/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_8/mlp.down_proj/compressed.log
best_loss 6.761233329772949 running bpv: 2.014826
COMMANDS_FINISHED 21 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_39/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_39/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_39/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_39/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_39/mlp.gate_proj/compressed.log
best_loss 451.78900146484375 running bpv: 2.014589
COMMANDS_FINISHED 22 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_39/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_39/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_39/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_39/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_39/self_attn.q_proj/compressed.log
best_loss 187.46661376953125 running bpv: 2.014794
COMMANDS_FINISHED 23 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_39/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_39/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_39/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_39/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_39/mlp.up_proj/compressed.log
best_loss 385.41595458984375 running bpv: 2.01458
COMMANDS_FINISHED 24 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_39/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_39/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_39/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_39/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_39/self_attn.k_proj/compressed.log
best_loss 192.29318237304688 running bpv: 2.014768
COMMANDS_FINISHED 25 n_commands 280
  9%|‚ñâ         | 26/280 [1:24:30<10:42:34, 151.79s/it] 10%|‚ñâ         | 27/280 [1:26:55<10:31:28, 149.76s/it] 10%|‚ñà         | 28/280 [1:36:40<19:37:27, 280.35s/it] 10%|‚ñà         | 29/280 [1:39:05<16:42:56, 239.75s/it] 11%|‚ñà         | 30/280 [1:41:30<14:40:31, 211.33s/it] 11%|‚ñà         | 31/280 [1:42:15<11:09:56, 161.43s/it] 11%|‚ñà‚ñè        | 32/280 [1:44:30<10:34:29, 153.51s/it] 12%|‚ñà‚ñè        | 33/280 [1:46:55<10:21:26, 150.96s/it] 12%|‚ñà‚ñè        | 34/280 [1:50:00<11:00:49, 161.18s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_39/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_39/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_39/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_39/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_39/self_attn.o_proj/compressed.log
best_loss 48.25054931640625 running bpv: 2.014948
COMMANDS_FINISHED 26 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_12/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_12/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_12/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_39/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_39/self_attn.v_proj/compressed.log
best_loss 201.0594482421875 running bpv: 2.01512
COMMANDS_FINISHED 27 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_12/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_12/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_12/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_39/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_39/mlp.down_proj/compressed.log
best_loss 163.70167541503906 running bpv: 2.014826
COMMANDS_FINISHED 28 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_12/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_12/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_12/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_12/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_12/mlp.gate_proj/compressed.log
best_loss 138.8164520263672 running bpv: 2.014645
COMMANDS_FINISHED 29 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_12/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_12/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_12/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_12/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_12/mlp.up_proj/compressed.log
best_loss 129.9423370361328 running bpv: 2.014482
COMMANDS_FINISHED 30 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_12/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_12/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_12/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_12/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_12/self_attn.q_proj/compressed.log
best_loss 168.62298583984375 running bpv: 2.014634
COMMANDS_FINISHED 31 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_12/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_12/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_12/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_12/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_12/self_attn.k_proj/compressed.log
best_loss 174.66668701171875 running bpv: 2.014781
COMMANDS_FINISHED 32 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_12/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_12/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_12/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_12/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_12/self_attn.o_proj/compressed.log
best_loss 6.615882873535156 running bpv: 2.014922
COMMANDS_FINISHED 33 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_1/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_1/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_1/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_12/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_12/self_attn.v_proj/compressed.log
best_loss 73.3291015625 running bpv: 2.015059
COMMANDS_FINISHED 34 n_commands 280
 12%|‚ñà‚ñé        | 35/280 [1:58:25<17:59:21, 264.33s/it] 13%|‚ñà‚ñé        | 36/280 [2:01:30<16:18:11, 240.54s/it] 13%|‚ñà‚ñé        | 37/280 [2:03:45<14:05:58, 208.88s/it] 14%|‚ñà‚ñé        | 38/280 [2:04:30<10:44:12, 159.72s/it] 14%|‚ñà‚ñç        | 39/280 [2:06:55<10:23:49, 155.31s/it] 14%|‚ñà‚ñç        | 40/280 [2:09:20<10:08:52, 152.22s/it] 15%|‚ñà‚ñç        | 41/280 [2:12:25<10:45:32, 162.06s/it] 15%|‚ñà‚ñå        | 42/280 [2:20:40<17:19:04, 261.95s/it] 15%|‚ñà‚ñå        | 43/280 [2:24:05<16:07:14, 244.87s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_1/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_1/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_1/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_12/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_12/mlp.down_proj/compressed.log
best_loss 11.747458457946777 running bpv: 2.014826
COMMANDS_FINISHED 35 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_1/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_1/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_1/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_1/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_1/mlp.gate_proj/compressed.log
best_loss 5.5860114097595215 running bpv: 2.014679
COMMANDS_FINISHED 36 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_1/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_1/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_1/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_1/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_1/self_attn.q_proj/compressed.log
best_loss 1.9876008033752441 running bpv: 2.014806
COMMANDS_FINISHED 37 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_1/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_1/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_1/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_1/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_1/mlp.up_proj/compressed.log
best_loss 4.980776786804199 running bpv: 2.014669
COMMANDS_FINISHED 38 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_1/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_1/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_1/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_1/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_1/self_attn.k_proj/compressed.log
best_loss 2.0568206310272217 running bpv: 2.014789
COMMANDS_FINISHED 39 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_1/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_1/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_1/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_1/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_1/self_attn.o_proj/compressed.log
best_loss 0.051941026002168655 running bpv: 2.014905
COMMANDS_FINISHED 40 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_7/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_7/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_7/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_1/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_1/self_attn.v_proj/compressed.log
best_loss 0.5502371788024902 running bpv: 2.015018
COMMANDS_FINISHED 41 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_7/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_7/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_7/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_1/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_1/mlp.down_proj/compressed.log
best_loss 0.18453466892242432 running bpv: 2.014826
COMMANDS_FINISHED 42 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_7/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_7/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_7/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_7/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_7/mlp.gate_proj/compressed.log
best_loss 99.28993225097656 running bpv: 2.014703
COMMANDS_FINISHED 43 n_commands 280
 16%|‚ñà‚ñå        | 44/280 [2:26:00<13:29:55, 205.91s/it] 16%|‚ñà‚ñå        | 45/280 [2:27:05<10:40:56, 163.64s/it] 16%|‚ñà‚ñã        | 46/280 [2:29:30<10:16:24, 158.05s/it] 17%|‚ñà‚ñã        | 47/280 [2:31:25<9:23:38, 145.14s/it]  17%|‚ñà‚ñã        | 48/280 [2:34:50<10:30:40, 163.11s/it] 18%|‚ñà‚ñä        | 49/280 [2:43:05<16:51:20, 262.68s/it] 18%|‚ñà‚ñä        | 50/280 [2:45:50<14:54:38, 233.38s/it] 18%|‚ñà‚ñä        | 51/280 [2:48:25<13:21:01, 209.87s/it] 19%|‚ñà‚ñä        | 52/280 [2:49:20<10:20:58, 163.41s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_7/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_7/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_7/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_7/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_7/self_attn.q_proj/compressed.log
best_loss 103.08335876464844 running bpv: 2.014809
COMMANDS_FINISHED 44 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_7/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_7/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_7/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_7/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_7/mlp.up_proj/compressed.log
best_loss 79.520263671875 running bpv: 2.014693
COMMANDS_FINISHED 45 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_7/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_7/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_7/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_7/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_7/self_attn.k_proj/compressed.log
best_loss 106.28524017333984 running bpv: 2.014794
COMMANDS_FINISHED 46 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_7/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_7/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_7/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_7/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_7/self_attn.o_proj/compressed.log
best_loss 1.8803246021270752 running bpv: 2.014893
COMMANDS_FINISHED 47 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_33/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_33/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_33/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_7/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_7/self_attn.v_proj/compressed.log
best_loss 38.818443298339844 running bpv: 2.01499
COMMANDS_FINISHED 48 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_33/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_33/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_33/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_7/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_7/mlp.down_proj/compressed.log
best_loss 5.248479843139648 running bpv: 2.014826
COMMANDS_FINISHED 49 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_33/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_33/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_33/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_33/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_33/mlp.gate_proj/compressed.log
best_loss 531.997314453125 running bpv: 2.01472
COMMANDS_FINISHED 50 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_33/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_33/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_33/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_33/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_33/self_attn.q_proj/compressed.log
best_loss 313.70428466796875 running bpv: 2.014811
COMMANDS_FINISHED 51 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_33/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_33/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_33/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_33/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_33/mlp.up_proj/compressed.log
best_loss 461.6003112792969 running bpv: 2.01471
COMMANDS_FINISHED 52 n_commands 280
 19%|‚ñà‚ñâ        | 53/280 [2:51:15<9:23:19, 148.89s/it]  19%|‚ñà‚ñâ        | 54/280 [2:53:50<9:27:45, 150.73s/it] 20%|‚ñà‚ñâ        | 55/280 [2:56:45<9:52:33, 158.02s/it] 20%|‚ñà‚ñà        | 56/280 [3:05:30<16:40:59, 268.12s/it] 20%|‚ñà‚ñà        | 57/280 [3:08:05<14:30:24, 234.19s/it] 21%|‚ñà‚ñà        | 58/280 [3:11:00<13:20:49, 216.44s/it] 21%|‚ñà‚ñà        | 59/280 [3:11:15<9:34:38, 156.01s/it]  21%|‚ñà‚ñà‚ñè       | 60/280 [3:13:30<9:08:56, 149.71s/it] 22%|‚ñà‚ñà‚ñè       | 61/280 [3:16:26<9:34:09, 157.30s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_33/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_33/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_33/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_33/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_33/self_attn.k_proj/compressed.log
best_loss 321.994384765625 running bpv: 2.014798
COMMANDS_FINISHED 53 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_33/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_33/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_33/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_33/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_33/self_attn.o_proj/compressed.log
best_loss 14.502838134765625 running bpv: 2.014884
COMMANDS_FINISHED 54 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_34/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_34/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_34/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_33/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_33/self_attn.v_proj/compressed.log
best_loss 262.9896240234375 running bpv: 2.014969
COMMANDS_FINISHED 55 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_34/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_34/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_34/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_33/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_33/mlp.down_proj/compressed.log
best_loss 76.36129760742188 running bpv: 2.014826
COMMANDS_FINISHED 56 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_34/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_34/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_34/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_34/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_34/mlp.gate_proj/compressed.log
best_loss 548.2796630859375 running bpv: 2.014733
COMMANDS_FINISHED 57 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_34/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_34/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_34/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_34/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_34/self_attn.q_proj/compressed.log
best_loss 317.3287048339844 running bpv: 2.014813
COMMANDS_FINISHED 58 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_34/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_34/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_34/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_34/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_34/mlp.up_proj/compressed.log
best_loss 486.5736083984375 running bpv: 2.014724
COMMANDS_FINISHED 59 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_34/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_34/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_34/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_34/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_34/self_attn.k_proj/compressed.log
best_loss 324.40167236328125 running bpv: 2.014801
COMMANDS_FINISHED 60 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_34/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_34/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_34/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_34/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_34/self_attn.o_proj/compressed.log
best_loss 19.560707092285156 running bpv: 2.014878
COMMANDS_FINISHED 61 n_commands 280
 22%|‚ñà‚ñà‚ñè       | 62/280 [3:19:01<9:29:02, 156.62s/it] 22%|‚ñà‚ñà‚ñé       | 63/280 [3:27:26<15:44:27, 261.14s/it] 23%|‚ñà‚ñà‚ñé       | 64/280 [3:30:51<14:39:29, 244.31s/it] 23%|‚ñà‚ñà‚ñé       | 65/280 [3:32:56<12:27:11, 208.52s/it] 24%|‚ñà‚ñà‚ñé       | 66/280 [3:33:21<9:07:21, 153.46s/it]  24%|‚ñà‚ñà‚ñç       | 67/280 [3:36:26<9:38:24, 162.93s/it] 24%|‚ñà‚ñà‚ñç       | 68/280 [3:38:21<8:44:53, 148.55s/it] 25%|‚ñà‚ñà‚ñç       | 69/280 [3:41:46<9:41:59, 165.49s/it] 25%|‚ñà‚ñà‚ñå       | 70/280 [3:49:21<14:43:14, 252.36s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_0/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_0/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_0/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_34/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_34/self_attn.v_proj/compressed.log
best_loss 289.1496276855469 running bpv: 2.014952
COMMANDS_FINISHED 62 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_0/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_0/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_0/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_34/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_34/mlp.down_proj/compressed.log
best_loss 84.46216583251953 running bpv: 2.014826
COMMANDS_FINISHED 63 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_0/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_0/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_0/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_0/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_0/mlp.gate_proj/compressed.log
best_loss 1.0257160663604736 running bpv: 2.014743
COMMANDS_FINISHED 64 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_0/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_0/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_0/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_0/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_0/self_attn.q_proj/compressed.log
best_loss 0.0538080669939518 running bpv: 2.014814
COMMANDS_FINISHED 65 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_0/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_0/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_0/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_0/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_0/mlp.up_proj/compressed.log
best_loss 0.9663498997688293 running bpv: 2.014735
COMMANDS_FINISHED 66 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_0/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_0/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_0/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_0/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_0/self_attn.k_proj/compressed.log
best_loss 0.03322174772620201 running bpv: 2.014804
COMMANDS_FINISHED 67 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_0/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_0/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_0/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_0/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_0/self_attn.o_proj/compressed.log
best_loss 0.001732352189719677 running bpv: 2.014872
COMMANDS_FINISHED 68 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_32/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_32/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_32/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_0/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_0/self_attn.v_proj/compressed.log
best_loss 0.009753542020916939 running bpv: 2.014939
COMMANDS_FINISHED 69 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_32/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_32/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_32/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_0/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_0/mlp.down_proj/compressed.log
best_loss 0.017108239233493805 running bpv: 2.014826
COMMANDS_FINISHED 70 n_commands 280
 25%|‚ñà‚ñà‚ñå       | 71/280 [3:52:46<13:49:34, 238.15s/it] 26%|‚ñà‚ñà‚ñå       | 72/280 [3:54:51<11:47:56, 204.21s/it] 26%|‚ñà‚ñà‚ñå       | 73/280 [3:56:16<9:41:09, 168.45s/it]  26%|‚ñà‚ñà‚ñã       | 74/280 [3:58:11<8:43:18, 152.42s/it] 27%|‚ñà‚ñà‚ñã       | 75/280 [4:00:16<8:12:40, 144.20s/it] 27%|‚ñà‚ñà‚ñã       | 76/280 [4:03:31<9:02:06, 159.44s/it] 28%|‚ñà‚ñà‚ñä       | 77/280 [4:12:26<15:20:40, 272.12s/it] 28%|‚ñà‚ñà‚ñä       | 78/280 [4:14:51<13:07:45, 233.99s/it] 28%|‚ñà‚ñà‚ñä       | 79/280 [4:17:56<12:14:38, 219.30s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_32/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_32/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_32/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_32/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_32/mlp.gate_proj/compressed.log
best_loss 515.7071533203125 running bpv: 2.014751
COMMANDS_FINISHED 71 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_32/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_32/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_32/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_32/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_32/self_attn.q_proj/compressed.log
best_loss 340.80816650390625 running bpv: 2.014816
COMMANDS_FINISHED 72 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_32/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_32/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_32/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_32/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_32/mlp.up_proj/compressed.log
best_loss 442.90399169921875 running bpv: 2.014743
COMMANDS_FINISHED 73 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_32/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_32/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_32/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_32/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_32/self_attn.k_proj/compressed.log
best_loss 345.48907470703125 running bpv: 2.014806
COMMANDS_FINISHED 74 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_32/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_32/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_32/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_32/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_32/self_attn.o_proj/compressed.log
best_loss 15.65975570678711 running bpv: 2.014868
COMMANDS_FINISHED 75 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_31/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_31/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_31/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_32/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_32/self_attn.v_proj/compressed.log
best_loss 294.1742858886719 running bpv: 2.014929
COMMANDS_FINISHED 76 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_31/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_31/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_31/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_32/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_32/mlp.down_proj/compressed.log
best_loss 72.14163208007812 running bpv: 2.014826
COMMANDS_FINISHED 77 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_31/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_31/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_31/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_31/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_31/mlp.gate_proj/compressed.log
best_loss 496.1485900878906 running bpv: 2.014758
COMMANDS_FINISHED 78 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_31/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_31/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_31/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_31/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_31/mlp.up_proj/compressed.log
best_loss 420.9993896484375 running bpv: 2.014692
COMMANDS_FINISHED 79 n_commands 280
meta-llama/Llama-2-13b-hf/layer_31/self_attn.q_proj is done
reading log  29%|‚ñà‚ñà‚ñâ       | 81/280 [4:20:16<8:18:48, 150.40s/it]  29%|‚ñà‚ñà‚ñâ       | 82/280 [4:23:21<8:44:38, 158.98s/it] 30%|‚ñà‚ñà‚ñâ       | 83/280 [4:25:46<8:29:59, 155.33s/it] 30%|‚ñà‚ñà‚ñà       | 84/280 [4:34:11<13:38:08, 250.45s/it] 30%|‚ñà‚ñà‚ñà       | 85/280 [4:37:46<13:01:44, 240.53s/it] 31%|‚ñà‚ñà‚ñà       | 86/280 [4:39:31<10:52:34, 201.83s/it] 31%|‚ñà‚ñà‚ñà       | 87/280 [4:40:06<8:13:43, 153.49s/it]  31%|‚ñà‚ñà‚ñà‚ñè      | 88/280 [4:43:11<8:40:42, 162.72s/it]/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_31/self_attn.q_proj/compressed.log
best_loss 323.8048095703125 running bpv: 2.01475
COMMANDS_FINISHED 80 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_31/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_31/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_31/self_attn.o_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_31/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_31/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_31/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_31/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_31/self_attn.k_proj/compressed.log
best_loss 335.27081298828125 running bpv: 2.014808
COMMANDS_FINISHED 81 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_31/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_31/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_31/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_31/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_31/self_attn.o_proj/compressed.log
best_loss 14.562607765197754 running bpv: 2.014864
COMMANDS_FINISHED 82 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_21/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_21/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_21/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_31/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_31/self_attn.v_proj/compressed.log
best_loss 253.82720947265625 running bpv: 2.01492
COMMANDS_FINISHED 83 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_21/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_21/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_21/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_31/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_31/mlp.down_proj/compressed.log
best_loss 67.75274658203125 running bpv: 2.014826
COMMANDS_FINISHED 84 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_21/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_21/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_21/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_21/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_21/mlp.gate_proj/compressed.log
best_loss 289.2236022949219 running bpv: 2.014763
COMMANDS_FINISHED 85 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_21/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_21/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_21/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_21/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_21/self_attn.q_proj/compressed.log
best_loss 218.23342895507812 running bpv: 2.014817
COMMANDS_FINISHED 86 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_21/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_21/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_21/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_21/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_21/mlp.up_proj/compressed.log
best_loss 257.1943664550781 running bpv: 2.014756
COMMANDS_FINISHED 87 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_21/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_21/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_21/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_21/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_21/self_attn.k_proj/compressed.log
best_loss 225.02703857421875 running bpv: 2.014809
COMMANDS_FINISHED 88 n_commands 280
 32%|‚ñà‚ñà‚ñà‚ñè      | 89/280 [4:44:56<7:43:48, 145.70s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 90/280 [4:48:41<8:55:50, 169.21s/it] 32%|‚ñà‚ñà‚ñà‚ñé      | 91/280 [4:56:06<13:11:28, 251.26s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 92/280 [4:59:21<12:14:44, 234.49s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 93/280 [5:01:36<10:38:12, 204.77s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 94/280 [5:03:11<8:53:00, 171.94s/it]  34%|‚ñà‚ñà‚ñà‚ñç      | 95/280 [5:04:56<7:48:21, 151.90s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 96/280 [5:07:01<7:21:07, 143.85s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 97/280 [5:10:26<8:14:38, 162.18s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_21/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_21/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_21/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_21/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_21/self_attn.o_proj/compressed.log
best_loss 16.28801918029785 running bpv: 2.014861
COMMANDS_FINISHED 89 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_26/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_26/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_26/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_21/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_21/self_attn.v_proj/compressed.log
best_loss 134.537353515625 running bpv: 2.014913
COMMANDS_FINISHED 90 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_26/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_26/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_26/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_21/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_21/mlp.down_proj/compressed.log
best_loss 44.41973114013672 running bpv: 2.014826
COMMANDS_FINISHED 91 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_26/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_26/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_26/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_26/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_26/mlp.gate_proj/compressed.log
best_loss 395.15106201171875 running bpv: 2.014768
COMMANDS_FINISHED 92 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_26/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_26/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_26/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_26/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_26/self_attn.q_proj/compressed.log
best_loss 267.249755859375 running bpv: 2.014818
COMMANDS_FINISHED 93 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_26/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_26/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_26/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_26/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_26/mlp.up_proj/compressed.log
best_loss 332.4889831542969 running bpv: 2.014761
COMMANDS_FINISHED 94 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_26/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_26/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_26/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_26/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_26/self_attn.k_proj/compressed.log
best_loss 273.210693359375 running bpv: 2.01481
COMMANDS_FINISHED 95 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_26/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_26/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_26/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_26/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_26/self_attn.o_proj/compressed.log
best_loss 13.541940689086914 running bpv: 2.014859
COMMANDS_FINISHED 96 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_14/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_14/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_14/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_26/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_26/self_attn.v_proj/compressed.log
best_loss 205.73077392578125 running bpv: 2.014906
COMMANDS_FINISHED 97 n_commands 280
 35%|‚ñà‚ñà‚ñà‚ñå      | 98/280 [5:19:21<13:51:00, 273.96s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 99/280 [5:21:26<11:31:42, 229.30s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 100/280 [5:24:51<11:06:02, 222.01s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 101/280 [5:25:06<7:57:06, 159.93s/it]  36%|‚ñà‚ñà‚ñà‚ñã      | 102/280 [5:26:51<7:05:34, 143.45s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 103/280 [5:30:16<7:57:39, 161.92s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 104/280 [5:32:11<7:13:41, 147.85s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 105/280 [5:41:36<13:16:14, 273.00s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 106/280 [5:44:51<12:03:51, 249.60s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_14/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_14/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_14/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_26/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_26/mlp.down_proj/compressed.log
best_loss 56.4207763671875 running bpv: 2.014826
COMMANDS_FINISHED 98 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_14/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_14/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_14/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_14/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_14/mlp.gate_proj/compressed.log
best_loss 160.4903564453125 running bpv: 2.014772
COMMANDS_FINISHED 99 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_14/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_14/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_14/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_14/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_14/self_attn.q_proj/compressed.log
best_loss 198.15969848632812 running bpv: 2.014818
COMMANDS_FINISHED 100 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_14/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_14/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_14/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_14/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_14/mlp.up_proj/compressed.log
best_loss 155.54672241210938 running bpv: 2.014766
COMMANDS_FINISHED 101 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_14/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_14/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_14/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_14/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_14/self_attn.k_proj/compressed.log
best_loss 205.46768188476562 running bpv: 2.014811
COMMANDS_FINISHED 102 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_14/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_14/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_14/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_14/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_14/self_attn.o_proj/compressed.log
best_loss 9.736760139465332 running bpv: 2.014856
COMMANDS_FINISHED 103 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_15/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_15/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_15/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_14/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_14/self_attn.v_proj/compressed.log
best_loss 88.76100158691406 running bpv: 2.014901
COMMANDS_FINISHED 104 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_15/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_15/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_15/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_14/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_14/mlp.down_proj/compressed.log
best_loss 16.355026245117188 running bpv: 2.014826
COMMANDS_FINISHED 105 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_15/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_15/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_15/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_15/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_15/mlp.gate_proj/compressed.log
best_loss 173.770751953125 running bpv: 2.014775
COMMANDS_FINISHED 106 n_commands 280
 38%|‚ñà‚ñà‚ñà‚ñä      | 107/280 [5:46:46<10:03:16, 209.23s/it] 39%|‚ñà‚ñà‚ñà‚ñä      | 108/280 [5:47:11<7:21:21, 153.96s/it]  39%|‚ñà‚ñà‚ñà‚ñâ      | 109/280 [5:50:16<7:45:20, 163.28s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 110/280 [5:52:11<7:01:35, 148.80s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 111/280 [5:55:46<7:55:04, 168.66s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 112/280 [6:03:21<11:52:48, 254.57s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 113/280 [6:06:46<11:07:11, 239.71s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 114/280 [6:08:51<9:27:59, 205.30s/it]  41%|‚ñà‚ñà‚ñà‚ñà      | 115/280 [6:10:16<7:45:19, 169.21s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_15/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_15/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_15/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_15/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_15/mlp.up_proj/compressed.log
best_loss 169.47694396972656 running bpv: 2.014727
COMMANDS_FINISHED 107 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_15/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_15/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_15/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_15/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_15/self_attn.q_proj/compressed.log
best_loss 187.41934204101562 running bpv: 2.01477
COMMANDS_FINISHED 108 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_15/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_15/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_15/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_15/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_15/self_attn.k_proj/compressed.log
best_loss 199.0099334716797 running bpv: 2.014812
COMMANDS_FINISHED 109 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_15/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_15/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_15/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_15/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_15/self_attn.o_proj/compressed.log
best_loss 10.813850402832031 running bpv: 2.014854
COMMANDS_FINISHED 110 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_4/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_4/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_4/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_15/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_15/self_attn.v_proj/compressed.log
best_loss 92.91421508789062 running bpv: 2.014896
COMMANDS_FINISHED 111 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_4/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_4/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_4/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_15/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_15/mlp.down_proj/compressed.log
best_loss 18.868518829345703 running bpv: 2.014826
COMMANDS_FINISHED 112 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_4/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_4/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_4/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_4/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_4/mlp.gate_proj/compressed.log
best_loss 47.02478790283203 running bpv: 2.014778
COMMANDS_FINISHED 113 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_4/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_4/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_4/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_4/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_4/self_attn.q_proj/compressed.log
best_loss 66.58546447753906 running bpv: 2.014819
COMMANDS_FINISHED 114 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_4/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_4/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_4/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_4/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_4/mlp.up_proj/compressed.log
best_loss 39.86082458496094 running bpv: 2.014773
COMMANDS_FINISHED 115 n_commands 280
 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 116/280 [6:12:11<6:58:04, 152.95s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 117/280 [6:14:16<6:32:44, 144.57s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 118/280 [6:17:41<7:19:17, 162.70s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 119/280 [6:26:26<12:08:15, 271.40s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 120/280 [6:29:02<10:30:37, 236.49s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 121/280 [6:31:57<9:37:49, 218.05s/it]  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 122/280 [6:32:12<6:53:47, 157.14s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 123/280 [6:34:37<6:41:39, 153.50s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 124/280 [6:37:22<6:48:04, 156.95s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_4/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_4/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_4/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_4/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_4/self_attn.k_proj/compressed.log
best_loss 68.00794982910156 running bpv: 2.014813
COMMANDS_FINISHED 116 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_4/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_4/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_4/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_4/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_4/self_attn.o_proj/compressed.log
best_loss 0.4833875298500061 running bpv: 2.014853
COMMANDS_FINISHED 117 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_27/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_27/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_27/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_4/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_4/self_attn.v_proj/compressed.log
best_loss 21.96603775024414 running bpv: 2.014892
COMMANDS_FINISHED 118 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_27/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_27/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_27/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_4/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_4/mlp.down_proj/compressed.log
best_loss 1.6488090753555298 running bpv: 2.014826
COMMANDS_FINISHED 119 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_27/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_27/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_27/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_27/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_27/mlp.gate_proj/compressed.log
best_loss 417.5897521972656 running bpv: 2.014781
COMMANDS_FINISHED 120 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_27/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_27/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_27/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_27/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_27/self_attn.q_proj/compressed.log
best_loss 306.6197509765625 running bpv: 2.01482
COMMANDS_FINISHED 121 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_27/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_27/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_27/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_27/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_27/mlp.up_proj/compressed.log
best_loss 349.9084167480469 running bpv: 2.014776
COMMANDS_FINISHED 122 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_27/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_27/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_27/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_27/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_27/self_attn.k_proj/compressed.log
best_loss 311.4854736328125 running bpv: 2.014814
COMMANDS_FINISHED 123 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_27/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_27/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_27/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_27/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_27/self_attn.o_proj/compressed.log
best_loss 11.818522453308105 running bpv: 2.014851
COMMANDS_FINISHED 124 n_commands 280
 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 125/280 [6:40:07<6:51:42, 159.37s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 126/280 [6:48:12<10:59:48, 257.07s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 127/280 [6:51:47<10:23:21, 244.45s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 128/280 [6:53:32<8:33:18, 202.62s/it]  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 129/280 [6:54:47<6:53:34, 164.34s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 130/280 [6:57:12<6:36:21, 158.54s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 131/280 [6:58:57<5:53:49, 142.48s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 132/280 [7:02:32<6:45:07, 164.24s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 133/280 [7:10:57<10:52:52, 266.48s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_2/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_2/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_2/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_27/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_27/self_attn.v_proj/compressed.log
best_loss 232.29074096679688 running bpv: 2.014888
COMMANDS_FINISHED 125 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_2/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_2/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_2/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_27/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_27/mlp.down_proj/compressed.log
best_loss 58.249610900878906 running bpv: 2.014826
COMMANDS_FINISHED 126 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_2/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_2/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_2/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_2/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_2/mlp.gate_proj/compressed.log
best_loss 18.089876174926758 running bpv: 2.014784
COMMANDS_FINISHED 127 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_2/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_2/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_2/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_2/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_2/self_attn.q_proj/compressed.log
best_loss 17.337045669555664 running bpv: 2.01482
COMMANDS_FINISHED 128 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_2/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_2/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_2/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_2/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_2/mlp.up_proj/compressed.log
best_loss 15.47304916381836 running bpv: 2.014779
COMMANDS_FINISHED 129 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_2/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_2/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_2/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_2/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_2/self_attn.k_proj/compressed.log
best_loss 18.65667152404785 running bpv: 2.014814
COMMANDS_FINISHED 130 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_2/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_2/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_2/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_2/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_2/self_attn.o_proj/compressed.log
best_loss 0.14047174155712128 running bpv: 2.01485
COMMANDS_FINISHED 131 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_36/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_36/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_36/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_2/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_2/self_attn.v_proj/compressed.log
best_loss 5.152611255645752 running bpv: 2.014885
COMMANDS_FINISHED 132 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_36/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_36/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_36/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_2/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_2/mlp.down_proj/compressed.log
best_loss 0.5312461256980896 running bpv: 2.014826
COMMANDS_FINISHED 133 n_commands 280
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 134/280 [7:13:32<9:27:03, 233.04s/it]  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 135/280 [7:16:27<8:41:06, 215.63s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 136/280 [7:17:02<6:27:28, 161.45s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 137/280 [7:18:57<5:51:34, 147.51s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 138/280 [7:22:02<6:15:44, 158.77s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 139/280 [7:24:27<6:03:24, 154.64s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 140/280 [7:33:12<10:20:05, 265.76s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 141/280 [7:36:37<9:33:27, 247.53s/it]  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 142/280 [7:38:42<8:04:47, 210.78s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_36/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_36/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_36/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_36/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_36/mlp.gate_proj/compressed.log
best_loss 577.3005981445312 running bpv: 2.014786
COMMANDS_FINISHED 134 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_36/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_36/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_36/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_36/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_36/self_attn.q_proj/compressed.log
best_loss 275.9599609375 running bpv: 2.01482
COMMANDS_FINISHED 135 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_36/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_36/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_36/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_36/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_36/mlp.up_proj/compressed.log
best_loss 531.7222290039062 running bpv: 2.014781
COMMANDS_FINISHED 136 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_36/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_36/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_36/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_36/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_36/self_attn.k_proj/compressed.log
best_loss 285.73712158203125 running bpv: 2.014815
COMMANDS_FINISHED 137 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_36/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_36/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_36/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_36/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_36/self_attn.o_proj/compressed.log
best_loss 28.56385040283203 running bpv: 2.014849
COMMANDS_FINISHED 138 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_28/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_28/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_28/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_36/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_36/self_attn.v_proj/compressed.log
best_loss 265.7882385253906 running bpv: 2.014882
COMMANDS_FINISHED 139 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_28/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_28/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_28/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_36/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_36/mlp.down_proj/compressed.log
best_loss 107.98548889160156 running bpv: 2.014826
COMMANDS_FINISHED 140 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_28/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_28/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_28/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_28/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_28/mlp.gate_proj/compressed.log
best_loss 433.9275207519531 running bpv: 2.014788
COMMANDS_FINISHED 141 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_28/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_28/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_28/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_28/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_28/self_attn.q_proj/compressed.log
best_loss 305.54461669921875 running bpv: 2.01482
COMMANDS_FINISHED 142 n_commands 280
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 143/280 [7:38:57<5:47:10, 152.05s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 144/280 [7:42:02<6:07:03, 161.94s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 145/280 [7:44:07<5:39:26, 150.86s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 146/280 [7:47:32<6:13:12, 167.11s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 147/280 [7:55:07<9:21:53, 253.48s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 148/280 [7:58:32<8:45:40, 238.94s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 149/280 [8:00:27<7:20:31, 201.76s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 150/280 [8:02:02<6:07:46, 169.74s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 151/280 [8:03:57<5:29:38, 153.32s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_28/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_28/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_28/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_28/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_28/mlp.up_proj/compressed.log
best_loss 364.46636962890625 running bpv: 2.014783
COMMANDS_FINISHED 143 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_28/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_28/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_28/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_28/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_28/self_attn.k_proj/compressed.log
best_loss 309.959716796875 running bpv: 2.014816
COMMANDS_FINISHED 144 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_28/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_28/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_28/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_28/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_28/self_attn.o_proj/compressed.log
best_loss 12.877068519592285 running bpv: 2.014847
COMMANDS_FINISHED 145 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_18/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_18/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_18/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_28/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_28/self_attn.v_proj/compressed.log
best_loss 235.86212158203125 running bpv: 2.014879
COMMANDS_FINISHED 146 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_18/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_18/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_18/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_28/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_28/mlp.down_proj/compressed.log
best_loss 59.422325134277344 running bpv: 2.014826
COMMANDS_FINISHED 147 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_18/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_18/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_18/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_18/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_18/mlp.gate_proj/compressed.log
best_loss 236.49642944335938 running bpv: 2.01479
COMMANDS_FINISHED 148 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_18/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_18/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_18/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_18/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_18/self_attn.q_proj/compressed.log
best_loss 219.87374877929688 running bpv: 2.014821
COMMANDS_FINISHED 149 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_18/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_18/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_18/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_18/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_18/mlp.up_proj/compressed.log
best_loss 219.25851440429688 running bpv: 2.014785
COMMANDS_FINISHED 150 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_18/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_18/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_18/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_18/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_18/self_attn.k_proj/compressed.log
best_loss 229.62782287597656 running bpv: 2.014816
COMMANDS_FINISHED 151 n_commands 280
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 152/280 [8:05:52<5:02:34, 141.83s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 153/280 [8:09:17<5:40:19, 160.78s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 154/280 [8:18:12<9:33:25, 273.06s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 155/280 [8:20:07<7:50:05, 225.65s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 156/280 [8:23:42<7:39:44, 222.46s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 158/280 [8:25:32<4:55:11, 145.17s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 159/280 [8:29:07<5:27:41, 162.49s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 160/280 [8:30:52<4:54:54, 147.46s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_18/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_18/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_18/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_18/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_18/self_attn.o_proj/compressed.log
best_loss 10.676154136657715 running bpv: 2.014846
COMMANDS_FINISHED 152 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_25/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_25/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_25/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_18/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_18/self_attn.v_proj/compressed.log
best_loss 122.31105041503906 running bpv: 2.014877
COMMANDS_FINISHED 153 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_25/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_25/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_25/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_18/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_18/mlp.down_proj/compressed.log
best_loss 28.53128433227539 running bpv: 2.014826
COMMANDS_FINISHED 154 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_25/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_25/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_25/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_25/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_25/mlp.gate_proj/compressed.log
best_loss 379.68072509765625 running bpv: 2.014791
COMMANDS_FINISHED 155 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_25/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_25/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_25/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_25/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_25/mlp.up_proj/compressed.log
best_loss 320.465576171875 running bpv: 2.014758
COMMANDS_FINISHED 156 n_commands 280
meta-llama/Llama-2-13b-hf/layer_25/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_25/self_attn.q_proj/compressed.log
best_loss 266.1650390625 running bpv: 2.014787
COMMANDS_FINISHED 157 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_25/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_25/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_25/self_attn.o_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_25/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_25/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_25/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_25/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_25/self_attn.k_proj/compressed.log
best_loss 271.85968017578125 running bpv: 2.014816
COMMANDS_FINISHED 158 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_25/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_25/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_25/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_25/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_25/self_attn.o_proj/compressed.log
best_loss 12.753484725952148 running bpv: 2.014846
COMMANDS_FINISHED 159 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_37/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_37/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_37/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_25/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_25/self_attn.v_proj/compressed.log
best_loss 199.77334594726562 running bpv: 2.014874
COMMANDS_FINISHED 160 n_commands 280
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 161/280 [8:39:57<8:26:56, 255.60s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 162/280 [8:43:32<8:00:20, 244.24s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 163/280 [8:45:17<6:38:43, 204.48s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 164/280 [8:45:32<4:49:10, 149.57s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 165/280 [8:48:57<5:17:47, 165.81s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 166/280 [8:50:42<4:40:58, 147.88s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 167/280 [8:54:17<5:15:59, 167.78s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 168/280 [9:02:02<7:58:15, 256.21s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 169/280 [9:05:17<7:20:13, 237.96s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_37/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_37/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_37/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_25/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_25/mlp.down_proj/compressed.log
best_loss 53.82794952392578 running bpv: 2.014826
COMMANDS_FINISHED 161 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_37/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_37/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_37/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_37/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_37/mlp.gate_proj/compressed.log
best_loss 573.5250854492188 running bpv: 2.014793
COMMANDS_FINISHED 162 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_37/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_37/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_37/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_37/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_37/mlp.up_proj/compressed.log
best_loss 530.830810546875 running bpv: 2.01476
COMMANDS_FINISHED 163 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_37/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_37/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_37/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_37/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_37/self_attn.q_proj/compressed.log
best_loss 243.36756896972656 running bpv: 2.014789
COMMANDS_FINISHED 164 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_37/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_37/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_37/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_37/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_37/self_attn.k_proj/compressed.log
best_loss 242.87925720214844 running bpv: 2.014817
COMMANDS_FINISHED 165 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_37/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_37/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_37/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_37/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_37/self_attn.o_proj/compressed.log
best_loss 28.627674102783203 running bpv: 2.014845
COMMANDS_FINISHED 166 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_30/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_30/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_30/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_37/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_37/self_attn.v_proj/compressed.log
best_loss 263.4740295410156 running bpv: 2.014872
COMMANDS_FINISHED 167 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_30/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_30/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_30/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_37/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_37/mlp.down_proj/compressed.log
best_loss 122.47067260742188 running bpv: 2.014826
COMMANDS_FINISHED 168 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_30/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_30/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_30/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_30/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_30/mlp.gate_proj/compressed.log
best_loss 476.1356201171875 running bpv: 2.014794
COMMANDS_FINISHED 169 n_commands 280
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 170/280 [9:07:32<6:19:52, 207.20s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 171/280 [9:08:47<5:04:34, 167.66s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 172/280 [9:10:42<4:33:24, 151.90s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 173/280 [9:12:57<4:21:51, 146.84s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 174/280 [9:16:02<4:39:37, 158.28s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 175/280 [9:24:57<7:54:39, 271.23s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 176/280 [9:27:42<6:54:55, 239.38s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 177/280 [9:30:27<6:12:39, 217.08s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_30/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_30/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_30/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_30/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_30/self_attn.q_proj/compressed.log
best_loss 354.9568176269531 running bpv: 2.014821
COMMANDS_FINISHED 170 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_30/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_30/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_30/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_30/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_30/mlp.up_proj/compressed.log
best_loss 403.24639892578125 running bpv: 2.01479
COMMANDS_FINISHED 171 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_30/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_30/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_30/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_30/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_30/self_attn.k_proj/compressed.log
best_loss 359.5875244140625 running bpv: 2.014817
COMMANDS_FINISHED 172 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_30/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_30/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_30/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_30/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_30/self_attn.o_proj/compressed.log
best_loss 14.255324363708496 running bpv: 2.014844
COMMANDS_FINISHED 173 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_29/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_29/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_29/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_30/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_30/self_attn.v_proj/compressed.log
best_loss 299.4254455566406 running bpv: 2.014871
COMMANDS_FINISHED 174 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_29/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_29/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_29/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_30/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_30/mlp.down_proj/compressed.log
best_loss 65.5691909790039 running bpv: 2.014826
COMMANDS_FINISHED 175 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_29/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_29/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_29/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_29/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_29/mlp.gate_proj/compressed.log
best_loss 450.8978576660156 running bpv: 2.014795
COMMANDS_FINISHED 176 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_29/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_29/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_29/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_29/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_29/self_attn.q_proj/compressed.log
best_loss 328.7220153808594 running bpv: 2.014821
COMMANDS_FINISHED 177 n_commands 280
meta-llama/Llama-2-13b-hf/layer_29/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_29/mlp.up_proj/compressed.log
best_loss 381.9146423339844 running bpv: 2.014792
COMMANDS_FINISHED 178 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_29/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_29/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_29/self_attn.o_proj/compressed.log 2>&1 &
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 179/280 [9:33:07<4:18:56, 153.83s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 180/280 [9:35:52<4:21:00, 156.60s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 181/280 [9:38:37<4:22:01, 158.80s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 182/280 [9:46:33<6:39:51, 244.81s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 183/280 [9:50:28<6:31:21, 242.07s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 184/280 [9:52:03<5:20:07, 200.07s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 185/280 [9:53:18<4:19:24, 163.84s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 186/280 [9:55:53<4:12:37, 161.25s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 187/280 [9:57:28<3:39:39, 141.72s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_29/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_29/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_29/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_29/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_29/self_attn.k_proj/compressed.log
best_loss 336.74853515625 running bpv: 2.014817
COMMANDS_FINISHED 179 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_29/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_29/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_29/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_29/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_29/self_attn.o_proj/compressed.log
best_loss 12.569284439086914 running bpv: 2.014843
COMMANDS_FINISHED 180 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_16/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_16/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_16/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_29/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_29/self_attn.v_proj/compressed.log
best_loss 249.5765838623047 running bpv: 2.014869
COMMANDS_FINISHED 181 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_16/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_16/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_16/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_29/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_29/mlp.down_proj/compressed.log
best_loss 62.220401763916016 running bpv: 2.014826
COMMANDS_FINISHED 182 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_16/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_16/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_16/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_16/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_16/mlp.gate_proj/compressed.log
best_loss 191.13851928710938 running bpv: 2.014796
COMMANDS_FINISHED 183 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_16/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_16/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_16/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_16/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_16/self_attn.q_proj/compressed.log
best_loss 208.30841064453125 running bpv: 2.014822
COMMANDS_FINISHED 184 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_16/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_16/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_16/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_16/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_16/mlp.up_proj/compressed.log
best_loss 185.45162963867188 running bpv: 2.014793
COMMANDS_FINISHED 185 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_16/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_16/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_16/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_16/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_16/self_attn.k_proj/compressed.log
best_loss 216.4896240234375 running bpv: 2.014818
COMMANDS_FINISHED 186 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_16/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_16/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_16/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_16/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_16/self_attn.o_proj/compressed.log
best_loss 11.2431001663208 running bpv: 2.014843
COMMANDS_FINISHED 187 n_commands 280
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 188/280 [10:01:13<4:15:09, 166.41s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 189/280 [10:09:28<6:40:39, 264.17s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 190/280 [10:11:43<5:38:28, 225.65s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 191/280 [10:14:58<5:21:08, 216.50s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 192/280 [10:15:43<4:02:17, 165.20s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 193/280 [10:17:08<3:24:43, 141.19s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 194/280 [10:20:23<3:45:29, 157.32s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 195/280 [10:22:28<3:29:08, 147.63s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 196/280 [10:31:53<6:21:52, 272.77s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_13/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_13/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_13/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_16/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_16/self_attn.v_proj/compressed.log
best_loss 105.3782730102539 running bpv: 2.014867
COMMANDS_FINISHED 188 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_13/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_13/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_13/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_16/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_16/mlp.down_proj/compressed.log
best_loss 23.59103775024414 running bpv: 2.014826
COMMANDS_FINISHED 189 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_13/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_13/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_13/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_13/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_13/mlp.gate_proj/compressed.log
best_loss 148.78570556640625 running bpv: 2.014798
COMMANDS_FINISHED 190 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_13/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_13/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_13/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_13/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_13/self_attn.q_proj/compressed.log
best_loss 194.12835693359375 running bpv: 2.014822
COMMANDS_FINISHED 191 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_13/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_13/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_13/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_13/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_13/mlp.up_proj/compressed.log
best_loss 141.91207885742188 running bpv: 2.014794
COMMANDS_FINISHED 192 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_13/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_13/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_13/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_13/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_13/self_attn.k_proj/compressed.log
best_loss 192.433837890625 running bpv: 2.014818
COMMANDS_FINISHED 193 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_13/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_13/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_13/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_13/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_13/self_attn.o_proj/compressed.log
best_loss 8.221665382385254 running bpv: 2.014842
COMMANDS_FINISHED 194 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_10/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_10/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_10/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_13/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_13/self_attn.v_proj/compressed.log
best_loss 91.41255187988281 running bpv: 2.014866
COMMANDS_FINISHED 195 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_10/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_10/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_10/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_13/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_13/mlp.down_proj/compressed.log
best_loss 13.784451484680176 running bpv: 2.014826
COMMANDS_FINISHED 196 n_commands 280
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 197/280 [10:35:08<5:45:04, 249.45s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 198/280 [10:37:03<4:45:49, 209.14s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 199/280 [10:37:18<3:23:43, 150.91s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 200/280 [10:40:33<3:38:51, 164.14s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 201/280 [10:42:28<3:16:42, 149.40s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 202/280 [10:46:03<3:39:48, 169.09s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 203/280 [10:53:28<5:23:13, 251.86s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 204/280 [10:56:53<5:01:13, 237.81s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 205/280 [10:58:58<4:14:57, 203.97s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_10/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_10/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_10/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_10/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_10/mlp.gate_proj/compressed.log
best_loss 128.79281616210938 running bpv: 2.014799
COMMANDS_FINISHED 197 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_10/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_10/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_10/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_10/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_10/mlp.up_proj/compressed.log
best_loss 113.99176025390625 running bpv: 2.014772
COMMANDS_FINISHED 198 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_10/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_10/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_10/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_10/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_10/self_attn.q_proj/compressed.log
best_loss 155.70677185058594 running bpv: 2.014795
COMMANDS_FINISHED 199 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_10/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_10/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_10/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_10/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_10/self_attn.k_proj/compressed.log
best_loss 160.92599487304688 running bpv: 2.014818
COMMANDS_FINISHED 200 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_10/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_10/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_10/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_10/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_10/self_attn.o_proj/compressed.log
best_loss 5.024991512298584 running bpv: 2.014841
COMMANDS_FINISHED 201 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_19/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_19/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_19/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_10/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_10/self_attn.v_proj/compressed.log
best_loss 62.115447998046875 running bpv: 2.014864
COMMANDS_FINISHED 202 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_19/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_19/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_19/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_10/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_10/mlp.down_proj/compressed.log
best_loss 9.48143482208252 running bpv: 2.014826
COMMANDS_FINISHED 203 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_19/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_19/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_19/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_19/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_19/mlp.gate_proj/compressed.log
best_loss 256.2569274902344 running bpv: 2.014799
COMMANDS_FINISHED 204 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_19/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_19/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_19/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_19/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_19/self_attn.q_proj/compressed.log
best_loss 218.01638793945312 running bpv: 2.014822
COMMANDS_FINISHED 205 n_commands 280
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 206/280 [11:00:43<3:34:57, 174.29s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 207/280 [11:02:18<3:03:06, 150.50s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 208/280 [11:04:23<2:51:25, 142.86s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 209/280 [11:07:48<3:11:06, 161.50s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 210/280 [11:17:13<5:29:39, 282.56s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 211/280 [11:18:48<4:20:14, 226.30s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 212/280 [11:22:13<4:09:14, 219.92s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 213/280 [11:22:38<3:00:16, 161.44s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 214/280 [11:24:13<2:35:39, 141.51s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_19/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_19/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_19/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_19/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_19/mlp.up_proj/compressed.log
best_loss 234.161376953125 running bpv: 2.014796
COMMANDS_FINISHED 206 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_19/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_19/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_19/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_19/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_19/self_attn.k_proj/compressed.log
best_loss 224.84500122070312 running bpv: 2.014819
COMMANDS_FINISHED 207 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_19/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_19/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_19/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_19/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_19/self_attn.o_proj/compressed.log
best_loss 11.5775146484375 running bpv: 2.014841
COMMANDS_FINISHED 208 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_6/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_6/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_6/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_19/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_19/self_attn.v_proj/compressed.log
best_loss 126.62628173828125 running bpv: 2.014863
COMMANDS_FINISHED 209 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_6/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_6/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_6/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_19/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_19/mlp.down_proj/compressed.log
best_loss 32.10886764526367 running bpv: 2.014826
COMMANDS_FINISHED 210 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_6/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_6/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_6/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_6/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_6/mlp.gate_proj/compressed.log
best_loss 84.67906188964844 running bpv: 2.0148
COMMANDS_FINISHED 211 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_6/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_6/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_6/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_6/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_6/mlp.up_proj/compressed.log
best_loss 68.18142700195312 running bpv: 2.014775
COMMANDS_FINISHED 212 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_6/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_6/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_6/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_6/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_6/self_attn.q_proj/compressed.log
best_loss 102.23343658447266 running bpv: 2.014797
COMMANDS_FINISHED 213 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_6/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_6/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_6/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_6/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_6/self_attn.k_proj/compressed.log
best_loss 105.3641586303711 running bpv: 2.014819
COMMANDS_FINISHED 214 n_commands 280
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 215/280 [11:27:38<2:53:56, 160.56s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 216/280 [11:29:33<2:36:41, 146.90s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 217/280 [11:38:58<4:45:57, 272.34s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 218/280 [11:42:13<4:17:26, 249.14s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 219/280 [11:43:58<3:29:20, 205.90s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 220/280 [11:44:23<2:31:38, 151.63s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 221/280 [11:47:38<2:41:54, 164.65s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 222/280 [11:49:23<2:21:51, 146.76s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 223/280 [11:52:58<2:38:52, 167.23s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_6/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_6/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_6/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_6/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_6/self_attn.o_proj/compressed.log
best_loss 1.1885671615600586 running bpv: 2.01484
COMMANDS_FINISHED 215 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_11/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_11/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_11/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_6/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_6/self_attn.v_proj/compressed.log
best_loss 38.15472412109375 running bpv: 2.014862
COMMANDS_FINISHED 216 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_11/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_11/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_11/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_6/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_6/mlp.down_proj/compressed.log
best_loss 3.9544613361358643 running bpv: 2.014826
COMMANDS_FINISHED 217 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_11/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_11/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_11/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_11/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_11/mlp.gate_proj/compressed.log
best_loss 131.75328063964844 running bpv: 2.014801
COMMANDS_FINISHED 218 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_11/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_11/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_11/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_11/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_11/mlp.up_proj/compressed.log
best_loss 120.85443878173828 running bpv: 2.014777
COMMANDS_FINISHED 219 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_11/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_11/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_11/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_11/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_11/self_attn.q_proj/compressed.log
best_loss 153.68905639648438 running bpv: 2.014798
COMMANDS_FINISHED 220 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_11/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_11/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_11/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_11/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_11/self_attn.k_proj/compressed.log
best_loss 160.4502410888672 running bpv: 2.014819
COMMANDS_FINISHED 221 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_11/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_11/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_11/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_11/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_11/self_attn.o_proj/compressed.log
best_loss 5.720973014831543 running bpv: 2.01484
COMMANDS_FINISHED 222 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_20/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_20/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_20/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_11/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_11/self_attn.v_proj/compressed.log
best_loss 59.63456726074219 running bpv: 2.014861
COMMANDS_FINISHED 223 n_commands 280
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 224/280 [12:00:43<3:59:28, 256.57s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 225/280 [12:03:48<3:35:30, 235.11s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 226/280 [12:06:13<3:07:16, 208.08s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 227/280 [12:07:18<2:25:53, 165.16s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 228/280 [12:09:13<2:10:05, 150.12s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 229/280 [12:11:38<2:06:17, 148.58s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 230/280 [12:14:43<2:12:55, 159.51s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 231/280 [12:23:18<3:37:22, 266.17s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 232/280 [12:26:03<3:08:39, 235.82s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_20/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_20/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_20/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_11/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_11/mlp.down_proj/compressed.log
best_loss 10.557750701904297 running bpv: 2.014826
COMMANDS_FINISHED 224 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_20/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_20/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_20/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_20/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_20/mlp.gate_proj/compressed.log
best_loss 269.97149658203125 running bpv: 2.014802
COMMANDS_FINISHED 225 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_20/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_20/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_20/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_20/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_20/self_attn.q_proj/compressed.log
best_loss 204.31549072265625 running bpv: 2.014822
COMMANDS_FINISHED 226 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_20/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_20/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_20/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_20/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_20/mlp.up_proj/compressed.log
best_loss 245.215087890625 running bpv: 2.014799
COMMANDS_FINISHED 227 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_20/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_20/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_20/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_20/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_20/self_attn.k_proj/compressed.log
best_loss 212.96102905273438 running bpv: 2.014819
COMMANDS_FINISHED 228 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_20/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_20/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_20/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_20/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_20/self_attn.o_proj/compressed.log
best_loss 13.051627159118652 running bpv: 2.014839
COMMANDS_FINISHED 229 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_23/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_23/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_23/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_20/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_20/self_attn.v_proj/compressed.log
best_loss 115.93032836914062 running bpv: 2.01486
COMMANDS_FINISHED 230 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_23/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_23/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_23/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_20/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_20/mlp.down_proj/compressed.log
best_loss 35.89832305908203 running bpv: 2.014826
COMMANDS_FINISHED 231 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_23/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_23/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_23/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_23/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_23/mlp.gate_proj/compressed.log
best_loss 338.86602783203125 running bpv: 2.014803
COMMANDS_FINISHED 232 n_commands 280
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 233/280 [12:28:38<2:45:44, 211.58s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 234/280 [12:29:13<2:01:36, 158.61s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 235/280 [12:31:38<1:55:53, 154.53s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 236/280 [12:34:03<1:51:13, 151.68s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 237/280 [12:37:08<1:55:52, 161.68s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 238/280 [12:45:23<3:03:10, 261.68s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 239/280 [12:48:38<2:45:09, 241.68s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 240/280 [12:50:43<2:17:47, 206.68s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 241/280 [12:51:48<1:46:43, 164.18s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_23/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_23/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_23/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_23/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_23/self_attn.q_proj/compressed.log
best_loss 235.50772094726562 running bpv: 2.014822
COMMANDS_FINISHED 233 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_23/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_23/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_23/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_23/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_23/mlp.up_proj/compressed.log
best_loss 290.4291076660156 running bpv: 2.0148
COMMANDS_FINISHED 234 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_23/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_23/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_23/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_23/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_23/self_attn.k_proj/compressed.log
best_loss 241.2714385986328 running bpv: 2.014819
COMMANDS_FINISHED 235 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_23/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_23/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_23/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_23/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_23/self_attn.o_proj/compressed.log
best_loss 11.992776870727539 running bpv: 2.014839
COMMANDS_FINISHED 236 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_35/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_35/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_35/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_23/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_23/self_attn.v_proj/compressed.log
best_loss 167.62222290039062 running bpv: 2.014859
COMMANDS_FINISHED 237 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_35/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_35/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_35/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_23/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_23/mlp.down_proj/compressed.log
best_loss 49.30744934082031 running bpv: 2.014826
COMMANDS_FINISHED 238 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_35/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_35/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_35/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_35/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_35/mlp.gate_proj/compressed.log
best_loss 563.8709106445312 running bpv: 2.014803
COMMANDS_FINISHED 239 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_35/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_35/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_35/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_35/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_35/self_attn.q_proj/compressed.log
best_loss 293.2166442871094 running bpv: 2.014823
COMMANDS_FINISHED 240 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_35/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_35/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_35/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_35/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_35/mlp.up_proj/compressed.log
best_loss 512.275146484375 running bpv: 2.0148
COMMANDS_FINISHED 241 n_commands 280
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 242/280 [12:54:03<1:38:26, 155.43s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 243/280 [12:56:09<1:30:13, 146.31s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 244/280 [12:59:34<1:38:21, 163.92s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 245/280 [13:08:19<2:38:48, 272.25s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 246/280 [13:10:44<2:12:38, 234.08s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 247/280 [13:13:49<2:00:38, 219.36s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 248/280 [13:14:14<1:25:53, 161.06s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 249/280 [13:16:09<1:16:04, 147.24s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 250/280 [13:19:24<1:20:47, 161.58s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_35/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_35/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_35/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_35/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_35/self_attn.k_proj/compressed.log
best_loss 300.87945556640625 running bpv: 2.01482
COMMANDS_FINISHED 242 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_35/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_35/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_35/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_35/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_35/self_attn.o_proj/compressed.log
best_loss 18.585887908935547 running bpv: 2.014839
COMMANDS_FINISHED 243 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_38/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_38/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_38/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_35/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_35/self_attn.v_proj/compressed.log
best_loss 271.9737243652344 running bpv: 2.014858
COMMANDS_FINISHED 244 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_38/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_38/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_38/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_35/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_35/mlp.down_proj/compressed.log
best_loss 94.29501342773438 running bpv: 2.014826
COMMANDS_FINISHED 245 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_38/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_38/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_38/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_38/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_38/mlp.gate_proj/compressed.log
best_loss 561.97802734375 running bpv: 2.014804
COMMANDS_FINISHED 246 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_38/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_38/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_38/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_38/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_38/self_attn.q_proj/compressed.log
best_loss 231.0064697265625 running bpv: 2.014823
COMMANDS_FINISHED 247 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_38/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_38/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_38/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_38/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_38/mlp.up_proj/compressed.log
best_loss 497.68585205078125 running bpv: 2.014801
COMMANDS_FINISHED 248 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_38/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_38/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_38/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_38/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_38/self_attn.k_proj/compressed.log
best_loss 234.2393798828125 running bpv: 2.01482
COMMANDS_FINISHED 249 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_38/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_38/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_38/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_38/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_38/self_attn.o_proj/compressed.log
best_loss 42.33241271972656 running bpv: 2.014838
COMMANDS_FINISHED 250 n_commands 280
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 251/280 [13:21:39<1:14:14, 153.61s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 252/280 [13:30:14<2:02:16, 262.04s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 253/280 [13:33:49<1:51:34, 247.93s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 254/280 [13:35:44<1:30:09, 208.05s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 255/280 [13:36:09<1:03:48, 153.14s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 256/280 [13:39:14<1:05:04, 162.70s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 257/280 [13:41:09<56:53, 148.40s/it]   92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 258/280 [13:44:34<1:00:38, 165.38s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 259/280 [13:52:19<1:29:20, 255.28s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_17/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_17/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_17/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_38/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_38/self_attn.v_proj/compressed.log
best_loss 280.7869873046875 running bpv: 2.014857
COMMANDS_FINISHED 251 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_17/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_17/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_17/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_38/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_38/mlp.down_proj/compressed.log
best_loss 137.28109741210938 running bpv: 2.014826
COMMANDS_FINISHED 252 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_17/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_17/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_17/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_17/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_17/mlp.gate_proj/compressed.log
best_loss 214.62234497070312 running bpv: 2.014804
COMMANDS_FINISHED 253 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_17/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_17/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_17/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_17/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_17/self_attn.q_proj/compressed.log
best_loss 207.10577392578125 running bpv: 2.014823
COMMANDS_FINISHED 254 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_17/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_17/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_17/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_17/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_17/mlp.up_proj/compressed.log
best_loss 203.23687744140625 running bpv: 2.014802
COMMANDS_FINISHED 255 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_17/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_17/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_17/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_17/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_17/self_attn.k_proj/compressed.log
best_loss 216.64744567871094 running bpv: 2.01482
COMMANDS_FINISHED 256 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_17/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_17/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_17/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_17/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_17/self_attn.o_proj/compressed.log
best_loss 11.463580131530762 running bpv: 2.014838
COMMANDS_FINISHED 257 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_9/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_9/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_9/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_17/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_17/self_attn.v_proj/compressed.log
best_loss 108.89409637451172 running bpv: 2.014856
COMMANDS_FINISHED 258 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_9/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_9/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_9/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_17/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_17/mlp.down_proj/compressed.log
best_loss 26.416542053222656 running bpv: 2.014826
COMMANDS_FINISHED 259 n_commands 280
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 260/280 [13:55:24<1:18:03, 234.20s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 261/280 [13:57:49<1:05:41, 207.44s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 262/280 [13:59:04<50:18, 167.71s/it]   94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 263/280 [14:00:49<42:11, 148.90s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 264/280 [14:03:14<39:23, 147.74s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 265/280 [14:06:19<39:43, 158.92s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 266/280 [14:15:34<1:04:48, 277.76s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 267/280 [14:17:39<50:15, 231.93s/it]   96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 268/280 [14:20:54<44:10, 220.86s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_9/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_9/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_9/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_9/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_9/mlp.gate_proj/compressed.log
best_loss 125.15962982177734 running bpv: 2.014805
COMMANDS_FINISHED 260 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_9/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_9/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_9/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_9/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_9/self_attn.q_proj/compressed.log
best_loss 156.02224731445312 running bpv: 2.014823
COMMANDS_FINISHED 261 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_9/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_9/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_9/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_9/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_9/mlp.up_proj/compressed.log
best_loss 106.90383911132812 running bpv: 2.014802
COMMANDS_FINISHED 262 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_9/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_9/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_9/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_9/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_9/self_attn.k_proj/compressed.log
best_loss 155.98318481445312 running bpv: 2.01482
COMMANDS_FINISHED 263 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_9/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_9/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_9/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_9/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_9/self_attn.o_proj/compressed.log
best_loss 3.4929299354553223 running bpv: 2.014838
COMMANDS_FINISHED 264 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_22/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_22/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_22/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_9/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_9/self_attn.v_proj/compressed.log
best_loss 62.27252197265625 running bpv: 2.014855
COMMANDS_FINISHED 265 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_22/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_22/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_22/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_9/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_9/mlp.down_proj/compressed.log
best_loss 8.063344955444336 running bpv: 2.014826
COMMANDS_FINISHED 266 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_22/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_22/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_22/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_22/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_22/mlp.gate_proj/compressed.log
best_loss 317.01385498046875 running bpv: 2.014806
COMMANDS_FINISHED 267 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_22/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_22/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_22/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_22/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_22/mlp.up_proj/compressed.log
best_loss 276.54608154296875 running bpv: 2.014786
COMMANDS_FINISHED 268 n_commands 280
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 269/280 [14:21:09<29:10, 159.10s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 270/280 [14:23:04<24:18, 145.88s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 271/280 [14:26:19<24:05, 160.62s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 272/280 [14:28:24<19:59, 149.94s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 273/280 [14:37:39<31:40, 271.47s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 274/280 [14:40:44<24:33, 245.53s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 275/280 [14:42:49<17:26, 209.38s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 276/280 [14:43:04<10:04, 151.07s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 277/280 [14:46:09<08:03, 161.25s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_22/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_22/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_22/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_22/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_22/self_attn.q_proj/compressed.log
best_loss 240.24496459960938 running bpv: 2.014803
COMMANDS_FINISHED 269 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_22/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_22/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_22/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_22/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_22/self_attn.k_proj/compressed.log
best_loss 249.73477172851562 running bpv: 2.01482
COMMANDS_FINISHED 270 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_22/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_22/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_22/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_22/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_22/self_attn.o_proj/compressed.log
best_loss 11.57453441619873 running bpv: 2.014837
COMMANDS_FINISHED 271 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_24/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_24/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_24/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_22/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_22/self_attn.v_proj/compressed.log
best_loss 168.06959533691406 running bpv: 2.014854
COMMANDS_FINISHED 272 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_24/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_24/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_24/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_22/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_22/mlp.down_proj/compressed.log
best_loss 47.122840881347656 running bpv: 2.014826
COMMANDS_FINISHED 273 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_24/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_24/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_24/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_24/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_24/mlp.gate_proj/compressed.log
best_loss 356.59063720703125 running bpv: 2.014806
COMMANDS_FINISHED 274 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_24/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_24/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_24/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_24/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_24/mlp.up_proj/compressed.log
best_loss 303.3809509277344 running bpv: 2.014787
COMMANDS_FINISHED 275 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_24/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_24/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_24/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_24/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_24/self_attn.q_proj/compressed.log
best_loss 245.25643920898438 running bpv: 2.014804
COMMANDS_FINISHED 276 n_commands 280
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_24/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_24/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_24/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_24/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_24/self_attn.k_proj/compressed.log
best_loss 251.69093322753906 running bpv: 2.01482
COMMANDS_FINISHED 277 n_commands 280
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 278/280 [14:48:14<05:00, 150.38s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 279/280 [14:51:34<02:45, 165.27s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 280/280 [14:59:34<00:00, 259.70s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/2048/layer_24/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_24/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_24/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_24/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_24/self_attn.o_proj/compressed.log
best_loss 10.753314971923828 running bpv: 2.014837
COMMANDS_FINISHED 278 n_commands 280
meta-llama/Llama-2-13b-hf/layer_24/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_24/self_attn.v_proj/compressed.log
best_loss 175.0033416748047 running bpv: 2.014854
COMMANDS_FINISHED 279 n_commands 280
meta-llama/Llama-2-13b-hf/layer_24/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_24/mlp.down_proj/compressed.log
best_loss 50.76611328125 running bpv: 2.014826
COMMANDS_FINISHED 280 n_commands 280
done with meta-llama/Llama-2-13b-hf
done with {'meta-llama/Llama-2-13b-hf/layer_3/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_3/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_3/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_3/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_3/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_3/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_3/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_3/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_3/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_3/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_3/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_3/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_3/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_3/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_5/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_5/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_5/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_5/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_5/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_5/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_5/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_5/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_5/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_5/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_5/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_5/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_5/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_5/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_8/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_8/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_8/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_8/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_8/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_8/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_8/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_8/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_8/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_8/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_8/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_8/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_8/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_8/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_39/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_39/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_39/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_39/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_39/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_39/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_39/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_39/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_39/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_39/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_39/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_39/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_39/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_39/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_12/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_12/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_12/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_12/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_12/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_12/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_12/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_12/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_12/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_12/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_12/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_12/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_12/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_12/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_1/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_1/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_1/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_1/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_1/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_1/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_1/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_1/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_1/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_1/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_1/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_1/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_1/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_1/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_7/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_7/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_7/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_7/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_7/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_7/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_7/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_7/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_7/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_7/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_7/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_7/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_7/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_7/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_33/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_33/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_33/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_33/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_33/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_33/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_33/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_33/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_33/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_33/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_33/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_33/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_33/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_33/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_34/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_34/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_34/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_34/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_34/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_34/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_34/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_34/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_34/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_34/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_34/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_34/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_34/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_34/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_0/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_0/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_0/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_0/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_0/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_0/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_0/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_0/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_0/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_0/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_0/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_0/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_0/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_0/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_32/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_32/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_32/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_32/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_32/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_32/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_32/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_32/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_32/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_32/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_32/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_32/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_32/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_32/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_31/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_31/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_31/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_31/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_31/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_31/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_31/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_31/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_31/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_31/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_31/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_31/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_31/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_31/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_21/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_21/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_21/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_21/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_21/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_21/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_21/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_21/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_21/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_21/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_21/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_21/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_21/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_21/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_26/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_26/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_26/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_26/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_26/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_26/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_26/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_26/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_26/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_26/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_26/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_26/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_26/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_26/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_14/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_14/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_14/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_14/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_14/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_14/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_14/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_14/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_14/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_14/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_14/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_14/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_14/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_14/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_15/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_15/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_15/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_15/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_15/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_15/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_15/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_15/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_15/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_15/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_15/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_15/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_15/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_15/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_4/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_4/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_4/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_4/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_4/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_4/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_4/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_4/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_4/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_4/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_4/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_4/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_4/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_4/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_27/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_27/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_27/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_27/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_27/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_27/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_27/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_27/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_27/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_27/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_27/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_27/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_27/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_27/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_2/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_2/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_2/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_2/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_2/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_2/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_2/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_2/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_2/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_2/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_2/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_2/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_2/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_2/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_36/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_36/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_36/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_36/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_36/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_36/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_36/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_36/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_36/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_36/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_36/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_36/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_36/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_36/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_28/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_28/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_28/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_28/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_28/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_28/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_28/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_28/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_28/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_28/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_28/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_28/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_28/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_28/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_18/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_18/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_18/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_18/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_18/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_18/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_18/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_18/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_18/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_18/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_18/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_18/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_18/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_18/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_25/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_25/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_25/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_25/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_25/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_25/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_25/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_25/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_25/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_25/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_25/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_25/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_25/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_25/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_37/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_37/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_37/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_37/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_37/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_37/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_37/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_37/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_37/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_37/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_37/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_37/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_37/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_37/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_30/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_30/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_30/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_30/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_30/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_30/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_30/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_30/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_30/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_30/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_30/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_30/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_30/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_30/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_29/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_29/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_29/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_29/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_29/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_29/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_29/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_29/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_29/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_29/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_29/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_29/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_29/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_29/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_16/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_16/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_16/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_16/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_16/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_16/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_16/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_16/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_16/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_16/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_16/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_16/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_16/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_16/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_13/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_13/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_13/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_13/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_13/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_13/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_13/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_13/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_13/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_13/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_13/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_13/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_13/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_13/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_10/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_10/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_10/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_10/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_10/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_10/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_10/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_10/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_10/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_10/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_10/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_10/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_10/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_10/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_19/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_19/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_19/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_19/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_19/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_19/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_19/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_19/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_19/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_19/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_19/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_19/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_19/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_19/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_6/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_6/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_6/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_6/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_6/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_6/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_6/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_6/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_6/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_6/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_6/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_6/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_6/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_6/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_11/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_11/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_11/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_11/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_11/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_11/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_11/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_11/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_11/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_11/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_11/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_11/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_11/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_11/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_20/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_20/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_20/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_20/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_20/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_20/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_20/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_20/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_20/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_20/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_20/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_20/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_20/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_20/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_23/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_23/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_23/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_23/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_23/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_23/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_23/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_23/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_23/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_23/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_23/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_23/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_23/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_23/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_35/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_35/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_35/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_35/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_35/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_35/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_35/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_35/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_35/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_35/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_35/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_35/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_35/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_35/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_38/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_38/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_38/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_38/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_38/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_38/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_38/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_38/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_38/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_38/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_38/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_38/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_38/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_38/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_17/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_17/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_17/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_17/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_17/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_17/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_17/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_17/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_17/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_17/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_17/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_17/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_17/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_17/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_9/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_9/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_9/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_9/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_9/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_9/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_9/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_9/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_9/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_9/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_9/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_9/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_9/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_9/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_22/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_22/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_22/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_22/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_22/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_22/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_22/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_22/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_22/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_22/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_22/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_22/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_22/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_22/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_24/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_24/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_24/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_24/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_24/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_24/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_24/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_24/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_24/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_24/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_24/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_24/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_24/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/meta-llama/Llama-2-13b-hf/layer_24/mlp.down_proj/compressed.pt'}
/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/checkpoints.yaml
perplexity_inference_command:
 python -u perplexity_eval.py --base_model meta-llama/Llama-2-13b-hf --seqlen 4096 --checkpoint_list_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/checkpoints.yaml --log_wandb --wandb_project compression_no_finetune --wandb_id ggzzgfuk
running: nohup python -u perplexity_eval.py --base_model meta-llama/Llama-2-13b-hf --seqlen 4096 --checkpoint_list_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/checkpoints.yaml --log_wandb --wandb_project compression_no_finetune --wandb_id ggzzgfuk --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/still-firefly-64/ppl_eval.log 2>&1 &
eval is done
dict_keys([])
wandb run_id ggzzgfuk
wandb_project compression_no_finetune
done
[1;34mwandb[0m: üöÄ View run [33mstill-firefly-64[0m at: [34mhttps://wandb.ai/m6481/compression_no_finetune/runs/ggzzgfuk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250105_010922-ggzzgfuk/logs[0m
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 280/280 [15:14:20<00:00, 195.93s/it]
