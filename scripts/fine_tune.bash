python -u post_quantization_fine_tune.py \
--checkpoint_list_path="/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/wandering-leaf-43/checkpoints.yaml" \
--device=cuda:1 \
--log_wandb \
--finetune_epochs=1 \
--train_seqlen=512 \
--finetune_lr=1e-5 \
--eval_every_samples=4 \
--update_every_n_tokens=4096 \
--finetune_nsamples_train=128 \
--finetune_nsamples_val=0 \
--finetune_adam_beta2=0.95 \
--add_bias