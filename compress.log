wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: m6481. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /data/lliu/huffman/wandb/run-20250102_011938-tdxolj32
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-aardvark-58
wandb: ‚≠êÔ∏è View project at https://wandb.ai/m6481/compression_no_finetune
wandb: üöÄ View run at https://wandb.ai/m6481/compression_no_finetune/runs/tdxolj32
Namespace(models_to_compress=['meta-llama/Llama-2-7b-hf', 'meta-llama/Llama-2-13b-hf', 'meta-llama/Llama-2-70b-hf', 'meta-llama/Meta-Llama-3-8B', 'meta-llama/Meta-Llama-3-70B'], seqlens=[4096, 4096, 4096, 8192, 8192], batch_size=1, hessian_path='/data/lliu/huffman/models/{model_name}/hessians_new/pajama/128/', save_path='/data/lliu/huffman/models/{model_name}/compressed', self_attn_compression_algorithm='quantize', mlp_compression_algorithm='quantize', devices=['cuda:5', 'cuda:6', 'cuda:4', 'cuda:7'], yaml_path='/data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml', self_attn_yaml_path=None, mlp_yaml_path=None, use_already_done=False, use_wandb=True, wandb_project='compression_no_finetune')
  0%|          | 0/1848 [00:00<?, ?it/s]  0%|          | 1/1848 [04:20<133:24:34, 260.03s/it]  0%|          | 3/1848 [08:20<80:06:37, 156.31s/it]   0%|          | 4/1848 [09:05<60:20:21, 117.80s/it]n_commands 1848
sample command python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_3/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_3/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_3/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_3/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_3/mlp.gate_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_3/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_3/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_3/mlp.up_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_3/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_3/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_3/self_attn.q_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_3/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_3/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_3/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_3/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_3/self_attn.q_proj/compressed.log
best_loss 103.04051971435547 running bpv: 2.132812
COMMANDS_FINISHED 1 n_commands 1848
meta-llama/Llama-2-7b-hf/layer_3/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_3/self_attn.k_proj/compressed.log
best_loss 111.42822265625 running bpv: 2.132812
COMMANDS_FINISHED 2 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_3/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_3/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_3/self_attn.o_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_3/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_3/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_3/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_3/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_3/self_attn.o_proj/compressed.log
best_loss 0.2231036275625229 running bpv: 2.132812
COMMANDS_FINISHED 3 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_3/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_3/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_3/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_3/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_3/mlp.gate_proj/compressed.log
best_loss 51.68672561645508 running bpv: 2.057478
COMMANDS_FINISHED 4 n_commands 1848
meta-llama/Llama-2-7b-hf/layer_3/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_3/mlp.up_proj/compressed.log
best_loss 43.84796142578125 running bpv: 2.030492
COMMANDS_FINISHED 5 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_5/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_5/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_5/mlp.gate_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_5/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_5/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_5/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
  0%|          | 6/1848 [12:25<55:44:55, 108.96s/it]  0%|          | 7/1848 [13:30<49:49:45, 97.44s/it]   0%|          | 8/1848 [16:25<60:36:09, 118.57s/it]  0%|          | 9/1848 [17:30<52:54:18, 103.57s/it]  1%|          | 10/1848 [18:05<42:52:20, 83.97s/it]  1%|          | 11/1848 [18:20<32:38:45, 63.98s/it]  1%|          | 12/1848 [20:25<41:44:41, 81.85s/it]  1%|          | 13/1848 [22:00<43:42:01, 85.73s/it]meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_3/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_3/self_attn.v_proj/compressed.log
best_loss 30.461612701416016 running bpv: 2.041406
COMMANDS_FINISHED 6 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_5/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_5/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_5/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_3/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_3/mlp.down_proj/compressed.log
best_loss 0.8861550092697144 running bpv: 2.026251
COMMANDS_FINISHED 7 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_5/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_5/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_5/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_5/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_5/self_attn.q_proj/compressed.log
best_loss 113.5957260131836 running bpv: 2.034409
COMMANDS_FINISHED 8 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_5/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_5/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_5/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_5/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_5/self_attn.k_proj/compressed.log
best_loss 122.68465423583984 running bpv: 2.041406
COMMANDS_FINISHED 9 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_5/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_5/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_5/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_5/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_5/mlp.gate_proj/compressed.log
best_loss 91.75440979003906 running bpv: 2.030492
COMMANDS_FINISHED 10 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_5/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_5/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_5/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_5/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_5/mlp.up_proj/compressed.log
best_loss 72.93339538574219 running bpv: 2.022596
COMMANDS_FINISHED 11 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_8/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_8/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_8/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_5/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_5/self_attn.o_proj/compressed.log
best_loss 0.7878435254096985 running bpv: 2.027989
COMMANDS_FINISHED 12 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_8/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_8/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_8/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_5/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_5/self_attn.v_proj/compressed.log
best_loss 35.448944091796875 running bpv: 2.032879
COMMANDS_FINISHED 13 n_commands 1848
  1%|          | 14/1848 [26:05<67:44:04, 132.96s/it]  1%|          | 15/1848 [26:40<52:51:34, 103.82s/it]  1%|          | 16/1848 [27:35<45:25:21, 89.26s/it]   1%|          | 17/1848 [29:30<49:18:41, 96.95s/it]  1%|          | 18/1848 [30:05<39:51:52, 78.42s/it]  1%|          | 19/1848 [30:40<33:14:20, 65.42s/it]  1%|          | 20/1848 [33:35<49:53:31, 98.26s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_8/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_8/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_8/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_8/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_8/self_attn.q_proj/compressed.log
best_loss 178.63294982910156 running bpv: 2.037332
COMMANDS_FINISHED 14 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_8/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_8/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_8/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_5/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_5/mlp.down_proj/compressed.log
best_loss 2.3998119831085205 running bpv: 2.030492
COMMANDS_FINISHED 15 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_8/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_8/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_8/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_8/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_8/mlp.gate_proj/compressed.log
best_loss 136.32501220703125 running bpv: 2.024974
COMMANDS_FINISHED 16 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_8/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_8/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_8/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_8/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_8/mlp.up_proj/compressed.log
best_loss 111.16808319091797 running bpv: 2.020428
COMMANDS_FINISHED 17 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_8/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_8/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_8/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_8/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_8/self_attn.k_proj/compressed.log
best_loss 180.409912109375 running bpv: 2.023996
COMMANDS_FINISHED 18 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_12/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_12/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_12/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_8/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_8/self_attn.o_proj/compressed.log
best_loss 2.6211771965026855 running bpv: 2.027344
COMMANDS_FINISHED 19 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_12/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_12/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_12/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_8/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_8/self_attn.v_proj/compressed.log
best_loss 57.47013854980469 running bpv: 2.030492
COMMANDS_FINISHED 20 n_commands 1848
  1%|          | 21/1848 [36:50<64:34:55, 127.26s/it]  1%|          | 22/1848 [37:45<53:33:38, 105.60s/it]  1%|          | 23/1848 [39:10<50:24:06, 99.42s/it]   1%|‚ñè         | 24/1848 [39:45<40:35:10, 80.10s/it]  1%|‚ñè         | 25/1848 [40:50<38:16:16, 75.58s/it]  1%|‚ñè         | 26/1848 [41:45<35:07:39, 69.41s/it]  1%|‚ñè         | 27/1848 [43:50<43:32:43, 86.09s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_12/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_12/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_12/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_8/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_8/mlp.down_proj/compressed.log
best_loss 5.823155403137207 running bpv: 2.026251
COMMANDS_FINISHED 21 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_12/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_12/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_12/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_12/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_12/self_attn.q_proj/compressed.log
best_loss 228.64962768554688 running bpv: 2.029116
COMMANDS_FINISHED 22 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_12/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_12/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_12/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_12/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_12/mlp.gate_proj/compressed.log
best_loss 169.40371704101562 running bpv: 2.02536
COMMANDS_FINISHED 23 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_12/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_12/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_12/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_12/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_12/mlp.up_proj/compressed.log
best_loss 155.5160675048828 running bpv: 2.022078
COMMANDS_FINISHED 24 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_12/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_12/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_12/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_12/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_12/self_attn.k_proj/compressed.log
best_loss 243.2017364501953 running bpv: 2.02462
COMMANDS_FINISHED 25 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_1/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_1/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_1/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_12/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_12/self_attn.o_proj/compressed.log
best_loss 6.197705268859863 running bpv: 2.027048
COMMANDS_FINISHED 26 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_1/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_1/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_1/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_12/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_12/self_attn.v_proj/compressed.log
best_loss 84.32506561279297 running bpv: 2.029369
COMMANDS_FINISHED 27 n_commands 1848
  2%|‚ñè         | 28/1848 [47:55<67:37:27, 133.76s/it]  2%|‚ñè         | 29/1848 [48:20<51:06:08, 101.14s/it]  2%|‚ñè         | 30/1848 [49:55<50:08:47, 99.30s/it]   2%|‚ñè         | 31/1848 [50:50<43:24:45, 86.01s/it]  2%|‚ñè         | 32/1848 [51:55<40:12:36, 79.71s/it]  2%|‚ñè         | 33/1848 [52:20<31:54:49, 63.30s/it]  2%|‚ñè         | 34/1848 [54:55<45:45:37, 90.81s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_1/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_1/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_1/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_1/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_1/self_attn.q_proj/compressed.log
best_loss 4.067144870758057 running bpv: 2.031591
COMMANDS_FINISHED 28 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_1/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_1/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_1/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_12/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_12/mlp.down_proj/compressed.log
best_loss 10.558582305908203 running bpv: 2.028414
COMMANDS_FINISHED 29 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_1/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_1/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_1/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_1/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_1/mlp.gate_proj/compressed.log
best_loss 13.287349700927734 running bpv: 2.025567
COMMANDS_FINISHED 30 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_1/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_1/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_1/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_1/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_1/mlp.up_proj/compressed.log
best_loss 11.72177505493164 running bpv: 2.022999
COMMANDS_FINISHED 31 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_1/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_1/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_1/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_1/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_1/self_attn.k_proj/compressed.log
best_loss 4.02894926071167 running bpv: 2.024974
COMMANDS_FINISHED 32 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_7/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_7/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_7/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_1/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_1/self_attn.o_proj/compressed.log
best_loss 0.047882433980703354 running bpv: 2.026878
COMMANDS_FINISHED 33 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_7/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_7/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_7/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_1/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_1/self_attn.v_proj/compressed.log
best_loss 0.5814502239227295 running bpv: 2.028716
COMMANDS_FINISHED 34 n_commands 1848
  2%|‚ñè         | 35/1848 [59:00<69:02:01, 137.08s/it]  2%|‚ñè         | 36/1848 [59:15<50:33:46, 100.46s/it]  2%|‚ñè         | 37/1848 [1:01:00<51:13:21, 101.82s/it]  2%|‚ñè         | 38/1848 [1:01:25<39:36:27, 78.78s/it]   2%|‚ñè         | 39/1848 [1:03:10<43:32:25, 86.65s/it]  2%|‚ñè         | 40/1848 [1:03:25<32:43:20, 65.15s/it]  2%|‚ñè         | 41/1848 [1:05:30<41:43:04, 83.11s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_7/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_7/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_7/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_7/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_7/self_attn.q_proj/compressed.log
best_loss 180.4994354248047 running bpv: 2.030492
COMMANDS_FINISHED 35 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_7/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_7/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_7/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_1/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_1/mlp.down_proj/compressed.log
best_loss 0.20696872472763062 running bpv: 2.027989
COMMANDS_FINISHED 36 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_7/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_7/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_7/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_7/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_7/mlp.gate_proj/compressed.log
best_loss 131.68714904785156 running bpv: 2.025696
COMMANDS_FINISHED 37 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_7/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_7/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_7/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_7/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_7/mlp.up_proj/compressed.log
best_loss 101.28619384765625 running bpv: 2.023588
COMMANDS_FINISHED 38 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_7/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_7/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_7/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_7/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_7/self_attn.k_proj/compressed.log
best_loss 182.46539306640625 running bpv: 2.025201
COMMANDS_FINISHED 39 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_0/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_0/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_0/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_7/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_7/self_attn.o_proj/compressed.log
best_loss 1.6781718730926514 running bpv: 2.026768
COMMANDS_FINISHED 40 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_0/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_0/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_0/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_7/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_7/self_attn.v_proj/compressed.log
best_loss 55.95782470703125 running bpv: 2.02829
COMMANDS_FINISHED 41 n_commands 1848
  2%|‚ñè         | 42/1848 [1:09:35<66:03:43, 131.69s/it]  2%|‚ñè         | 43/1848 [1:10:10<51:29:01, 102.68s/it]  2%|‚ñè         | 44/1848 [1:12:15<54:48:43, 109.38s/it]  2%|‚ñè         | 45/1848 [1:12:30<40:36:05, 81.07s/it]   2%|‚ñè         | 46/1848 [1:13:35<38:10:03, 76.25s/it]  3%|‚ñé         | 47/1848 [1:14:10<31:57:23, 63.88s/it]  3%|‚ñé         | 48/1848 [1:16:35<44:06:34, 88.22s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_0/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_0/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_0/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_0/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_0/self_attn.q_proj/compressed.log
best_loss 0.0974874496459961 running bpv: 2.029768
COMMANDS_FINISHED 42 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_0/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_0/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_0/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_7/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_7/mlp.down_proj/compressed.log
best_loss 4.713006496429443 running bpv: 2.027703
COMMANDS_FINISHED 43 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_0/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_0/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_0/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_0/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_0/mlp.gate_proj/compressed.log
best_loss 3.0106325149536133 running bpv: 2.025784
COMMANDS_FINISHED 44 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_0/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_0/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_0/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_0/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_0/mlp.up_proj/compressed.log
best_loss 2.9139795303344727 running bpv: 2.023996
COMMANDS_FINISHED 45 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_0/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_0/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_0/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_0/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_0/self_attn.k_proj/compressed.log
best_loss 0.08964192867279053 running bpv: 2.02536
COMMANDS_FINISHED 46 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_31/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_31/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_31/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_0/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_0/self_attn.o_proj/compressed.log
best_loss 0.0021019165869802237 running bpv: 2.026691
COMMANDS_FINISHED 47 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_31/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_31/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_31/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_0/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_0/self_attn.v_proj/compressed.log
best_loss 0.03755901753902435 running bpv: 2.027989
COMMANDS_FINISHED 48 n_commands 1848
  3%|‚ñé         | 49/1848 [1:20:40<67:35:32, 135.26s/it]  3%|‚ñé         | 50/1848 [1:21:25<54:01:55, 108.18s/it]  3%|‚ñé         | 51/1848 [1:22:40<49:02:02, 98.23s/it]   3%|‚ñé         | 52/1848 [1:23:15<39:32:38, 79.26s/it]  3%|‚ñé         | 53/1848 [1:24:40<40:22:53, 80.99s/it]  3%|‚ñé         | 54/1848 [1:25:25<34:58:47, 70.19s/it]  3%|‚ñé         | 55/1848 [1:27:20<41:39:25, 83.64s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_31/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_31/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_31/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_31/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_31/self_attn.q_proj/compressed.log
best_loss 249.89364624023438 running bpv: 2.029256
COMMANDS_FINISHED 49 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_31/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_31/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_31/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_0/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_0/mlp.down_proj/compressed.log
best_loss 0.023153727874159813 running bpv: 2.027498
COMMANDS_FINISHED 50 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_31/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_31/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_31/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_31/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_31/mlp.gate_proj/compressed.log
best_loss 592.3468017578125 running bpv: 2.025848
COMMANDS_FINISHED 51 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_31/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_31/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_31/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_31/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_31/mlp.up_proj/compressed.log
best_loss 527.5628662109375 running bpv: 2.024295
COMMANDS_FINISHED 52 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_31/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_31/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_31/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_31/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_31/self_attn.k_proj/compressed.log
best_loss 268.43359375 running bpv: 2.025477
COMMANDS_FINISHED 53 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_21/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_21/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_21/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_31/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_31/self_attn.o_proj/compressed.log
best_loss 29.95252227783203 running bpv: 2.026634
COMMANDS_FINISHED 54 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_21/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_21/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_21/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_31/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_31/self_attn.v_proj/compressed.log
best_loss 191.61419677734375 running bpv: 2.027765
COMMANDS_FINISHED 55 n_commands 1848
  3%|‚ñé         | 56/1848 [1:31:25<65:44:02, 132.06s/it]  3%|‚ñé         | 57/1848 [1:31:50<49:43:13, 99.94s/it]   3%|‚ñé         | 58/1848 [1:33:45<51:56:26, 104.46s/it]  3%|‚ñé         | 59/1848 [1:34:30<43:02:53, 86.63s/it]   3%|‚ñé         | 60/1848 [1:35:25<38:18:46, 77.14s/it]  3%|‚ñé         | 61/1848 [1:35:50<30:31:40, 61.50s/it]  3%|‚ñé         | 62/1848 [1:38:35<45:55:03, 92.55s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_21/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_21/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_21/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_21/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_21/self_attn.q_proj/compressed.log
best_loss 294.30218505859375 running bpv: 2.028873
COMMANDS_FINISHED 56 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_21/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_21/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_21/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_31/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_31/mlp.down_proj/compressed.log
best_loss 249.789306640625 running bpv: 2.027344
COMMANDS_FINISHED 57 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_21/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_21/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_21/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_21/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_21/mlp.gate_proj/compressed.log
best_loss 418.5148620605469 running bpv: 2.025896
COMMANDS_FINISHED 58 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_21/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_21/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_21/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_21/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_21/mlp.up_proj/compressed.log
best_loss 358.5552673339844 running bpv: 2.024524
COMMANDS_FINISHED 59 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_21/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_21/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_21/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_21/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_21/self_attn.k_proj/compressed.log
best_loss 300.513427734375 running bpv: 2.025567
COMMANDS_FINISHED 60 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_26/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_26/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_26/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_21/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_21/self_attn.o_proj/compressed.log
best_loss 10.41537857055664 running bpv: 2.02659
COMMANDS_FINISHED 61 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_26/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_26/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_26/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_21/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_21/self_attn.v_proj/compressed.log
best_loss 191.1563262939453 running bpv: 2.027593
COMMANDS_FINISHED 62 n_commands 1848
  3%|‚ñé         | 63/1848 [1:42:40<68:34:18, 138.30s/it]  3%|‚ñé         | 64/1848 [1:42:55<50:12:14, 101.31s/it]  4%|‚ñé         | 65/1848 [1:44:30<49:14:24, 99.42s/it]   4%|‚ñé         | 66/1848 [1:44:55<38:09:44, 77.10s/it]  4%|‚ñé         | 67/1848 [1:46:40<42:17:02, 85.47s/it]  4%|‚ñé         | 68/1848 [1:47:55<40:42:30, 82.33s/it]  4%|‚ñé         | 69/1848 [1:49:00<38:07:02, 77.13s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_26/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_26/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_26/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_26/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_26/self_attn.q_proj/compressed.log
best_loss 346.39630126953125 running bpv: 2.028577
COMMANDS_FINISHED 63 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_26/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_26/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_26/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_21/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_21/mlp.down_proj/compressed.log
best_loss 44.7724609375 running bpv: 2.027223
COMMANDS_FINISHED 64 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_26/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_26/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_26/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_26/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_26/mlp.gate_proj/compressed.log
best_loss 563.0769653320312 running bpv: 2.025934
COMMANDS_FINISHED 65 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_26/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_26/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_26/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_26/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_26/mlp.up_proj/compressed.log
best_loss 484.68560791015625 running bpv: 2.024706
COMMANDS_FINISHED 66 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_26/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_26/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_26/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_26/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_26/self_attn.k_proj/compressed.log
best_loss 351.9620361328125 running bpv: 2.025638
COMMANDS_FINISHED 67 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_14/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_14/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_14/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_26/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_26/self_attn.o_proj/compressed.log
best_loss 388.0816955566406 running bpv: 2.026555
COMMANDS_FINISHED 68 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_14/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_14/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_14/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_26/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_26/self_attn.v_proj/compressed.log
best_loss 284.375244140625 running bpv: 2.027456
COMMANDS_FINISHED 69 n_commands 1848
  4%|‚ñç         | 70/1848 [1:53:05<62:58:16, 127.50s/it]  4%|‚ñç         | 71/1848 [1:53:40<49:14:19, 99.75s/it]   4%|‚ñç         | 72/1848 [1:55:45<52:56:58, 107.33s/it]  4%|‚ñç         | 73/1848 [1:57:00<48:08:20, 97.63s/it]   4%|‚ñç         | 74/1848 [1:57:15<35:53:46, 72.84s/it]  4%|‚ñç         | 75/1848 [1:57:40<28:48:28, 58.49s/it]  4%|‚ñç         | 76/1848 [2:01:05<50:25:42, 102.45s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_14/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_14/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_14/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_14/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_14/self_attn.q_proj/compressed.log
best_loss 245.23550415039062 running bpv: 2.028341
COMMANDS_FINISHED 70 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_14/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_14/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_14/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_26/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_26/mlp.down_proj/compressed.log
best_loss 66.95122528076172 running bpv: 2.027127
COMMANDS_FINISHED 71 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_14/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_14/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_14/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_14/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_14/mlp.gate_proj/compressed.log
best_loss 195.81170654296875 running bpv: 2.025965
COMMANDS_FINISHED 72 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_14/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_14/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_14/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_14/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_14/mlp.up_proj/compressed.log
best_loss 185.93572998046875 running bpv: 2.024852
COMMANDS_FINISHED 73 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_14/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_14/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_14/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_14/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_14/self_attn.k_proj/compressed.log
best_loss 253.9083251953125 running bpv: 2.025696
COMMANDS_FINISHED 74 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_15/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_15/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_15/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_14/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_14/self_attn.o_proj/compressed.log
best_loss 8.5706787109375 running bpv: 2.026526
COMMANDS_FINISHED 75 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_15/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_15/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_15/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_14/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_14/self_attn.v_proj/compressed.log
best_loss 95.0372543334961 running bpv: 2.027344
COMMANDS_FINISHED 76 n_commands 1848
  4%|‚ñç         | 77/1848 [2:05:00<69:57:55, 142.22s/it]  4%|‚ñç         | 78/1848 [2:05:15<51:09:41, 104.06s/it]  4%|‚ñç         | 79/1848 [2:06:20<45:22:34, 92.34s/it]   4%|‚ñç         | 80/1848 [2:06:45<35:25:46, 72.14s/it]  4%|‚ñç         | 81/1848 [2:09:00<44:40:03, 91.00s/it]  4%|‚ñç         | 82/1848 [2:09:15<33:27:28, 68.20s/it]  4%|‚ñç         | 83/1848 [2:10:50<37:22:55, 76.25s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_15/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_15/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_15/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_14/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_14/mlp.down_proj/compressed.log
best_loss 15.061869621276855 running bpv: 2.026251
COMMANDS_FINISHED 77 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_15/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_15/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_15/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_15/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_15/self_attn.q_proj/compressed.log
best_loss 229.14617919921875 running bpv: 2.027048
COMMANDS_FINISHED 78 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_15/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_15/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_15/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_15/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_15/mlp.gate_proj/compressed.log
best_loss 215.45355224609375 running bpv: 2.02599
COMMANDS_FINISHED 79 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_15/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_15/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_15/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_15/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_15/mlp.up_proj/compressed.log
best_loss 204.54730224609375 running bpv: 2.024974
COMMANDS_FINISHED 80 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_15/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_15/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_15/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_15/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_15/self_attn.k_proj/compressed.log
best_loss 245.69482421875 running bpv: 2.025744
COMMANDS_FINISHED 81 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_4/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_4/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_4/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_15/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_15/self_attn.o_proj/compressed.log
best_loss 9.262563705444336 running bpv: 2.026503
COMMANDS_FINISHED 82 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_4/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_4/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_4/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_15/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_15/self_attn.v_proj/compressed.log
best_loss 99.17191314697266 running bpv: 2.027251
COMMANDS_FINISHED 83 n_commands 1848
  5%|‚ñç         | 84/1848 [2:14:55<62:10:18, 126.88s/it]  5%|‚ñç         | 85/1848 [2:15:30<48:38:18, 99.32s/it]   5%|‚ñç         | 86/1848 [2:18:05<56:47:21, 116.03s/it]  5%|‚ñç         | 87/1848 [2:18:20<41:55:54, 85.72s/it]   5%|‚ñç         | 88/1848 [2:18:55<34:28:11, 70.51s/it]  5%|‚ñç         | 89/1848 [2:19:30<29:14:48, 59.86s/it]  5%|‚ñç         | 90/1848 [2:22:26<46:06:05, 94.41s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_4/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_4/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_4/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_4/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_4/self_attn.q_proj/compressed.log
best_loss 99.48759460449219 running bpv: 2.027989
COMMANDS_FINISHED 84 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_4/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_4/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_4/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_15/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_15/mlp.down_proj/compressed.log
best_loss 18.843107223510742 running bpv: 2.026982
COMMANDS_FINISHED 85 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_4/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_4/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_4/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_4/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_4/mlp.gate_proj/compressed.log
best_loss 72.3624267578125 running bpv: 2.026012
COMMANDS_FINISHED 86 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_4/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_4/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_4/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_4/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_4/mlp.up_proj/compressed.log
best_loss 58.17361831665039 running bpv: 2.025076
COMMANDS_FINISHED 87 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_4/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_4/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_4/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_4/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_4/self_attn.k_proj/compressed.log
best_loss 103.31560516357422 running bpv: 2.025784
COMMANDS_FINISHED 88 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_27/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_27/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_27/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_4/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_4/self_attn.o_proj/compressed.log
best_loss 0.4944494962692261 running bpv: 2.026483
COMMANDS_FINISHED 89 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_27/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_27/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_27/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_4/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_4/self_attn.v_proj/compressed.log
best_loss 29.95985984802246 running bpv: 2.027173
COMMANDS_FINISHED 90 n_commands 1848
  5%|‚ñç         | 91/1848 [2:26:31<68:07:43, 139.59s/it]  5%|‚ñç         | 92/1848 [2:27:16<54:14:57, 111.22s/it]  5%|‚ñå         | 93/1848 [2:28:01<44:32:06, 91.35s/it]   5%|‚ñå         | 94/1848 [2:28:36<36:16:25, 74.45s/it]  5%|‚ñå         | 95/1848 [2:30:41<43:38:22, 89.62s/it]  5%|‚ñå         | 96/1848 [2:31:16<35:38:29, 73.24s/it]  5%|‚ñå         | 97/1848 [2:32:41<37:20:21, 76.77s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_27/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_27/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_27/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_27/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_27/self_attn.q_proj/compressed.log
best_loss 385.53094482421875 running bpv: 2.027854
COMMANDS_FINISHED 91 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_27/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_27/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_27/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_4/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_4/mlp.down_proj/compressed.log
best_loss 1.6186964511871338 running bpv: 2.026926
COMMANDS_FINISHED 92 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_27/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_27/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_27/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_27/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_27/mlp.gate_proj/compressed.log
best_loss 598.160400390625 running bpv: 2.026029
COMMANDS_FINISHED 93 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_27/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_27/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_27/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_27/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_27/mlp.up_proj/compressed.log
best_loss 519.2447509765625 running bpv: 2.025162
COMMANDS_FINISHED 94 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_27/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_27/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_27/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_27/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_27/self_attn.k_proj/compressed.log
best_loss 393.6852722167969 running bpv: 2.025818
COMMANDS_FINISHED 95 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_2/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_2/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_2/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_27/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_27/self_attn.o_proj/compressed.log
best_loss 17.61007308959961 running bpv: 2.026466
COMMANDS_FINISHED 96 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_2/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_2/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_2/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_27/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_27/self_attn.v_proj/compressed.log
best_loss 296.169189453125 running bpv: 2.027106
COMMANDS_FINISHED 97 n_commands 1848
  5%|‚ñå         | 98/1848 [2:36:46<61:51:19, 127.25s/it]  5%|‚ñå         | 99/1848 [2:37:11<46:55:06, 96.57s/it]   5%|‚ñå         | 100/1848 [2:39:46<55:24:17, 114.11s/it]  5%|‚ñå         | 101/1848 [2:40:21<43:51:27, 90.38s/it]   6%|‚ñå         | 102/1848 [2:40:46<34:19:15, 70.77s/it]  6%|‚ñå         | 103/1848 [2:41:11<27:38:50, 57.04s/it]  6%|‚ñå         | 104/1848 [2:44:26<47:41:07, 98.43s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_2/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_2/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_2/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_2/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_2/self_attn.q_proj/compressed.log
best_loss 36.49727249145508 running bpv: 2.027738
COMMANDS_FINISHED 98 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_2/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_2/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_2/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_27/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_27/mlp.down_proj/compressed.log
best_loss 75.97834777832031 running bpv: 2.026878
COMMANDS_FINISHED 99 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_2/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_2/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_2/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_2/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_2/mlp.gate_proj/compressed.log
best_loss 30.566204071044922 running bpv: 2.026045
COMMANDS_FINISHED 100 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_2/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_2/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_2/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_2/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_2/mlp.up_proj/compressed.log
best_loss 26.30846405029297 running bpv: 2.025237
COMMANDS_FINISHED 101 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_2/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_2/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_2/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_2/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_2/self_attn.k_proj/compressed.log
best_loss 40.056732177734375 running bpv: 2.025848
COMMANDS_FINISHED 102 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_28/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_28/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_28/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_2/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_2/self_attn.o_proj/compressed.log
best_loss 0.13737095892429352 running bpv: 2.026451
COMMANDS_FINISHED 103 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_28/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_28/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_28/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_2/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_2/self_attn.v_proj/compressed.log
best_loss 10.906603813171387 running bpv: 2.027048
COMMANDS_FINISHED 104 n_commands 1848
  6%|‚ñå         | 105/1848 [2:48:31<68:57:02, 142.41s/it]  6%|‚ñå         | 106/1848 [2:49:06<53:19:10, 110.19s/it]  6%|‚ñå         | 107/1848 [2:49:51<43:49:56, 90.64s/it]   6%|‚ñå         | 108/1848 [2:50:16<34:17:28, 70.95s/it]  6%|‚ñå         | 109/1848 [2:52:31<43:33:20, 90.17s/it]  6%|‚ñå         | 110/1848 [2:53:16<36:59:24, 76.62s/it]  6%|‚ñå         | 111/1848 [2:54:21<35:17:17, 73.14s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_28/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_28/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_28/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_28/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_28/self_attn.q_proj/compressed.log
best_loss 377.4018859863281 running bpv: 2.027638
COMMANDS_FINISHED 105 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_28/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_28/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_28/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_2/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_2/mlp.down_proj/compressed.log
best_loss 0.43652164936065674 running bpv: 2.026837
COMMANDS_FINISHED 106 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_28/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_28/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_28/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_28/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_28/mlp.gate_proj/compressed.log
best_loss 621.0789794921875 running bpv: 2.026058
COMMANDS_FINISHED 107 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_28/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_28/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_28/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_28/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_28/mlp.up_proj/compressed.log
best_loss 555.245361328125 running bpv: 2.025303
COMMANDS_FINISHED 108 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_28/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_28/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_28/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_28/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_28/self_attn.k_proj/compressed.log
best_loss 386.855224609375 running bpv: 2.025874
COMMANDS_FINISHED 109 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_18/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_18/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_18/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_28/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_28/self_attn.o_proj/compressed.log
best_loss 24.158443450927734 running bpv: 2.026438
COMMANDS_FINISHED 110 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_18/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_18/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_18/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_28/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_28/self_attn.v_proj/compressed.log
best_loss 326.0440673828125 running bpv: 2.026997
COMMANDS_FINISHED 111 n_commands 1848
  6%|‚ñå         | 112/1848 [2:58:26<60:08:05, 124.70s/it]  6%|‚ñå         | 113/1848 [2:59:01<47:07:54, 97.80s/it]   6%|‚ñå         | 114/1848 [3:01:36<55:22:25, 114.96s/it]  6%|‚ñå         | 115/1848 [3:02:21<45:14:20, 93.98s/it]   6%|‚ñã         | 116/1848 [3:02:36<33:48:54, 70.29s/it]  6%|‚ñã         | 117/1848 [3:03:11<28:42:24, 59.70s/it]  6%|‚ñã         | 118/1848 [3:06:26<48:11:55, 100.30s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_18/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_18/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_18/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_18/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_18/self_attn.q_proj/compressed.log
best_loss 273.8238220214844 running bpv: 2.02755
COMMANDS_FINISHED 112 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_18/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_18/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_18/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_28/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_28/mlp.down_proj/compressed.log
best_loss 91.25467681884766 running bpv: 2.0268
COMMANDS_FINISHED 113 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_18/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_18/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_18/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_18/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_18/mlp.gate_proj/compressed.log
best_loss 330.8441162109375 running bpv: 2.02607
COMMANDS_FINISHED 114 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_18/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_18/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_18/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_18/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_18/mlp.up_proj/compressed.log
best_loss 293.9581604003906 running bpv: 2.02536
COMMANDS_FINISHED 115 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_18/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_18/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_18/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_18/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_18/self_attn.k_proj/compressed.log
best_loss 285.4631652832031 running bpv: 2.025896
COMMANDS_FINISHED 116 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_25/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_25/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_25/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_18/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_18/self_attn.o_proj/compressed.log
best_loss 10.052875518798828 running bpv: 2.026427
COMMANDS_FINISHED 117 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_25/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_25/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_25/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_18/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_18/self_attn.v_proj/compressed.log
best_loss 150.58802795410156 running bpv: 2.026953
COMMANDS_FINISHED 118 n_commands 1848
  6%|‚ñã         | 119/1848 [3:10:31<69:01:26, 143.72s/it]  6%|‚ñã         | 120/1848 [3:10:46<50:26:58, 105.10s/it]  7%|‚ñã         | 121/1848 [3:11:41<43:12:39, 90.07s/it]   7%|‚ñã         | 122/1848 [3:12:16<35:15:54, 73.55s/it]  7%|‚ñã         | 123/1848 [3:14:31<44:04:46, 91.99s/it]  7%|‚ñã         | 124/1848 [3:14:46<32:59:36, 68.90s/it]  7%|‚ñã         | 125/1848 [3:16:21<36:43:26, 76.73s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_25/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_25/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_25/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_25/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_25/self_attn.q_proj/compressed.log
best_loss 375.2106018066406 running bpv: 2.027473
COMMANDS_FINISHED 119 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_25/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_25/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_25/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_18/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_18/mlp.down_proj/compressed.log
best_loss 32.66584396362305 running bpv: 2.026768
COMMANDS_FINISHED 120 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_25/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_25/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_25/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_25/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_25/mlp.gate_proj/compressed.log
best_loss 531.197265625 running bpv: 2.026081
COMMANDS_FINISHED 121 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_25/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_25/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_25/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_25/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_25/mlp.up_proj/compressed.log
best_loss 456.3532409667969 running bpv: 2.025411
COMMANDS_FINISHED 122 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_25/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_25/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_25/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_25/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_25/self_attn.k_proj/compressed.log
best_loss 377.3086242675781 running bpv: 2.025916
COMMANDS_FINISHED 123 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_30/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_30/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_30/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_25/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_25/self_attn.o_proj/compressed.log
best_loss 12.510932922363281 running bpv: 2.026417
COMMANDS_FINISHED 124 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_30/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_30/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_30/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_25/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_25/self_attn.v_proj/compressed.log
best_loss 289.32476806640625 running bpv: 2.026913
COMMANDS_FINISHED 125 n_commands 1848
  7%|‚ñã         | 126/1848 [3:20:26<60:51:10, 127.22s/it]  7%|‚ñã         | 127/1848 [3:20:51<46:09:31, 96.55s/it]   7%|‚ñã         | 128/1848 [3:23:46<57:22:42, 120.09s/it]  7%|‚ñã         | 130/1848 [3:24:36<36:22:05, 76.21s/it]   7%|‚ñã         | 131/1848 [3:24:51<29:06:35, 61.03s/it]  7%|‚ñã         | 132/1848 [3:27:56<44:33:03, 93.46s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_30/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_30/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_30/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_30/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_30/self_attn.q_proj/compressed.log
best_loss 358.5686950683594 running bpv: 2.027405
COMMANDS_FINISHED 126 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_30/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_30/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_30/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_25/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_25/mlp.down_proj/compressed.log
best_loss 60.58721160888672 running bpv: 2.026739
COMMANDS_FINISHED 127 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_30/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_30/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_30/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_30/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_30/mlp.gate_proj/compressed.log
best_loss 667.4099731445312 running bpv: 2.02609
COMMANDS_FINISHED 128 n_commands 1848
meta-llama/Llama-2-7b-hf/layer_30/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_30/mlp.up_proj/compressed.log
best_loss 598.1068115234375 running bpv: 2.025456
COMMANDS_FINISHED 129 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_30/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_30/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_30/mlp.down_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_30/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_30/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_30/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_30/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_30/self_attn.k_proj/compressed.log
best_loss 370.02734375 running bpv: 2.025934
COMMANDS_FINISHED 130 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_29/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_29/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_29/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_30/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_30/self_attn.o_proj/compressed.log
best_loss 28.788917541503906 running bpv: 2.026408
COMMANDS_FINISHED 131 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_29/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_29/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_29/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_30/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_30/self_attn.v_proj/compressed.log
best_loss 341.6867370605469 running bpv: 2.026878
COMMANDS_FINISHED 132 n_commands 1848
  7%|‚ñã         | 133/1848 [3:32:01<64:09:54, 134.69s/it]  7%|‚ñã         | 134/1848 [3:32:56<53:30:40, 112.39s/it]  7%|‚ñã         | 135/1848 [3:33:41<44:19:21, 93.15s/it]   7%|‚ñã         | 136/1848 [3:33:56<33:31:42, 70.50s/it]  7%|‚ñã         | 137/1848 [3:36:01<41:05:38, 86.46s/it]  7%|‚ñã         | 138/1848 [3:37:06<38:03:53, 80.14s/it]  8%|‚ñä         | 139/1848 [3:38:01<34:30:24, 72.69s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_29/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_29/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_29/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_29/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_29/self_attn.q_proj/compressed.log
best_loss 332.330078125 running bpv: 2.027344
COMMANDS_FINISHED 133 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_29/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_29/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_29/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_30/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_30/mlp.down_proj/compressed.log
best_loss 145.89280700683594 running bpv: 2.026714
COMMANDS_FINISHED 134 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_29/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_29/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_29/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_29/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_29/mlp.gate_proj/compressed.log
best_loss 643.479248046875 running bpv: 2.026098
COMMANDS_FINISHED 135 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_29/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_29/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_29/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_29/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_29/mlp.up_proj/compressed.log
best_loss 582.8184204101562 running bpv: 2.025497
COMMANDS_FINISHED 136 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_29/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_29/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_29/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_29/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_29/self_attn.k_proj/compressed.log
best_loss 339.44940185546875 running bpv: 2.025951
COMMANDS_FINISHED 137 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_16/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_16/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_16/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_29/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_29/self_attn.o_proj/compressed.log
best_loss 22.49486541748047 running bpv: 2.0264
COMMANDS_FINISHED 138 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_16/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_16/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_16/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_29/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_29/self_attn.v_proj/compressed.log
best_loss 305.7704772949219 running bpv: 2.026846
COMMANDS_FINISHED 139 n_commands 1848
  8%|‚ñä         | 140/1848 [3:42:06<58:48:35, 123.95s/it]  8%|‚ñä         | 141/1848 [3:42:51<47:36:40, 100.41s/it]  8%|‚ñä         | 142/1848 [3:45:06<52:28:57, 110.75s/it]  8%|‚ñä         | 143/1848 [3:46:11<45:58:19, 97.07s/it]   8%|‚ñä         | 145/1848 [3:46:51<29:07:09, 61.56s/it]  8%|‚ñä         | 146/1848 [3:50:16<45:53:56, 97.08s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_16/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_16/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_16/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_16/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_16/self_attn.q_proj/compressed.log
best_loss 240.67770385742188 running bpv: 2.027289
COMMANDS_FINISHED 140 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_16/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_16/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_16/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_29/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_29/mlp.down_proj/compressed.log
best_loss 109.37599182128906 running bpv: 2.026691
COMMANDS_FINISHED 141 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_16/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_16/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_16/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_16/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_16/mlp.gate_proj/compressed.log
best_loss 251.49560546875 running bpv: 2.026106
COMMANDS_FINISHED 142 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_16/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_16/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_16/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_16/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_16/mlp.up_proj/compressed.log
best_loss 234.9910888671875 running bpv: 2.025534
COMMANDS_FINISHED 143 n_commands 1848
meta-llama/Llama-2-7b-hf/layer_16/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_16/self_attn.k_proj/compressed.log
best_loss 253.9752197265625 running bpv: 2.025965
COMMANDS_FINISHED 144 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_16/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_16/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_16/self_attn.v_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_13/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_13/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_13/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_16/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_16/self_attn.o_proj/compressed.log
best_loss 12.379643440246582 running bpv: 2.026393
COMMANDS_FINISHED 145 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_13/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_13/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_13/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_16/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_16/self_attn.v_proj/compressed.log
best_loss 114.44029998779297 running bpv: 2.026818
COMMANDS_FINISHED 146 n_commands 1848
  8%|‚ñä         | 147/1848 [3:54:11<62:54:16, 133.13s/it]  8%|‚ñä         | 148/1848 [3:54:26<47:42:14, 101.02s/it]  8%|‚ñä         | 149/1848 [3:55:21<41:36:07, 88.15s/it]   8%|‚ñä         | 150/1848 [3:55:56<34:25:15, 72.98s/it]  8%|‚ñä         | 151/1848 [3:58:11<42:52:21, 90.95s/it]  8%|‚ñä         | 152/1848 [3:58:26<32:22:28, 68.72s/it]  8%|‚ñä         | 153/1848 [4:00:01<36:00:20, 76.47s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_13/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_13/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_13/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_16/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_16/mlp.down_proj/compressed.log
best_loss 25.264524459838867 running bpv: 2.026251
COMMANDS_FINISHED 147 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_13/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_13/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_13/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_13/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_13/self_attn.q_proj/compressed.log
best_loss 234.59634399414062 running bpv: 2.02667
COMMANDS_FINISHED 148 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_13/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_13/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_13/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_13/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_13/mlp.gate_proj/compressed.log
best_loss 179.79710388183594 running bpv: 2.026113
COMMANDS_FINISHED 149 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_13/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_13/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_13/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_13/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_13/mlp.up_proj/compressed.log
best_loss 169.54226684570312 running bpv: 2.025567
COMMANDS_FINISHED 150 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_13/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_13/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_13/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_13/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_13/self_attn.k_proj/compressed.log
best_loss 242.37167358398438 running bpv: 2.025978
COMMANDS_FINISHED 151 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_10/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_10/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_10/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_13/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_13/self_attn.o_proj/compressed.log
best_loss 7.02793550491333 running bpv: 2.026387
COMMANDS_FINISHED 152 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_10/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_10/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_10/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_13/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_13/self_attn.v_proj/compressed.log
best_loss 94.36779022216797 running bpv: 2.026792
COMMANDS_FINISHED 153 n_commands 1848
  8%|‚ñä         | 154/1848 [4:04:06<59:29:33, 126.43s/it]  8%|‚ñä         | 155/1848 [4:04:31<45:16:09, 96.26s/it]   8%|‚ñä         | 156/1848 [4:07:16<54:52:46, 116.76s/it]  8%|‚ñä         | 157/1848 [4:07:41<41:58:13, 89.35s/it]   9%|‚ñä         | 158/1848 [4:08:06<32:54:36, 70.10s/it]  9%|‚ñä         | 159/1848 [4:08:31<26:33:22, 56.60s/it]  9%|‚ñä         | 160/1848 [4:11:46<45:59:00, 98.07s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_10/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_10/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_10/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_10/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_10/self_attn.q_proj/compressed.log
best_loss 195.47067260742188 running bpv: 2.027194
COMMANDS_FINISHED 154 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_10/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_10/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_10/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_13/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_13/mlp.down_proj/compressed.log
best_loss 13.02698802947998 running bpv: 2.026651
COMMANDS_FINISHED 155 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_10/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_10/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_10/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_10/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_10/mlp.gate_proj/compressed.log
best_loss 149.52195739746094 running bpv: 2.026119
COMMANDS_FINISHED 156 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_10/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_10/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_10/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_10/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_10/mlp.up_proj/compressed.log
best_loss 129.8904571533203 running bpv: 2.025597
COMMANDS_FINISHED 157 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_10/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_10/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_10/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_10/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_10/self_attn.k_proj/compressed.log
best_loss 207.0264129638672 running bpv: 2.02599
COMMANDS_FINISHED 158 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_19/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_19/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_19/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_10/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_10/self_attn.o_proj/compressed.log
best_loss 5.252163410186768 running bpv: 2.026381
COMMANDS_FINISHED 159 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_19/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_19/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_19/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_10/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_10/self_attn.v_proj/compressed.log
best_loss 63.85990905761719 running bpv: 2.026768
COMMANDS_FINISHED 160 n_commands 1848
  9%|‚ñä         | 161/1848 [4:15:51<66:35:41, 142.11s/it]  9%|‚ñâ         | 162/1848 [4:16:26<51:31:04, 110.00s/it]  9%|‚ñâ         | 163/1848 [4:17:11<42:21:55, 90.51s/it]   9%|‚ñâ         | 164/1848 [4:17:36<33:09:02, 70.87s/it]  9%|‚ñâ         | 165/1848 [4:20:01<43:31:38, 93.11s/it]  9%|‚ñâ         | 166/1848 [4:20:26<33:57:28, 72.68s/it]  9%|‚ñâ         | 167/1848 [4:21:41<34:15:51, 73.38s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_19/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_19/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_19/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_19/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_19/self_attn.q_proj/compressed.log
best_loss 266.3195495605469 running bpv: 2.027153
COMMANDS_FINISHED 161 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_19/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_19/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_19/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_10/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_10/mlp.down_proj/compressed.log
best_loss 8.086536407470703 running bpv: 2.026634
COMMANDS_FINISHED 162 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_19/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_19/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_19/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_19/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_19/mlp.gate_proj/compressed.log
best_loss 357.5982666015625 running bpv: 2.026124
COMMANDS_FINISHED 163 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_19/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_19/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_19/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_19/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_19/mlp.up_proj/compressed.log
best_loss 315.22418212890625 running bpv: 2.025625
COMMANDS_FINISHED 164 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_19/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_19/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_19/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_19/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_19/self_attn.k_proj/compressed.log
best_loss 276.23077392578125 running bpv: 2.026001
COMMANDS_FINISHED 165 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_6/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_6/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_6/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_19/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_19/self_attn.o_proj/compressed.log
best_loss 9.458218574523926 running bpv: 2.026375
COMMANDS_FINISHED 166 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_6/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_6/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_6/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_19/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_19/self_attn.v_proj/compressed.log
best_loss 153.26165771484375 running bpv: 2.026746
COMMANDS_FINISHED 167 n_commands 1848
  9%|‚ñâ         | 168/1848 [4:25:46<58:16:18, 124.87s/it]  9%|‚ñâ         | 169/1848 [4:26:21<45:39:52, 97.91s/it]   9%|‚ñâ         | 170/1848 [4:29:07<55:01:14, 118.04s/it]  9%|‚ñâ         | 171/1848 [4:29:32<41:59:11, 90.13s/it]   9%|‚ñâ         | 172/1848 [4:29:47<31:28:08, 67.59s/it]  9%|‚ñâ         | 173/1848 [4:30:22<26:54:06, 57.82s/it]  9%|‚ñâ         | 174/1848 [4:33:37<46:01:32, 98.98s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_6/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_6/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_6/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_6/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_6/self_attn.q_proj/compressed.log
best_loss 165.67279052734375 running bpv: 2.027115
COMMANDS_FINISHED 168 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_6/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_6/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_6/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_19/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_19/mlp.down_proj/compressed.log
best_loss 36.19470977783203 running bpv: 2.026618
COMMANDS_FINISHED 169 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_6/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_6/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_6/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_6/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_6/mlp.gate_proj/compressed.log
best_loss 114.94694519042969 running bpv: 2.02613
COMMANDS_FINISHED 170 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_6/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_6/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_6/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_6/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_6/mlp.up_proj/compressed.log
best_loss 87.588623046875 running bpv: 2.025651
COMMANDS_FINISHED 171 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_6/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_6/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_6/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_6/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_6/self_attn.k_proj/compressed.log
best_loss 171.9468994140625 running bpv: 2.026012
COMMANDS_FINISHED 172 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_11/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_11/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_11/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_6/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_6/self_attn.o_proj/compressed.log
best_loss 1.154327630996704 running bpv: 2.02637
COMMANDS_FINISHED 173 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_11/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_11/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_11/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_6/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_6/self_attn.v_proj/compressed.log
best_loss 49.907772064208984 running bpv: 2.026726
COMMANDS_FINISHED 174 n_commands 1848
  9%|‚ñâ         | 175/1848 [4:37:42<66:21:31, 142.79s/it] 10%|‚ñâ         | 176/1848 [4:38:17<51:18:03, 110.46s/it] 10%|‚ñâ         | 177/1848 [4:38:52<40:45:50, 87.82s/it]  10%|‚ñâ         | 178/1848 [4:39:27<33:23:22, 71.98s/it] 10%|‚ñâ         | 179/1848 [4:41:42<42:08:12, 90.89s/it] 10%|‚ñâ         | 180/1848 [4:42:17<34:20:38, 74.12s/it] 10%|‚ñâ         | 181/1848 [4:43:32<34:26:47, 74.39s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_11/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_11/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_11/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_11/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_11/self_attn.q_proj/compressed.log
best_loss 217.6738739013672 running bpv: 2.02708
COMMANDS_FINISHED 175 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_11/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_11/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_11/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_6/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_6/mlp.down_proj/compressed.log
best_loss 3.5142288208007812 running bpv: 2.026603
COMMANDS_FINISHED 176 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_11/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_11/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_11/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_11/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_11/mlp.gate_proj/compressed.log
best_loss 160.3902130126953 running bpv: 2.026134
COMMANDS_FINISHED 177 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_11/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_11/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_11/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_11/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_11/mlp.up_proj/compressed.log
best_loss 142.68096923828125 running bpv: 2.025674
COMMANDS_FINISHED 178 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_11/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_11/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_11/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_11/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_11/self_attn.k_proj/compressed.log
best_loss 216.48794555664062 running bpv: 2.026021
COMMANDS_FINISHED 179 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_20/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_20/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_20/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_11/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_11/self_attn.o_proj/compressed.log
best_loss 5.58598518371582 running bpv: 2.026365
COMMANDS_FINISHED 180 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_20/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_20/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_20/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_11/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_11/self_attn.v_proj/compressed.log
best_loss 86.1187744140625 running bpv: 2.026708
COMMANDS_FINISHED 181 n_commands 1848
 10%|‚ñâ         | 182/1848 [4:47:37<58:06:55, 125.58s/it] 10%|‚ñâ         | 183/1848 [4:48:02<44:07:33, 95.41s/it]  10%|‚ñâ         | 184/1848 [4:50:47<53:45:08, 116.29s/it] 10%|‚ñà         | 185/1848 [4:51:22<42:27:19, 91.91s/it]  10%|‚ñà         | 186/1848 [4:51:47<33:09:51, 71.84s/it] 10%|‚ñà         | 187/1848 [4:52:02<25:16:41, 54.79s/it] 10%|‚ñà         | 188/1848 [4:55:27<46:02:44, 99.86s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_20/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_20/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_20/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_20/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_20/self_attn.q_proj/compressed.log
best_loss 274.7257080078125 running bpv: 2.027048
COMMANDS_FINISHED 182 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_20/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_20/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_20/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_11/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_11/mlp.down_proj/compressed.log
best_loss 9.14950180053711 running bpv: 2.02659
COMMANDS_FINISHED 183 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_20/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_20/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_20/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_20/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_20/mlp.gate_proj/compressed.log
best_loss 388.1263732910156 running bpv: 2.026139
COMMANDS_FINISHED 184 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_20/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_20/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_20/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_20/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_20/mlp.up_proj/compressed.log
best_loss 338.1041564941406 running bpv: 2.025696
COMMANDS_FINISHED 185 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_20/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_20/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_20/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_20/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_20/self_attn.k_proj/compressed.log
best_loss 284.7218322753906 running bpv: 2.026029
COMMANDS_FINISHED 186 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_23/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_23/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_23/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_20/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_20/self_attn.o_proj/compressed.log
best_loss 11.746471405029297 running bpv: 2.026361
COMMANDS_FINISHED 187 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_23/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_23/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_23/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_20/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_20/self_attn.v_proj/compressed.log
best_loss 160.30670166015625 running bpv: 2.026691
COMMANDS_FINISHED 188 n_commands 1848
 10%|‚ñà         | 189/1848 [4:59:32<66:05:15, 143.41s/it] 10%|‚ñà         | 190/1848 [4:59:57<49:41:19, 107.89s/it] 10%|‚ñà         | 191/1848 [5:00:52<42:21:24, 92.02s/it]  10%|‚ñà         | 192/1848 [5:01:07<31:42:09, 68.92s/it] 10%|‚ñà         | 193/1848 [5:03:32<42:10:42, 91.75s/it] 10%|‚ñà         | 194/1848 [5:04:07<34:19:55, 74.73s/it] 11%|‚ñà         | 195/1848 [5:05:12<32:58:23, 71.81s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_23/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_23/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_23/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_23/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_23/self_attn.q_proj/compressed.log
best_loss 348.5025634765625 running bpv: 2.027018
COMMANDS_FINISHED 189 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_23/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_23/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_23/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_20/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_20/mlp.down_proj/compressed.log
best_loss 43.25493621826172 running bpv: 2.026577
COMMANDS_FINISHED 190 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_23/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_23/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_23/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_23/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_23/mlp.gate_proj/compressed.log
best_loss 474.6742248535156 running bpv: 2.026143
COMMANDS_FINISHED 191 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_23/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_23/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_23/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_23/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_23/mlp.up_proj/compressed.log
best_loss 405.1858825683594 running bpv: 2.025716
COMMANDS_FINISHED 192 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_23/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_23/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_23/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_23/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_23/self_attn.k_proj/compressed.log
best_loss 354.11468505859375 running bpv: 2.026038
COMMANDS_FINISHED 193 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_17/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_17/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_17/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_23/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_23/self_attn.o_proj/compressed.log
best_loss 12.472940444946289 running bpv: 2.026357
COMMANDS_FINISHED 194 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_17/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_17/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_17/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_23/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_23/self_attn.v_proj/compressed.log
best_loss 244.48483276367188 running bpv: 2.026675
COMMANDS_FINISHED 195 n_commands 1848
 11%|‚ñà         | 196/1848 [5:09:17<56:47:56, 123.77s/it] 11%|‚ñà         | 197/1848 [5:10:02<45:55:39, 100.15s/it] 11%|‚ñà         | 198/1848 [5:12:37<53:26:42, 116.61s/it] 11%|‚ñà         | 199/1848 [5:13:12<42:11:58, 92.13s/it]  11%|‚ñà         | 200/1848 [5:13:27<31:34:56, 68.99s/it] 11%|‚ñà         | 201/1848 [5:14:02<26:53:56, 58.80s/it] 11%|‚ñà         | 202/1848 [5:17:17<45:34:06, 99.66s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_17/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_17/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_17/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_17/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_17/self_attn.q_proj/compressed.log
best_loss 255.7299346923828 running bpv: 2.026991
COMMANDS_FINISHED 196 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_17/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_17/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_17/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_23/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_23/mlp.down_proj/compressed.log
best_loss 53.718997955322266 running bpv: 2.026565
COMMANDS_FINISHED 197 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_17/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_17/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_17/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_17/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_17/mlp.gate_proj/compressed.log
best_loss 289.1304626464844 running bpv: 2.026147
COMMANDS_FINISHED 198 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_17/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_17/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_17/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_17/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_17/mlp.up_proj/compressed.log
best_loss 263.0362243652344 running bpv: 2.025735
COMMANDS_FINISHED 199 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_17/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_17/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_17/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_17/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_17/self_attn.k_proj/compressed.log
best_loss 266.5591735839844 running bpv: 2.026045
COMMANDS_FINISHED 200 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_9/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_9/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_9/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_17/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_17/self_attn.o_proj/compressed.log
best_loss 9.036933898925781 running bpv: 2.026353
COMMANDS_FINISHED 201 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_9/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_9/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_9/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_17/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_17/self_attn.v_proj/compressed.log
best_loss 122.44451904296875 running bpv: 2.02666
COMMANDS_FINISHED 202 n_commands 1848
 11%|‚ñà         | 203/1848 [5:21:22<65:28:03, 143.27s/it] 11%|‚ñà         | 204/1848 [5:21:47<49:13:31, 107.79s/it] 11%|‚ñà         | 205/1848 [5:22:32<40:35:57, 88.96s/it]  11%|‚ñà         | 206/1848 [5:23:07<33:11:32, 72.77s/it] 11%|‚ñà         | 207/1848 [5:25:22<41:41:02, 91.45s/it] 11%|‚ñà‚ñè        | 208/1848 [5:25:57<33:56:43, 74.51s/it] 11%|‚ñà‚ñè        | 209/1848 [5:27:12<33:59:32, 74.66s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_9/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_9/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_9/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_9/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_9/self_attn.q_proj/compressed.log
best_loss 190.3146514892578 running bpv: 2.026965
COMMANDS_FINISHED 203 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_9/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_9/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_9/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_17/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_17/mlp.down_proj/compressed.log
best_loss 27.94457244873047 running bpv: 2.026555
COMMANDS_FINISHED 204 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_9/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_9/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_9/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_9/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_9/mlp.gate_proj/compressed.log
best_loss 143.9170684814453 running bpv: 2.02615
COMMANDS_FINISHED 205 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_9/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_9/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_9/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_9/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_9/mlp.up_proj/compressed.log
best_loss 121.46317291259766 running bpv: 2.025752
COMMANDS_FINISHED 206 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_9/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_9/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_9/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_9/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_9/self_attn.k_proj/compressed.log
best_loss 198.79495239257812 running bpv: 2.026052
COMMANDS_FINISHED 207 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_22/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_22/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_22/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_9/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_9/self_attn.o_proj/compressed.log
best_loss 3.6543221473693848 running bpv: 2.02635
COMMANDS_FINISHED 208 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_22/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_22/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_22/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_9/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_9/self_attn.v_proj/compressed.log
best_loss 63.07299041748047 running bpv: 2.026646
COMMANDS_FINISHED 209 n_commands 1848
 11%|‚ñà‚ñè        | 210/1848 [5:31:07<55:51:41, 122.77s/it] 11%|‚ñà‚ñè        | 211/1848 [5:31:32<42:29:25, 93.44s/it]  11%|‚ñà‚ñè        | 212/1848 [5:34:27<53:35:10, 117.92s/it] 12%|‚ñà‚ñè        | 213/1848 [5:35:02<42:15:25, 93.04s/it]  12%|‚ñà‚ñè        | 214/1848 [5:35:17<31:36:18, 69.63s/it] 12%|‚ñà‚ñè        | 215/1848 [5:35:32<24:09:08, 53.24s/it] 12%|‚ñà‚ñè        | 216/1848 [5:39:07<46:08:19, 101.78s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_22/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_22/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_22/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_22/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_22/self_attn.q_proj/compressed.log
best_loss 314.695068359375 running bpv: 2.026941
COMMANDS_FINISHED 210 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_22/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_22/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_22/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_9/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_9/mlp.down_proj/compressed.log
best_loss 6.917778968811035 running bpv: 2.026544
COMMANDS_FINISHED 211 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_22/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_22/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_22/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_22/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_22/mlp.gate_proj/compressed.log
best_loss 448.93505859375 running bpv: 2.026154
COMMANDS_FINISHED 212 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_22/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_22/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_22/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_22/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_22/mlp.up_proj/compressed.log
best_loss 378.89068603515625 running bpv: 2.025769
COMMANDS_FINISHED 213 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_22/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_22/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_22/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_22/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_22/self_attn.k_proj/compressed.log
best_loss 323.0196533203125 running bpv: 2.026058
COMMANDS_FINISHED 214 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_24/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_24/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_24/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_22/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_22/self_attn.o_proj/compressed.log
best_loss 13.044971466064453 running bpv: 2.026347
COMMANDS_FINISHED 215 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_24/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_24/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_24/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_22/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_22/self_attn.v_proj/compressed.log
best_loss 198.09634399414062 running bpv: 2.026634
COMMANDS_FINISHED 216 n_commands 1848
 12%|‚ñà‚ñè        | 217/1848 [5:43:12<65:34:47, 144.75s/it] 12%|‚ñà‚ñè        | 218/1848 [5:43:37<49:16:28, 108.83s/it] 12%|‚ñà‚ñè        | 219/1848 [5:44:22<40:34:50, 89.68s/it]  12%|‚ñà‚ñè        | 220/1848 [5:44:37<30:25:29, 67.28s/it] 12%|‚ñà‚ñè        | 221/1848 [5:47:12<42:18:07, 93.60s/it] 12%|‚ñà‚ñè        | 222/1848 [5:47:37<32:58:54, 73.02s/it] 12%|‚ñà‚ñè        | 223/1848 [5:48:42<31:52:34, 70.62s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_24/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_24/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_24/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_24/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_24/self_attn.q_proj/compressed.log
best_loss 317.51837158203125 running bpv: 2.026919
COMMANDS_FINISHED 217 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_24/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_24/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_24/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_22/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_22/mlp.down_proj/compressed.log
best_loss 51.02394485473633 running bpv: 2.026535
COMMANDS_FINISHED 218 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_24/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_24/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_24/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_24/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_24/mlp.gate_proj/compressed.log
best_loss 500.1645812988281 running bpv: 2.026157
COMMANDS_FINISHED 219 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_24/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_24/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_24/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_24/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_24/mlp.up_proj/compressed.log
best_loss 428.15509033203125 running bpv: 2.025784
COMMANDS_FINISHED 220 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/pajama/128/layer_24/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_24/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_24/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_24/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_24/self_attn.k_proj/compressed.log
best_loss 320.605712890625 running bpv: 2.026065
COMMANDS_FINISHED 221 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_3/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_3/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_3/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_24/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_24/self_attn.o_proj/compressed.log
best_loss 14.730501174926758 running bpv: 2.026344
COMMANDS_FINISHED 222 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_3/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_3/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_3/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_24/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_24/self_attn.v_proj/compressed.log
best_loss 231.13780212402344 running bpv: 2.026621
COMMANDS_FINISHED 223 n_commands 1848
 12%|‚ñà‚ñè        | 224/1848 [5:53:27<60:52:24, 134.94s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_3/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_3/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_3/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf
meta-llama/Llama-2-7b-hf/layer_24/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_24/mlp.down_proj/compressed.log
best_loss 57.166744232177734 running bpv: 2.026251
COMMANDS_FINISHED 224 n_commands 1848
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_3/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_3/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_3/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf
done with meta-llama/Llama-2-7b-hf
done with {'meta-llama/Llama-2-7b-hf/layer_3/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_3/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_3/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_3/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_3/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_3/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_3/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_3/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_3/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_3/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_3/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_3/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_3/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_3/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_5/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_5/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_5/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_5/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_5/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_5/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_5/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_5/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_5/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_5/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_5/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_5/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_8/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_8/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_5/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_5/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_8/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_8/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_8/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_8/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_8/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_8/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_8/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_8/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_8/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_8/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_8/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_8/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_12/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_12/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_12/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_12/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_12/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_12/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_12/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_12/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_12/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_12/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_12/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_12/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_1/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_1/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_12/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_12/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_1/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_1/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_1/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_1/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_1/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_1/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_1/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_1/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_1/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_1/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_7/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_7/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_1/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_1/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_7/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_7/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_7/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_7/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_7/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_7/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_7/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_7/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_7/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_7/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_0/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_0/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_7/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_7/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_0/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_0/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_0/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_0/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_0/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_0/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_0/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_0/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_0/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_0/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_31/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_31/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_0/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_0/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_31/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_31/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_31/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_31/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_31/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_31/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_31/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_31/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_31/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_31/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_21/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_21/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_31/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_31/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_21/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_21/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_21/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_21/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_21/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_21/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_21/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_21/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_21/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_21/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_26/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_26/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_21/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_21/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_26/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_26/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_26/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_26/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_26/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_26/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_26/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_26/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_26/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_26/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_14/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_14/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_26/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_26/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_14/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_14/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_14/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_14/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_14/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_14/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_14/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_14/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_14/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_14/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_14/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_14/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_15/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_15/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_15/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_15/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_15/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_15/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_15/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_15/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_15/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_15/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_15/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_15/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_4/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_4/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_15/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_15/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_4/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_4/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_4/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_4/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_4/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_4/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_4/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_4/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_4/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_4/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_27/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_27/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_4/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_4/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_27/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_27/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_27/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_27/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_27/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_27/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_27/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_27/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_27/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_27/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_2/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_2/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_27/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_27/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_2/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_2/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_2/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_2/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_2/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_2/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_2/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_2/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_2/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_2/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_28/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_28/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_2/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_2/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_28/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_28/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_28/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_28/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_28/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_28/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_28/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_28/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_28/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_28/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_18/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_18/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_28/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_28/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_18/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_18/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_18/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_18/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_18/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_18/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_18/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_18/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_18/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_18/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_25/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_25/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_18/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_18/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_25/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_25/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_25/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_25/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_25/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_25/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_25/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_25/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_25/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_25/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_30/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_30/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_25/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_25/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_30/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_30/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_30/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_30/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_30/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_30/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_30/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_30/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_30/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_30/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_29/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_29/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_30/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_30/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_29/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_29/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_29/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_29/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_29/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_29/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_29/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_29/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_29/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_29/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_16/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_16/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_29/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_29/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_16/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_16/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_16/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_16/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_16/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_16/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_16/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_16/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_16/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_16/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_16/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_16/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_13/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_13/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_13/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_13/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_13/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_13/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_13/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_13/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_13/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_13/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_13/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_13/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_10/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_10/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_13/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_13/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_10/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_10/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_10/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_10/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_10/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_10/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_10/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_10/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_10/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_10/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_19/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_19/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_10/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_10/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_19/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_19/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_19/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_19/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_19/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_19/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_19/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_19/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_19/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_19/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_6/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_6/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_19/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_19/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_6/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_6/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_6/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_6/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_6/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_6/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_6/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_6/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_6/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_6/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_11/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_11/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_6/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_6/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_11/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_11/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_11/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_11/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_11/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_11/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_11/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_11/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_11/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_11/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_20/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_20/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_11/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_11/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_20/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_20/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_20/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_20/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_20/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_20/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_20/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_20/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_20/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_20/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_23/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_23/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_20/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_20/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_23/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_23/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_23/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_23/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_23/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_23/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_23/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_23/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_23/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_23/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_17/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_17/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_23/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_23/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_17/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_17/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_17/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_17/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_17/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_17/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_17/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_17/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_17/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_17/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_9/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_9/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_17/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_17/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_9/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_9/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_9/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_9/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_9/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_9/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_9/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_9/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_9/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_9/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_22/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_22/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_9/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_9/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_22/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_22/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_22/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_22/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_22/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_22/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_22/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_22/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_22/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_22/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_24/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_24/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_22/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_22/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_24/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_24/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_24/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_24/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_24/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_24/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_24/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_24/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_24/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_24/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_24/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-7b-hf/layer_24/mlp.down_proj/compressed.pt'} 12%|‚ñà‚ñè        | 225/1848 [5:54:22<50:01:44, 110.97s/it] 12%|‚ñà‚ñè        | 226/1848 [5:59:07<73:31:28, 163.19s/it] 12%|‚ñà‚ñè        | 227/1848 [6:00:52<65:37:15, 145.73s/it] 12%|‚ñà‚ñè        | 228/1848 [6:01:17<49:16:56, 109.52s/it] 12%|‚ñà‚ñè        | 229/1848 [6:04:47<62:48:45, 139.67s/it] 12%|‚ñà‚ñè        | 230/1848 [6:07:02<62:08:46, 138.27s/it]
/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/checkpoints.yaml
perplexity_inference_command:
 python -u perplexity_eval.py --base_model meta-llama/Llama-2-7b-hf --seqlen 4096 --checkpoint_list_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/checkpoints.yaml --log_wandb --wandb_project compression_no_finetune --wandb_id tdxolj32
meta-llama/Llama-2-13b-hf/layer_3/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_3/self_attn.q_proj/compressed.log
best_loss 48.861473083496094 running bpv: 2.026311
COMMANDS_FINISHED 225 n_commands 1849
running: nohup python -u perplexity_eval.py --base_model meta-llama/Llama-2-7b-hf --seqlen 4096 --checkpoint_list_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/checkpoints.yaml --log_wandb --wandb_project compression_no_finetune --wandb_id tdxolj32 --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/legendary-aardvark-58/ppl_eval.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_3/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_3/self_attn.k_proj/compressed.log
best_loss 54.80079650878906 running bpv: 2.026371
COMMANDS_FINISHED 226 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_3/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_3/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_3/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_3/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_3/mlp.gate_proj/compressed.log
best_loss 57.42009735107422 running bpv: 2.025429
COMMANDS_FINISHED 227 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_3/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_3/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_3/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_3/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_3/mlp.up_proj/compressed.log
best_loss 48.767024993896484 running bpv: 2.024507
COMMANDS_FINISHED 228 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_3/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_3/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_3/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
eval is done
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_5/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_5/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_5/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_3/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_3/self_attn.o_proj/compressed.log
best_loss 0.4057503342628479 running bpv: 2.024573
COMMANDS_FINISHED 230 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_5/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_5/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_5/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_3/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_3/self_attn.v_proj/compressed.log
best_loss 15.999958038330078 running bpv: 2.024638
COMMANDS_FINISHED 231 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_5/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_5/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_5/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
 12%|‚ñà‚ñé        | 231/1848 [6:12:47<89:58:09, 200.30s/it] 13%|‚ñà‚ñé        | 232/1848 [6:14:42<78:25:41, 174.72s/it] 13%|‚ñà‚ñé        | 233/1848 [6:15:17<59:34:37, 132.80s/it] 13%|‚ñà‚ñé        | 234/1848 [6:18:32<67:54:31, 151.47s/it] 13%|‚ñà‚ñé        | 236/1848 [6:20:22<47:53:21, 106.95s/it]meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_5/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_5/self_attn.q_proj/compressed.log
best_loss 119.68915557861328 running bpv: 2.024702
COMMANDS_FINISHED 232 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_5/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_5/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_5/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_3/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_3/mlp.down_proj/compressed.log
best_loss 1.3841089010238647 running bpv: 2.023808
COMMANDS_FINISHED 233 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_5/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_5/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_5/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_5/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_5/mlp.gate_proj/compressed.log
best_loss 105.07110595703125 running bpv: 2.022932
COMMANDS_FINISHED 234 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_5/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_5/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_5/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_5/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_5/mlp.up_proj/compressed.log
best_loss 86.55846405029297 running bpv: 2.022074
COMMANDS_FINISHED 235 n_commands 1849
meta-llama/Llama-2-13b-hf/layer_5/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_5/self_attn.k_proj/compressed.log
best_loss 117.03496551513672 running bpv: 2.022146
COMMANDS_FINISHED 236 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_5/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_5/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_5/self_attn.v_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_8/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_8/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_8/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_5/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_5/self_attn.o_proj/compressed.log
best_loss 1.0951240062713623 running bpv: 2.022217
COMMANDS_FINISHED 237 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_8/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_8/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_8/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_5/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_5/self_attn.v_proj/compressed.log
best_loss  13%|‚ñà‚ñé        | 237/1848 [6:24:07<60:57:35, 136.22s/it] 13%|‚ñà‚ñé        | 238/1848 [6:29:02<79:29:50, 177.76s/it] 13%|‚ñà‚ñé        | 239/1848 [6:29:47<63:18:32, 141.65s/it] 13%|‚ñà‚ñé        | 240/1848 [6:32:22<64:56:25, 145.39s/it] 13%|‚ñà‚ñé        | 241/1848 [6:34:07<59:45:09, 133.86s/it] 13%|‚ñà‚ñé        | 242/1848 [6:34:42<46:56:13, 105.21s/it] 13%|‚ñà‚ñé        | 243/1848 [6:35:27<39:02:58, 87.59s/it] 44.4066047668457 running bpv: 2.022288
COMMANDS_FINISHED 238 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_8/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_8/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_8/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_5/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_5/mlp.down_proj/compressed.log
best_loss 3.613011360168457 running bpv: 2.021455
COMMANDS_FINISHED 239 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_8/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_8/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_8/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_8/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_8/self_attn.q_proj/compressed.log
best_loss 182.3715057373047 running bpv: 2.021527
COMMANDS_FINISHED 240 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_8/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_8/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_8/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_8/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_8/mlp.gate_proj/compressed.log
best_loss 173.90174865722656 running bpv: 2.020712
COMMANDS_FINISHED 241 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_8/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_8/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_8/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_8/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_8/mlp.up_proj/compressed.log
best_loss 142.32217407226562 running bpv: 2.019913
COMMANDS_FINISHED 242 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_8/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_8/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_8/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_8/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_8/self_attn.k_proj/compressed.log
best_loss 187.6349334716797 running bpv: 2.01999
COMMANDS_FINISHED 243 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_39/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_39/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_39/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_8/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_8/self_attn.o_proj/compressed.log
best_loss 3.8386127948760986 running bpv: 2.020066
COMMANDS_FINISHED 244 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_39/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_39/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_39/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
 13%|‚ñà‚ñé        | 244/1848 [6:39:53<62:20:24, 139.92s/it] 13%|‚ñà‚ñé        | 245/1848 [6:45:38<89:22:28, 200.72s/it] 13%|‚ñà‚ñé        | 246/1848 [6:46:13<67:22:57, 151.42s/it] 13%|‚ñà‚ñé        | 247/1848 [6:48:18<63:50:17, 143.55s/it] 13%|‚ñà‚ñé        | 248/1848 [6:49:13<52:02:31, 117.09s/it] 13%|‚ñà‚ñé        | 249/1848 [6:51:18<53:03:42, 119.46s/it] 14%|‚ñà‚ñé        | 250/1848 [6:52:03<43:08:01, 97.17s/it] meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_8/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_8/self_attn.v_proj/compressed.log
best_loss 74.8665771484375 running bpv: 2.020141
COMMANDS_FINISHED 245 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_39/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_39/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_39/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_39/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_39/self_attn.q_proj/compressed.log
best_loss 265.29888916015625 running bpv: 2.020216
COMMANDS_FINISHED 246 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_39/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_39/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_39/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_8/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_8/mlp.down_proj/compressed.log
best_loss 9.203112602233887 running bpv: 2.019441
COMMANDS_FINISHED 247 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_39/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_39/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_39/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_39/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_39/mlp.gate_proj/compressed.log
best_loss 697.420654296875 running bpv: 2.01868
COMMANDS_FINISHED 248 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_39/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_39/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_39/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_39/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_39/mlp.up_proj/compressed.log
best_loss 592.5654296875 running bpv: 2.017933
COMMANDS_FINISHED 249 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_39/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_39/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_39/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_39/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_39/self_attn.k_proj/compressed.log
best_loss 271.1474304199219 running bpv: 2.018013
COMMANDS_FINISHED 250 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_12/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_12/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_12/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_39/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_39/self_attn.o_proj/compressed.log
best_loss 72.7171401977539 running bpv: 2.018093
COMMANDS_FINISHED 251 n_commands 1849
 14%|‚ñà‚ñé        | 251/1848 [6:54:58<53:27:06, 120.49s/it] 14%|‚ñà‚ñé        | 252/1848 [7:00:43<83:15:07, 187.79s/it] 14%|‚ñà‚ñé        | 253/1848 [7:02:08<69:32:55, 156.98s/it] 14%|‚ñà‚ñé        | 254/1848 [7:05:03<71:54:02, 162.39s/it] 14%|‚ñà‚ñç        | 255/1848 [7:05:48<56:16:44, 127.18s/it] 14%|‚ñà‚ñç        | 256/1848 [7:06:23<44:01:04, 99.54s/it] running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_12/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_12/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_12/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_39/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_39/self_attn.v_proj/compressed.log
best_loss 286.815673828125 running bpv: 2.018172
COMMANDS_FINISHED 252 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_12/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_12/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_12/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_12/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_12/self_attn.q_proj/compressed.log
best_loss 238.7185516357422 running bpv: 2.018251
COMMANDS_FINISHED 253 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_12/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_12/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_12/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_39/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_39/mlp.down_proj/compressed.log
best_loss 272.23046875 running bpv: 2.017525
COMMANDS_FINISHED 254 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_12/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_12/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_12/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_12/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_12/mlp.gate_proj/compressed.log
best_loss 206.50668334960938 running bpv: 2.016812
COMMANDS_FINISHED 255 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_12/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_12/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_12/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_12/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_12/mlp.up_proj/compressed.log
best_loss 193.4150390625 running bpv: 2.016112
COMMANDS_FINISHED 256 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_12/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_12/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_12/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_12/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_12/self_attn.k_proj/compressed.log
best_loss 246.3864288330078 running bpv: 2.016195
COMMANDS_FINISHED 257 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_1/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_1/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_1/mlp.gate_proj/compressed.log 2>&1 &
 14%|‚ñà‚ñç        | 257/1848 [7:07:48<42:03:52, 95.18s/it] 14%|‚ñà‚ñç        | 258/1848 [7:11:33<59:14:23, 134.13s/it] 14%|‚ñà‚ñç        | 259/1848 [7:17:18<87:07:37, 197.39s/it] 14%|‚ñà‚ñç        | 260/1848 [7:18:53<73:31:28, 166.68s/it] 14%|‚ñà‚ñç        | 261/1848 [7:19:58<60:01:57, 136.18s/it] 14%|‚ñà‚ñç        | 262/1848 [7:21:23<53:13:57, 120.83s/it] 14%|‚ñà‚ñç        | 263/1848 [7:22:58<49:47:19, 113.09s/it]meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_12/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_12/self_attn.o_proj/compressed.log
best_loss 10.320697784423828 running bpv: 2.016277
COMMANDS_FINISHED 258 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_1/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_1/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_1/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_12/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_12/self_attn.v_proj/compressed.log
best_loss 105.80294799804688 running bpv: 2.016359
COMMANDS_FINISHED 259 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_1/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_1/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_1/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_1/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_1/self_attn.q_proj/compressed.log
best_loss 4.170092582702637 running bpv: 2.01644
COMMANDS_FINISHED 260 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_1/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_1/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_1/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_12/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_12/mlp.down_proj/compressed.log
best_loss 16.050189971923828 running bpv: 2.015759
COMMANDS_FINISHED 261 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_1/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_1/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_1/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_1/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_1/mlp.gate_proj/compressed.log
best_loss 12.877880096435547 running bpv: 2.015089
COMMANDS_FINISHED 262 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_1/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_1/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_1/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_1/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_1/mlp.up_proj/compressed.log
best_loss 11.49549388885498 running bpv: 2.014431
COMMANDS_FINISHED 263 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_1/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_1/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_1/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_1/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_1/self_attn.k_proj/compressed.log
best_loss 4.286160469055176 running bpv: 2.014516
 14%|‚ñà‚ñç        | 264/1848 [7:24:43<48:41:29, 110.66s/it] 14%|‚ñà‚ñç        | 265/1848 [7:27:08<53:11:33, 120.97s/it] 14%|‚ñà‚ñç        | 266/1848 [7:32:53<82:41:51, 188.19s/it] 14%|‚ñà‚ñç        | 267/1848 [7:33:48<65:05:56, 148.23s/it] 15%|‚ñà‚ñç        | 268/1848 [7:36:43<68:35:03, 156.27s/it] 15%|‚ñà‚ñç        | 269/1848 [7:38:28<61:47:46, 140.89s/it]COMMANDS_FINISHED 264 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_7/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_7/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_7/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_1/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_1/self_attn.o_proj/compressed.log
best_loss 0.07972849905490875 running bpv: 2.0146
COMMANDS_FINISHED 265 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_7/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_7/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_7/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_1/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_1/self_attn.v_proj/compressed.log
best_loss 1.262369155883789 running bpv: 2.014684
COMMANDS_FINISHED 266 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_7/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_7/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_7/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_7/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_7/self_attn.q_proj/compressed.log
best_loss 150.43072509765625 running bpv: 2.014768
COMMANDS_FINISHED 267 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_7/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_7/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_7/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_1/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_1/mlp.down_proj/compressed.log
best_loss 0.29549920558929443 running bpv: 2.014126
COMMANDS_FINISHED 268 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_7/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_7/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_7/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_7/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_7/mlp.gate_proj/compressed.log
best_loss 153.76321411132812 running bpv: 2.013495
COMMANDS_FINISHED 269 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_7/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_7/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_7/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_7/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_7/mlp.up_proj/compressed.log
best_loss 122.77017974853516 running bpv: 2.012874
COMMANDS_FINISHED 270 n_commands 1849
 15%|‚ñà‚ñç        | 270/1848 [7:38:43<45:12:11, 103.13s/it] 15%|‚ñà‚ñç        | 271/1848 [7:39:28<37:32:13, 85.69s/it]  15%|‚ñà‚ñç        | 272/1848 [7:44:13<63:41:33, 145.49s/it] 15%|‚ñà‚ñç        | 273/1848 [7:49:58<89:50:32, 205.35s/it] 15%|‚ñà‚ñç        | 274/1848 [7:50:33<67:26:29, 154.25s/it] 15%|‚ñà‚ñç        | 275/1848 [7:52:18<60:56:39, 139.48s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_7/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_7/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_7/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_7/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_7/self_attn.k_proj/compressed.log
best_loss 154.80728149414062 running bpv: 2.012961
COMMANDS_FINISHED 271 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_33/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_33/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_33/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_7/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_7/self_attn.o_proj/compressed.log
best_loss 2.8568930625915527 running bpv: 2.013047
COMMANDS_FINISHED 272 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_33/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_33/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_33/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_7/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_7/self_attn.v_proj/compressed.log
best_loss 58.30504608154297 running bpv: 2.013133
COMMANDS_FINISHED 273 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_33/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_33/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_33/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_33/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_33/self_attn.q_proj/compressed.log
best_loss 414.1087341308594 running bpv: 2.013218
COMMANDS_FINISHED 274 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_33/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_33/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_33/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_7/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_7/mlp.down_proj/compressed.log
best_loss 7.213529586791992 running bpv: 2.012612
COMMANDS_FINISHED 275 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_33/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_33/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_33/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_33/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_33/mlp.gate_proj/compressed.log
best_loss 743.0961303710938 running bpv: 2.012016
COMMANDS_FINISHED 276 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_33/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_33/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_33/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
 15%|‚ñà‚ñç        | 276/1848 [7:53:13<49:50:23, 114.14s/it] 15%|‚ñà‚ñç        | 277/1848 [7:55:48<55:09:35, 126.40s/it] 15%|‚ñà‚ñå        | 278/1848 [7:56:13<41:51:32, 95.98s/it]  15%|‚ñà‚ñå        | 279/1848 [7:58:58<50:51:31, 116.69s/it] 15%|‚ñà‚ñå        | 280/1848 [8:04:43<80:39:44, 185.19s/it] 15%|‚ñà‚ñå        | 281/1848 [8:05:58<66:13:22, 152.14s/it]meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_33/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_33/mlp.up_proj/compressed.log
best_loss 643.67626953125 running bpv: 2.011429
COMMANDS_FINISHED 277 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_33/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_33/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_33/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_33/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_33/self_attn.k_proj/compressed.log
best_loss 425.31488037109375 running bpv: 2.011517
COMMANDS_FINISHED 278 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_34/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_34/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_34/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_33/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_33/self_attn.o_proj/compressed.log
best_loss 18.875244140625 running bpv: 2.011605
COMMANDS_FINISHED 279 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_34/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_34/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_34/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_33/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_33/self_attn.v_proj/compressed.log
best_loss 352.1144104003906 running bpv: 2.011691
COMMANDS_FINISHED 280 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_34/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_34/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_34/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_34/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_34/self_attn.q_proj/compressed.log
best_loss 418.6864318847656 running bpv: 2.011778
COMMANDS_FINISHED 281 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_34/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_34/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_34/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_33/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_33/mlp.down_proj/compressed.log
best_loss 92.27983093261719 running bpv: 2.011204
COMMANDS_FINISHED 282 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_34/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_34/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_34/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_34/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_34/mlp.gate_proj/compressed.log
best_loss  15%|‚ñà‚ñå        | 282/1848 [8:09:33<74:23:12, 171.00s/it] 15%|‚ñà‚ñå        | 283/1848 [8:09:58<55:17:54, 127.20s/it] 15%|‚ñà‚ñå        | 284/1848 [8:10:23<41:56:35, 96.54s/it]  15%|‚ñà‚ñå        | 285/1848 [8:11:48<40:24:51, 93.08s/it] 15%|‚ñà‚ñå        | 286/1848 [8:15:43<58:51:49, 135.67s/it] 16%|‚ñà‚ñå        | 287/1848 [8:21:28<86:03:38, 198.47s/it] 16%|‚ñà‚ñå        | 288/1848 [8:23:23<75:09:20, 173.44s/it]766.689208984375 running bpv: 2.01064
COMMANDS_FINISHED 283 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_34/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_34/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_34/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_34/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_34/mlp.up_proj/compressed.log
best_loss 678.9559326171875 running bpv: 2.010084
COMMANDS_FINISHED 284 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_34/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_34/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_34/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_34/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_34/self_attn.k_proj/compressed.log
best_loss 427.63092041015625 running bpv: 2.010173
COMMANDS_FINISHED 285 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_0/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_0/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_0/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_34/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_34/self_attn.o_proj/compressed.log
best_loss 25.758193969726562 running bpv: 2.010261
COMMANDS_FINISHED 286 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_0/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_0/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_0/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_34/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_34/self_attn.v_proj/compressed.log
best_loss 386.7333984375 running bpv: 2.010349
COMMANDS_FINISHED 287 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_0/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_0/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_0/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_0/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_0/self_attn.q_proj/compressed.log
best_loss 0.1479349583387375 running bpv: 2.010436
COMMANDS_FINISHED 288 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_0/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_0/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_0/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_34/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_34/mlp.down_proj/compressed.log
best_loss 102.63274383544922 running bpv: 2.009892
COMMANDS_FINISHED 289 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_0/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_0/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_0/self_attn.o_proj/compressed.log 2>&1 &
 16%|‚ñà‚ñå        | 289/1848 [8:24:08<58:25:21, 134.91s/it] 16%|‚ñà‚ñå        | 290/1848 [8:25:23<50:36:29, 116.94s/it] 16%|‚ñà‚ñå        | 291/1848 [8:27:08<49:01:43, 113.36s/it] 16%|‚ñà‚ñå        | 292/1848 [8:29:13<50:30:29, 116.86s/it] 16%|‚ñà‚ñå        | 293/1848 [8:31:08<50:14:12, 116.30s/it] 16%|‚ñà‚ñå        | 294/1848 [8:36:53<79:49:27, 184.92s/it] 16%|‚ñà‚ñå        | 295/1848 [8:37:58<64:15:15, 148.95s/it]meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_0/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_0/mlp.gate_proj/compressed.log
best_loss 2.239938259124756 running bpv: 2.009357
COMMANDS_FINISHED 290 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_0/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_0/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_0/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_0/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_0/mlp.up_proj/compressed.log
best_loss 2.1311256885528564 running bpv: 2.008829
COMMANDS_FINISHED 291 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_0/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_0/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_0/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_0/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_0/self_attn.k_proj/compressed.log
best_loss 0.10173327475786209 running bpv: 2.008918
COMMANDS_FINISHED 292 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_32/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_32/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_32/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_0/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_0/self_attn.o_proj/compressed.log
best_loss 0.0029790690168738365 running bpv: 2.009007
COMMANDS_FINISHED 293 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_32/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_32/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_32/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_0/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_0/self_attn.v_proj/compressed.log
best_loss 0.021786104887723923 running bpv: 2.009095
COMMANDS_FINISHED 294 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_32/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_32/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_32/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_32/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_32/self_attn.q_proj/compressed.log
best_loss 451.50494384765625 running bpv: 2.009183
COMMANDS_FINISHED 295 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_32/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_32/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_32/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_0/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_0/mlp.down_proj/compressed.log
best_loss 0.03400375694036484 running bpv: 2.008666
COMMANDS_FINISHED 296 n_commands 1849
 16%|‚ñà‚ñå        | 296/1848 [8:40:53<67:35:05, 156.77s/it] 16%|‚ñà‚ñå        | 297/1848 [8:42:28<59:33:32, 138.24s/it] 16%|‚ñà‚ñå        | 298/1848 [8:43:03<46:11:09, 107.27s/it] 16%|‚ñà‚ñå        | 299/1848 [8:43:38<36:49:41, 85.59s/it]  16%|‚ñà‚ñå        | 300/1848 [8:48:13<61:14:31, 142.42s/it] 16%|‚ñà‚ñã        | 301/1848 [8:53:58<87:19:18, 203.21s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_32/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_32/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_32/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_32/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_32/mlp.gate_proj/compressed.log
best_loss 721.9760131835938 running bpv: 2.008157
COMMANDS_FINISHED 297 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_32/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_32/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_32/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_32/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_32/self_attn.k_proj/compressed.log
best_loss 456.7814636230469 running bpv: 2.008246
COMMANDS_FINISHED 298 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_32/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_32/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_32/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_32/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_32/mlp.up_proj/compressed.log
best_loss 618.7240600585938 running bpv: 2.007744
COMMANDS_FINISHED 299 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_31/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_31/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_31/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_32/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_32/self_attn.o_proj/compressed.log
best_loss 19.753475189208984 running bpv: 2.007833
COMMANDS_FINISHED 300 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_31/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_31/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_31/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_32/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_32/self_attn.v_proj/compressed.log
best_loss 394.68182373046875 running bpv: 2.007922
COMMANDS_FINISHED 301 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_31/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_31/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_31/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_31/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_31/self_attn.q_proj/compressed.log
best_loss 430.34014892578125 running bpv: 2.00801
COMMANDS_FINISHED 302 n_commands 1849
 16%|‚ñà‚ñã        | 302/1848 [8:54:43<66:53:03, 155.75s/it] 16%|‚ñà‚ñã        | 303/1848 [8:56:48<62:53:04, 146.53s/it] 16%|‚ñà‚ñã        | 304/1848 [8:57:13<47:12:29, 110.07s/it] 17%|‚ñà‚ñã        | 305/1848 [8:59:38<51:40:14, 120.55s/it] 17%|‚ñà‚ñã        | 306/1848 [9:00:33<43:12:52, 100.89s/it] 17%|‚ñà‚ñã        | 307/1848 [9:02:58<48:51:10, 114.13s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_31/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_31/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_31/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_32/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_32/mlp.down_proj/compressed.log
best_loss 87.34098815917969 running bpv: 2.007518
COMMANDS_FINISHED 303 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_31/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_31/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_31/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_31/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_31/mlp.gate_proj/compressed.log
best_loss 698.8650512695312 running bpv: 2.007033
COMMANDS_FINISHED 304 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_31/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_31/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_31/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_31/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_31/mlp.up_proj/compressed.log
best_loss 591.45751953125 running bpv: 2.006554
COMMANDS_FINISHED 305 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_31/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_31/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_31/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_31/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_31/self_attn.k_proj/compressed.log
best_loss 445.0378723144531 running bpv: 2.006644
COMMANDS_FINISHED 306 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_21/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_21/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_21/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_31/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_31/self_attn.o_proj/compressed.log
best_loss 19.344697952270508 running bpv: 2.006733
COMMANDS_FINISHED 307 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_21/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_21/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_21/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_31/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_31/self_attn.v_proj/compressed.log
best_loss 341.7860107421875 running bpv: 2.006821
COMMANDS_FINISHED 308 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_21/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_21/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_21/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
 17%|‚ñà‚ñã        | 308/1848 [9:08:43<78:27:14, 183.40s/it] 17%|‚ñà‚ñã        | 309/1848 [9:10:39<69:37:57, 162.88s/it] 17%|‚ñà‚ñã        | 310/1848 [9:13:14<68:34:44, 160.52s/it] 17%|‚ñà‚ñã        | 311/1848 [9:14:09<55:01:10, 128.87s/it] 17%|‚ñà‚ñã        | 312/1848 [9:14:34<41:41:22, 97.71s/it]  17%|‚ñà‚ñã        | 313/1848 [9:16:29<43:52:33, 102.90s/it] 17%|‚ñà‚ñã        | 314/1848 [9:19:54<56:54:05, 133.54s/it]meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_21/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_21/self_attn.q_proj/compressed.log
best_loss 305.93927001953125 running bpv: 2.00691
COMMANDS_FINISHED 309 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_21/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_21/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_21/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_31/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_31/mlp.down_proj/compressed.log
best_loss 81.90521240234375 running bpv: 2.00644
COMMANDS_FINISHED 310 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_21/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_21/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_21/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_21/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_21/mlp.gate_proj/compressed.log
best_loss 439.33953857421875 running bpv: 2.005977
COMMANDS_FINISHED 311 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_21/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_21/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_21/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_21/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_21/mlp.up_proj/compressed.log
best_loss 390.12359619140625 running bpv: 2.00552
COMMANDS_FINISHED 312 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_21/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_21/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_21/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_21/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_21/self_attn.k_proj/compressed.log
best_loss 314.374755859375 running bpv: 2.00561
COMMANDS_FINISHED 313 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_26/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_26/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_26/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_21/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_21/self_attn.o_proj/compressed.log
best_loss 23.47037124633789 running bpv: 2.005699
COMMANDS_FINISHED 314 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_26/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_26/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_26/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_21/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_21/self_attn.v_proj/compressed.log
best_loss 191.36773681640625 running bpv: 2.005787
COMMANDS_FINISHED 315 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_26/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_26/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_26/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
 17%|‚ñà‚ñã        | 315/1848 [9:25:39<83:52:57, 196.98s/it] 17%|‚ñà‚ñã        | 316/1848 [9:27:04<69:31:57, 163.39s/it] 17%|‚ñà‚ñã        | 317/1848 [9:28:19<58:12:39, 136.88s/it] 17%|‚ñà‚ñã        | 318/1848 [9:30:14<55:23:06, 130.32s/it] 17%|‚ñà‚ñã        | 319/1848 [9:31:29<48:18:06, 113.73s/it] 17%|‚ñà‚ñã        | 320/1848 [9:32:44<43:20:25, 102.11s/it] 17%|‚ñà‚ñã        | 321/1848 [9:35:59<55:08:04, 129.98s/it]meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_26/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_26/self_attn.q_proj/compressed.log
best_loss 366.26312255859375 running bpv: 2.005875
COMMANDS_FINISHED 316 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_26/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_26/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_26/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_21/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_21/mlp.down_proj/compressed.log
best_loss 57.613914489746094 running bpv: 2.005427
COMMANDS_FINISHED 317 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_26/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_26/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_26/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_26/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_26/mlp.gate_proj/compressed.log
best_loss 578.4857177734375 running bpv: 2.004984
COMMANDS_FINISHED 318 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_26/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_26/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_26/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_26/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_26/mlp.up_proj/compressed.log
best_loss 484.6937561035156 running bpv: 2.004547
COMMANDS_FINISHED 319 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_26/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_26/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_26/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_26/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_26/self_attn.k_proj/compressed.log
best_loss 373.98529052734375 running bpv: 2.004637
COMMANDS_FINISHED 320 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_14/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_14/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_14/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_26/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_26/self_attn.o_proj/compressed.log
best_loss 18.272220611572266 running bpv: 2.004725
COMMANDS_FINISHED 321 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_14/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_14/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_14/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_26/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_26/self_attn.v_proj/compressed.log
best_loss 285.7960205078125 running bpv: 2.004814
COMMANDS_FINISHED 322 n_commands 1849
 17%|‚ñà‚ñã        | 322/1848 [9:41:44<82:26:44, 194.50s/it] 17%|‚ñà‚ñã        | 323/1848 [9:41:59<59:34:51, 140.65s/it] 18%|‚ñà‚ñä        | 324/1848 [9:45:14<66:26:49, 156.96s/it] 18%|‚ñà‚ñä        | 325/1848 [9:46:19<54:44:00, 129.38s/it] 18%|‚ñà‚ñä        | 326/1848 [9:47:34<47:48:06, 113.07s/it] 18%|‚ñà‚ñä        | 327/1848 [9:47:49<35:20:28, 83.65s/it] running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_14/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_14/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_14/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_14/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_14/self_attn.q_proj/compressed.log
best_loss 279.2001953125 running bpv: 2.004901
COMMANDS_FINISHED 323 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_14/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_14/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_14/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_26/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_26/mlp.down_proj/compressed.log
best_loss 69.96096801757812 running bpv: 2.004472
COMMANDS_FINISHED 324 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_14/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_14/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_14/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_14/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_14/mlp.gate_proj/compressed.log
best_loss 238.56045532226562 running bpv: 2.004049
COMMANDS_FINISHED 325 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_14/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_14/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_14/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_14/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_14/mlp.up_proj/compressed.log
best_loss 230.9809112548828 running bpv: 2.00363
COMMANDS_FINISHED 326 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_14/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_14/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_14/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_14/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_14/self_attn.k_proj/compressed.log
best_loss 288.135986328125 running bpv: 2.003719
COMMANDS_FINISHED 327 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_15/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_15/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_15/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_14/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_14/self_attn.o_proj/compressed.log
best_loss 15.062973022460938 running bpv: 2.003807
COMMANDS_FINISHED 328 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_15/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_15/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_15/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
 18%|‚ñà‚ñä        | 328/1848 [9:51:54<55:45:33, 132.06s/it] 18%|‚ñà‚ñä        | 329/1848 [9:57:39<82:40:52, 195.95s/it] 18%|‚ñà‚ñä        | 330/1848 [9:59:04<68:35:33, 162.67s/it] 18%|‚ñà‚ñä        | 331/1848 [10:01:19<65:03:04, 154.37s/it] 18%|‚ñà‚ñä        | 332/1848 [10:01:34<47:24:05, 112.56s/it] 18%|‚ñà‚ñä        | 333/1848 [10:03:19<46:25:01, 110.30s/it] 18%|‚ñà‚ñä        | 334/1848 [10:04:44<43:11:45, 102.71s/it]meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_14/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_14/self_attn.v_proj/compressed.log
best_loss 127.18466186523438 running bpv: 2.003895
COMMANDS_FINISHED 329 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_15/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_15/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_15/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_15/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_15/self_attn.q_proj/compressed.log
best_loss 262.9718322753906 running bpv: 2.003983
COMMANDS_FINISHED 330 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_15/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_15/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_15/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_14/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_14/mlp.down_proj/compressed.log
best_loss 22.3135929107666 running bpv: 2.003571
COMMANDS_FINISHED 331 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_15/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_15/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_15/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_15/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_15/mlp.gate_proj/compressed.log
best_loss 258.3653259277344 running bpv: 2.003165
COMMANDS_FINISHED 332 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_15/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_15/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_15/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_15/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_15/mlp.up_proj/compressed.log
best_loss 251.78305053710938 running bpv: 2.002764
COMMANDS_FINISHED 333 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_15/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_15/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_15/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_15/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_15/self_attn.k_proj/compressed.log
best_loss 277.9706115722656 running bpv: 2.002852
COMMANDS_FINISHED 334 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_4/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_4/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_4/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_15/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_15/self_attn.o_proj/compressed.log
best_loss 17.32345962524414 running bpv: 2.00294
COMMANDS_FINISHED 335 n_commands 1849
 18%|‚ñà‚ñä        | 335/1848 [10:07:19<49:45:43, 118.40s/it] 18%|‚ñà‚ñä        | 336/1848 [10:13:04<78:17:04, 186.39s/it] 18%|‚ñà‚ñä        | 337/1848 [10:15:09<70:30:16, 167.98s/it] 18%|‚ñà‚ñä        | 338/1848 [10:16:54<62:32:03, 149.09s/it] 18%|‚ñà‚ñä        | 339/1848 [10:18:19<54:26:06, 129.87s/it] 18%|‚ñà‚ñä        | 340/1848 [10:18:44<41:13:18, 98.41s/it] running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_4/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_4/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_4/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_15/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_15/self_attn.v_proj/compressed.log
best_loss 132.53091430664062 running bpv: 2.003028
COMMANDS_FINISHED 336 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_4/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_4/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_4/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_4/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_4/self_attn.q_proj/compressed.log
best_loss 105.25019836425781 running bpv: 2.003115
COMMANDS_FINISHED 337 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_4/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_4/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_4/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_15/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_15/mlp.down_proj/compressed.log
best_loss 25.75462532043457 running bpv: 2.00272
COMMANDS_FINISHED 338 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_4/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_4/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_4/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_4/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_4/mlp.gate_proj/compressed.log
best_loss 79.1500473022461 running bpv: 2.00233
COMMANDS_FINISHED 339 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_4/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_4/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_4/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_4/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_4/mlp.up_proj/compressed.log
best_loss 66.78926086425781 running bpv: 2.001945
COMMANDS_FINISHED 340 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_4/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_4/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_4/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_4/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_4/self_attn.k_proj/compressed.log
best_loss 107.26741027832031 running bpv: 2.002032
COMMANDS_FINISHED 341 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_27/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_27/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_27/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
 18%|‚ñà‚ñä        | 341/1848 [10:20:49<44:32:08, 106.39s/it] 19%|‚ñà‚ñä        | 342/1848 [10:24:04<55:37:45, 132.98s/it] 19%|‚ñà‚ñä        | 343/1848 [10:29:49<82:11:12, 196.59s/it] 19%|‚ñà‚ñä        | 344/1848 [10:30:44<64:23:13, 154.12s/it] 19%|‚ñà‚ñä        | 345/1848 [10:32:19<56:56:28, 136.39s/it] 19%|‚ñà‚ñä        | 346/1848 [10:34:34<56:43:54, 135.98s/it] 19%|‚ñà‚ñâ        | 347/1848 [10:35:29<46:33:59, 111.68s/it]meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_4/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_4/self_attn.o_proj/compressed.log
best_loss 0.698184609413147 running bpv: 2.00212
COMMANDS_FINISHED 342 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_27/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_27/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_27/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_4/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_4/self_attn.v_proj/compressed.log
best_loss 36.14442443847656 running bpv: 2.002207
COMMANDS_FINISHED 343 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_27/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_27/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_27/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_27/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_27/self_attn.q_proj/compressed.log
best_loss 418.632568359375 running bpv: 2.002293
COMMANDS_FINISHED 344 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_27/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_27/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_27/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_4/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_4/mlp.down_proj/compressed.log
best_loss 2.267388105392456 running bpv: 2.001914
COMMANDS_FINISHED 345 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_27/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_27/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_27/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_27/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_27/mlp.gate_proj/compressed.log
best_loss 606.2467041015625 running bpv: 2.001539
COMMANDS_FINISHED 346 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_27/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_27/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_27/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_27/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_27/mlp.up_proj/compressed.log
best_loss 505.7303466796875 running bpv: 2.001169
COMMANDS_FINISHED 347 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_27/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_27/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_27/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_27/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_27/self_attn.k_proj/compressed.log
best_loss 424.81591796875 running bpv: 2.001256
COMMANDS_FINISHED 348 n_commands 1849
 19%|‚ñà‚ñâ        | 348/1848 [10:36:24<39:27:02, 94.68s/it]  19%|‚ñà‚ñâ        | 349/1848 [10:40:19<56:57:18, 136.78s/it] 19%|‚ñà‚ñâ        | 350/1848 [10:46:04<82:54:49, 199.26s/it] 19%|‚ñà‚ñâ        | 352/1848 [10:49:14<62:48:32, 151.14s/it] 19%|‚ñà‚ñâ        | 353/1848 [10:49:59<51:50:21, 124.83s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_2/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_2/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_2/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_27/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_27/self_attn.o_proj/compressed.log
best_loss 15.634716033935547 running bpv: 2.001342
COMMANDS_FINISHED 349 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_2/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_2/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_2/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_27/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_27/self_attn.v_proj/compressed.log
best_loss 321.3272399902344 running bpv: 2.001429
COMMANDS_FINISHED 350 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_2/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_2/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_2/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_27/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_27/mlp.down_proj/compressed.log
best_loss 71.78756713867188 running bpv: 2.001064
COMMANDS_FINISHED 351 n_commands 1849
meta-llama/Llama-2-13b-hf/layer_2/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_2/self_attn.q_proj/compressed.log
best_loss 32.5213508605957 running bpv: 2.00115
COMMANDS_FINISHED 352 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_2/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_2/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_2/self_attn.k_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_2/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_2/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_2/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_2/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_2/mlp.gate_proj/compressed.log
best_loss 35.00533676147461 running bpv: 2.000789
COMMANDS_FINISHED 353 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_2/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_2/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_2/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_2/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_2/mlp.up_proj/compressed.log
best_loss 29.835281372070312 running bpv: 2.000432
COMMANDS_FINISHED 354 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_2/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_2/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_2/self_attn.v_proj/compressed.log 2>&1 &
 19%|‚ñà‚ñâ        | 354/1848 [10:51:44<49:39:12, 119.65s/it] 19%|‚ñà‚ñâ        | 355/1848 [10:51:59<37:48:57, 91.18s/it]  19%|‚ñà‚ñâ        | 356/1848 [10:55:34<52:09:12, 125.84s/it] 19%|‚ñà‚ñâ        | 357/1848 [11:01:19<78:02:46, 188.44s/it] 19%|‚ñà‚ñâ        | 358/1848 [11:03:04<67:59:16, 164.27s/it] 19%|‚ñà‚ñâ        | 359/1848 [11:05:19<64:24:00, 155.70s/it] 19%|‚ñà‚ñâ        | 360/1848 [11:05:44<48:25:34, 117.16s/it]meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_2/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_2/self_attn.k_proj/compressed.log
best_loss 34.816192626953125 running bpv: 2.000519
COMMANDS_FINISHED 355 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_36/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_36/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_36/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_2/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_2/self_attn.o_proj/compressed.log
best_loss 0.21762357652187347 running bpv: 2.000605
COMMANDS_FINISHED 356 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_36/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_36/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_36/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_2/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_2/self_attn.v_proj/compressed.log
best_loss 10.164555549621582 running bpv: 2.000691
COMMANDS_FINISHED 357 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_36/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_36/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_36/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_36/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_36/self_attn.q_proj/compressed.log
best_loss 368.07568359375 running bpv: 2.000776
COMMANDS_FINISHED 358 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_36/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_36/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_36/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_2/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_2/mlp.down_proj/compressed.log
best_loss 0.7688379287719727 running bpv: 2.000424
COMMANDS_FINISHED 359 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_36/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_36/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_36/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_36/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_36/mlp.gate_proj/compressed.log
best_loss 817.794189453125 running bpv: 2.000077
COMMANDS_FINISHED 360 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_36/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_36/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_36/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_36/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_36/mlp.up_proj/compressed.log
best_loss 752.0406494140625 running bpv: 1.999733
COMMANDS_FINISHED 361 n_commands 1849
 20%|‚ñà‚ñâ        | 361/1848 [11:06:59<43:13:59, 104.67s/it] 20%|‚ñà‚ñâ        | 362/1848 [11:08:54<44:28:29, 107.75s/it] 20%|‚ñà‚ñâ        | 363/1848 [11:11:29<50:15:38, 121.84s/it] 20%|‚ñà‚ñâ        | 364/1848 [11:17:14<77:42:47, 188.52s/it] 20%|‚ñà‚ñâ        | 365/1848 [11:18:59<67:22:12, 163.54s/it] 20%|‚ñà‚ñâ        | 366/1848 [11:20:34<58:52:42, 143.02s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_36/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_36/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_36/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_36/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_36/self_attn.k_proj/compressed.log
best_loss 380.653076171875 running bpv: 1.999819
COMMANDS_FINISHED 362 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_28/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_28/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_28/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_36/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_36/self_attn.o_proj/compressed.log
best_loss 39.23580551147461 running bpv: 1.999904
COMMANDS_FINISHED 363 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_28/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_28/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_28/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_36/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_36/self_attn.v_proj/compressed.log
best_loss 358.9580078125 running bpv: 1.999989
COMMANDS_FINISHED 364 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_28/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_28/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_28/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_28/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_28/self_attn.q_proj/compressed.log
best_loss 413.6713562011719 running bpv: 2.000074
COMMANDS_FINISHED 365 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_28/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_28/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_28/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_36/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_36/mlp.down_proj/compressed.log
best_loss 135.3486785888672 running bpv: 1.999735
COMMANDS_FINISHED 366 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_28/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_28/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_28/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_28/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_28/mlp.gate_proj/compressed.log
best_loss 622.2201538085938 running bpv: 1.999399
COMMANDS_FINISHED 367 n_commands 1849
 20%|‚ñà‚ñâ        | 367/1848 [11:22:39<56:37:08, 137.63s/it] 20%|‚ñà‚ñâ        | 368/1848 [11:22:54<41:28:19, 100.88s/it] 20%|‚ñà‚ñâ        | 369/1848 [11:24:39<41:57:12, 102.12s/it] 20%|‚ñà‚ñà        | 370/1848 [11:28:24<57:03:18, 138.97s/it] 20%|‚ñà‚ñà        | 371/1848 [11:34:09<82:22:13, 200.77s/it] 20%|‚ñà‚ñà        | 372/1848 [11:34:24<59:28:16, 145.05s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_28/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_28/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_28/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_28/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_28/mlp.up_proj/compressed.log
best_loss 520.42724609375 running bpv: 1.999068
COMMANDS_FINISHED 368 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_28/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_28/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_28/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_28/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_28/self_attn.k_proj/compressed.log
best_loss 419.6014709472656 running bpv: 1.999153
COMMANDS_FINISHED 369 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_18/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_18/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_18/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_28/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_28/self_attn.o_proj/compressed.log
best_loss 16.323766708374023 running bpv: 1.999237
COMMANDS_FINISHED 370 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_18/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_18/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_18/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_28/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_28/self_attn.v_proj/compressed.log
best_loss 323.9805908203125 running bpv: 1.999322
COMMANDS_FINISHED 371 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_18/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_18/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_18/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_18/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_18/self_attn.q_proj/compressed.log
best_loss 305.2962646484375 running bpv: 1.999406
COMMANDS_FINISHED 372 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_18/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_18/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_18/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_28/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_28/mlp.down_proj/compressed.log
best_loss 72.58397674560547 running bpv: 1.999078
COMMANDS_FINISHED 373 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_18/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_18/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_18/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
 20%|‚ñà‚ñà        | 373/1848 [11:36:39<58:11:51, 142.04s/it] 20%|‚ñà‚ñà        | 374/1848 [11:38:14<52:22:54, 127.93s/it] 20%|‚ñà‚ñà        | 375/1848 [11:39:59<49:31:58, 121.06s/it] 20%|‚ñà‚ñà        | 376/1848 [11:40:14<36:29:28, 89.24s/it]  20%|‚ñà‚ñà        | 377/1848 [11:44:00<53:06:34, 129.98s/it] 20%|‚ñà‚ñà        | 378/1848 [11:49:35<78:11:30, 191.49s/it] 21%|‚ñà‚ñà        | 379/1848 [11:50:30<61:25:52, 150.55s/it]meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_18/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_18/mlp.gate_proj/compressed.log
best_loss 349.2008972167969 running bpv: 1.998755
COMMANDS_FINISHED 374 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_18/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_18/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_18/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_18/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_18/mlp.up_proj/compressed.log
best_loss 323.2002258300781 running bpv: 1.998434
COMMANDS_FINISHED 375 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_18/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_18/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_18/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_18/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_18/self_attn.k_proj/compressed.log
best_loss 318.1780090332031 running bpv: 1.998518
COMMANDS_FINISHED 376 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_25/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_25/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_25/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_18/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_18/self_attn.o_proj/compressed.log
best_loss 15.64172077178955 running bpv: 1.998602
COMMANDS_FINISHED 377 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_25/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_25/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_25/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_18/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_18/self_attn.v_proj/compressed.log
best_loss 172.2281036376953 running bpv: 1.998686
COMMANDS_FINISHED 378 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_25/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_25/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_25/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_25/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_25/self_attn.q_proj/compressed.log
best_loss 367.96563720703125 running bpv: 1.998769
COMMANDS_FINISHED 379 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_25/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_25/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_25/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_18/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_18/mlp.down_proj/compressed.log
best_loss 37.45255661010742 running bpv: 1.998453
COMMANDS_FINISHED 380 n_commands 1849
 21%|‚ñà‚ñà        | 380/1848 [11:53:35<65:36:22, 160.89s/it] 21%|‚ñà‚ñà        | 381/1848 [11:53:50<47:43:39, 117.12s/it] 21%|‚ñà‚ñà        | 382/1848 [11:55:15<43:46:19, 107.49s/it] 21%|‚ñà‚ñà        | 383/1848 [11:56:20<38:33:21, 94.74s/it]  21%|‚ñà‚ñà        | 384/1848 [11:59:35<50:45:46, 124.83s/it] 21%|‚ñà‚ñà        | 385/1848 [12:05:20<77:34:26, 190.89s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_25/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_25/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_25/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_25/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_25/mlp.gate_proj/compressed.log
best_loss 557.410888671875 running bpv: 1.99814
COMMANDS_FINISHED 381 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_25/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_25/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_25/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_25/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_25/mlp.up_proj/compressed.log
best_loss 468.79718017578125 running bpv: 1.99783
COMMANDS_FINISHED 382 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_25/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_25/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_25/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_25/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_25/self_attn.k_proj/compressed.log
best_loss 375.02178955078125 running bpv: 1.997914
COMMANDS_FINISHED 383 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_37/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_37/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_37/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_25/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_25/self_attn.o_proj/compressed.log
best_loss 17.368783950805664 running bpv: 1.997997
COMMANDS_FINISHED 384 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_37/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_37/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_37/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_25/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_25/self_attn.v_proj/compressed.log
best_loss 279.75726318359375 running bpv: 1.998079
COMMANDS_FINISHED 385 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_37/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_37/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_37/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_37/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_37/self_attn.q_proj/compressed.log
best_loss 327.46002197265625 running bpv: 1.998162
COMMANDS_FINISHED 386 n_commands 1849
 21%|‚ñà‚ñà        | 386/1848 [12:07:25<69:29:43, 171.12s/it] 21%|‚ñà‚ñà        | 387/1848 [12:08:50<58:57:49, 145.29s/it] 21%|‚ñà‚ñà        | 388/1848 [12:10:05<50:22:22, 124.21s/it] 21%|‚ñà‚ñà        | 389/1848 [12:11:00<41:55:29, 103.45s/it] 21%|‚ñà‚ñà        | 390/1848 [12:13:15<45:43:52, 112.92s/it] 21%|‚ñà‚ñà        | 391/1848 [12:15:50<50:48:40, 125.55s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_37/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_37/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_37/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_25/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_25/mlp.down_proj/compressed.log
best_loss 66.89434814453125 running bpv: 1.997856
COMMANDS_FINISHED 387 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_37/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_37/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_37/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_37/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_37/mlp.gate_proj/compressed.log
best_loss 820.9737548828125 running bpv: 1.997553
COMMANDS_FINISHED 388 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_37/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_37/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_37/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_37/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_37/mlp.up_proj/compressed.log
best_loss 759.2908325195312 running bpv: 1.997254
COMMANDS_FINISHED 389 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_37/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_37/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_37/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_37/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_37/self_attn.k_proj/compressed.log
best_loss 326.6355895996094 running bpv: 1.997336
COMMANDS_FINISHED 390 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_30/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_30/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_30/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_37/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_37/self_attn.o_proj/compressed.log
best_loss 39.88216781616211 running bpv: 1.997419
COMMANDS_FINISHED 391 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_30/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_30/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_30/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_37/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_37/self_attn.v_proj/compressed.log
best_loss 359.32293701171875 running bpv: 1.997501
COMMANDS_FINISHED 392 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_30/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_30/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_30/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
 21%|‚ñà‚ñà        | 392/1848 [12:21:35<77:24:24, 191.39s/it] 21%|‚ñà‚ñà‚ñè       | 393/1848 [12:22:40<62:01:47, 153.48s/it] 21%|‚ñà‚ñà‚ñè       | 394/1848 [12:24:35<57:19:36, 141.94s/it] 21%|‚ñà‚ñà‚ñè       | 395/1848 [12:27:00<57:39:36, 142.86s/it] 21%|‚ñà‚ñà‚ñè       | 396/1848 [12:27:15<42:09:00, 104.50s/it] 21%|‚ñà‚ñà‚ñè       | 397/1848 [12:28:20<37:20:42, 92.66s/it]  22%|‚ñà‚ñà‚ñè       | 398/1848 [12:32:45<58:08:51, 144.37s/it]meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_30/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_30/self_attn.q_proj/compressed.log
best_loss 475.31951904296875 running bpv: 1.997582
COMMANDS_FINISHED 393 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_30/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_30/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_30/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_37/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_37/mlp.down_proj/compressed.log
best_loss 158.79721069335938 running bpv: 1.997286
COMMANDS_FINISHED 394 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_30/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_30/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_30/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_30/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_30/mlp.gate_proj/compressed.log
best_loss 674.0216674804688 running bpv: 1.996993
COMMANDS_FINISHED 395 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_30/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_30/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_30/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_30/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_30/mlp.up_proj/compressed.log
best_loss 569.3419799804688 running bpv: 1.996703
COMMANDS_FINISHED 396 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_30/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_30/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_30/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_30/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_30/self_attn.k_proj/compressed.log
best_loss 480.57177734375 running bpv: 1.996785
COMMANDS_FINISHED 397 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_29/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_29/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_29/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_30/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_30/self_attn.o_proj/compressed.log
best_loss 17.99252700805664 running bpv: 1.996866
COMMANDS_FINISHED 398 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_29/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_29/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_29/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_30/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_30/self_attn.v_proj/compressed.log
best_loss 405.9778137207031 running bpv: 1.996947
COMMANDS_FINISHED 399 n_commands 1849
 22%|‚ñà‚ñà‚ñè       | 399/1848 [12:38:20<81:07:47, 201.56s/it] 22%|‚ñà‚ñà‚ñè       | 400/1848 [12:38:35<58:33:44, 145.60s/it] 22%|‚ñà‚ñà‚ñè       | 401/1848 [12:41:00<58:27:06, 145.42s/it] 22%|‚ñà‚ñà‚ñè       | 402/1848 [12:42:05<48:43:18, 121.30s/it] 22%|‚ñà‚ñà‚ñè       | 403/1848 [12:44:00<47:55:52, 119.41s/it] 22%|‚ñà‚ñà‚ñè       | 404/1848 [12:44:15<35:20:03, 88.09s/it] running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_29/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_29/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_29/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_30/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_30/mlp.down_proj/compressed.log
best_loss 79.41648864746094 running bpv: 1.99666
COMMANDS_FINISHED 400 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_29/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_29/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_29/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_29/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_29/self_attn.q_proj/compressed.log
best_loss 441.2637023925781 running bpv: 1.996741
COMMANDS_FINISHED 401 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_29/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_29/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_29/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_29/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_29/mlp.gate_proj/compressed.log
best_loss 643.6992797851562 running bpv: 1.996457
COMMANDS_FINISHED 402 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_29/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_29/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_29/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_29/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_29/mlp.up_proj/compressed.log
best_loss 542.7534790039062 running bpv: 1.996176
COMMANDS_FINISHED 403 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_29/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_29/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_29/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_29/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_29/self_attn.k_proj/compressed.log
best_loss 451.5089111328125 running bpv: 1.996257
COMMANDS_FINISHED 404 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_16/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_16/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_16/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_29/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_29/self_attn.o_proj/compressed.log
best_loss 16.36355209350586 running bpv: 1.996338
COMMANDS_FINISHED 405 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_16/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_16/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_16/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
 22%|‚ñà‚ñà‚ñè       | 405/1848 [12:47:50<50:34:22, 126.17s/it] 22%|‚ñà‚ñà‚ñè       | 406/1848 [12:53:35<76:50:15, 191.83s/it] 22%|‚ñà‚ñà‚ñè       | 407/1848 [12:54:50<62:45:23, 156.78s/it] 22%|‚ñà‚ñà‚ñè       | 408/1848 [12:57:35<63:42:04, 159.25s/it] 22%|‚ñà‚ñà‚ñè       | 409/1848 [12:58:00<47:33:30, 118.98s/it] 22%|‚ñà‚ñà‚ñè       | 410/1848 [12:59:15<42:15:22, 105.79s/it] 22%|‚ñà‚ñà‚ñè       | 411/1848 [13:00:30<38:32:29, 96.55s/it] meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_29/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_29/self_attn.v_proj/compressed.log
best_loss 339.6009521484375 running bpv: 1.996418
COMMANDS_FINISHED 406 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_16/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_16/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_16/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_16/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_16/self_attn.q_proj/compressed.log
best_loss 292.1453857421875 running bpv: 1.996498
COMMANDS_FINISHED 407 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_16/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_16/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_16/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_29/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_29/mlp.down_proj/compressed.log
best_loss 75.65847778320312 running bpv: 1.99622
COMMANDS_FINISHED 408 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_16/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_16/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_16/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_16/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_16/mlp.gate_proj/compressed.log
best_loss 285.10968017578125 running bpv: 1.995944
COMMANDS_FINISHED 409 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_16/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_16/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_16/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_16/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_16/mlp.up_proj/compressed.log
best_loss 276.502197265625 running bpv: 1.995672
COMMANDS_FINISHED 410 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_16/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_16/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_16/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_16/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_16/self_attn.k_proj/compressed.log
best_loss 302.5887451171875 running bpv: 1.995752
COMMANDS_FINISHED 411 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_13/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_13/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_13/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_16/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_16/self_attn.o_proj/compressed.log
best_loss 17.685626983642578 running bpv: 1.995831
COMMANDS_FINISHED 412 n_commands 1849
 22%|‚ñà‚ñà‚ñè       | 412/1848 [13:03:45<50:17:51, 126.09s/it] 22%|‚ñà‚ñà‚ñè       | 413/1848 [13:09:30<76:26:37, 191.78s/it] 22%|‚ñà‚ñà‚ñè       | 414/1848 [13:11:15<66:01:19, 165.75s/it] 22%|‚ñà‚ñà‚ñè       | 415/1848 [13:13:00<58:43:24, 147.53s/it] 23%|‚ñà‚ñà‚ñé       | 416/1848 [13:14:15<50:01:45, 125.77s/it] 23%|‚ñà‚ñà‚ñé       | 417/1848 [13:15:10<41:33:20, 104.54s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_13/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_13/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_13/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_16/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_16/self_attn.v_proj/compressed.log
best_loss 149.80784606933594 running bpv: 1.995911
COMMANDS_FINISHED 413 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_13/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_13/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_13/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_13/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_13/self_attn.q_proj/compressed.log
best_loss 273.73626708984375 running bpv: 1.99599
COMMANDS_FINISHED 414 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_13/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_13/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_13/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_16/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_16/mlp.down_proj/compressed.log
best_loss 32.1731071472168 running bpv: 1.99572
COMMANDS_FINISHED 415 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_13/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_13/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_13/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_13/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_13/mlp.gate_proj/compressed.log
best_loss 221.65292358398438 running bpv: 1.995453
COMMANDS_FINISHED 416 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_13/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_13/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_13/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_13/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_13/mlp.up_proj/compressed.log
best_loss 211.23147583007812 running bpv: 1.995188
COMMANDS_FINISHED 417 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_13/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_13/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_13/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_13/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_13/self_attn.k_proj/compressed.log
best_loss 270.61932373046875 running bpv: 1.995267
COMMANDS_FINISHED 418 n_commands 1849
 23%|‚ñà‚ñà‚ñé       | 418/1848 [13:16:55<41:34:57, 104.68s/it] 23%|‚ñà‚ñà‚ñé       | 419/1848 [13:20:00<51:07:13, 128.78s/it] 23%|‚ñà‚ñà‚ñé       | 420/1848 [13:25:45<76:49:03, 193.66s/it] 23%|‚ñà‚ñà‚ñé       | 421/1848 [13:26:50<61:27:55, 155.06s/it] 23%|‚ñà‚ñà‚ñé       | 422/1848 [13:28:55<57:51:04, 146.05s/it] 23%|‚ñà‚ñà‚ñé       | 423/1848 [13:30:30<51:45:00, 130.74s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_10/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_10/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_10/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_13/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_13/self_attn.o_proj/compressed.log
best_loss 12.226865768432617 running bpv: 1.995346
COMMANDS_FINISHED 419 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_10/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_10/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_10/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_13/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_13/self_attn.v_proj/compressed.log
best_loss 131.59417724609375 running bpv: 1.995425
COMMANDS_FINISHED 420 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_10/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_10/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_10/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_10/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_10/self_attn.q_proj/compressed.log
best_loss 222.17990112304688 running bpv: 1.995504
COMMANDS_FINISHED 421 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_10/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_10/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_10/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_13/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_13/mlp.down_proj/compressed.log
best_loss 18.962026596069336 running bpv: 1.995241
COMMANDS_FINISHED 422 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_10/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_10/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_10/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_10/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_10/mlp.gate_proj/compressed.log
best_loss 194.21615600585938 running bpv: 1.994982
COMMANDS_FINISHED 423 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_10/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_10/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_10/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_10/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_10/mlp.up_proj/compressed.log
best_loss 171.70346069335938 running bpv: 1.994724
COMMANDS_FINISHED 424 n_commands 1849
 23%|‚ñà‚ñà‚ñé       | 424/1848 [13:31:25<42:43:38, 108.02s/it] 23%|‚ñà‚ñà‚ñé       | 425/1848 [13:32:30<37:35:50, 95.12s/it]  23%|‚ñà‚ñà‚ñé       | 426/1848 [13:36:15<52:57:53, 134.09s/it] 23%|‚ñà‚ñà‚ñé       | 427/1848 [13:42:00<77:54:23, 197.37s/it] 23%|‚ñà‚ñà‚ñé       | 428/1848 [13:42:45<59:49:19, 151.66s/it] 23%|‚ñà‚ñà‚ñé       | 429/1848 [13:45:10<58:59:38, 149.67s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_10/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_10/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_10/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_10/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_10/self_attn.k_proj/compressed.log
best_loss 229.022216796875 running bpv: 1.994803
COMMANDS_FINISHED 425 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_19/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_19/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_19/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_10/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_10/self_attn.o_proj/compressed.log
best_loss 7.520218372344971 running bpv: 1.994881
COMMANDS_FINISHED 426 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_19/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_19/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_19/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_10/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_10/self_attn.v_proj/compressed.log
best_loss 90.85631561279297 running bpv: 1.994959
COMMANDS_FINISHED 427 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_19/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_19/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_19/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_19/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_19/self_attn.q_proj/compressed.log
best_loss 302.94921875 running bpv: 1.995037
COMMANDS_FINISHED 428 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_19/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_19/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_19/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_10/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_10/mlp.down_proj/compressed.log
best_loss 12.980445861816406 running bpv: 1.994782
COMMANDS_FINISHED 429 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_19/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_19/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_19/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_19/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_19/mlp.gate_proj/compressed.log
best_loss 378.0321044921875 running bpv: 1.99453
COMMANDS_FINISHED 430 n_commands 1849
 23%|‚ñà‚ñà‚ñé       | 430/1848 [13:46:15<48:56:56, 124.27s/it] 23%|‚ñà‚ñà‚ñé       | 431/1848 [13:47:40<44:16:43, 112.49s/it] 23%|‚ñà‚ñà‚ñé       | 432/1848 [13:48:35<37:27:51, 95.25s/it]  23%|‚ñà‚ñà‚ñé       | 433/1848 [13:52:00<50:22:55, 128.18s/it] 23%|‚ñà‚ñà‚ñé       | 434/1848 [13:57:45<75:53:56, 193.24s/it] 24%|‚ñà‚ñà‚ñé       | 435/1848 [13:59:00<61:55:26, 157.77s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_19/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_19/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_19/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_19/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_19/mlp.up_proj/compressed.log
best_loss 344.9677734375 running bpv: 1.994279
COMMANDS_FINISHED 431 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_19/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_19/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_19/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_19/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_19/self_attn.k_proj/compressed.log
best_loss 311.104736328125 running bpv: 1.994357
COMMANDS_FINISHED 432 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_6/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_6/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_6/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_19/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_19/self_attn.o_proj/compressed.log
best_loss 16.71726417541504 running bpv: 1.994434
COMMANDS_FINISHED 433 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_6/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_6/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_6/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_19/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_19/self_attn.v_proj/compressed.log
best_loss 178.4147491455078 running bpv: 1.994511
COMMANDS_FINISHED 434 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_6/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_6/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_6/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_6/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_6/self_attn.q_proj/compressed.log
best_loss 151.69638061523438 running bpv: 1.994588
COMMANDS_FINISHED 435 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_6/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_6/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_6/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_19/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_19/mlp.down_proj/compressed.log
best_loss 41.78691864013672 running bpv: 1.994341
COMMANDS_FINISHED 436 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_6/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_6/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_6/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
 24%|‚ñà‚ñà‚ñé       | 436/1848 [14:01:15<59:12:10, 150.94s/it] 24%|‚ñà‚ñà‚ñé       | 437/1848 [14:02:10<47:52:49, 122.16s/it] 24%|‚ñà‚ñà‚ñé       | 438/1848 [14:03:25<42:18:22, 108.02s/it] 24%|‚ñà‚ñà‚ñç       | 439/1848 [14:04:50<39:34:29, 101.11s/it] 24%|‚ñà‚ñà‚ñç       | 440/1848 [14:07:55<49:23:28, 126.28s/it] 24%|‚ñà‚ñà‚ñç       | 441/1848 [14:13:40<75:00:13, 191.91s/it] 24%|‚ñà‚ñà‚ñç       | 442/1848 [14:14:55<61:15:13, 156.84s/it]meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_6/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_6/mlp.gate_proj/compressed.log
best_loss 133.26861572265625 running bpv: 1.994095
COMMANDS_FINISHED 437 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_6/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_6/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_6/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_6/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_6/mlp.up_proj/compressed.log
best_loss 106.90892028808594 running bpv: 1.993852
COMMANDS_FINISHED 438 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_6/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_6/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_6/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_6/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_6/self_attn.k_proj/compressed.log
best_loss 155.9900665283203 running bpv: 1.993929
COMMANDS_FINISHED 439 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_11/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_11/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_11/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_6/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_6/self_attn.o_proj/compressed.log
best_loss 1.747347116470337 running bpv: 1.994005
COMMANDS_FINISHED 440 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_11/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_11/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_11/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_6/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_6/self_attn.v_proj/compressed.log
best_loss 58.14463806152344 running bpv: 1.994081
COMMANDS_FINISHED 441 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_11/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_11/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_11/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_11/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_11/self_attn.q_proj/compressed.log
best_loss 218.78639221191406 running bpv: 1.994157
COMMANDS_FINISHED 442 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_11/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_11/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_11/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_6/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_6/mlp.down_proj/compressed.log
best_loss 5.3473591804504395 running bpv: 1.993916
COMMANDS_FINISHED 443 n_commands 1849
 24%|‚ñà‚ñà‚ñç       | 443/1848 [14:17:00<57:29:02, 147.29s/it] 24%|‚ñà‚ñà‚ñç       | 444/1848 [14:18:35<51:19:34, 131.61s/it] 24%|‚ñà‚ñà‚ñç       | 445/1848 [14:19:20<41:09:53, 105.63s/it] 24%|‚ñà‚ñà‚ñç       | 446/1848 [14:20:36<37:33:30, 96.44s/it]  24%|‚ñà‚ñà‚ñç       | 447/1848 [14:24:21<52:32:35, 135.01s/it] 24%|‚ñà‚ñà‚ñç       | 448/1848 [14:30:06<77:00:25, 198.02s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_11/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_11/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_11/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_11/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_11/mlp.gate_proj/compressed.log
best_loss 196.46792602539062 running bpv: 1.993677
COMMANDS_FINISHED 444 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_11/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_11/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_11/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_11/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_11/mlp.up_proj/compressed.log
best_loss 180.1000213623047 running bpv: 1.993441
COMMANDS_FINISHED 445 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_11/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_11/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_11/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_11/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_11/self_attn.k_proj/compressed.log
best_loss 228.16427612304688 running bpv: 1.993517
COMMANDS_FINISHED 446 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_20/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_20/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_20/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_11/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_11/self_attn.o_proj/compressed.log
best_loss 8.845260620117188 running bpv: 1.993592
COMMANDS_FINISHED 447 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_20/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_20/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_20/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_11/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_11/self_attn.v_proj/compressed.log
best_loss 86.89087677001953 running bpv: 1.993668
COMMANDS_FINISHED 448 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_20/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_20/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_20/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_20/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_20/self_attn.q_proj/compressed.log
best_loss 285.88641357421875 running bpv: 1.993743
COMMANDS_FINISHED 449 n_commands 1849
 24%|‚ñà‚ñà‚ñç       | 449/1848 [14:30:51<59:06:49, 152.12s/it] 24%|‚ñà‚ñà‚ñç       | 450/1848 [14:33:06<57:04:44, 146.98s/it] 24%|‚ñà‚ñà‚ñç       | 451/1848 [14:34:11<47:29:41, 122.39s/it] 24%|‚ñà‚ñà‚ñç       | 452/1848 [14:35:56<45:26:20, 117.18s/it] 25%|‚ñà‚ñà‚ñç       | 453/1848 [14:36:31<35:51:15, 92.53s/it]  25%|‚ñà‚ñà‚ñç       | 454/1848 [14:39:56<48:53:47, 126.28s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_20/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_20/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_20/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_11/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_11/mlp.down_proj/compressed.log
best_loss 14.519819259643555 running bpv: 1.993508
COMMANDS_FINISHED 450 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_20/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_20/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_20/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_20/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_20/mlp.gate_proj/compressed.log
best_loss 400.4762878417969 running bpv: 1.993276
COMMANDS_FINISHED 451 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_20/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_20/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_20/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_20/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_20/mlp.up_proj/compressed.log
best_loss 363.56585693359375 running bpv: 1.993045
COMMANDS_FINISHED 452 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_20/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_20/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_20/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_20/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_20/self_attn.k_proj/compressed.log
best_loss 297.0573425292969 running bpv: 1.99312
COMMANDS_FINISHED 453 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_23/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_23/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_23/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_20/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_20/self_attn.o_proj/compressed.log
best_loss 18.86407470703125 running bpv: 1.993195
COMMANDS_FINISHED 454 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_23/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_23/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_23/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_20/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_20/self_attn.v_proj/compressed.log
best_loss 164.45452880859375 running bpv: 1.99327
COMMANDS_FINISHED 455 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_23/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_23/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_23/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
 25%|‚ñà‚ñà‚ñç       | 455/1848 [14:45:41<74:15:19, 191.90s/it] 25%|‚ñà‚ñà‚ñç       | 456/1848 [14:47:06<61:48:08, 159.83s/it] 25%|‚ñà‚ñà‚ñç       | 457/1848 [14:49:51<62:21:31, 161.39s/it] 25%|‚ñà‚ñà‚ñç       | 458/1848 [14:50:16<46:30:58, 120.47s/it] 25%|‚ñà‚ñà‚ñç       | 459/1848 [14:51:21<40:03:45, 103.83s/it] 25%|‚ñà‚ñà‚ñç       | 460/1848 [14:52:56<39:00:47, 101.19s/it] 25%|‚ñà‚ñà‚ñç       | 461/1848 [14:56:01<48:40:29, 126.34s/it]meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_23/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_23/self_attn.q_proj/compressed.log
best_loss 330.08349609375 running bpv: 1.993344
COMMANDS_FINISHED 456 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_23/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_23/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_23/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_20/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_20/mlp.down_proj/compressed.log
best_loss 46.65653610229492 running bpv: 1.993116
COMMANDS_FINISHED 457 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_23/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_23/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_23/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_23/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_23/mlp.gate_proj/compressed.log
best_loss 504.5553283691406 running bpv: 1.992889
COMMANDS_FINISHED 458 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_23/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_23/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_23/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_23/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_23/mlp.up_proj/compressed.log
best_loss 431.6806640625 running bpv: 1.992664
COMMANDS_FINISHED 459 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_23/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_23/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_23/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_23/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_23/self_attn.k_proj/compressed.log
best_loss 337.3849792480469 running bpv: 1.992738
COMMANDS_FINISHED 460 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_35/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_35/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_35/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_23/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_23/self_attn.o_proj/compressed.log
best_loss 16.488737106323242 running bpv: 1.992813
COMMANDS_FINISHED 461 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_35/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_35/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_35/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_23/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_23/self_attn.v_proj/compressed.log
best_loss 237.8804931640625 running bpv: 1.992886
COMMANDS_FINISHED 462 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_35/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_35/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_35/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
 25%|‚ñà‚ñà‚ñå       | 462/1848 [15:01:46<73:53:56, 191.95s/it] 25%|‚ñà‚ñà‚ñå       | 463/1848 [15:03:41<64:57:59, 168.87s/it] 25%|‚ñà‚ñà‚ñå       | 464/1848 [15:04:56<54:05:40, 140.71s/it] 25%|‚ñà‚ñà‚ñå       | 465/1848 [15:06:41<49:56:30, 130.00s/it] 25%|‚ñà‚ñà‚ñå       | 466/1848 [15:07:26<40:07:02, 104.50s/it] 25%|‚ñà‚ñà‚ñå       | 467/1848 [15:09:21<41:17:52, 107.66s/it] 25%|‚ñà‚ñà‚ñå       | 468/1848 [15:12:26<50:09:52, 130.86s/it]meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_35/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_35/self_attn.q_proj/compressed.log
best_loss 388.9427185058594 running bpv: 1.99296
COMMANDS_FINISHED 463 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_35/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_35/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_35/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_23/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_23/mlp.down_proj/compressed.log
best_loss 62.21778869628906 running bpv: 1.992737
COMMANDS_FINISHED 464 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_35/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_35/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_35/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_35/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_35/mlp.gate_proj/compressed.log
best_loss 791.3907470703125 running bpv: 1.992516
COMMANDS_FINISHED 465 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_35/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_35/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_35/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_35/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_35/mlp.up_proj/compressed.log
best_loss 718.1339111328125 running bpv: 1.992297
COMMANDS_FINISHED 466 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_35/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_35/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_35/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_35/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_35/self_attn.k_proj/compressed.log
best_loss 397.9788818359375 running bpv: 1.992371
COMMANDS_FINISHED 467 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_38/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_38/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_38/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_35/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_35/self_attn.o_proj/compressed.log
best_loss 25.783607482910156 running bpv: 1.992444
COMMANDS_FINISHED 468 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_38/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_38/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_38/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_35/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_35/self_attn.v_proj/compressed.log
best_loss 365.1009521484375 running bpv: 1.992517
COMMANDS_FINISHED 469 n_commands 1849
 25%|‚ñà‚ñà‚ñå       | 469/1848 [15:18:11<74:44:22, 195.11s/it] 25%|‚ñà‚ñà‚ñå       | 470/1848 [15:18:46<56:17:58, 147.08s/it] 25%|‚ñà‚ñà‚ñå       | 471/1848 [15:21:01<54:52:25, 143.46s/it] 26%|‚ñà‚ñà‚ñå       | 472/1848 [15:23:06<52:43:07, 137.93s/it] 26%|‚ñà‚ñà‚ñå       | 473/1848 [15:23:51<42:02:00, 110.05s/it] 26%|‚ñà‚ñà‚ñå       | 474/1848 [15:24:26<33:24:37, 87.54s/it] running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_38/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_38/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_38/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_38/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_38/self_attn.q_proj/compressed.log
best_loss 315.0389099121094 running bpv: 1.99259
COMMANDS_FINISHED 470 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_38/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_38/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_38/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_35/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_35/mlp.down_proj/compressed.log
best_loss 116.09458923339844 running bpv: 1.992372
COMMANDS_FINISHED 471 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_38/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_38/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_38/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_38/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_38/mlp.gate_proj/compressed.log
best_loss 826.3509521484375 running bpv: 1.992157
COMMANDS_FINISHED 472 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_38/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_38/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_38/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_38/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_38/mlp.up_proj/compressed.log
best_loss 730.6761474609375 running bpv: 1.991943
COMMANDS_FINISHED 473 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_38/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_38/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_38/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_38/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_38/self_attn.k_proj/compressed.log
best_loss 318.4870910644531 running bpv: 1.992016
COMMANDS_FINISHED 474 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_17/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_17/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_17/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_38/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_38/self_attn.o_proj/compressed.log
best_loss 62.399009704589844 running bpv: 1.992088
COMMANDS_FINISHED 475 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_17/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_17/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_17/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
 26%|‚ñà‚ñà‚ñå       | 475/1848 [15:28:51<53:41:35, 140.78s/it] 26%|‚ñà‚ñà‚ñå       | 476/1848 [15:34:36<77:00:23, 202.06s/it] 26%|‚ñà‚ñà‚ñå       | 477/1848 [15:34:51<55:34:46, 145.94s/it] 26%|‚ñà‚ñà‚ñå       | 478/1848 [15:37:26<56:34:29, 148.66s/it] 26%|‚ñà‚ñà‚ñå       | 479/1848 [15:38:01<43:34:01, 114.57s/it] 26%|‚ñà‚ñà‚ñå       | 480/1848 [15:40:16<45:51:58, 120.70s/it] 26%|‚ñà‚ñà‚ñå       | 481/1848 [15:40:31<33:47:32, 88.99s/it] meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_38/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_38/self_attn.v_proj/compressed.log
best_loss 387.47747802734375 running bpv: 1.992161
COMMANDS_FINISHED 476 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_17/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_17/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_17/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_17/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_17/self_attn.q_proj/compressed.log
best_loss 289.8739013671875 running bpv: 1.992233
COMMANDS_FINISHED 477 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_17/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_17/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_17/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_38/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_38/mlp.down_proj/compressed.log
best_loss 191.78756713867188 running bpv: 1.992021
COMMANDS_FINISHED 478 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_17/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_17/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_17/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_17/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_17/mlp.gate_proj/compressed.log
best_loss 318.15618896484375 running bpv: 1.99181
COMMANDS_FINISHED 479 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_17/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_17/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_17/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_17/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_17/mlp.up_proj/compressed.log
best_loss 300.94207763671875 running bpv: 1.991602
COMMANDS_FINISHED 480 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_17/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_17/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_17/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_17/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_17/self_attn.k_proj/compressed.log
best_loss 302.1077575683594 running bpv: 1.991673
COMMANDS_FINISHED 481 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_9/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_9/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_9/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_17/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_17/self_attn.o_proj/compressed.log
best_loss 17.15703773498535 running bpv: 1.991745
COMMANDS_FINISHED 482 n_commands 1849
 26%|‚ñà‚ñà‚ñå       | 482/1848 [15:43:36<44:41:55, 117.80s/it] 26%|‚ñà‚ñà‚ñå       | 483/1848 [15:49:21<70:30:48, 185.97s/it] 26%|‚ñà‚ñà‚ñå       | 484/1848 [15:51:16<62:23:47, 164.68s/it] 26%|‚ñà‚ñà‚ñå       | 485/1848 [15:54:01<62:23:18, 164.78s/it] 26%|‚ñà‚ñà‚ñã       | 486/1848 [15:54:16<45:20:34, 119.85s/it] 26%|‚ñà‚ñà‚ñã       | 487/1848 [15:55:01<36:49:16, 97.40s/it] running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_9/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_9/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_9/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_17/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_17/self_attn.v_proj/compressed.log
best_loss 154.68862915039062 running bpv: 1.991817
COMMANDS_FINISHED 483 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_9/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_9/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_9/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_9/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_9/self_attn.q_proj/compressed.log
best_loss 222.9819793701172 running bpv: 1.991888
COMMANDS_FINISHED 484 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_9/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_9/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_9/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_17/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_17/mlp.down_proj/compressed.log
best_loss 35.283714294433594 running bpv: 1.991681
COMMANDS_FINISHED 485 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_9/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_9/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_9/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_9/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_9/mlp.gate_proj/compressed.log
best_loss 189.32473754882812 running bpv: 1.991476
COMMANDS_FINISHED 486 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_9/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_9/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_9/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_9/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_9/mlp.up_proj/compressed.log
best_loss 161.3802947998047 running bpv: 1.991272
COMMANDS_FINISHED 487 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_9/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_9/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_9/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_9/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_9/self_attn.k_proj/compressed.log
best_loss 222.9478302001953 running bpv: 1.991343
COMMANDS_FINISHED 488 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_22/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_22/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_22/mlp.gate_proj/compressed.log 2>&1 &
 26%|‚ñà‚ñà‚ñã       | 488/1848 [15:56:56<38:47:26, 102.68s/it] 26%|‚ñà‚ñà‚ñã       | 489/1848 [16:00:01<48:05:12, 127.38s/it] 27%|‚ñà‚ñà‚ñã       | 490/1848 [16:05:46<72:40:55, 192.68s/it] 27%|‚ñà‚ñà‚ñã       | 491/1848 [16:07:51<64:58:36, 172.38s/it] 27%|‚ñà‚ñà‚ñã       | 492/1848 [16:08:36<50:32:09, 134.17s/it] 27%|‚ñà‚ñà‚ñã       | 493/1848 [16:10:41<49:27:54, 131.42s/it] 27%|‚ñà‚ñà‚ñã       | 494/1848 [16:11:26<39:40:42, 105.50s/it]meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_9/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_9/self_attn.o_proj/compressed.log
best_loss 5.20764684677124 running bpv: 1.991414
COMMANDS_FINISHED 489 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_22/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_22/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_22/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_9/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_9/self_attn.v_proj/compressed.log
best_loss 91.49734497070312 running bpv: 1.991485
COMMANDS_FINISHED 490 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_22/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_22/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_22/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_22/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_22/self_attn.q_proj/compressed.log
best_loss 340.1962585449219 running bpv: 1.991555
COMMANDS_FINISHED 491 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_22/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_22/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_22/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_9/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_9/mlp.down_proj/compressed.log
best_loss 10.929880142211914 running bpv: 1.991353
COMMANDS_FINISHED 492 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_22/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_22/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_22/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_22/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_22/mlp.gate_proj/compressed.log
best_loss 475.3147888183594 running bpv: 1.991152
COMMANDS_FINISHED 493 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_22/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_22/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_22/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_22/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_22/mlp.up_proj/compressed.log
best_loss 413.5224609375 running bpv: 1.990953
COMMANDS_FINISHED 494 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_22/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_22/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_22/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_22/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_22/self_attn.k_proj/compressed.log
best_loss 353.3033142089844 running bpv: 1.991024
COMMANDS_FINISHED  27%|‚ñà‚ñà‚ñã       | 495/1848 [16:13:31<41:50:58, 111.35s/it] 27%|‚ñà‚ñà‚ñã       | 496/1848 [16:16:26<48:59:29, 130.45s/it] 27%|‚ñà‚ñà‚ñã       | 497/1848 [16:22:11<73:06:46, 194.82s/it] 27%|‚ñà‚ñà‚ñã       | 498/1848 [16:22:26<52:49:45, 140.88s/it] 27%|‚ñà‚ñà‚ñã       | 499/1848 [16:25:01<54:22:45, 145.12s/it] 27%|‚ñà‚ñà‚ñã       | 500/1848 [16:27:16<53:12:13, 142.09s/it]495 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_24/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_24/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_24/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_22/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_22/self_attn.o_proj/compressed.log
best_loss 16.082727432250977 running bpv: 1.991094
COMMANDS_FINISHED 496 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_24/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_24/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_24/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_22/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_22/self_attn.v_proj/compressed.log
best_loss 241.33746337890625 running bpv: 1.991164
COMMANDS_FINISHED 497 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_24/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_24/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_24/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_24/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_24/self_attn.q_proj/compressed.log
best_loss 341.65850830078125 running bpv: 1.991234
COMMANDS_FINISHED 498 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_24/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_24/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_24/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_22/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_22/mlp.down_proj/compressed.log
best_loss 60.098411560058594 running bpv: 1.991036
COMMANDS_FINISHED 499 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_24/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_24/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_24/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_24/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_24/mlp.gate_proj/compressed.log
best_loss 527.2381591796875 running bpv: 1.99084
COMMANDS_FINISHED 500 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_24/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_24/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_24/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_24/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_24/mlp.up_proj/compressed.log
best_loss 447.04681396484375 running bpv: 1.990645
COMMANDS_FINISHED 501 n_commands 1849
 27%|‚ñà‚ñà‚ñã       | 501/1848 [16:27:51<41:08:41, 109.96s/it] 27%|‚ñà‚ñà‚ñã       | 502/1848 [16:28:06<30:27:47, 81.48s/it]  27%|‚ñà‚ñà‚ñã       | 503/1848 [16:33:01<54:22:31, 145.54s/it] 27%|‚ñà‚ñà‚ñã       | 504/1848 [16:38:46<76:40:38, 205.39s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/pajama/128/layer_24/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_24/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_24/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_24/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_24/self_attn.k_proj/compressed.log
best_loss 349.7667236328125 running bpv: 1.990715
COMMANDS_FINISHED 502 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/hessians_new/pajama/128/layer_3/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_3/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_3/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_24/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_24/self_attn.o_proj/compressed.log
best_loss 14.546026229858398 running bpv: 1.990784
COMMANDS_FINISHED 503 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/hessians_new/pajama/128/layer_3/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_3/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_3/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_24/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_24/self_attn.v_proj/compressed.log
best_loss 247.17478942871094 running bpv: 1.990854
COMMANDS_FINISHED 504 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/hessians_new/pajama/128/layer_3/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_3/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_3/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf
meta-llama/Llama-2-13b-hf/layer_24/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_24/mlp.down_proj/compressed.log
best_loss 63.36486053466797 running bpv: 1.990661
COMMANDS_FINISHED 505 n_commands 1849
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/hessians_new/pajama/128/layer_3/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_3/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_3/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf
done with meta-llama/Llama-2-13b-hf
done with {'meta-llama/Llama-2-13b-hf/layer_3/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_3/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_3/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_3/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_3/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_3/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_3/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_3/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_3/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_3/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_3/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_3/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_5/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_5/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_3/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_3/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_5/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_5/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_5/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_5/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_5/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_5/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_5/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_5/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_5/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_5/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_5/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_5/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_8/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_8/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_8/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_8/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_8/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_8/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_8/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_8/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_8/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_8/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_8/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_8/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_39/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_39/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_8/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_8/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_39/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_39/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_39/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_39/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_39/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_39/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_39/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_39/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_39/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_39/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_12/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_12/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_39/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_39/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_12/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_12/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_12/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_12/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_12/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_12/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_12/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_12/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_12/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_12/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_1/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_1/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_12/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_12/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_1/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_1/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_1/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_1/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_1/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_1/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_1/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_1/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_1/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_1/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_7/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_7/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_1/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_1/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_7/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_7/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_7/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_7/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_7/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_7/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_7/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_7/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_7/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_7/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_33/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_33/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_7/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_7/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_33/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_33/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_33/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_33/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_33/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_33/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_33/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_33/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_33/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_33/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_34/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_34/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_33/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_33/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_34/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_34/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_34/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_34/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_34/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_34/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_34/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_34/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_34/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_34/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_0/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_0/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_34/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_34/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_0/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_0/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_0/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_0/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_0/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_0/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_0/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_0/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_0/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_0/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_32/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_32/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_0/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_0/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_32/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_32/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_32/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_32/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_32/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_32/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_32/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_32/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_32/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_32/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_31/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_31/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_32/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_32/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_31/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_31/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_31/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_31/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_31/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_31/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_31/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_31/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_31/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_31/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_21/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_21/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_31/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_31/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_21/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_21/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_21/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_21/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_21/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_21/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_21/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_21/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_21/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_21/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_26/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_26/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_21/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_21/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_26/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_26/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_26/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_26/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_26/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_26/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_26/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_26/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_26/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_26/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_14/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_14/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_26/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_26/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_14/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_14/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_14/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_14/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_14/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_14/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_14/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_14/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_14/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_14/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_15/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_15/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_14/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_14/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_15/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_15/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_15/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_15/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_15/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_15/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_15/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_15/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_15/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_15/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_4/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_4/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_15/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_15/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_4/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_4/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_4/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_4/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_4/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_4/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_4/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_4/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_4/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_4/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_27/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_27/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_4/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_4/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_27/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_27/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_27/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_27/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_27/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_27/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_27/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_27/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_27/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_27/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_27/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_27/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_2/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_2/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_2/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_2/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_2/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_2/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_2/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_2/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_2/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_2/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_2/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_2/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_36/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_36/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_2/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_2/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_36/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_36/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_36/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_36/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_36/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_36/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_36/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_36/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_36/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_36/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_28/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_28/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_36/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_36/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_28/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_28/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_28/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_28/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_28/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_28/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_28/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_28/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_28/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_28/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_18/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_18/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_28/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_28/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_18/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_18/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_18/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_18/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_18/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_18/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_18/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_18/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_18/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_18/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_25/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_25/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_18/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_18/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_25/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_25/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_25/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_25/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_25/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_25/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_25/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_25/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_25/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_25/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_37/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_37/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_25/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_25/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_37/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_37/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_37/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_37/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_37/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_37/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_37/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_37/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_37/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_37/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_30/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_30/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_37/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_37/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_30/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_30/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_30/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_30/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_30/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_30/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_30/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_30/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_30/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_30/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_30/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_30/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_29/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_29/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_29/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_29/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_29/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_29/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_29/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_29/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_29/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_29/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_29/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_29/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_16/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_16/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_29/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_29/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_16/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_16/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_16/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_16/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_16/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_16/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_16/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_16/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_16/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_16/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_13/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_13/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_16/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_16/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_13/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_13/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_13/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_13/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_13/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_13/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_13/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_13/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_13/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_13/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_10/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_10/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_13/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_13/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_10/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_10/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_10/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_10/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_10/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_10/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_10/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_10/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_10/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_10/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_19/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_19/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_10/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_10/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_19/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_19/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_19/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_19/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_19/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_19/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_19/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_19/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_19/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_19/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_6/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_6/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_19/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_19/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_6/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_6/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_6/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_6/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_6/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_6/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_6/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_6/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_6/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_6/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_11/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_11/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_6/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_6/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_11/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_11/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_11/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_11/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_11/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_11/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_11/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_11/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_11/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_11/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_20/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_20/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_11/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_11/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_20/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_20/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_20/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_20/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_20/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_20/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_20/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_20/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_20/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_20/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_23/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_23/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_20/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_20/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_23/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_23/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_23/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_23/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_23/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_23/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_23/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_23/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_23/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_23/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_35/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_35/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_23/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_23/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_35/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_35/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_35/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_35/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_35/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_35/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_35/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_35/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_35/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_35/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_38/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_38/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_35/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_35/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_38/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_38/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_38/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_38/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_38/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_38/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_38/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_38/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_38/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_38/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_17/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_17/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_38/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_38/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_17/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_17/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_17/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_17/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_17/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_17/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_17/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_17/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_17/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_17/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_9/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_9/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_17/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_17/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_9/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_9/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_9/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_9/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_9/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_9/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_9/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_9/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_9/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_9/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_22/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_22/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_9/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_9/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_22/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_22/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_22/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_22/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_22/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_22/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_22/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_22/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_22/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_22/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_24/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_24/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_22/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_22/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_24/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_24/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_24/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_24/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_24/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_24/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_24/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_24/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_24/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_24/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_24/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-13b-hf/layer_24/mlp.down_proj/compressed.pt'} 27%|‚ñà‚ñà‚ñã       | 505/1848 [16:41:21<70:59:11, 190.28s/it] 27%|‚ñà‚ñà‚ñã       | 506/1848 [16:46:06<81:31:44, 218.71s/it] 27%|‚ñà‚ñà‚ñã       | 507/1848 [16:59:16<145:19:01, 390.11s/it] 27%|‚ñà‚ñà‚ñã       | 508/1848 [17:01:52<118:57:22, 319.58s/it]
/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/checkpoints.yaml
perplexity_inference_command:
 python -u perplexity_eval.py --base_model meta-llama/Llama-2-13b-hf --seqlen 4096 --checkpoint_list_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/checkpoints.yaml --log_wandb --wandb_project compression_no_finetune --wandb_id tdxolj32
meta-llama/Llama-2-70b-hf/layer_3/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_3/self_attn.k_proj/compressed.log
best_loss 3.9219002723693848 running bpv: 1.990836
COMMANDS_FINISHED 506 n_commands 1850
running: nohup python -u perplexity_eval.py --base_model meta-llama/Llama-2-13b-hf --seqlen 4096 --checkpoint_list_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/checkpoints.yaml --log_wandb --wandb_project compression_no_finetune --wandb_id tdxolj32 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/legendary-aardvark-58/ppl_eval.log 2>&1 &
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf/layer_3/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_3/self_attn.q_proj/compressed.log
best_loss 16.313995361328125 running bpv: 1.990664
COMMANDS_FINISHED 507 n_commands 1850
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/hessians_new/pajama/128/layer_3/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_3/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_3/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
eval is done
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/hessians_new/pajama/128/layer_3/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_3/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_3/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf/layer_3/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_3/self_attn.o_proj/compressed.log
best_loss 0.35620468854904175 running bpv: 1.990493
COMMANDS_FINISHED 509 n_commands 1850
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/hessians_new/pajama/128/layer_3/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_3/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_3/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf/layer_3/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_3/self_attn.v_proj/compressed.log
best_loss 0.6562741994857788 running bpv: 1.990667
COMMANDS_FINISHED 510 n_commands 1850
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/hessians_new/pajama/128/layer_5/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_5/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_5/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
 28%|‚ñà‚ñà‚ñä       | 509/1848 [17:11:47<149:36:18, 402.22s/it] 28%|‚ñà‚ñà‚ñä       | 510/1848 [17:12:02<106:19:06, 286.06s/it] 28%|‚ñà‚ñà‚ñä       | 511/1848 [17:25:07<161:50:10, 435.76s/it] 28%|‚ñà‚ñà‚ñä       | 512/1848 [17:27:42<130:27:34, 351.54s/it]meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf/layer_3/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_3/mlp.up_proj/compressed.log
best_loss 31.15378761291504 running bpv: 1.989522
COMMANDS_FINISHED 511 n_commands 1850
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/hessians_new/pajama/128/layer_5/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_5/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_5/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf/layer_3/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_3/mlp.gate_proj/compressed.log
best_loss 34.28466796875 running bpv: 1.988405
COMMANDS_FINISHED 512 n_commands 1850
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/hessians_new/pajama/128/layer_5/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_5/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_5/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf/layer_5/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_5/self_attn.q_proj/compressed.log
best_loss 43.35441589355469 running bpv: 1.988246
COMMANDS_FINISHED 513 n_commands 1850
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/hessians_new/pajama/128/layer_5/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_5/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_5/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf/layer_5/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_5/self_attn.k_proj/compressed.log
best_loss 9.205645561218262 running bpv: 1.988417
COMMANDS_FINISHED 514 n_commands 1850
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/hessians_new/pajama/128/layer_5/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_5/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_5/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
 28%|‚ñà‚ñà‚ñä       | 513/1848 [17:38:27<163:00:55, 439.59s/it] 28%|‚ñà‚ñà‚ñä       | 514/1848 [17:40:52<130:08:45, 351.22s/it] 28%|‚ñà‚ñà‚ñä       | 515/1848 [17:43:57<111:35:09, 301.36s/it] 28%|‚ñà‚ñà‚ñä       | 516/1848 [17:46:02<91:55:41, 248.45s/it]  28%|‚ñà‚ñà‚ñä       | 517/1848 [17:55:27<126:58:26, 343.43s/it]meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf/layer_3/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_3/mlp.down_proj/compressed.log
best_loss 0.5937985181808472 running bpv: 1.987329
COMMANDS_FINISHED 515 n_commands 1850
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/hessians_new/pajama/128/layer_5/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_5/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_5/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf/layer_5/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_5/self_attn.o_proj/compressed.log
best_loss 0.5603199601173401 running bpv: 1.987176
COMMANDS_FINISHED 516 n_commands 1850
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/hessians_new/pajama/128/layer_5/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_5/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_5/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf/layer_5/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_5/self_attn.v_proj/compressed.log
best_loss 77.32087707519531 running bpv: 1.987345
COMMANDS_FINISHED 517 n_commands 1850
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/hessians_new/pajama/128/layer_8/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_8/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_8/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf/layer_5/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_5/mlp.gate_proj/compressed.log
best_loss 59.97560119628906 running bpv: 1.986286
COMMANDS_FINISHED 518 n_commands 1850
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/hessians_new/pajama/128/layer_8/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_8/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_8/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf/layer_5/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_5/mlp.up_proj/compressed.log
best_loss 54.21388626098633 running bpv: 1.985251
COMMANDS_FINISHED 519 n_commands 1850
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/hessians_new/pajama/128/layer_8/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_8/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_8/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
 28%|‚ñà‚ñà‚ñä       | 518/1848 [18:08:32<175:49:33, 475.92s/it] 28%|‚ñà‚ñà‚ñä       | 519/1848 [18:11:07<140:09:13, 379.65s/it] 28%|‚ñà‚ñà‚ñä       | 520/1848 [18:23:42<181:35:35, 492.27s/it] 28%|‚ñà‚ñà‚ñä       | 521/1848 [18:24:07<129:47:05, 352.09s/it] 28%|‚ñà‚ñà‚ñä       | 522/1848 [18:26:42<107:54:36, 292.97s/it]meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf/layer_8/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_8/self_attn.q_proj/compressed.log
best_loss 68.32754516601562 running bpv: 1.985109
COMMANDS_FINISHED 520 n_commands 1850
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/hessians_new/pajama/128/layer_8/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_8/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_8/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf/layer_8/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_8/self_attn.k_proj/compressed.log
best_loss 15.98597240447998 running bpv: 1.985274
COMMANDS_FINISHED 521 n_commands 1850
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/hessians_new/pajama/128/layer_8/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_8/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_8/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf/layer_5/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_5/mlp.down_proj/compressed.log
best_loss 1.2569677829742432 running bpv: 1.984266
COMMANDS_FINISHED 522 n_commands 1850
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/hessians_new/pajama/128/layer_8/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_8/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_8/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf/layer_8/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_8/self_attn.o_proj/compressed.log
best_loss 2.4322896003723145 running bpv: 1.984129
COMMANDS_FINISHED 523 n_commands 1850
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/hessians_new/pajama/128/layer_8/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_8/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_8/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf/layer_8/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_8/self_attn.v_proj/compressed.log
best_loss 2.8311805725097656 running bpv: 1.984292
COMMANDS_FINISHED 524 n_commands 1850
 28%|‚ñà‚ñà‚ñä       | 523/1848 [18:27:57<83:45:45, 227.58s/it]  28%|‚ñà‚ñà‚ñä       | 524/1848 [18:30:12<73:29:09, 199.81s/it] 28%|‚ñà‚ñà‚ñä       | 525/1848 [18:43:17<137:57:16, 375.39s/it] 28%|‚ñà‚ñà‚ñä       | 526/1848 [18:45:52<113:34:20, 309.27s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/hessians_new/pajama/128/layer_76/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_76/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_76/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf/layer_8/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_8/mlp.gate_proj/compressed.log
best_loss 125.47659301757812 running bpv: 1.98331
COMMANDS_FINISHED 525 n_commands 1850
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/hessians_new/pajama/128/layer_76/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_76/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_76/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf/layer_8/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_8/mlp.up_proj/compressed.log
best_loss 109.79869079589844 running bpv: 1.982349
COMMANDS_FINISHED 526 n_commands 1850
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/hessians_new/pajama/128/layer_76/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_76/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_76/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf/layer_76/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_76/self_attn.q_proj/compressed.log
best_loss 280.7800598144531 running bpv: 1.982222
COMMANDS_FINISHED 527 n_commands 1850
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/hessians_new/pajama/128/layer_76/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_76/self_attn.k_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_76/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf/layer_76/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_76/self_attn.k_proj/compressed.log
best_loss 55.41348648071289 running bpv: 1.982381
COMMANDS_FINISHED 528 n_commands 1850
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/hessians_new/pajama/128/layer_76/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_76/self_attn.o_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_76/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf 29%|‚ñà‚ñà‚ñä       | 527/1848 [18:58:57<165:51:47, 452.01s/it] 29%|‚ñà‚ñà‚ñä       | 528/1848 [19:08:52<181:28:16, 494.92s/it] 29%|‚ñà‚ñà‚ñä       | 529/1848 [19:10:27<137:22:37, 374.95s/it] 29%|‚ñà‚ñà‚ñä       | 530/1848 [19:11:22<102:07:57, 278.97s/it] 29%|‚ñà‚ñà‚ñä       | 531/1848 [19:11:57<75:16:50, 205.78s/it] 
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf/layer_76/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_76/self_attn.o_proj/compressed.log
best_loss 186.60772705078125 running bpv: 1.982254
COMMANDS_FINISHED 529 n_commands 1850
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/hessians_new/pajama/128/layer_76/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_76/mlp.down_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_76/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf/layer_8/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_8/mlp.down_proj/compressed.log
best_loss 565.3014526367188 running bpv: 1.981321
COMMANDS_FINISHED 530 n_commands 1850
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/hessians_new/pajama/128/layer_76/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_76/self_attn.v_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_76/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf/layer_76/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_76/mlp.gate_proj/compressed.log
best_loss 1953.238525390625 running bpv: 1.980408
COMMANDS_FINISHED 531 n_commands 1850
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/hessians_new/pajama/128/layer_66/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_66/mlp.gate_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:7 > /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_66/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf/layer_76/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_76/self_attn.v_proj/compressed.log
best_loss 60.01142120361328 running bpv: 1.980564
COMMANDS_FINISHED 532 n_commands 1850
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/hessians_new/pajama/128/layer_66/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_66/mlp.up_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_66/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf/layer_76/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_76/mlp.up_proj/compressed.log
best_loss 1770.4189453125 running bpv: 1.979669
COMMANDS_FINISHED 533 n_commands 1850
running: nohup python -u scripts/1layer_compress/quantize_compress.py --load_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/hessians_new/pajama/128/layer_66/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_66/self_attn.q_proj/compressed.pt --yaml_path /data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/legendary-aardvark-58/meta-llama/Llama-2-70b-hf/layer_66/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
meta-llama/Llama-2-70b-hf
 29%|‚ñà‚ñà‚ñâ       | 532/1848 [19:25:02<138:45:08, 379.57s/it] 29%|‚ñà‚ñà‚ñâ       | 533/1848 [19:27:37<114:02:23, 312.20s/it]Terminated
