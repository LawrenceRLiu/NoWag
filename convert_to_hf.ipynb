{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# set to auto reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "!CUDA_VISIBLE_DEVICES=0,1\n",
    "\n",
    "import torch\n",
    "import yaml \n",
    "import os \n",
    "import glob\n",
    "import argparse\n",
    "from src.model.llama import LlamaForCausalLM\n",
    "from transformers import LlamaForCausalLM as OrigLlama\n",
    "from transformers import AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"meta-llama/Llama-2-70b-hf\"\n",
    "checkpoints_path = \"/data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed/run_18/checkpoints.yaml\"\n",
    "hf_model_save_path = \"/data/lliu/huffman/models/meta-llama/Llama-2-70b-hf/compressed_hf/run_18/\"\n",
    "add_bias = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a935ec18594463f98292aa501f034b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "orig_config = AutoConfig.from_pretrained(base_model,dtype = \"auto\",\n",
    "                                         device_map=\"cpu\",\n",
    "                                        attn_implementation='sdpa')\n",
    "orig_model = OrigLlama.from_pretrained(base_model, config=orig_config, torch_dtype=\"auto\",\n",
    "                                        device_map=\"cpu\",\n",
    "                                        low_cpu_mem_usage=True, attn_implementation='sdpa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in orig_model.named_parameters():\n",
    "    assert param.dtype == torch.float16, f\"{name} is not fp16, it is {param.dtype}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_dict = yaml.load(open(checkpoints_path, \"r\"), Loader=yaml.FullLoader)\n",
    "\n",
    "\n",
    "compression_kwargs = yaml.load(open((checkpoints_dict[list(checkpoints_dict.keys())[0]]).replace(\"compressed.pt\", \"compressed_args.yaml\")),\n",
    "                                Loader=yaml.FullLoader)\n",
    "#check that all the other checkpoints have the same compression args\n",
    "for checkpoint in checkpoints_dict.values():\n",
    "    assert compression_kwargs == yaml.load(open(checkpoint.replace(\"compressed.pt\", \"compressed_args.yaml\"), \"r\"), Loader=yaml.FullLoader)\n",
    "\n",
    "#remove dtype from the compression kwargs\n",
    "compression_kwargs.pop(\"dtype\", None)\n",
    "\n",
    "compression_type = compression_kwargs[\"compression_type\"]\n",
    "\n",
    "\n",
    "compression_config = {\"compression_kwargs\": compression_kwargs, \"compression_type\": compression_type,\n",
    "                        \"add_bias\": add_bias, \"skip_list\":None}\n",
    "\n",
    "orig_config.compress_config = compression_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['model.layers.0.self_attn.q_proj.bias', 'model.layers.0.self_attn.q_proj.codebook', 'model.layers.0.self_attn.q_proj.assignments', 'model.layers.0.self_attn.q_proj.normalizer.norms.0', 'model.layers.0.self_attn.q_proj.normalizer.norms.1', 'model.layers.0.self_attn.q_proj.normalizer.zeros.0', 'model.layers.0.self_attn.q_proj.normalizer.zeros.1', 'model.layers.0.self_attn.k_proj.bias', 'model.layers.0.self_attn.k_proj.codebook', 'model.layers.0.self_attn.k_proj.assignments', 'model.layers.0.self_attn.k_proj.normalizer.norms.0', 'model.layers.0.self_attn.k_proj.normalizer.norms.1', 'model.layers.0.self_attn.k_proj.normalizer.zeros.0', 'model.layers.0.self_attn.k_proj.normalizer.zeros.1', 'model.layers.0.self_attn.v_proj.bias', 'model.layers.0.self_attn.v_proj.codebook', 'model.layers.0.self_attn.v_proj.assignments', 'model.layers.0.self_attn.v_proj.normalizer.norms.0', 'model.layers.0.self_attn.v_proj.normalizer.norms.1', 'model.layers.0.self_attn.v_proj.normalizer.zeros.0', 'model.layers.0.self_attn.v_proj.normalizer.zeros.1', 'model.layers.0.self_attn.o_proj.bias', 'model.layers.0.self_attn.o_proj.codebook', 'model.layers.0.self_attn.o_proj.assignments', 'model.layers.0.self_attn.o_proj.normalizer.norms.0', 'model.layers.0.self_attn.o_proj.normalizer.norms.1', 'model.layers.0.self_attn.o_proj.normalizer.zeros.0', 'model.layers.0.self_attn.o_proj.normalizer.zeros.1', 'model.layers.0.mlp.gate_proj.bias', 'model.layers.0.mlp.gate_proj.codebook', 'model.layers.0.mlp.gate_proj.assignments', 'model.layers.0.mlp.gate_proj.normalizer.norms.0', 'model.layers.0.mlp.gate_proj.normalizer.norms.1', 'model.layers.0.mlp.gate_proj.normalizer.zeros.0', 'model.layers.0.mlp.gate_proj.normalizer.zeros.1', 'model.layers.0.mlp.up_proj.bias', 'model.layers.0.mlp.up_proj.codebook', 'model.layers.0.mlp.up_proj.assignments', 'model.layers.0.mlp.up_proj.normalizer.norms.0', 'model.layers.0.mlp.up_proj.normalizer.norms.1', 'model.layers.0.mlp.up_proj.normalizer.zeros.0', 'model.layers.0.mlp.up_proj.normalizer.zeros.1', 'model.layers.0.mlp.down_proj.bias', 'model.layers.0.mlp.down_proj.codebook', 'model.layers.0.mlp.down_proj.assignments', 'model.layers.0.mlp.down_proj.normalizer.norms.0', 'model.layers.0.mlp.down_proj.normalizer.norms.1', 'model.layers.0.mlp.down_proj.normalizer.zeros.0', 'model.layers.0.mlp.down_proj.normalizer.zeros.1', 'model.layers.1.self_attn.q_proj.bias', 'model.layers.1.self_attn.q_proj.codebook', 'model.layers.1.self_attn.q_proj.assignments', 'model.layers.1.self_attn.q_proj.normalizer.norms.0', 'model.layers.1.self_attn.q_proj.normalizer.norms.1', 'model.layers.1.self_attn.q_proj.normalizer.zeros.0', 'model.layers.1.self_attn.q_proj.normalizer.zeros.1', 'model.layers.1.self_attn.k_proj.bias', 'model.layers.1.self_attn.k_proj.codebook', 'model.layers.1.self_attn.k_proj.assignments', 'model.layers.1.self_attn.k_proj.normalizer.norms.0', 'model.layers.1.self_attn.k_proj.normalizer.norms.1', 'model.layers.1.self_attn.k_proj.normalizer.zeros.0', 'model.layers.1.self_attn.k_proj.normalizer.zeros.1', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.1.self_attn.v_proj.codebook', 'model.layers.1.self_attn.v_proj.assignments', 'model.layers.1.self_attn.v_proj.normalizer.norms.0', 'model.layers.1.self_attn.v_proj.normalizer.norms.1', 'model.layers.1.self_attn.v_proj.normalizer.zeros.0', 'model.layers.1.self_attn.v_proj.normalizer.zeros.1', 'model.layers.1.self_attn.o_proj.bias', 'model.layers.1.self_attn.o_proj.codebook', 'model.layers.1.self_attn.o_proj.assignments', 'model.layers.1.self_attn.o_proj.normalizer.norms.0', 'model.layers.1.self_attn.o_proj.normalizer.norms.1', 'model.layers.1.self_attn.o_proj.normalizer.zeros.0', 'model.layers.1.self_attn.o_proj.normalizer.zeros.1', 'model.layers.1.mlp.gate_proj.bias', 'model.layers.1.mlp.gate_proj.codebook', 'model.layers.1.mlp.gate_proj.assignments', 'model.layers.1.mlp.gate_proj.normalizer.norms.0', 'model.layers.1.mlp.gate_proj.normalizer.norms.1', 'model.layers.1.mlp.gate_proj.normalizer.zeros.0', 'model.layers.1.mlp.gate_proj.normalizer.zeros.1', 'model.layers.1.mlp.up_proj.bias', 'model.layers.1.mlp.up_proj.codebook', 'model.layers.1.mlp.up_proj.assignments', 'model.layers.1.mlp.up_proj.normalizer.norms.0', 'model.layers.1.mlp.up_proj.normalizer.norms.1', 'model.layers.1.mlp.up_proj.normalizer.zeros.0', 'model.layers.1.mlp.up_proj.normalizer.zeros.1', 'model.layers.1.mlp.down_proj.bias', 'model.layers.1.mlp.down_proj.codebook', 'model.layers.1.mlp.down_proj.assignments', 'model.layers.1.mlp.down_proj.normalizer.norms.0', 'model.layers.1.mlp.down_proj.normalizer.norms.1', 'model.layers.1.mlp.down_proj.normalizer.zeros.0', 'model.layers.1.mlp.down_proj.normalizer.zeros.1', 'model.layers.2.self_attn.q_proj.bias', 'model.layers.2.self_attn.q_proj.codebook', 'model.layers.2.self_attn.q_proj.assignments', 'model.layers.2.self_attn.q_proj.normalizer.norms.0', 'model.layers.2.self_attn.q_proj.normalizer.norms.1', 'model.layers.2.self_attn.q_proj.normalizer.zeros.0', 'model.layers.2.self_attn.q_proj.normalizer.zeros.1', 'model.layers.2.self_attn.k_proj.bias', 'model.layers.2.self_attn.k_proj.codebook', 'model.layers.2.self_attn.k_proj.assignments', 'model.layers.2.self_attn.k_proj.normalizer.norms.0', 'model.layers.2.self_attn.k_proj.normalizer.norms.1', 'model.layers.2.self_attn.k_proj.normalizer.zeros.0', 'model.layers.2.self_attn.k_proj.normalizer.zeros.1', 'model.layers.2.self_attn.v_proj.bias', 'model.layers.2.self_attn.v_proj.codebook', 'model.layers.2.self_attn.v_proj.assignments', 'model.layers.2.self_attn.v_proj.normalizer.norms.0', 'model.layers.2.self_attn.v_proj.normalizer.norms.1', 'model.layers.2.self_attn.v_proj.normalizer.zeros.0', 'model.layers.2.self_attn.v_proj.normalizer.zeros.1', 'model.layers.2.self_attn.o_proj.bias', 'model.layers.2.self_attn.o_proj.codebook', 'model.layers.2.self_attn.o_proj.assignments', 'model.layers.2.self_attn.o_proj.normalizer.norms.0', 'model.layers.2.self_attn.o_proj.normalizer.norms.1', 'model.layers.2.self_attn.o_proj.normalizer.zeros.0', 'model.layers.2.self_attn.o_proj.normalizer.zeros.1', 'model.layers.2.mlp.gate_proj.bias', 'model.layers.2.mlp.gate_proj.codebook', 'model.layers.2.mlp.gate_proj.assignments', 'model.layers.2.mlp.gate_proj.normalizer.norms.0', 'model.layers.2.mlp.gate_proj.normalizer.norms.1', 'model.layers.2.mlp.gate_proj.normalizer.zeros.0', 'model.layers.2.mlp.gate_proj.normalizer.zeros.1', 'model.layers.2.mlp.up_proj.bias', 'model.layers.2.mlp.up_proj.codebook', 'model.layers.2.mlp.up_proj.assignments', 'model.layers.2.mlp.up_proj.normalizer.norms.0', 'model.layers.2.mlp.up_proj.normalizer.norms.1', 'model.layers.2.mlp.up_proj.normalizer.zeros.0', 'model.layers.2.mlp.up_proj.normalizer.zeros.1', 'model.layers.2.mlp.down_proj.bias', 'model.layers.2.mlp.down_proj.codebook', 'model.layers.2.mlp.down_proj.assignments', 'model.layers.2.mlp.down_proj.normalizer.norms.0', 'model.layers.2.mlp.down_proj.normalizer.norms.1', 'model.layers.2.mlp.down_proj.normalizer.zeros.0', 'model.layers.2.mlp.down_proj.normalizer.zeros.1', 'model.layers.3.self_attn.q_proj.bias', 'model.layers.3.self_attn.q_proj.codebook', 'model.layers.3.self_attn.q_proj.assignments', 'model.layers.3.self_attn.q_proj.normalizer.norms.0', 'model.layers.3.self_attn.q_proj.normalizer.norms.1', 'model.layers.3.self_attn.q_proj.normalizer.zeros.0', 'model.layers.3.self_attn.q_proj.normalizer.zeros.1', 'model.layers.3.self_attn.k_proj.bias', 'model.layers.3.self_attn.k_proj.codebook', 'model.layers.3.self_attn.k_proj.assignments', 'model.layers.3.self_attn.k_proj.normalizer.norms.0', 'model.layers.3.self_attn.k_proj.normalizer.norms.1', 'model.layers.3.self_attn.k_proj.normalizer.zeros.0', 'model.layers.3.self_attn.k_proj.normalizer.zeros.1', 'model.layers.3.self_attn.v_proj.bias', 'model.layers.3.self_attn.v_proj.codebook', 'model.layers.3.self_attn.v_proj.assignments', 'model.layers.3.self_attn.v_proj.normalizer.norms.0', 'model.layers.3.self_attn.v_proj.normalizer.norms.1', 'model.layers.3.self_attn.v_proj.normalizer.zeros.0', 'model.layers.3.self_attn.v_proj.normalizer.zeros.1', 'model.layers.3.self_attn.o_proj.bias', 'model.layers.3.self_attn.o_proj.codebook', 'model.layers.3.self_attn.o_proj.assignments', 'model.layers.3.self_attn.o_proj.normalizer.norms.0', 'model.layers.3.self_attn.o_proj.normalizer.norms.1', 'model.layers.3.self_attn.o_proj.normalizer.zeros.0', 'model.layers.3.self_attn.o_proj.normalizer.zeros.1', 'model.layers.3.mlp.gate_proj.bias', 'model.layers.3.mlp.gate_proj.codebook', 'model.layers.3.mlp.gate_proj.assignments', 'model.layers.3.mlp.gate_proj.normalizer.norms.0', 'model.layers.3.mlp.gate_proj.normalizer.norms.1', 'model.layers.3.mlp.gate_proj.normalizer.zeros.0', 'model.layers.3.mlp.gate_proj.normalizer.zeros.1', 'model.layers.3.mlp.up_proj.bias', 'model.layers.3.mlp.up_proj.codebook', 'model.layers.3.mlp.up_proj.assignments', 'model.layers.3.mlp.up_proj.normalizer.norms.0', 'model.layers.3.mlp.up_proj.normalizer.norms.1', 'model.layers.3.mlp.up_proj.normalizer.zeros.0', 'model.layers.3.mlp.up_proj.normalizer.zeros.1', 'model.layers.3.mlp.down_proj.bias', 'model.layers.3.mlp.down_proj.codebook', 'model.layers.3.mlp.down_proj.assignments', 'model.layers.3.mlp.down_proj.normalizer.norms.0', 'model.layers.3.mlp.down_proj.normalizer.norms.1', 'model.layers.3.mlp.down_proj.normalizer.zeros.0', 'model.layers.3.mlp.down_proj.normalizer.zeros.1', 'model.layers.4.self_attn.q_proj.bias', 'model.layers.4.self_attn.q_proj.codebook', 'model.layers.4.self_attn.q_proj.assignments', 'model.layers.4.self_attn.q_proj.normalizer.norms.0', 'model.layers.4.self_attn.q_proj.normalizer.norms.1', 'model.layers.4.self_attn.q_proj.normalizer.zeros.0', 'model.layers.4.self_attn.q_proj.normalizer.zeros.1', 'model.layers.4.self_attn.k_proj.bias', 'model.layers.4.self_attn.k_proj.codebook', 'model.layers.4.self_attn.k_proj.assignments', 'model.layers.4.self_attn.k_proj.normalizer.norms.0', 'model.layers.4.self_attn.k_proj.normalizer.norms.1', 'model.layers.4.self_attn.k_proj.normalizer.zeros.0', 'model.layers.4.self_attn.k_proj.normalizer.zeros.1', 'model.layers.4.self_attn.v_proj.bias', 'model.layers.4.self_attn.v_proj.codebook', 'model.layers.4.self_attn.v_proj.assignments', 'model.layers.4.self_attn.v_proj.normalizer.norms.0', 'model.layers.4.self_attn.v_proj.normalizer.norms.1', 'model.layers.4.self_attn.v_proj.normalizer.zeros.0', 'model.layers.4.self_attn.v_proj.normalizer.zeros.1', 'model.layers.4.self_attn.o_proj.bias', 'model.layers.4.self_attn.o_proj.codebook', 'model.layers.4.self_attn.o_proj.assignments', 'model.layers.4.self_attn.o_proj.normalizer.norms.0', 'model.layers.4.self_attn.o_proj.normalizer.norms.1', 'model.layers.4.self_attn.o_proj.normalizer.zeros.0', 'model.layers.4.self_attn.o_proj.normalizer.zeros.1', 'model.layers.4.mlp.gate_proj.bias', 'model.layers.4.mlp.gate_proj.codebook', 'model.layers.4.mlp.gate_proj.assignments', 'model.layers.4.mlp.gate_proj.normalizer.norms.0', 'model.layers.4.mlp.gate_proj.normalizer.norms.1', 'model.layers.4.mlp.gate_proj.normalizer.zeros.0', 'model.layers.4.mlp.gate_proj.normalizer.zeros.1', 'model.layers.4.mlp.up_proj.bias', 'model.layers.4.mlp.up_proj.codebook', 'model.layers.4.mlp.up_proj.assignments', 'model.layers.4.mlp.up_proj.normalizer.norms.0', 'model.layers.4.mlp.up_proj.normalizer.norms.1', 'model.layers.4.mlp.up_proj.normalizer.zeros.0', 'model.layers.4.mlp.up_proj.normalizer.zeros.1', 'model.layers.4.mlp.down_proj.bias', 'model.layers.4.mlp.down_proj.codebook', 'model.layers.4.mlp.down_proj.assignments', 'model.layers.4.mlp.down_proj.normalizer.norms.0', 'model.layers.4.mlp.down_proj.normalizer.norms.1', 'model.layers.4.mlp.down_proj.normalizer.zeros.0', 'model.layers.4.mlp.down_proj.normalizer.zeros.1', 'model.layers.5.self_attn.q_proj.bias', 'model.layers.5.self_attn.q_proj.codebook', 'model.layers.5.self_attn.q_proj.assignments', 'model.layers.5.self_attn.q_proj.normalizer.norms.0', 'model.layers.5.self_attn.q_proj.normalizer.norms.1', 'model.layers.5.self_attn.q_proj.normalizer.zeros.0', 'model.layers.5.self_attn.q_proj.normalizer.zeros.1', 'model.layers.5.self_attn.k_proj.bias', 'model.layers.5.self_attn.k_proj.codebook', 'model.layers.5.self_attn.k_proj.assignments', 'model.layers.5.self_attn.k_proj.normalizer.norms.0', 'model.layers.5.self_attn.k_proj.normalizer.norms.1', 'model.layers.5.self_attn.k_proj.normalizer.zeros.0', 'model.layers.5.self_attn.k_proj.normalizer.zeros.1', 'model.layers.5.self_attn.v_proj.bias', 'model.layers.5.self_attn.v_proj.codebook', 'model.layers.5.self_attn.v_proj.assignments', 'model.layers.5.self_attn.v_proj.normalizer.norms.0', 'model.layers.5.self_attn.v_proj.normalizer.norms.1', 'model.layers.5.self_attn.v_proj.normalizer.zeros.0', 'model.layers.5.self_attn.v_proj.normalizer.zeros.1', 'model.layers.5.self_attn.o_proj.bias', 'model.layers.5.self_attn.o_proj.codebook', 'model.layers.5.self_attn.o_proj.assignments', 'model.layers.5.self_attn.o_proj.normalizer.norms.0', 'model.layers.5.self_attn.o_proj.normalizer.norms.1', 'model.layers.5.self_attn.o_proj.normalizer.zeros.0', 'model.layers.5.self_attn.o_proj.normalizer.zeros.1', 'model.layers.5.mlp.gate_proj.bias', 'model.layers.5.mlp.gate_proj.codebook', 'model.layers.5.mlp.gate_proj.assignments', 'model.layers.5.mlp.gate_proj.normalizer.norms.0', 'model.layers.5.mlp.gate_proj.normalizer.norms.1', 'model.layers.5.mlp.gate_proj.normalizer.zeros.0', 'model.layers.5.mlp.gate_proj.normalizer.zeros.1', 'model.layers.5.mlp.up_proj.bias', 'model.layers.5.mlp.up_proj.codebook', 'model.layers.5.mlp.up_proj.assignments', 'model.layers.5.mlp.up_proj.normalizer.norms.0', 'model.layers.5.mlp.up_proj.normalizer.norms.1', 'model.layers.5.mlp.up_proj.normalizer.zeros.0', 'model.layers.5.mlp.up_proj.normalizer.zeros.1', 'model.layers.5.mlp.down_proj.bias', 'model.layers.5.mlp.down_proj.codebook', 'model.layers.5.mlp.down_proj.assignments', 'model.layers.5.mlp.down_proj.normalizer.norms.0', 'model.layers.5.mlp.down_proj.normalizer.norms.1', 'model.layers.5.mlp.down_proj.normalizer.zeros.0', 'model.layers.5.mlp.down_proj.normalizer.zeros.1', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.6.self_attn.q_proj.codebook', 'model.layers.6.self_attn.q_proj.assignments', 'model.layers.6.self_attn.q_proj.normalizer.norms.0', 'model.layers.6.self_attn.q_proj.normalizer.norms.1', 'model.layers.6.self_attn.q_proj.normalizer.zeros.0', 'model.layers.6.self_attn.q_proj.normalizer.zeros.1', 'model.layers.6.self_attn.k_proj.bias', 'model.layers.6.self_attn.k_proj.codebook', 'model.layers.6.self_attn.k_proj.assignments', 'model.layers.6.self_attn.k_proj.normalizer.norms.0', 'model.layers.6.self_attn.k_proj.normalizer.norms.1', 'model.layers.6.self_attn.k_proj.normalizer.zeros.0', 'model.layers.6.self_attn.k_proj.normalizer.zeros.1', 'model.layers.6.self_attn.v_proj.bias', 'model.layers.6.self_attn.v_proj.codebook', 'model.layers.6.self_attn.v_proj.assignments', 'model.layers.6.self_attn.v_proj.normalizer.norms.0', 'model.layers.6.self_attn.v_proj.normalizer.norms.1', 'model.layers.6.self_attn.v_proj.normalizer.zeros.0', 'model.layers.6.self_attn.v_proj.normalizer.zeros.1', 'model.layers.6.self_attn.o_proj.bias', 'model.layers.6.self_attn.o_proj.codebook', 'model.layers.6.self_attn.o_proj.assignments', 'model.layers.6.self_attn.o_proj.normalizer.norms.0', 'model.layers.6.self_attn.o_proj.normalizer.norms.1', 'model.layers.6.self_attn.o_proj.normalizer.zeros.0', 'model.layers.6.self_attn.o_proj.normalizer.zeros.1', 'model.layers.6.mlp.gate_proj.bias', 'model.layers.6.mlp.gate_proj.codebook', 'model.layers.6.mlp.gate_proj.assignments', 'model.layers.6.mlp.gate_proj.normalizer.norms.0', 'model.layers.6.mlp.gate_proj.normalizer.norms.1', 'model.layers.6.mlp.gate_proj.normalizer.zeros.0', 'model.layers.6.mlp.gate_proj.normalizer.zeros.1', 'model.layers.6.mlp.up_proj.bias', 'model.layers.6.mlp.up_proj.codebook', 'model.layers.6.mlp.up_proj.assignments', 'model.layers.6.mlp.up_proj.normalizer.norms.0', 'model.layers.6.mlp.up_proj.normalizer.norms.1', 'model.layers.6.mlp.up_proj.normalizer.zeros.0', 'model.layers.6.mlp.up_proj.normalizer.zeros.1', 'model.layers.6.mlp.down_proj.bias', 'model.layers.6.mlp.down_proj.codebook', 'model.layers.6.mlp.down_proj.assignments', 'model.layers.6.mlp.down_proj.normalizer.norms.0', 'model.layers.6.mlp.down_proj.normalizer.norms.1', 'model.layers.6.mlp.down_proj.normalizer.zeros.0', 'model.layers.6.mlp.down_proj.normalizer.zeros.1', 'model.layers.7.self_attn.q_proj.bias', 'model.layers.7.self_attn.q_proj.codebook', 'model.layers.7.self_attn.q_proj.assignments', 'model.layers.7.self_attn.q_proj.normalizer.norms.0', 'model.layers.7.self_attn.q_proj.normalizer.norms.1', 'model.layers.7.self_attn.q_proj.normalizer.zeros.0', 'model.layers.7.self_attn.q_proj.normalizer.zeros.1', 'model.layers.7.self_attn.k_proj.bias', 'model.layers.7.self_attn.k_proj.codebook', 'model.layers.7.self_attn.k_proj.assignments', 'model.layers.7.self_attn.k_proj.normalizer.norms.0', 'model.layers.7.self_attn.k_proj.normalizer.norms.1', 'model.layers.7.self_attn.k_proj.normalizer.zeros.0', 'model.layers.7.self_attn.k_proj.normalizer.zeros.1', 'model.layers.7.self_attn.v_proj.bias', 'model.layers.7.self_attn.v_proj.codebook', 'model.layers.7.self_attn.v_proj.assignments', 'model.layers.7.self_attn.v_proj.normalizer.norms.0', 'model.layers.7.self_attn.v_proj.normalizer.norms.1', 'model.layers.7.self_attn.v_proj.normalizer.zeros.0', 'model.layers.7.self_attn.v_proj.normalizer.zeros.1', 'model.layers.7.self_attn.o_proj.bias', 'model.layers.7.self_attn.o_proj.codebook', 'model.layers.7.self_attn.o_proj.assignments', 'model.layers.7.self_attn.o_proj.normalizer.norms.0', 'model.layers.7.self_attn.o_proj.normalizer.norms.1', 'model.layers.7.self_attn.o_proj.normalizer.zeros.0', 'model.layers.7.self_attn.o_proj.normalizer.zeros.1', 'model.layers.7.mlp.gate_proj.bias', 'model.layers.7.mlp.gate_proj.codebook', 'model.layers.7.mlp.gate_proj.assignments', 'model.layers.7.mlp.gate_proj.normalizer.norms.0', 'model.layers.7.mlp.gate_proj.normalizer.norms.1', 'model.layers.7.mlp.gate_proj.normalizer.zeros.0', 'model.layers.7.mlp.gate_proj.normalizer.zeros.1', 'model.layers.7.mlp.up_proj.bias', 'model.layers.7.mlp.up_proj.codebook', 'model.layers.7.mlp.up_proj.assignments', 'model.layers.7.mlp.up_proj.normalizer.norms.0', 'model.layers.7.mlp.up_proj.normalizer.norms.1', 'model.layers.7.mlp.up_proj.normalizer.zeros.0', 'model.layers.7.mlp.up_proj.normalizer.zeros.1', 'model.layers.7.mlp.down_proj.bias', 'model.layers.7.mlp.down_proj.codebook', 'model.layers.7.mlp.down_proj.assignments', 'model.layers.7.mlp.down_proj.normalizer.norms.0', 'model.layers.7.mlp.down_proj.normalizer.norms.1', 'model.layers.7.mlp.down_proj.normalizer.zeros.0', 'model.layers.7.mlp.down_proj.normalizer.zeros.1', 'model.layers.8.self_attn.q_proj.bias', 'model.layers.8.self_attn.q_proj.codebook', 'model.layers.8.self_attn.q_proj.assignments', 'model.layers.8.self_attn.q_proj.normalizer.norms.0', 'model.layers.8.self_attn.q_proj.normalizer.norms.1', 'model.layers.8.self_attn.q_proj.normalizer.zeros.0', 'model.layers.8.self_attn.q_proj.normalizer.zeros.1', 'model.layers.8.self_attn.k_proj.bias', 'model.layers.8.self_attn.k_proj.codebook', 'model.layers.8.self_attn.k_proj.assignments', 'model.layers.8.self_attn.k_proj.normalizer.norms.0', 'model.layers.8.self_attn.k_proj.normalizer.norms.1', 'model.layers.8.self_attn.k_proj.normalizer.zeros.0', 'model.layers.8.self_attn.k_proj.normalizer.zeros.1', 'model.layers.8.self_attn.v_proj.bias', 'model.layers.8.self_attn.v_proj.codebook', 'model.layers.8.self_attn.v_proj.assignments', 'model.layers.8.self_attn.v_proj.normalizer.norms.0', 'model.layers.8.self_attn.v_proj.normalizer.norms.1', 'model.layers.8.self_attn.v_proj.normalizer.zeros.0', 'model.layers.8.self_attn.v_proj.normalizer.zeros.1', 'model.layers.8.self_attn.o_proj.bias', 'model.layers.8.self_attn.o_proj.codebook', 'model.layers.8.self_attn.o_proj.assignments', 'model.layers.8.self_attn.o_proj.normalizer.norms.0', 'model.layers.8.self_attn.o_proj.normalizer.norms.1', 'model.layers.8.self_attn.o_proj.normalizer.zeros.0', 'model.layers.8.self_attn.o_proj.normalizer.zeros.1', 'model.layers.8.mlp.gate_proj.bias', 'model.layers.8.mlp.gate_proj.codebook', 'model.layers.8.mlp.gate_proj.assignments', 'model.layers.8.mlp.gate_proj.normalizer.norms.0', 'model.layers.8.mlp.gate_proj.normalizer.norms.1', 'model.layers.8.mlp.gate_proj.normalizer.zeros.0', 'model.layers.8.mlp.gate_proj.normalizer.zeros.1', 'model.layers.8.mlp.up_proj.bias', 'model.layers.8.mlp.up_proj.codebook', 'model.layers.8.mlp.up_proj.assignments', 'model.layers.8.mlp.up_proj.normalizer.norms.0', 'model.layers.8.mlp.up_proj.normalizer.norms.1', 'model.layers.8.mlp.up_proj.normalizer.zeros.0', 'model.layers.8.mlp.up_proj.normalizer.zeros.1', 'model.layers.8.mlp.down_proj.bias', 'model.layers.8.mlp.down_proj.codebook', 'model.layers.8.mlp.down_proj.assignments', 'model.layers.8.mlp.down_proj.normalizer.norms.0', 'model.layers.8.mlp.down_proj.normalizer.norms.1', 'model.layers.8.mlp.down_proj.normalizer.zeros.0', 'model.layers.8.mlp.down_proj.normalizer.zeros.1', 'model.layers.9.self_attn.q_proj.bias', 'model.layers.9.self_attn.q_proj.codebook', 'model.layers.9.self_attn.q_proj.assignments', 'model.layers.9.self_attn.q_proj.normalizer.norms.0', 'model.layers.9.self_attn.q_proj.normalizer.norms.1', 'model.layers.9.self_attn.q_proj.normalizer.zeros.0', 'model.layers.9.self_attn.q_proj.normalizer.zeros.1', 'model.layers.9.self_attn.k_proj.bias', 'model.layers.9.self_attn.k_proj.codebook', 'model.layers.9.self_attn.k_proj.assignments', 'model.layers.9.self_attn.k_proj.normalizer.norms.0', 'model.layers.9.self_attn.k_proj.normalizer.norms.1', 'model.layers.9.self_attn.k_proj.normalizer.zeros.0', 'model.layers.9.self_attn.k_proj.normalizer.zeros.1', 'model.layers.9.self_attn.v_proj.bias', 'model.layers.9.self_attn.v_proj.codebook', 'model.layers.9.self_attn.v_proj.assignments', 'model.layers.9.self_attn.v_proj.normalizer.norms.0', 'model.layers.9.self_attn.v_proj.normalizer.norms.1', 'model.layers.9.self_attn.v_proj.normalizer.zeros.0', 'model.layers.9.self_attn.v_proj.normalizer.zeros.1', 'model.layers.9.self_attn.o_proj.bias', 'model.layers.9.self_attn.o_proj.codebook', 'model.layers.9.self_attn.o_proj.assignments', 'model.layers.9.self_attn.o_proj.normalizer.norms.0', 'model.layers.9.self_attn.o_proj.normalizer.norms.1', 'model.layers.9.self_attn.o_proj.normalizer.zeros.0', 'model.layers.9.self_attn.o_proj.normalizer.zeros.1', 'model.layers.9.mlp.gate_proj.bias', 'model.layers.9.mlp.gate_proj.codebook', 'model.layers.9.mlp.gate_proj.assignments', 'model.layers.9.mlp.gate_proj.normalizer.norms.0', 'model.layers.9.mlp.gate_proj.normalizer.norms.1', 'model.layers.9.mlp.gate_proj.normalizer.zeros.0', 'model.layers.9.mlp.gate_proj.normalizer.zeros.1', 'model.layers.9.mlp.up_proj.bias', 'model.layers.9.mlp.up_proj.codebook', 'model.layers.9.mlp.up_proj.assignments', 'model.layers.9.mlp.up_proj.normalizer.norms.0', 'model.layers.9.mlp.up_proj.normalizer.norms.1', 'model.layers.9.mlp.up_proj.normalizer.zeros.0', 'model.layers.9.mlp.up_proj.normalizer.zeros.1', 'model.layers.9.mlp.down_proj.bias', 'model.layers.9.mlp.down_proj.codebook', 'model.layers.9.mlp.down_proj.assignments', 'model.layers.9.mlp.down_proj.normalizer.norms.0', 'model.layers.9.mlp.down_proj.normalizer.norms.1', 'model.layers.9.mlp.down_proj.normalizer.zeros.0', 'model.layers.9.mlp.down_proj.normalizer.zeros.1', 'model.layers.10.self_attn.q_proj.bias', 'model.layers.10.self_attn.q_proj.codebook', 'model.layers.10.self_attn.q_proj.assignments', 'model.layers.10.self_attn.q_proj.normalizer.norms.0', 'model.layers.10.self_attn.q_proj.normalizer.norms.1', 'model.layers.10.self_attn.q_proj.normalizer.zeros.0', 'model.layers.10.self_attn.q_proj.normalizer.zeros.1', 'model.layers.10.self_attn.k_proj.bias', 'model.layers.10.self_attn.k_proj.codebook', 'model.layers.10.self_attn.k_proj.assignments', 'model.layers.10.self_attn.k_proj.normalizer.norms.0', 'model.layers.10.self_attn.k_proj.normalizer.norms.1', 'model.layers.10.self_attn.k_proj.normalizer.zeros.0', 'model.layers.10.self_attn.k_proj.normalizer.zeros.1', 'model.layers.10.self_attn.v_proj.bias', 'model.layers.10.self_attn.v_proj.codebook', 'model.layers.10.self_attn.v_proj.assignments', 'model.layers.10.self_attn.v_proj.normalizer.norms.0', 'model.layers.10.self_attn.v_proj.normalizer.norms.1', 'model.layers.10.self_attn.v_proj.normalizer.zeros.0', 'model.layers.10.self_attn.v_proj.normalizer.zeros.1', 'model.layers.10.self_attn.o_proj.bias', 'model.layers.10.self_attn.o_proj.codebook', 'model.layers.10.self_attn.o_proj.assignments', 'model.layers.10.self_attn.o_proj.normalizer.norms.0', 'model.layers.10.self_attn.o_proj.normalizer.norms.1', 'model.layers.10.self_attn.o_proj.normalizer.zeros.0', 'model.layers.10.self_attn.o_proj.normalizer.zeros.1', 'model.layers.10.mlp.gate_proj.bias', 'model.layers.10.mlp.gate_proj.codebook', 'model.layers.10.mlp.gate_proj.assignments', 'model.layers.10.mlp.gate_proj.normalizer.norms.0', 'model.layers.10.mlp.gate_proj.normalizer.norms.1', 'model.layers.10.mlp.gate_proj.normalizer.zeros.0', 'model.layers.10.mlp.gate_proj.normalizer.zeros.1', 'model.layers.10.mlp.up_proj.bias', 'model.layers.10.mlp.up_proj.codebook', 'model.layers.10.mlp.up_proj.assignments', 'model.layers.10.mlp.up_proj.normalizer.norms.0', 'model.layers.10.mlp.up_proj.normalizer.norms.1', 'model.layers.10.mlp.up_proj.normalizer.zeros.0', 'model.layers.10.mlp.up_proj.normalizer.zeros.1', 'model.layers.10.mlp.down_proj.bias', 'model.layers.10.mlp.down_proj.codebook', 'model.layers.10.mlp.down_proj.assignments', 'model.layers.10.mlp.down_proj.normalizer.norms.0', 'model.layers.10.mlp.down_proj.normalizer.norms.1', 'model.layers.10.mlp.down_proj.normalizer.zeros.0', 'model.layers.10.mlp.down_proj.normalizer.zeros.1', 'model.layers.11.self_attn.q_proj.bias', 'model.layers.11.self_attn.q_proj.codebook', 'model.layers.11.self_attn.q_proj.assignments', 'model.layers.11.self_attn.q_proj.normalizer.norms.0', 'model.layers.11.self_attn.q_proj.normalizer.norms.1', 'model.layers.11.self_attn.q_proj.normalizer.zeros.0', 'model.layers.11.self_attn.q_proj.normalizer.zeros.1', 'model.layers.11.self_attn.k_proj.bias', 'model.layers.11.self_attn.k_proj.codebook', 'model.layers.11.self_attn.k_proj.assignments', 'model.layers.11.self_attn.k_proj.normalizer.norms.0', 'model.layers.11.self_attn.k_proj.normalizer.norms.1', 'model.layers.11.self_attn.k_proj.normalizer.zeros.0', 'model.layers.11.self_attn.k_proj.normalizer.zeros.1', 'model.layers.11.self_attn.v_proj.bias', 'model.layers.11.self_attn.v_proj.codebook', 'model.layers.11.self_attn.v_proj.assignments', 'model.layers.11.self_attn.v_proj.normalizer.norms.0', 'model.layers.11.self_attn.v_proj.normalizer.norms.1', 'model.layers.11.self_attn.v_proj.normalizer.zeros.0', 'model.layers.11.self_attn.v_proj.normalizer.zeros.1', 'model.layers.11.self_attn.o_proj.bias', 'model.layers.11.self_attn.o_proj.codebook', 'model.layers.11.self_attn.o_proj.assignments', 'model.layers.11.self_attn.o_proj.normalizer.norms.0', 'model.layers.11.self_attn.o_proj.normalizer.norms.1', 'model.layers.11.self_attn.o_proj.normalizer.zeros.0', 'model.layers.11.self_attn.o_proj.normalizer.zeros.1', 'model.layers.11.mlp.gate_proj.bias', 'model.layers.11.mlp.gate_proj.codebook', 'model.layers.11.mlp.gate_proj.assignments', 'model.layers.11.mlp.gate_proj.normalizer.norms.0', 'model.layers.11.mlp.gate_proj.normalizer.norms.1', 'model.layers.11.mlp.gate_proj.normalizer.zeros.0', 'model.layers.11.mlp.gate_proj.normalizer.zeros.1', 'model.layers.11.mlp.up_proj.bias', 'model.layers.11.mlp.up_proj.codebook', 'model.layers.11.mlp.up_proj.assignments', 'model.layers.11.mlp.up_proj.normalizer.norms.0', 'model.layers.11.mlp.up_proj.normalizer.norms.1', 'model.layers.11.mlp.up_proj.normalizer.zeros.0', 'model.layers.11.mlp.up_proj.normalizer.zeros.1', 'model.layers.11.mlp.down_proj.bias', 'model.layers.11.mlp.down_proj.codebook', 'model.layers.11.mlp.down_proj.assignments', 'model.layers.11.mlp.down_proj.normalizer.norms.0', 'model.layers.11.mlp.down_proj.normalizer.norms.1', 'model.layers.11.mlp.down_proj.normalizer.zeros.0', 'model.layers.11.mlp.down_proj.normalizer.zeros.1', 'model.layers.12.self_attn.q_proj.bias', 'model.layers.12.self_attn.q_proj.codebook', 'model.layers.12.self_attn.q_proj.assignments', 'model.layers.12.self_attn.q_proj.normalizer.norms.0', 'model.layers.12.self_attn.q_proj.normalizer.norms.1', 'model.layers.12.self_attn.q_proj.normalizer.zeros.0', 'model.layers.12.self_attn.q_proj.normalizer.zeros.1', 'model.layers.12.self_attn.k_proj.bias', 'model.layers.12.self_attn.k_proj.codebook', 'model.layers.12.self_attn.k_proj.assignments', 'model.layers.12.self_attn.k_proj.normalizer.norms.0', 'model.layers.12.self_attn.k_proj.normalizer.norms.1', 'model.layers.12.self_attn.k_proj.normalizer.zeros.0', 'model.layers.12.self_attn.k_proj.normalizer.zeros.1', 'model.layers.12.self_attn.v_proj.bias', 'model.layers.12.self_attn.v_proj.codebook', 'model.layers.12.self_attn.v_proj.assignments', 'model.layers.12.self_attn.v_proj.normalizer.norms.0', 'model.layers.12.self_attn.v_proj.normalizer.norms.1', 'model.layers.12.self_attn.v_proj.normalizer.zeros.0', 'model.layers.12.self_attn.v_proj.normalizer.zeros.1', 'model.layers.12.self_attn.o_proj.bias', 'model.layers.12.self_attn.o_proj.codebook', 'model.layers.12.self_attn.o_proj.assignments', 'model.layers.12.self_attn.o_proj.normalizer.norms.0', 'model.layers.12.self_attn.o_proj.normalizer.norms.1', 'model.layers.12.self_attn.o_proj.normalizer.zeros.0', 'model.layers.12.self_attn.o_proj.normalizer.zeros.1', 'model.layers.12.mlp.gate_proj.bias', 'model.layers.12.mlp.gate_proj.codebook', 'model.layers.12.mlp.gate_proj.assignments', 'model.layers.12.mlp.gate_proj.normalizer.norms.0', 'model.layers.12.mlp.gate_proj.normalizer.norms.1', 'model.layers.12.mlp.gate_proj.normalizer.zeros.0', 'model.layers.12.mlp.gate_proj.normalizer.zeros.1', 'model.layers.12.mlp.up_proj.bias', 'model.layers.12.mlp.up_proj.codebook', 'model.layers.12.mlp.up_proj.assignments', 'model.layers.12.mlp.up_proj.normalizer.norms.0', 'model.layers.12.mlp.up_proj.normalizer.norms.1', 'model.layers.12.mlp.up_proj.normalizer.zeros.0', 'model.layers.12.mlp.up_proj.normalizer.zeros.1', 'model.layers.12.mlp.down_proj.bias', 'model.layers.12.mlp.down_proj.codebook', 'model.layers.12.mlp.down_proj.assignments', 'model.layers.12.mlp.down_proj.normalizer.norms.0', 'model.layers.12.mlp.down_proj.normalizer.norms.1', 'model.layers.12.mlp.down_proj.normalizer.zeros.0', 'model.layers.12.mlp.down_proj.normalizer.zeros.1', 'model.layers.13.self_attn.q_proj.bias', 'model.layers.13.self_attn.q_proj.codebook', 'model.layers.13.self_attn.q_proj.assignments', 'model.layers.13.self_attn.q_proj.normalizer.norms.0', 'model.layers.13.self_attn.q_proj.normalizer.norms.1', 'model.layers.13.self_attn.q_proj.normalizer.zeros.0', 'model.layers.13.self_attn.q_proj.normalizer.zeros.1', 'model.layers.13.self_attn.k_proj.bias', 'model.layers.13.self_attn.k_proj.codebook', 'model.layers.13.self_attn.k_proj.assignments', 'model.layers.13.self_attn.k_proj.normalizer.norms.0', 'model.layers.13.self_attn.k_proj.normalizer.norms.1', 'model.layers.13.self_attn.k_proj.normalizer.zeros.0', 'model.layers.13.self_attn.k_proj.normalizer.zeros.1', 'model.layers.13.self_attn.v_proj.bias', 'model.layers.13.self_attn.v_proj.codebook', 'model.layers.13.self_attn.v_proj.assignments', 'model.layers.13.self_attn.v_proj.normalizer.norms.0', 'model.layers.13.self_attn.v_proj.normalizer.norms.1', 'model.layers.13.self_attn.v_proj.normalizer.zeros.0', 'model.layers.13.self_attn.v_proj.normalizer.zeros.1', 'model.layers.13.self_attn.o_proj.bias', 'model.layers.13.self_attn.o_proj.codebook', 'model.layers.13.self_attn.o_proj.assignments', 'model.layers.13.self_attn.o_proj.normalizer.norms.0', 'model.layers.13.self_attn.o_proj.normalizer.norms.1', 'model.layers.13.self_attn.o_proj.normalizer.zeros.0', 'model.layers.13.self_attn.o_proj.normalizer.zeros.1', 'model.layers.13.mlp.gate_proj.bias', 'model.layers.13.mlp.gate_proj.codebook', 'model.layers.13.mlp.gate_proj.assignments', 'model.layers.13.mlp.gate_proj.normalizer.norms.0', 'model.layers.13.mlp.gate_proj.normalizer.norms.1', 'model.layers.13.mlp.gate_proj.normalizer.zeros.0', 'model.layers.13.mlp.gate_proj.normalizer.zeros.1', 'model.layers.13.mlp.up_proj.bias', 'model.layers.13.mlp.up_proj.codebook', 'model.layers.13.mlp.up_proj.assignments', 'model.layers.13.mlp.up_proj.normalizer.norms.0', 'model.layers.13.mlp.up_proj.normalizer.norms.1', 'model.layers.13.mlp.up_proj.normalizer.zeros.0', 'model.layers.13.mlp.up_proj.normalizer.zeros.1', 'model.layers.13.mlp.down_proj.bias', 'model.layers.13.mlp.down_proj.codebook', 'model.layers.13.mlp.down_proj.assignments', 'model.layers.13.mlp.down_proj.normalizer.norms.0', 'model.layers.13.mlp.down_proj.normalizer.norms.1', 'model.layers.13.mlp.down_proj.normalizer.zeros.0', 'model.layers.13.mlp.down_proj.normalizer.zeros.1', 'model.layers.14.self_attn.q_proj.bias', 'model.layers.14.self_attn.q_proj.codebook', 'model.layers.14.self_attn.q_proj.assignments', 'model.layers.14.self_attn.q_proj.normalizer.norms.0', 'model.layers.14.self_attn.q_proj.normalizer.norms.1', 'model.layers.14.self_attn.q_proj.normalizer.zeros.0', 'model.layers.14.self_attn.q_proj.normalizer.zeros.1', 'model.layers.14.self_attn.k_proj.bias', 'model.layers.14.self_attn.k_proj.codebook', 'model.layers.14.self_attn.k_proj.assignments', 'model.layers.14.self_attn.k_proj.normalizer.norms.0', 'model.layers.14.self_attn.k_proj.normalizer.norms.1', 'model.layers.14.self_attn.k_proj.normalizer.zeros.0', 'model.layers.14.self_attn.k_proj.normalizer.zeros.1', 'model.layers.14.self_attn.v_proj.bias', 'model.layers.14.self_attn.v_proj.codebook', 'model.layers.14.self_attn.v_proj.assignments', 'model.layers.14.self_attn.v_proj.normalizer.norms.0', 'model.layers.14.self_attn.v_proj.normalizer.norms.1', 'model.layers.14.self_attn.v_proj.normalizer.zeros.0', 'model.layers.14.self_attn.v_proj.normalizer.zeros.1', 'model.layers.14.self_attn.o_proj.bias', 'model.layers.14.self_attn.o_proj.codebook', 'model.layers.14.self_attn.o_proj.assignments', 'model.layers.14.self_attn.o_proj.normalizer.norms.0', 'model.layers.14.self_attn.o_proj.normalizer.norms.1', 'model.layers.14.self_attn.o_proj.normalizer.zeros.0', 'model.layers.14.self_attn.o_proj.normalizer.zeros.1', 'model.layers.14.mlp.gate_proj.bias', 'model.layers.14.mlp.gate_proj.codebook', 'model.layers.14.mlp.gate_proj.assignments', 'model.layers.14.mlp.gate_proj.normalizer.norms.0', 'model.layers.14.mlp.gate_proj.normalizer.norms.1', 'model.layers.14.mlp.gate_proj.normalizer.zeros.0', 'model.layers.14.mlp.gate_proj.normalizer.zeros.1', 'model.layers.14.mlp.up_proj.bias', 'model.layers.14.mlp.up_proj.codebook', 'model.layers.14.mlp.up_proj.assignments', 'model.layers.14.mlp.up_proj.normalizer.norms.0', 'model.layers.14.mlp.up_proj.normalizer.norms.1', 'model.layers.14.mlp.up_proj.normalizer.zeros.0', 'model.layers.14.mlp.up_proj.normalizer.zeros.1', 'model.layers.14.mlp.down_proj.bias', 'model.layers.14.mlp.down_proj.codebook', 'model.layers.14.mlp.down_proj.assignments', 'model.layers.14.mlp.down_proj.normalizer.norms.0', 'model.layers.14.mlp.down_proj.normalizer.norms.1', 'model.layers.14.mlp.down_proj.normalizer.zeros.0', 'model.layers.14.mlp.down_proj.normalizer.zeros.1', 'model.layers.15.self_attn.q_proj.bias', 'model.layers.15.self_attn.q_proj.codebook', 'model.layers.15.self_attn.q_proj.assignments', 'model.layers.15.self_attn.q_proj.normalizer.norms.0', 'model.layers.15.self_attn.q_proj.normalizer.norms.1', 'model.layers.15.self_attn.q_proj.normalizer.zeros.0', 'model.layers.15.self_attn.q_proj.normalizer.zeros.1', 'model.layers.15.self_attn.k_proj.bias', 'model.layers.15.self_attn.k_proj.codebook', 'model.layers.15.self_attn.k_proj.assignments', 'model.layers.15.self_attn.k_proj.normalizer.norms.0', 'model.layers.15.self_attn.k_proj.normalizer.norms.1', 'model.layers.15.self_attn.k_proj.normalizer.zeros.0', 'model.layers.15.self_attn.k_proj.normalizer.zeros.1', 'model.layers.15.self_attn.v_proj.bias', 'model.layers.15.self_attn.v_proj.codebook', 'model.layers.15.self_attn.v_proj.assignments', 'model.layers.15.self_attn.v_proj.normalizer.norms.0', 'model.layers.15.self_attn.v_proj.normalizer.norms.1', 'model.layers.15.self_attn.v_proj.normalizer.zeros.0', 'model.layers.15.self_attn.v_proj.normalizer.zeros.1', 'model.layers.15.self_attn.o_proj.bias', 'model.layers.15.self_attn.o_proj.codebook', 'model.layers.15.self_attn.o_proj.assignments', 'model.layers.15.self_attn.o_proj.normalizer.norms.0', 'model.layers.15.self_attn.o_proj.normalizer.norms.1', 'model.layers.15.self_attn.o_proj.normalizer.zeros.0', 'model.layers.15.self_attn.o_proj.normalizer.zeros.1', 'model.layers.15.mlp.gate_proj.bias', 'model.layers.15.mlp.gate_proj.codebook', 'model.layers.15.mlp.gate_proj.assignments', 'model.layers.15.mlp.gate_proj.normalizer.norms.0', 'model.layers.15.mlp.gate_proj.normalizer.norms.1', 'model.layers.15.mlp.gate_proj.normalizer.zeros.0', 'model.layers.15.mlp.gate_proj.normalizer.zeros.1', 'model.layers.15.mlp.up_proj.bias', 'model.layers.15.mlp.up_proj.codebook', 'model.layers.15.mlp.up_proj.assignments', 'model.layers.15.mlp.up_proj.normalizer.norms.0', 'model.layers.15.mlp.up_proj.normalizer.norms.1', 'model.layers.15.mlp.up_proj.normalizer.zeros.0', 'model.layers.15.mlp.up_proj.normalizer.zeros.1', 'model.layers.15.mlp.down_proj.bias', 'model.layers.15.mlp.down_proj.codebook', 'model.layers.15.mlp.down_proj.assignments', 'model.layers.15.mlp.down_proj.normalizer.norms.0', 'model.layers.15.mlp.down_proj.normalizer.norms.1', 'model.layers.15.mlp.down_proj.normalizer.zeros.0', 'model.layers.15.mlp.down_proj.normalizer.zeros.1', 'model.layers.16.self_attn.q_proj.bias', 'model.layers.16.self_attn.q_proj.codebook', 'model.layers.16.self_attn.q_proj.assignments', 'model.layers.16.self_attn.q_proj.normalizer.norms.0', 'model.layers.16.self_attn.q_proj.normalizer.norms.1', 'model.layers.16.self_attn.q_proj.normalizer.zeros.0', 'model.layers.16.self_attn.q_proj.normalizer.zeros.1', 'model.layers.16.self_attn.k_proj.bias', 'model.layers.16.self_attn.k_proj.codebook', 'model.layers.16.self_attn.k_proj.assignments', 'model.layers.16.self_attn.k_proj.normalizer.norms.0', 'model.layers.16.self_attn.k_proj.normalizer.norms.1', 'model.layers.16.self_attn.k_proj.normalizer.zeros.0', 'model.layers.16.self_attn.k_proj.normalizer.zeros.1', 'model.layers.16.self_attn.v_proj.bias', 'model.layers.16.self_attn.v_proj.codebook', 'model.layers.16.self_attn.v_proj.assignments', 'model.layers.16.self_attn.v_proj.normalizer.norms.0', 'model.layers.16.self_attn.v_proj.normalizer.norms.1', 'model.layers.16.self_attn.v_proj.normalizer.zeros.0', 'model.layers.16.self_attn.v_proj.normalizer.zeros.1', 'model.layers.16.self_attn.o_proj.bias', 'model.layers.16.self_attn.o_proj.codebook', 'model.layers.16.self_attn.o_proj.assignments', 'model.layers.16.self_attn.o_proj.normalizer.norms.0', 'model.layers.16.self_attn.o_proj.normalizer.norms.1', 'model.layers.16.self_attn.o_proj.normalizer.zeros.0', 'model.layers.16.self_attn.o_proj.normalizer.zeros.1', 'model.layers.16.mlp.gate_proj.bias', 'model.layers.16.mlp.gate_proj.codebook', 'model.layers.16.mlp.gate_proj.assignments', 'model.layers.16.mlp.gate_proj.normalizer.norms.0', 'model.layers.16.mlp.gate_proj.normalizer.norms.1', 'model.layers.16.mlp.gate_proj.normalizer.zeros.0', 'model.layers.16.mlp.gate_proj.normalizer.zeros.1', 'model.layers.16.mlp.up_proj.bias', 'model.layers.16.mlp.up_proj.codebook', 'model.layers.16.mlp.up_proj.assignments', 'model.layers.16.mlp.up_proj.normalizer.norms.0', 'model.layers.16.mlp.up_proj.normalizer.norms.1', 'model.layers.16.mlp.up_proj.normalizer.zeros.0', 'model.layers.16.mlp.up_proj.normalizer.zeros.1', 'model.layers.16.mlp.down_proj.bias', 'model.layers.16.mlp.down_proj.codebook', 'model.layers.16.mlp.down_proj.assignments', 'model.layers.16.mlp.down_proj.normalizer.norms.0', 'model.layers.16.mlp.down_proj.normalizer.norms.1', 'model.layers.16.mlp.down_proj.normalizer.zeros.0', 'model.layers.16.mlp.down_proj.normalizer.zeros.1', 'model.layers.17.self_attn.q_proj.bias', 'model.layers.17.self_attn.q_proj.codebook', 'model.layers.17.self_attn.q_proj.assignments', 'model.layers.17.self_attn.q_proj.normalizer.norms.0', 'model.layers.17.self_attn.q_proj.normalizer.norms.1', 'model.layers.17.self_attn.q_proj.normalizer.zeros.0', 'model.layers.17.self_attn.q_proj.normalizer.zeros.1', 'model.layers.17.self_attn.k_proj.bias', 'model.layers.17.self_attn.k_proj.codebook', 'model.layers.17.self_attn.k_proj.assignments', 'model.layers.17.self_attn.k_proj.normalizer.norms.0', 'model.layers.17.self_attn.k_proj.normalizer.norms.1', 'model.layers.17.self_attn.k_proj.normalizer.zeros.0', 'model.layers.17.self_attn.k_proj.normalizer.zeros.1', 'model.layers.17.self_attn.v_proj.bias', 'model.layers.17.self_attn.v_proj.codebook', 'model.layers.17.self_attn.v_proj.assignments', 'model.layers.17.self_attn.v_proj.normalizer.norms.0', 'model.layers.17.self_attn.v_proj.normalizer.norms.1', 'model.layers.17.self_attn.v_proj.normalizer.zeros.0', 'model.layers.17.self_attn.v_proj.normalizer.zeros.1', 'model.layers.17.self_attn.o_proj.bias', 'model.layers.17.self_attn.o_proj.codebook', 'model.layers.17.self_attn.o_proj.assignments', 'model.layers.17.self_attn.o_proj.normalizer.norms.0', 'model.layers.17.self_attn.o_proj.normalizer.norms.1', 'model.layers.17.self_attn.o_proj.normalizer.zeros.0', 'model.layers.17.self_attn.o_proj.normalizer.zeros.1', 'model.layers.17.mlp.gate_proj.bias', 'model.layers.17.mlp.gate_proj.codebook', 'model.layers.17.mlp.gate_proj.assignments', 'model.layers.17.mlp.gate_proj.normalizer.norms.0', 'model.layers.17.mlp.gate_proj.normalizer.norms.1', 'model.layers.17.mlp.gate_proj.normalizer.zeros.0', 'model.layers.17.mlp.gate_proj.normalizer.zeros.1', 'model.layers.17.mlp.up_proj.bias', 'model.layers.17.mlp.up_proj.codebook', 'model.layers.17.mlp.up_proj.assignments', 'model.layers.17.mlp.up_proj.normalizer.norms.0', 'model.layers.17.mlp.up_proj.normalizer.norms.1', 'model.layers.17.mlp.up_proj.normalizer.zeros.0', 'model.layers.17.mlp.up_proj.normalizer.zeros.1', 'model.layers.17.mlp.down_proj.bias', 'model.layers.17.mlp.down_proj.codebook', 'model.layers.17.mlp.down_proj.assignments', 'model.layers.17.mlp.down_proj.normalizer.norms.0', 'model.layers.17.mlp.down_proj.normalizer.norms.1', 'model.layers.17.mlp.down_proj.normalizer.zeros.0', 'model.layers.17.mlp.down_proj.normalizer.zeros.1', 'model.layers.18.self_attn.q_proj.bias', 'model.layers.18.self_attn.q_proj.codebook', 'model.layers.18.self_attn.q_proj.assignments', 'model.layers.18.self_attn.q_proj.normalizer.norms.0', 'model.layers.18.self_attn.q_proj.normalizer.norms.1', 'model.layers.18.self_attn.q_proj.normalizer.zeros.0', 'model.layers.18.self_attn.q_proj.normalizer.zeros.1', 'model.layers.18.self_attn.k_proj.bias', 'model.layers.18.self_attn.k_proj.codebook', 'model.layers.18.self_attn.k_proj.assignments', 'model.layers.18.self_attn.k_proj.normalizer.norms.0', 'model.layers.18.self_attn.k_proj.normalizer.norms.1', 'model.layers.18.self_attn.k_proj.normalizer.zeros.0', 'model.layers.18.self_attn.k_proj.normalizer.zeros.1', 'model.layers.18.self_attn.v_proj.bias', 'model.layers.18.self_attn.v_proj.codebook', 'model.layers.18.self_attn.v_proj.assignments', 'model.layers.18.self_attn.v_proj.normalizer.norms.0', 'model.layers.18.self_attn.v_proj.normalizer.norms.1', 'model.layers.18.self_attn.v_proj.normalizer.zeros.0', 'model.layers.18.self_attn.v_proj.normalizer.zeros.1', 'model.layers.18.self_attn.o_proj.bias', 'model.layers.18.self_attn.o_proj.codebook', 'model.layers.18.self_attn.o_proj.assignments', 'model.layers.18.self_attn.o_proj.normalizer.norms.0', 'model.layers.18.self_attn.o_proj.normalizer.norms.1', 'model.layers.18.self_attn.o_proj.normalizer.zeros.0', 'model.layers.18.self_attn.o_proj.normalizer.zeros.1', 'model.layers.18.mlp.gate_proj.bias', 'model.layers.18.mlp.gate_proj.codebook', 'model.layers.18.mlp.gate_proj.assignments', 'model.layers.18.mlp.gate_proj.normalizer.norms.0', 'model.layers.18.mlp.gate_proj.normalizer.norms.1', 'model.layers.18.mlp.gate_proj.normalizer.zeros.0', 'model.layers.18.mlp.gate_proj.normalizer.zeros.1', 'model.layers.18.mlp.up_proj.bias', 'model.layers.18.mlp.up_proj.codebook', 'model.layers.18.mlp.up_proj.assignments', 'model.layers.18.mlp.up_proj.normalizer.norms.0', 'model.layers.18.mlp.up_proj.normalizer.norms.1', 'model.layers.18.mlp.up_proj.normalizer.zeros.0', 'model.layers.18.mlp.up_proj.normalizer.zeros.1', 'model.layers.18.mlp.down_proj.bias', 'model.layers.18.mlp.down_proj.codebook', 'model.layers.18.mlp.down_proj.assignments', 'model.layers.18.mlp.down_proj.normalizer.norms.0', 'model.layers.18.mlp.down_proj.normalizer.norms.1', 'model.layers.18.mlp.down_proj.normalizer.zeros.0', 'model.layers.18.mlp.down_proj.normalizer.zeros.1', 'model.layers.19.self_attn.q_proj.bias', 'model.layers.19.self_attn.q_proj.codebook', 'model.layers.19.self_attn.q_proj.assignments', 'model.layers.19.self_attn.q_proj.normalizer.norms.0', 'model.layers.19.self_attn.q_proj.normalizer.norms.1', 'model.layers.19.self_attn.q_proj.normalizer.zeros.0', 'model.layers.19.self_attn.q_proj.normalizer.zeros.1', 'model.layers.19.self_attn.k_proj.bias', 'model.layers.19.self_attn.k_proj.codebook', 'model.layers.19.self_attn.k_proj.assignments', 'model.layers.19.self_attn.k_proj.normalizer.norms.0', 'model.layers.19.self_attn.k_proj.normalizer.norms.1', 'model.layers.19.self_attn.k_proj.normalizer.zeros.0', 'model.layers.19.self_attn.k_proj.normalizer.zeros.1', 'model.layers.19.self_attn.v_proj.bias', 'model.layers.19.self_attn.v_proj.codebook', 'model.layers.19.self_attn.v_proj.assignments', 'model.layers.19.self_attn.v_proj.normalizer.norms.0', 'model.layers.19.self_attn.v_proj.normalizer.norms.1', 'model.layers.19.self_attn.v_proj.normalizer.zeros.0', 'model.layers.19.self_attn.v_proj.normalizer.zeros.1', 'model.layers.19.self_attn.o_proj.bias', 'model.layers.19.self_attn.o_proj.codebook', 'model.layers.19.self_attn.o_proj.assignments', 'model.layers.19.self_attn.o_proj.normalizer.norms.0', 'model.layers.19.self_attn.o_proj.normalizer.norms.1', 'model.layers.19.self_attn.o_proj.normalizer.zeros.0', 'model.layers.19.self_attn.o_proj.normalizer.zeros.1', 'model.layers.19.mlp.gate_proj.bias', 'model.layers.19.mlp.gate_proj.codebook', 'model.layers.19.mlp.gate_proj.assignments', 'model.layers.19.mlp.gate_proj.normalizer.norms.0', 'model.layers.19.mlp.gate_proj.normalizer.norms.1', 'model.layers.19.mlp.gate_proj.normalizer.zeros.0', 'model.layers.19.mlp.gate_proj.normalizer.zeros.1', 'model.layers.19.mlp.up_proj.bias', 'model.layers.19.mlp.up_proj.codebook', 'model.layers.19.mlp.up_proj.assignments', 'model.layers.19.mlp.up_proj.normalizer.norms.0', 'model.layers.19.mlp.up_proj.normalizer.norms.1', 'model.layers.19.mlp.up_proj.normalizer.zeros.0', 'model.layers.19.mlp.up_proj.normalizer.zeros.1', 'model.layers.19.mlp.down_proj.bias', 'model.layers.19.mlp.down_proj.codebook', 'model.layers.19.mlp.down_proj.assignments', 'model.layers.19.mlp.down_proj.normalizer.norms.0', 'model.layers.19.mlp.down_proj.normalizer.norms.1', 'model.layers.19.mlp.down_proj.normalizer.zeros.0', 'model.layers.19.mlp.down_proj.normalizer.zeros.1', 'model.layers.20.self_attn.q_proj.bias', 'model.layers.20.self_attn.q_proj.codebook', 'model.layers.20.self_attn.q_proj.assignments', 'model.layers.20.self_attn.q_proj.normalizer.norms.0', 'model.layers.20.self_attn.q_proj.normalizer.norms.1', 'model.layers.20.self_attn.q_proj.normalizer.zeros.0', 'model.layers.20.self_attn.q_proj.normalizer.zeros.1', 'model.layers.20.self_attn.k_proj.bias', 'model.layers.20.self_attn.k_proj.codebook', 'model.layers.20.self_attn.k_proj.assignments', 'model.layers.20.self_attn.k_proj.normalizer.norms.0', 'model.layers.20.self_attn.k_proj.normalizer.norms.1', 'model.layers.20.self_attn.k_proj.normalizer.zeros.0', 'model.layers.20.self_attn.k_proj.normalizer.zeros.1', 'model.layers.20.self_attn.v_proj.bias', 'model.layers.20.self_attn.v_proj.codebook', 'model.layers.20.self_attn.v_proj.assignments', 'model.layers.20.self_attn.v_proj.normalizer.norms.0', 'model.layers.20.self_attn.v_proj.normalizer.norms.1', 'model.layers.20.self_attn.v_proj.normalizer.zeros.0', 'model.layers.20.self_attn.v_proj.normalizer.zeros.1', 'model.layers.20.self_attn.o_proj.bias', 'model.layers.20.self_attn.o_proj.codebook', 'model.layers.20.self_attn.o_proj.assignments', 'model.layers.20.self_attn.o_proj.normalizer.norms.0', 'model.layers.20.self_attn.o_proj.normalizer.norms.1', 'model.layers.20.self_attn.o_proj.normalizer.zeros.0', 'model.layers.20.self_attn.o_proj.normalizer.zeros.1', 'model.layers.20.mlp.gate_proj.bias', 'model.layers.20.mlp.gate_proj.codebook', 'model.layers.20.mlp.gate_proj.assignments', 'model.layers.20.mlp.gate_proj.normalizer.norms.0', 'model.layers.20.mlp.gate_proj.normalizer.norms.1', 'model.layers.20.mlp.gate_proj.normalizer.zeros.0', 'model.layers.20.mlp.gate_proj.normalizer.zeros.1', 'model.layers.20.mlp.up_proj.bias', 'model.layers.20.mlp.up_proj.codebook', 'model.layers.20.mlp.up_proj.assignments', 'model.layers.20.mlp.up_proj.normalizer.norms.0', 'model.layers.20.mlp.up_proj.normalizer.norms.1', 'model.layers.20.mlp.up_proj.normalizer.zeros.0', 'model.layers.20.mlp.up_proj.normalizer.zeros.1', 'model.layers.20.mlp.down_proj.bias', 'model.layers.20.mlp.down_proj.codebook', 'model.layers.20.mlp.down_proj.assignments', 'model.layers.20.mlp.down_proj.normalizer.norms.0', 'model.layers.20.mlp.down_proj.normalizer.norms.1', 'model.layers.20.mlp.down_proj.normalizer.zeros.0', 'model.layers.20.mlp.down_proj.normalizer.zeros.1', 'model.layers.21.self_attn.q_proj.bias', 'model.layers.21.self_attn.q_proj.codebook', 'model.layers.21.self_attn.q_proj.assignments', 'model.layers.21.self_attn.q_proj.normalizer.norms.0', 'model.layers.21.self_attn.q_proj.normalizer.norms.1', 'model.layers.21.self_attn.q_proj.normalizer.zeros.0', 'model.layers.21.self_attn.q_proj.normalizer.zeros.1', 'model.layers.21.self_attn.k_proj.bias', 'model.layers.21.self_attn.k_proj.codebook', 'model.layers.21.self_attn.k_proj.assignments', 'model.layers.21.self_attn.k_proj.normalizer.norms.0', 'model.layers.21.self_attn.k_proj.normalizer.norms.1', 'model.layers.21.self_attn.k_proj.normalizer.zeros.0', 'model.layers.21.self_attn.k_proj.normalizer.zeros.1', 'model.layers.21.self_attn.v_proj.bias', 'model.layers.21.self_attn.v_proj.codebook', 'model.layers.21.self_attn.v_proj.assignments', 'model.layers.21.self_attn.v_proj.normalizer.norms.0', 'model.layers.21.self_attn.v_proj.normalizer.norms.1', 'model.layers.21.self_attn.v_proj.normalizer.zeros.0', 'model.layers.21.self_attn.v_proj.normalizer.zeros.1', 'model.layers.21.self_attn.o_proj.bias', 'model.layers.21.self_attn.o_proj.codebook', 'model.layers.21.self_attn.o_proj.assignments', 'model.layers.21.self_attn.o_proj.normalizer.norms.0', 'model.layers.21.self_attn.o_proj.normalizer.norms.1', 'model.layers.21.self_attn.o_proj.normalizer.zeros.0', 'model.layers.21.self_attn.o_proj.normalizer.zeros.1', 'model.layers.21.mlp.gate_proj.bias', 'model.layers.21.mlp.gate_proj.codebook', 'model.layers.21.mlp.gate_proj.assignments', 'model.layers.21.mlp.gate_proj.normalizer.norms.0', 'model.layers.21.mlp.gate_proj.normalizer.norms.1', 'model.layers.21.mlp.gate_proj.normalizer.zeros.0', 'model.layers.21.mlp.gate_proj.normalizer.zeros.1', 'model.layers.21.mlp.up_proj.bias', 'model.layers.21.mlp.up_proj.codebook', 'model.layers.21.mlp.up_proj.assignments', 'model.layers.21.mlp.up_proj.normalizer.norms.0', 'model.layers.21.mlp.up_proj.normalizer.norms.1', 'model.layers.21.mlp.up_proj.normalizer.zeros.0', 'model.layers.21.mlp.up_proj.normalizer.zeros.1', 'model.layers.21.mlp.down_proj.bias', 'model.layers.21.mlp.down_proj.codebook', 'model.layers.21.mlp.down_proj.assignments', 'model.layers.21.mlp.down_proj.normalizer.norms.0', 'model.layers.21.mlp.down_proj.normalizer.norms.1', 'model.layers.21.mlp.down_proj.normalizer.zeros.0', 'model.layers.21.mlp.down_proj.normalizer.zeros.1', 'model.layers.22.self_attn.q_proj.bias', 'model.layers.22.self_attn.q_proj.codebook', 'model.layers.22.self_attn.q_proj.assignments', 'model.layers.22.self_attn.q_proj.normalizer.norms.0', 'model.layers.22.self_attn.q_proj.normalizer.norms.1', 'model.layers.22.self_attn.q_proj.normalizer.zeros.0', 'model.layers.22.self_attn.q_proj.normalizer.zeros.1', 'model.layers.22.self_attn.k_proj.bias', 'model.layers.22.self_attn.k_proj.codebook', 'model.layers.22.self_attn.k_proj.assignments', 'model.layers.22.self_attn.k_proj.normalizer.norms.0', 'model.layers.22.self_attn.k_proj.normalizer.norms.1', 'model.layers.22.self_attn.k_proj.normalizer.zeros.0', 'model.layers.22.self_attn.k_proj.normalizer.zeros.1', 'model.layers.22.self_attn.v_proj.bias', 'model.layers.22.self_attn.v_proj.codebook', 'model.layers.22.self_attn.v_proj.assignments', 'model.layers.22.self_attn.v_proj.normalizer.norms.0', 'model.layers.22.self_attn.v_proj.normalizer.norms.1', 'model.layers.22.self_attn.v_proj.normalizer.zeros.0', 'model.layers.22.self_attn.v_proj.normalizer.zeros.1', 'model.layers.22.self_attn.o_proj.bias', 'model.layers.22.self_attn.o_proj.codebook', 'model.layers.22.self_attn.o_proj.assignments', 'model.layers.22.self_attn.o_proj.normalizer.norms.0', 'model.layers.22.self_attn.o_proj.normalizer.norms.1', 'model.layers.22.self_attn.o_proj.normalizer.zeros.0', 'model.layers.22.self_attn.o_proj.normalizer.zeros.1', 'model.layers.22.mlp.gate_proj.bias', 'model.layers.22.mlp.gate_proj.codebook', 'model.layers.22.mlp.gate_proj.assignments', 'model.layers.22.mlp.gate_proj.normalizer.norms.0', 'model.layers.22.mlp.gate_proj.normalizer.norms.1', 'model.layers.22.mlp.gate_proj.normalizer.zeros.0', 'model.layers.22.mlp.gate_proj.normalizer.zeros.1', 'model.layers.22.mlp.up_proj.bias', 'model.layers.22.mlp.up_proj.codebook', 'model.layers.22.mlp.up_proj.assignments', 'model.layers.22.mlp.up_proj.normalizer.norms.0', 'model.layers.22.mlp.up_proj.normalizer.norms.1', 'model.layers.22.mlp.up_proj.normalizer.zeros.0', 'model.layers.22.mlp.up_proj.normalizer.zeros.1', 'model.layers.22.mlp.down_proj.bias', 'model.layers.22.mlp.down_proj.codebook', 'model.layers.22.mlp.down_proj.assignments', 'model.layers.22.mlp.down_proj.normalizer.norms.0', 'model.layers.22.mlp.down_proj.normalizer.norms.1', 'model.layers.22.mlp.down_proj.normalizer.zeros.0', 'model.layers.22.mlp.down_proj.normalizer.zeros.1', 'model.layers.23.self_attn.q_proj.bias', 'model.layers.23.self_attn.q_proj.codebook', 'model.layers.23.self_attn.q_proj.assignments', 'model.layers.23.self_attn.q_proj.normalizer.norms.0', 'model.layers.23.self_attn.q_proj.normalizer.norms.1', 'model.layers.23.self_attn.q_proj.normalizer.zeros.0', 'model.layers.23.self_attn.q_proj.normalizer.zeros.1', 'model.layers.23.self_attn.k_proj.bias', 'model.layers.23.self_attn.k_proj.codebook', 'model.layers.23.self_attn.k_proj.assignments', 'model.layers.23.self_attn.k_proj.normalizer.norms.0', 'model.layers.23.self_attn.k_proj.normalizer.norms.1', 'model.layers.23.self_attn.k_proj.normalizer.zeros.0', 'model.layers.23.self_attn.k_proj.normalizer.zeros.1', 'model.layers.23.self_attn.v_proj.bias', 'model.layers.23.self_attn.v_proj.codebook', 'model.layers.23.self_attn.v_proj.assignments', 'model.layers.23.self_attn.v_proj.normalizer.norms.0', 'model.layers.23.self_attn.v_proj.normalizer.norms.1', 'model.layers.23.self_attn.v_proj.normalizer.zeros.0', 'model.layers.23.self_attn.v_proj.normalizer.zeros.1', 'model.layers.23.self_attn.o_proj.bias', 'model.layers.23.self_attn.o_proj.codebook', 'model.layers.23.self_attn.o_proj.assignments', 'model.layers.23.self_attn.o_proj.normalizer.norms.0', 'model.layers.23.self_attn.o_proj.normalizer.norms.1', 'model.layers.23.self_attn.o_proj.normalizer.zeros.0', 'model.layers.23.self_attn.o_proj.normalizer.zeros.1', 'model.layers.23.mlp.gate_proj.bias', 'model.layers.23.mlp.gate_proj.codebook', 'model.layers.23.mlp.gate_proj.assignments', 'model.layers.23.mlp.gate_proj.normalizer.norms.0', 'model.layers.23.mlp.gate_proj.normalizer.norms.1', 'model.layers.23.mlp.gate_proj.normalizer.zeros.0', 'model.layers.23.mlp.gate_proj.normalizer.zeros.1', 'model.layers.23.mlp.up_proj.bias', 'model.layers.23.mlp.up_proj.codebook', 'model.layers.23.mlp.up_proj.assignments', 'model.layers.23.mlp.up_proj.normalizer.norms.0', 'model.layers.23.mlp.up_proj.normalizer.norms.1', 'model.layers.23.mlp.up_proj.normalizer.zeros.0', 'model.layers.23.mlp.up_proj.normalizer.zeros.1', 'model.layers.23.mlp.down_proj.bias', 'model.layers.23.mlp.down_proj.codebook', 'model.layers.23.mlp.down_proj.assignments', 'model.layers.23.mlp.down_proj.normalizer.norms.0', 'model.layers.23.mlp.down_proj.normalizer.norms.1', 'model.layers.23.mlp.down_proj.normalizer.zeros.0', 'model.layers.23.mlp.down_proj.normalizer.zeros.1', 'model.layers.24.self_attn.q_proj.bias', 'model.layers.24.self_attn.q_proj.codebook', 'model.layers.24.self_attn.q_proj.assignments', 'model.layers.24.self_attn.q_proj.normalizer.norms.0', 'model.layers.24.self_attn.q_proj.normalizer.norms.1', 'model.layers.24.self_attn.q_proj.normalizer.zeros.0', 'model.layers.24.self_attn.q_proj.normalizer.zeros.1', 'model.layers.24.self_attn.k_proj.bias', 'model.layers.24.self_attn.k_proj.codebook', 'model.layers.24.self_attn.k_proj.assignments', 'model.layers.24.self_attn.k_proj.normalizer.norms.0', 'model.layers.24.self_attn.k_proj.normalizer.norms.1', 'model.layers.24.self_attn.k_proj.normalizer.zeros.0', 'model.layers.24.self_attn.k_proj.normalizer.zeros.1', 'model.layers.24.self_attn.v_proj.bias', 'model.layers.24.self_attn.v_proj.codebook', 'model.layers.24.self_attn.v_proj.assignments', 'model.layers.24.self_attn.v_proj.normalizer.norms.0', 'model.layers.24.self_attn.v_proj.normalizer.norms.1', 'model.layers.24.self_attn.v_proj.normalizer.zeros.0', 'model.layers.24.self_attn.v_proj.normalizer.zeros.1', 'model.layers.24.self_attn.o_proj.bias', 'model.layers.24.self_attn.o_proj.codebook', 'model.layers.24.self_attn.o_proj.assignments', 'model.layers.24.self_attn.o_proj.normalizer.norms.0', 'model.layers.24.self_attn.o_proj.normalizer.norms.1', 'model.layers.24.self_attn.o_proj.normalizer.zeros.0', 'model.layers.24.self_attn.o_proj.normalizer.zeros.1', 'model.layers.24.mlp.gate_proj.bias', 'model.layers.24.mlp.gate_proj.codebook', 'model.layers.24.mlp.gate_proj.assignments', 'model.layers.24.mlp.gate_proj.normalizer.norms.0', 'model.layers.24.mlp.gate_proj.normalizer.norms.1', 'model.layers.24.mlp.gate_proj.normalizer.zeros.0', 'model.layers.24.mlp.gate_proj.normalizer.zeros.1', 'model.layers.24.mlp.up_proj.bias', 'model.layers.24.mlp.up_proj.codebook', 'model.layers.24.mlp.up_proj.assignments', 'model.layers.24.mlp.up_proj.normalizer.norms.0', 'model.layers.24.mlp.up_proj.normalizer.norms.1', 'model.layers.24.mlp.up_proj.normalizer.zeros.0', 'model.layers.24.mlp.up_proj.normalizer.zeros.1', 'model.layers.24.mlp.down_proj.bias', 'model.layers.24.mlp.down_proj.codebook', 'model.layers.24.mlp.down_proj.assignments', 'model.layers.24.mlp.down_proj.normalizer.norms.0', 'model.layers.24.mlp.down_proj.normalizer.norms.1', 'model.layers.24.mlp.down_proj.normalizer.zeros.0', 'model.layers.24.mlp.down_proj.normalizer.zeros.1', 'model.layers.25.self_attn.q_proj.bias', 'model.layers.25.self_attn.q_proj.codebook', 'model.layers.25.self_attn.q_proj.assignments', 'model.layers.25.self_attn.q_proj.normalizer.norms.0', 'model.layers.25.self_attn.q_proj.normalizer.norms.1', 'model.layers.25.self_attn.q_proj.normalizer.zeros.0', 'model.layers.25.self_attn.q_proj.normalizer.zeros.1', 'model.layers.25.self_attn.k_proj.bias', 'model.layers.25.self_attn.k_proj.codebook', 'model.layers.25.self_attn.k_proj.assignments', 'model.layers.25.self_attn.k_proj.normalizer.norms.0', 'model.layers.25.self_attn.k_proj.normalizer.norms.1', 'model.layers.25.self_attn.k_proj.normalizer.zeros.0', 'model.layers.25.self_attn.k_proj.normalizer.zeros.1', 'model.layers.25.self_attn.v_proj.bias', 'model.layers.25.self_attn.v_proj.codebook', 'model.layers.25.self_attn.v_proj.assignments', 'model.layers.25.self_attn.v_proj.normalizer.norms.0', 'model.layers.25.self_attn.v_proj.normalizer.norms.1', 'model.layers.25.self_attn.v_proj.normalizer.zeros.0', 'model.layers.25.self_attn.v_proj.normalizer.zeros.1', 'model.layers.25.self_attn.o_proj.bias', 'model.layers.25.self_attn.o_proj.codebook', 'model.layers.25.self_attn.o_proj.assignments', 'model.layers.25.self_attn.o_proj.normalizer.norms.0', 'model.layers.25.self_attn.o_proj.normalizer.norms.1', 'model.layers.25.self_attn.o_proj.normalizer.zeros.0', 'model.layers.25.self_attn.o_proj.normalizer.zeros.1', 'model.layers.25.mlp.gate_proj.bias', 'model.layers.25.mlp.gate_proj.codebook', 'model.layers.25.mlp.gate_proj.assignments', 'model.layers.25.mlp.gate_proj.normalizer.norms.0', 'model.layers.25.mlp.gate_proj.normalizer.norms.1', 'model.layers.25.mlp.gate_proj.normalizer.zeros.0', 'model.layers.25.mlp.gate_proj.normalizer.zeros.1', 'model.layers.25.mlp.up_proj.bias', 'model.layers.25.mlp.up_proj.codebook', 'model.layers.25.mlp.up_proj.assignments', 'model.layers.25.mlp.up_proj.normalizer.norms.0', 'model.layers.25.mlp.up_proj.normalizer.norms.1', 'model.layers.25.mlp.up_proj.normalizer.zeros.0', 'model.layers.25.mlp.up_proj.normalizer.zeros.1', 'model.layers.25.mlp.down_proj.bias', 'model.layers.25.mlp.down_proj.codebook', 'model.layers.25.mlp.down_proj.assignments', 'model.layers.25.mlp.down_proj.normalizer.norms.0', 'model.layers.25.mlp.down_proj.normalizer.norms.1', 'model.layers.25.mlp.down_proj.normalizer.zeros.0', 'model.layers.25.mlp.down_proj.normalizer.zeros.1', 'model.layers.26.self_attn.q_proj.bias', 'model.layers.26.self_attn.q_proj.codebook', 'model.layers.26.self_attn.q_proj.assignments', 'model.layers.26.self_attn.q_proj.normalizer.norms.0', 'model.layers.26.self_attn.q_proj.normalizer.norms.1', 'model.layers.26.self_attn.q_proj.normalizer.zeros.0', 'model.layers.26.self_attn.q_proj.normalizer.zeros.1', 'model.layers.26.self_attn.k_proj.bias', 'model.layers.26.self_attn.k_proj.codebook', 'model.layers.26.self_attn.k_proj.assignments', 'model.layers.26.self_attn.k_proj.normalizer.norms.0', 'model.layers.26.self_attn.k_proj.normalizer.norms.1', 'model.layers.26.self_attn.k_proj.normalizer.zeros.0', 'model.layers.26.self_attn.k_proj.normalizer.zeros.1', 'model.layers.26.self_attn.v_proj.bias', 'model.layers.26.self_attn.v_proj.codebook', 'model.layers.26.self_attn.v_proj.assignments', 'model.layers.26.self_attn.v_proj.normalizer.norms.0', 'model.layers.26.self_attn.v_proj.normalizer.norms.1', 'model.layers.26.self_attn.v_proj.normalizer.zeros.0', 'model.layers.26.self_attn.v_proj.normalizer.zeros.1', 'model.layers.26.self_attn.o_proj.bias', 'model.layers.26.self_attn.o_proj.codebook', 'model.layers.26.self_attn.o_proj.assignments', 'model.layers.26.self_attn.o_proj.normalizer.norms.0', 'model.layers.26.self_attn.o_proj.normalizer.norms.1', 'model.layers.26.self_attn.o_proj.normalizer.zeros.0', 'model.layers.26.self_attn.o_proj.normalizer.zeros.1', 'model.layers.26.mlp.gate_proj.bias', 'model.layers.26.mlp.gate_proj.codebook', 'model.layers.26.mlp.gate_proj.assignments', 'model.layers.26.mlp.gate_proj.normalizer.norms.0', 'model.layers.26.mlp.gate_proj.normalizer.norms.1', 'model.layers.26.mlp.gate_proj.normalizer.zeros.0', 'model.layers.26.mlp.gate_proj.normalizer.zeros.1', 'model.layers.26.mlp.up_proj.bias', 'model.layers.26.mlp.up_proj.codebook', 'model.layers.26.mlp.up_proj.assignments', 'model.layers.26.mlp.up_proj.normalizer.norms.0', 'model.layers.26.mlp.up_proj.normalizer.norms.1', 'model.layers.26.mlp.up_proj.normalizer.zeros.0', 'model.layers.26.mlp.up_proj.normalizer.zeros.1', 'model.layers.26.mlp.down_proj.bias', 'model.layers.26.mlp.down_proj.codebook', 'model.layers.26.mlp.down_proj.assignments', 'model.layers.26.mlp.down_proj.normalizer.norms.0', 'model.layers.26.mlp.down_proj.normalizer.norms.1', 'model.layers.26.mlp.down_proj.normalizer.zeros.0', 'model.layers.26.mlp.down_proj.normalizer.zeros.1', 'model.layers.27.self_attn.q_proj.bias', 'model.layers.27.self_attn.q_proj.codebook', 'model.layers.27.self_attn.q_proj.assignments', 'model.layers.27.self_attn.q_proj.normalizer.norms.0', 'model.layers.27.self_attn.q_proj.normalizer.norms.1', 'model.layers.27.self_attn.q_proj.normalizer.zeros.0', 'model.layers.27.self_attn.q_proj.normalizer.zeros.1', 'model.layers.27.self_attn.k_proj.bias', 'model.layers.27.self_attn.k_proj.codebook', 'model.layers.27.self_attn.k_proj.assignments', 'model.layers.27.self_attn.k_proj.normalizer.norms.0', 'model.layers.27.self_attn.k_proj.normalizer.norms.1', 'model.layers.27.self_attn.k_proj.normalizer.zeros.0', 'model.layers.27.self_attn.k_proj.normalizer.zeros.1', 'model.layers.27.self_attn.v_proj.bias', 'model.layers.27.self_attn.v_proj.codebook', 'model.layers.27.self_attn.v_proj.assignments', 'model.layers.27.self_attn.v_proj.normalizer.norms.0', 'model.layers.27.self_attn.v_proj.normalizer.norms.1', 'model.layers.27.self_attn.v_proj.normalizer.zeros.0', 'model.layers.27.self_attn.v_proj.normalizer.zeros.1', 'model.layers.27.self_attn.o_proj.bias', 'model.layers.27.self_attn.o_proj.codebook', 'model.layers.27.self_attn.o_proj.assignments', 'model.layers.27.self_attn.o_proj.normalizer.norms.0', 'model.layers.27.self_attn.o_proj.normalizer.norms.1', 'model.layers.27.self_attn.o_proj.normalizer.zeros.0', 'model.layers.27.self_attn.o_proj.normalizer.zeros.1', 'model.layers.27.mlp.gate_proj.bias', 'model.layers.27.mlp.gate_proj.codebook', 'model.layers.27.mlp.gate_proj.assignments', 'model.layers.27.mlp.gate_proj.normalizer.norms.0', 'model.layers.27.mlp.gate_proj.normalizer.norms.1', 'model.layers.27.mlp.gate_proj.normalizer.zeros.0', 'model.layers.27.mlp.gate_proj.normalizer.zeros.1', 'model.layers.27.mlp.up_proj.bias', 'model.layers.27.mlp.up_proj.codebook', 'model.layers.27.mlp.up_proj.assignments', 'model.layers.27.mlp.up_proj.normalizer.norms.0', 'model.layers.27.mlp.up_proj.normalizer.norms.1', 'model.layers.27.mlp.up_proj.normalizer.zeros.0', 'model.layers.27.mlp.up_proj.normalizer.zeros.1', 'model.layers.27.mlp.down_proj.bias', 'model.layers.27.mlp.down_proj.codebook', 'model.layers.27.mlp.down_proj.assignments', 'model.layers.27.mlp.down_proj.normalizer.norms.0', 'model.layers.27.mlp.down_proj.normalizer.norms.1', 'model.layers.27.mlp.down_proj.normalizer.zeros.0', 'model.layers.27.mlp.down_proj.normalizer.zeros.1', 'model.layers.28.self_attn.q_proj.bias', 'model.layers.28.self_attn.q_proj.codebook', 'model.layers.28.self_attn.q_proj.assignments', 'model.layers.28.self_attn.q_proj.normalizer.norms.0', 'model.layers.28.self_attn.q_proj.normalizer.norms.1', 'model.layers.28.self_attn.q_proj.normalizer.zeros.0', 'model.layers.28.self_attn.q_proj.normalizer.zeros.1', 'model.layers.28.self_attn.k_proj.bias', 'model.layers.28.self_attn.k_proj.codebook', 'model.layers.28.self_attn.k_proj.assignments', 'model.layers.28.self_attn.k_proj.normalizer.norms.0', 'model.layers.28.self_attn.k_proj.normalizer.norms.1', 'model.layers.28.self_attn.k_proj.normalizer.zeros.0', 'model.layers.28.self_attn.k_proj.normalizer.zeros.1', 'model.layers.28.self_attn.v_proj.bias', 'model.layers.28.self_attn.v_proj.codebook', 'model.layers.28.self_attn.v_proj.assignments', 'model.layers.28.self_attn.v_proj.normalizer.norms.0', 'model.layers.28.self_attn.v_proj.normalizer.norms.1', 'model.layers.28.self_attn.v_proj.normalizer.zeros.0', 'model.layers.28.self_attn.v_proj.normalizer.zeros.1', 'model.layers.28.self_attn.o_proj.bias', 'model.layers.28.self_attn.o_proj.codebook', 'model.layers.28.self_attn.o_proj.assignments', 'model.layers.28.self_attn.o_proj.normalizer.norms.0', 'model.layers.28.self_attn.o_proj.normalizer.norms.1', 'model.layers.28.self_attn.o_proj.normalizer.zeros.0', 'model.layers.28.self_attn.o_proj.normalizer.zeros.1', 'model.layers.28.mlp.gate_proj.bias', 'model.layers.28.mlp.gate_proj.codebook', 'model.layers.28.mlp.gate_proj.assignments', 'model.layers.28.mlp.gate_proj.normalizer.norms.0', 'model.layers.28.mlp.gate_proj.normalizer.norms.1', 'model.layers.28.mlp.gate_proj.normalizer.zeros.0', 'model.layers.28.mlp.gate_proj.normalizer.zeros.1', 'model.layers.28.mlp.up_proj.bias', 'model.layers.28.mlp.up_proj.codebook', 'model.layers.28.mlp.up_proj.assignments', 'model.layers.28.mlp.up_proj.normalizer.norms.0', 'model.layers.28.mlp.up_proj.normalizer.norms.1', 'model.layers.28.mlp.up_proj.normalizer.zeros.0', 'model.layers.28.mlp.up_proj.normalizer.zeros.1', 'model.layers.28.mlp.down_proj.bias', 'model.layers.28.mlp.down_proj.codebook', 'model.layers.28.mlp.down_proj.assignments', 'model.layers.28.mlp.down_proj.normalizer.norms.0', 'model.layers.28.mlp.down_proj.normalizer.norms.1', 'model.layers.28.mlp.down_proj.normalizer.zeros.0', 'model.layers.28.mlp.down_proj.normalizer.zeros.1', 'model.layers.29.self_attn.q_proj.bias', 'model.layers.29.self_attn.q_proj.codebook', 'model.layers.29.self_attn.q_proj.assignments', 'model.layers.29.self_attn.q_proj.normalizer.norms.0', 'model.layers.29.self_attn.q_proj.normalizer.norms.1', 'model.layers.29.self_attn.q_proj.normalizer.zeros.0', 'model.layers.29.self_attn.q_proj.normalizer.zeros.1', 'model.layers.29.self_attn.k_proj.bias', 'model.layers.29.self_attn.k_proj.codebook', 'model.layers.29.self_attn.k_proj.assignments', 'model.layers.29.self_attn.k_proj.normalizer.norms.0', 'model.layers.29.self_attn.k_proj.normalizer.norms.1', 'model.layers.29.self_attn.k_proj.normalizer.zeros.0', 'model.layers.29.self_attn.k_proj.normalizer.zeros.1', 'model.layers.29.self_attn.v_proj.bias', 'model.layers.29.self_attn.v_proj.codebook', 'model.layers.29.self_attn.v_proj.assignments', 'model.layers.29.self_attn.v_proj.normalizer.norms.0', 'model.layers.29.self_attn.v_proj.normalizer.norms.1', 'model.layers.29.self_attn.v_proj.normalizer.zeros.0', 'model.layers.29.self_attn.v_proj.normalizer.zeros.1', 'model.layers.29.self_attn.o_proj.bias', 'model.layers.29.self_attn.o_proj.codebook', 'model.layers.29.self_attn.o_proj.assignments', 'model.layers.29.self_attn.o_proj.normalizer.norms.0', 'model.layers.29.self_attn.o_proj.normalizer.norms.1', 'model.layers.29.self_attn.o_proj.normalizer.zeros.0', 'model.layers.29.self_attn.o_proj.normalizer.zeros.1', 'model.layers.29.mlp.gate_proj.bias', 'model.layers.29.mlp.gate_proj.codebook', 'model.layers.29.mlp.gate_proj.assignments', 'model.layers.29.mlp.gate_proj.normalizer.norms.0', 'model.layers.29.mlp.gate_proj.normalizer.norms.1', 'model.layers.29.mlp.gate_proj.normalizer.zeros.0', 'model.layers.29.mlp.gate_proj.normalizer.zeros.1', 'model.layers.29.mlp.up_proj.bias', 'model.layers.29.mlp.up_proj.codebook', 'model.layers.29.mlp.up_proj.assignments', 'model.layers.29.mlp.up_proj.normalizer.norms.0', 'model.layers.29.mlp.up_proj.normalizer.norms.1', 'model.layers.29.mlp.up_proj.normalizer.zeros.0', 'model.layers.29.mlp.up_proj.normalizer.zeros.1', 'model.layers.29.mlp.down_proj.bias', 'model.layers.29.mlp.down_proj.codebook', 'model.layers.29.mlp.down_proj.assignments', 'model.layers.29.mlp.down_proj.normalizer.norms.0', 'model.layers.29.mlp.down_proj.normalizer.norms.1', 'model.layers.29.mlp.down_proj.normalizer.zeros.0', 'model.layers.29.mlp.down_proj.normalizer.zeros.1', 'model.layers.30.self_attn.q_proj.bias', 'model.layers.30.self_attn.q_proj.codebook', 'model.layers.30.self_attn.q_proj.assignments', 'model.layers.30.self_attn.q_proj.normalizer.norms.0', 'model.layers.30.self_attn.q_proj.normalizer.norms.1', 'model.layers.30.self_attn.q_proj.normalizer.zeros.0', 'model.layers.30.self_attn.q_proj.normalizer.zeros.1', 'model.layers.30.self_attn.k_proj.bias', 'model.layers.30.self_attn.k_proj.codebook', 'model.layers.30.self_attn.k_proj.assignments', 'model.layers.30.self_attn.k_proj.normalizer.norms.0', 'model.layers.30.self_attn.k_proj.normalizer.norms.1', 'model.layers.30.self_attn.k_proj.normalizer.zeros.0', 'model.layers.30.self_attn.k_proj.normalizer.zeros.1', 'model.layers.30.self_attn.v_proj.bias', 'model.layers.30.self_attn.v_proj.codebook', 'model.layers.30.self_attn.v_proj.assignments', 'model.layers.30.self_attn.v_proj.normalizer.norms.0', 'model.layers.30.self_attn.v_proj.normalizer.norms.1', 'model.layers.30.self_attn.v_proj.normalizer.zeros.0', 'model.layers.30.self_attn.v_proj.normalizer.zeros.1', 'model.layers.30.self_attn.o_proj.bias', 'model.layers.30.self_attn.o_proj.codebook', 'model.layers.30.self_attn.o_proj.assignments', 'model.layers.30.self_attn.o_proj.normalizer.norms.0', 'model.layers.30.self_attn.o_proj.normalizer.norms.1', 'model.layers.30.self_attn.o_proj.normalizer.zeros.0', 'model.layers.30.self_attn.o_proj.normalizer.zeros.1', 'model.layers.30.mlp.gate_proj.bias', 'model.layers.30.mlp.gate_proj.codebook', 'model.layers.30.mlp.gate_proj.assignments', 'model.layers.30.mlp.gate_proj.normalizer.norms.0', 'model.layers.30.mlp.gate_proj.normalizer.norms.1', 'model.layers.30.mlp.gate_proj.normalizer.zeros.0', 'model.layers.30.mlp.gate_proj.normalizer.zeros.1', 'model.layers.30.mlp.up_proj.bias', 'model.layers.30.mlp.up_proj.codebook', 'model.layers.30.mlp.up_proj.assignments', 'model.layers.30.mlp.up_proj.normalizer.norms.0', 'model.layers.30.mlp.up_proj.normalizer.norms.1', 'model.layers.30.mlp.up_proj.normalizer.zeros.0', 'model.layers.30.mlp.up_proj.normalizer.zeros.1', 'model.layers.30.mlp.down_proj.bias', 'model.layers.30.mlp.down_proj.codebook', 'model.layers.30.mlp.down_proj.assignments', 'model.layers.30.mlp.down_proj.normalizer.norms.0', 'model.layers.30.mlp.down_proj.normalizer.norms.1', 'model.layers.30.mlp.down_proj.normalizer.zeros.0', 'model.layers.30.mlp.down_proj.normalizer.zeros.1', 'model.layers.31.self_attn.q_proj.bias', 'model.layers.31.self_attn.q_proj.codebook', 'model.layers.31.self_attn.q_proj.assignments', 'model.layers.31.self_attn.q_proj.normalizer.norms.0', 'model.layers.31.self_attn.q_proj.normalizer.norms.1', 'model.layers.31.self_attn.q_proj.normalizer.zeros.0', 'model.layers.31.self_attn.q_proj.normalizer.zeros.1', 'model.layers.31.self_attn.k_proj.bias', 'model.layers.31.self_attn.k_proj.codebook', 'model.layers.31.self_attn.k_proj.assignments', 'model.layers.31.self_attn.k_proj.normalizer.norms.0', 'model.layers.31.self_attn.k_proj.normalizer.norms.1', 'model.layers.31.self_attn.k_proj.normalizer.zeros.0', 'model.layers.31.self_attn.k_proj.normalizer.zeros.1', 'model.layers.31.self_attn.v_proj.bias', 'model.layers.31.self_attn.v_proj.codebook', 'model.layers.31.self_attn.v_proj.assignments', 'model.layers.31.self_attn.v_proj.normalizer.norms.0', 'model.layers.31.self_attn.v_proj.normalizer.norms.1', 'model.layers.31.self_attn.v_proj.normalizer.zeros.0', 'model.layers.31.self_attn.v_proj.normalizer.zeros.1', 'model.layers.31.self_attn.o_proj.bias', 'model.layers.31.self_attn.o_proj.codebook', 'model.layers.31.self_attn.o_proj.assignments', 'model.layers.31.self_attn.o_proj.normalizer.norms.0', 'model.layers.31.self_attn.o_proj.normalizer.norms.1', 'model.layers.31.self_attn.o_proj.normalizer.zeros.0', 'model.layers.31.self_attn.o_proj.normalizer.zeros.1', 'model.layers.31.mlp.gate_proj.bias', 'model.layers.31.mlp.gate_proj.codebook', 'model.layers.31.mlp.gate_proj.assignments', 'model.layers.31.mlp.gate_proj.normalizer.norms.0', 'model.layers.31.mlp.gate_proj.normalizer.norms.1', 'model.layers.31.mlp.gate_proj.normalizer.zeros.0', 'model.layers.31.mlp.gate_proj.normalizer.zeros.1', 'model.layers.31.mlp.up_proj.bias', 'model.layers.31.mlp.up_proj.codebook', 'model.layers.31.mlp.up_proj.assignments', 'model.layers.31.mlp.up_proj.normalizer.norms.0', 'model.layers.31.mlp.up_proj.normalizer.norms.1', 'model.layers.31.mlp.up_proj.normalizer.zeros.0', 'model.layers.31.mlp.up_proj.normalizer.zeros.1', 'model.layers.31.mlp.down_proj.bias', 'model.layers.31.mlp.down_proj.codebook', 'model.layers.31.mlp.down_proj.assignments', 'model.layers.31.mlp.down_proj.normalizer.norms.0', 'model.layers.31.mlp.down_proj.normalizer.norms.1', 'model.layers.31.mlp.down_proj.normalizer.zeros.0', 'model.layers.31.mlp.down_proj.normalizer.zeros.1', 'model.layers.32.self_attn.q_proj.bias', 'model.layers.32.self_attn.q_proj.codebook', 'model.layers.32.self_attn.q_proj.assignments', 'model.layers.32.self_attn.q_proj.normalizer.norms.0', 'model.layers.32.self_attn.q_proj.normalizer.norms.1', 'model.layers.32.self_attn.q_proj.normalizer.zeros.0', 'model.layers.32.self_attn.q_proj.normalizer.zeros.1', 'model.layers.32.self_attn.k_proj.bias', 'model.layers.32.self_attn.k_proj.codebook', 'model.layers.32.self_attn.k_proj.assignments', 'model.layers.32.self_attn.k_proj.normalizer.norms.0', 'model.layers.32.self_attn.k_proj.normalizer.norms.1', 'model.layers.32.self_attn.k_proj.normalizer.zeros.0', 'model.layers.32.self_attn.k_proj.normalizer.zeros.1', 'model.layers.32.self_attn.v_proj.bias', 'model.layers.32.self_attn.v_proj.codebook', 'model.layers.32.self_attn.v_proj.assignments', 'model.layers.32.self_attn.v_proj.normalizer.norms.0', 'model.layers.32.self_attn.v_proj.normalizer.norms.1', 'model.layers.32.self_attn.v_proj.normalizer.zeros.0', 'model.layers.32.self_attn.v_proj.normalizer.zeros.1', 'model.layers.32.self_attn.o_proj.bias', 'model.layers.32.self_attn.o_proj.codebook', 'model.layers.32.self_attn.o_proj.assignments', 'model.layers.32.self_attn.o_proj.normalizer.norms.0', 'model.layers.32.self_attn.o_proj.normalizer.norms.1', 'model.layers.32.self_attn.o_proj.normalizer.zeros.0', 'model.layers.32.self_attn.o_proj.normalizer.zeros.1', 'model.layers.32.mlp.gate_proj.bias', 'model.layers.32.mlp.gate_proj.codebook', 'model.layers.32.mlp.gate_proj.assignments', 'model.layers.32.mlp.gate_proj.normalizer.norms.0', 'model.layers.32.mlp.gate_proj.normalizer.norms.1', 'model.layers.32.mlp.gate_proj.normalizer.zeros.0', 'model.layers.32.mlp.gate_proj.normalizer.zeros.1', 'model.layers.32.mlp.up_proj.bias', 'model.layers.32.mlp.up_proj.codebook', 'model.layers.32.mlp.up_proj.assignments', 'model.layers.32.mlp.up_proj.normalizer.norms.0', 'model.layers.32.mlp.up_proj.normalizer.norms.1', 'model.layers.32.mlp.up_proj.normalizer.zeros.0', 'model.layers.32.mlp.up_proj.normalizer.zeros.1', 'model.layers.32.mlp.down_proj.bias', 'model.layers.32.mlp.down_proj.codebook', 'model.layers.32.mlp.down_proj.assignments', 'model.layers.32.mlp.down_proj.normalizer.norms.0', 'model.layers.32.mlp.down_proj.normalizer.norms.1', 'model.layers.32.mlp.down_proj.normalizer.zeros.0', 'model.layers.32.mlp.down_proj.normalizer.zeros.1', 'model.layers.33.self_attn.q_proj.bias', 'model.layers.33.self_attn.q_proj.codebook', 'model.layers.33.self_attn.q_proj.assignments', 'model.layers.33.self_attn.q_proj.normalizer.norms.0', 'model.layers.33.self_attn.q_proj.normalizer.norms.1', 'model.layers.33.self_attn.q_proj.normalizer.zeros.0', 'model.layers.33.self_attn.q_proj.normalizer.zeros.1', 'model.layers.33.self_attn.k_proj.bias', 'model.layers.33.self_attn.k_proj.codebook', 'model.layers.33.self_attn.k_proj.assignments', 'model.layers.33.self_attn.k_proj.normalizer.norms.0', 'model.layers.33.self_attn.k_proj.normalizer.norms.1', 'model.layers.33.self_attn.k_proj.normalizer.zeros.0', 'model.layers.33.self_attn.k_proj.normalizer.zeros.1', 'model.layers.33.self_attn.v_proj.bias', 'model.layers.33.self_attn.v_proj.codebook', 'model.layers.33.self_attn.v_proj.assignments', 'model.layers.33.self_attn.v_proj.normalizer.norms.0', 'model.layers.33.self_attn.v_proj.normalizer.norms.1', 'model.layers.33.self_attn.v_proj.normalizer.zeros.0', 'model.layers.33.self_attn.v_proj.normalizer.zeros.1', 'model.layers.33.self_attn.o_proj.bias', 'model.layers.33.self_attn.o_proj.codebook', 'model.layers.33.self_attn.o_proj.assignments', 'model.layers.33.self_attn.o_proj.normalizer.norms.0', 'model.layers.33.self_attn.o_proj.normalizer.norms.1', 'model.layers.33.self_attn.o_proj.normalizer.zeros.0', 'model.layers.33.self_attn.o_proj.normalizer.zeros.1', 'model.layers.33.mlp.gate_proj.bias', 'model.layers.33.mlp.gate_proj.codebook', 'model.layers.33.mlp.gate_proj.assignments', 'model.layers.33.mlp.gate_proj.normalizer.norms.0', 'model.layers.33.mlp.gate_proj.normalizer.norms.1', 'model.layers.33.mlp.gate_proj.normalizer.zeros.0', 'model.layers.33.mlp.gate_proj.normalizer.zeros.1', 'model.layers.33.mlp.up_proj.bias', 'model.layers.33.mlp.up_proj.codebook', 'model.layers.33.mlp.up_proj.assignments', 'model.layers.33.mlp.up_proj.normalizer.norms.0', 'model.layers.33.mlp.up_proj.normalizer.norms.1', 'model.layers.33.mlp.up_proj.normalizer.zeros.0', 'model.layers.33.mlp.up_proj.normalizer.zeros.1', 'model.layers.33.mlp.down_proj.bias', 'model.layers.33.mlp.down_proj.codebook', 'model.layers.33.mlp.down_proj.assignments', 'model.layers.33.mlp.down_proj.normalizer.norms.0', 'model.layers.33.mlp.down_proj.normalizer.norms.1', 'model.layers.33.mlp.down_proj.normalizer.zeros.0', 'model.layers.33.mlp.down_proj.normalizer.zeros.1', 'model.layers.34.self_attn.q_proj.bias', 'model.layers.34.self_attn.q_proj.codebook', 'model.layers.34.self_attn.q_proj.assignments', 'model.layers.34.self_attn.q_proj.normalizer.norms.0', 'model.layers.34.self_attn.q_proj.normalizer.norms.1', 'model.layers.34.self_attn.q_proj.normalizer.zeros.0', 'model.layers.34.self_attn.q_proj.normalizer.zeros.1', 'model.layers.34.self_attn.k_proj.bias', 'model.layers.34.self_attn.k_proj.codebook', 'model.layers.34.self_attn.k_proj.assignments', 'model.layers.34.self_attn.k_proj.normalizer.norms.0', 'model.layers.34.self_attn.k_proj.normalizer.norms.1', 'model.layers.34.self_attn.k_proj.normalizer.zeros.0', 'model.layers.34.self_attn.k_proj.normalizer.zeros.1', 'model.layers.34.self_attn.v_proj.bias', 'model.layers.34.self_attn.v_proj.codebook', 'model.layers.34.self_attn.v_proj.assignments', 'model.layers.34.self_attn.v_proj.normalizer.norms.0', 'model.layers.34.self_attn.v_proj.normalizer.norms.1', 'model.layers.34.self_attn.v_proj.normalizer.zeros.0', 'model.layers.34.self_attn.v_proj.normalizer.zeros.1', 'model.layers.34.self_attn.o_proj.bias', 'model.layers.34.self_attn.o_proj.codebook', 'model.layers.34.self_attn.o_proj.assignments', 'model.layers.34.self_attn.o_proj.normalizer.norms.0', 'model.layers.34.self_attn.o_proj.normalizer.norms.1', 'model.layers.34.self_attn.o_proj.normalizer.zeros.0', 'model.layers.34.self_attn.o_proj.normalizer.zeros.1', 'model.layers.34.mlp.gate_proj.bias', 'model.layers.34.mlp.gate_proj.codebook', 'model.layers.34.mlp.gate_proj.assignments', 'model.layers.34.mlp.gate_proj.normalizer.norms.0', 'model.layers.34.mlp.gate_proj.normalizer.norms.1', 'model.layers.34.mlp.gate_proj.normalizer.zeros.0', 'model.layers.34.mlp.gate_proj.normalizer.zeros.1', 'model.layers.34.mlp.up_proj.bias', 'model.layers.34.mlp.up_proj.codebook', 'model.layers.34.mlp.up_proj.assignments', 'model.layers.34.mlp.up_proj.normalizer.norms.0', 'model.layers.34.mlp.up_proj.normalizer.norms.1', 'model.layers.34.mlp.up_proj.normalizer.zeros.0', 'model.layers.34.mlp.up_proj.normalizer.zeros.1', 'model.layers.34.mlp.down_proj.bias', 'model.layers.34.mlp.down_proj.codebook', 'model.layers.34.mlp.down_proj.assignments', 'model.layers.34.mlp.down_proj.normalizer.norms.0', 'model.layers.34.mlp.down_proj.normalizer.norms.1', 'model.layers.34.mlp.down_proj.normalizer.zeros.0', 'model.layers.34.mlp.down_proj.normalizer.zeros.1', 'model.layers.35.self_attn.q_proj.bias', 'model.layers.35.self_attn.q_proj.codebook', 'model.layers.35.self_attn.q_proj.assignments', 'model.layers.35.self_attn.q_proj.normalizer.norms.0', 'model.layers.35.self_attn.q_proj.normalizer.norms.1', 'model.layers.35.self_attn.q_proj.normalizer.zeros.0', 'model.layers.35.self_attn.q_proj.normalizer.zeros.1', 'model.layers.35.self_attn.k_proj.bias', 'model.layers.35.self_attn.k_proj.codebook', 'model.layers.35.self_attn.k_proj.assignments', 'model.layers.35.self_attn.k_proj.normalizer.norms.0', 'model.layers.35.self_attn.k_proj.normalizer.norms.1', 'model.layers.35.self_attn.k_proj.normalizer.zeros.0', 'model.layers.35.self_attn.k_proj.normalizer.zeros.1', 'model.layers.35.self_attn.v_proj.bias', 'model.layers.35.self_attn.v_proj.codebook', 'model.layers.35.self_attn.v_proj.assignments', 'model.layers.35.self_attn.v_proj.normalizer.norms.0', 'model.layers.35.self_attn.v_proj.normalizer.norms.1', 'model.layers.35.self_attn.v_proj.normalizer.zeros.0', 'model.layers.35.self_attn.v_proj.normalizer.zeros.1', 'model.layers.35.self_attn.o_proj.bias', 'model.layers.35.self_attn.o_proj.codebook', 'model.layers.35.self_attn.o_proj.assignments', 'model.layers.35.self_attn.o_proj.normalizer.norms.0', 'model.layers.35.self_attn.o_proj.normalizer.norms.1', 'model.layers.35.self_attn.o_proj.normalizer.zeros.0', 'model.layers.35.self_attn.o_proj.normalizer.zeros.1', 'model.layers.35.mlp.gate_proj.bias', 'model.layers.35.mlp.gate_proj.codebook', 'model.layers.35.mlp.gate_proj.assignments', 'model.layers.35.mlp.gate_proj.normalizer.norms.0', 'model.layers.35.mlp.gate_proj.normalizer.norms.1', 'model.layers.35.mlp.gate_proj.normalizer.zeros.0', 'model.layers.35.mlp.gate_proj.normalizer.zeros.1', 'model.layers.35.mlp.up_proj.bias', 'model.layers.35.mlp.up_proj.codebook', 'model.layers.35.mlp.up_proj.assignments', 'model.layers.35.mlp.up_proj.normalizer.norms.0', 'model.layers.35.mlp.up_proj.normalizer.norms.1', 'model.layers.35.mlp.up_proj.normalizer.zeros.0', 'model.layers.35.mlp.up_proj.normalizer.zeros.1', 'model.layers.35.mlp.down_proj.bias', 'model.layers.35.mlp.down_proj.codebook', 'model.layers.35.mlp.down_proj.assignments', 'model.layers.35.mlp.down_proj.normalizer.norms.0', 'model.layers.35.mlp.down_proj.normalizer.norms.1', 'model.layers.35.mlp.down_proj.normalizer.zeros.0', 'model.layers.35.mlp.down_proj.normalizer.zeros.1', 'model.layers.36.self_attn.q_proj.bias', 'model.layers.36.self_attn.q_proj.codebook', 'model.layers.36.self_attn.q_proj.assignments', 'model.layers.36.self_attn.q_proj.normalizer.norms.0', 'model.layers.36.self_attn.q_proj.normalizer.norms.1', 'model.layers.36.self_attn.q_proj.normalizer.zeros.0', 'model.layers.36.self_attn.q_proj.normalizer.zeros.1', 'model.layers.36.self_attn.k_proj.bias', 'model.layers.36.self_attn.k_proj.codebook', 'model.layers.36.self_attn.k_proj.assignments', 'model.layers.36.self_attn.k_proj.normalizer.norms.0', 'model.layers.36.self_attn.k_proj.normalizer.norms.1', 'model.layers.36.self_attn.k_proj.normalizer.zeros.0', 'model.layers.36.self_attn.k_proj.normalizer.zeros.1', 'model.layers.36.self_attn.v_proj.bias', 'model.layers.36.self_attn.v_proj.codebook', 'model.layers.36.self_attn.v_proj.assignments', 'model.layers.36.self_attn.v_proj.normalizer.norms.0', 'model.layers.36.self_attn.v_proj.normalizer.norms.1', 'model.layers.36.self_attn.v_proj.normalizer.zeros.0', 'model.layers.36.self_attn.v_proj.normalizer.zeros.1', 'model.layers.36.self_attn.o_proj.bias', 'model.layers.36.self_attn.o_proj.codebook', 'model.layers.36.self_attn.o_proj.assignments', 'model.layers.36.self_attn.o_proj.normalizer.norms.0', 'model.layers.36.self_attn.o_proj.normalizer.norms.1', 'model.layers.36.self_attn.o_proj.normalizer.zeros.0', 'model.layers.36.self_attn.o_proj.normalizer.zeros.1', 'model.layers.36.mlp.gate_proj.bias', 'model.layers.36.mlp.gate_proj.codebook', 'model.layers.36.mlp.gate_proj.assignments', 'model.layers.36.mlp.gate_proj.normalizer.norms.0', 'model.layers.36.mlp.gate_proj.normalizer.norms.1', 'model.layers.36.mlp.gate_proj.normalizer.zeros.0', 'model.layers.36.mlp.gate_proj.normalizer.zeros.1', 'model.layers.36.mlp.up_proj.bias', 'model.layers.36.mlp.up_proj.codebook', 'model.layers.36.mlp.up_proj.assignments', 'model.layers.36.mlp.up_proj.normalizer.norms.0', 'model.layers.36.mlp.up_proj.normalizer.norms.1', 'model.layers.36.mlp.up_proj.normalizer.zeros.0', 'model.layers.36.mlp.up_proj.normalizer.zeros.1', 'model.layers.36.mlp.down_proj.bias', 'model.layers.36.mlp.down_proj.codebook', 'model.layers.36.mlp.down_proj.assignments', 'model.layers.36.mlp.down_proj.normalizer.norms.0', 'model.layers.36.mlp.down_proj.normalizer.norms.1', 'model.layers.36.mlp.down_proj.normalizer.zeros.0', 'model.layers.36.mlp.down_proj.normalizer.zeros.1', 'model.layers.37.self_attn.q_proj.bias', 'model.layers.37.self_attn.q_proj.codebook', 'model.layers.37.self_attn.q_proj.assignments', 'model.layers.37.self_attn.q_proj.normalizer.norms.0', 'model.layers.37.self_attn.q_proj.normalizer.norms.1', 'model.layers.37.self_attn.q_proj.normalizer.zeros.0', 'model.layers.37.self_attn.q_proj.normalizer.zeros.1', 'model.layers.37.self_attn.k_proj.bias', 'model.layers.37.self_attn.k_proj.codebook', 'model.layers.37.self_attn.k_proj.assignments', 'model.layers.37.self_attn.k_proj.normalizer.norms.0', 'model.layers.37.self_attn.k_proj.normalizer.norms.1', 'model.layers.37.self_attn.k_proj.normalizer.zeros.0', 'model.layers.37.self_attn.k_proj.normalizer.zeros.1', 'model.layers.37.self_attn.v_proj.bias', 'model.layers.37.self_attn.v_proj.codebook', 'model.layers.37.self_attn.v_proj.assignments', 'model.layers.37.self_attn.v_proj.normalizer.norms.0', 'model.layers.37.self_attn.v_proj.normalizer.norms.1', 'model.layers.37.self_attn.v_proj.normalizer.zeros.0', 'model.layers.37.self_attn.v_proj.normalizer.zeros.1', 'model.layers.37.self_attn.o_proj.bias', 'model.layers.37.self_attn.o_proj.codebook', 'model.layers.37.self_attn.o_proj.assignments', 'model.layers.37.self_attn.o_proj.normalizer.norms.0', 'model.layers.37.self_attn.o_proj.normalizer.norms.1', 'model.layers.37.self_attn.o_proj.normalizer.zeros.0', 'model.layers.37.self_attn.o_proj.normalizer.zeros.1', 'model.layers.37.mlp.gate_proj.bias', 'model.layers.37.mlp.gate_proj.codebook', 'model.layers.37.mlp.gate_proj.assignments', 'model.layers.37.mlp.gate_proj.normalizer.norms.0', 'model.layers.37.mlp.gate_proj.normalizer.norms.1', 'model.layers.37.mlp.gate_proj.normalizer.zeros.0', 'model.layers.37.mlp.gate_proj.normalizer.zeros.1', 'model.layers.37.mlp.up_proj.bias', 'model.layers.37.mlp.up_proj.codebook', 'model.layers.37.mlp.up_proj.assignments', 'model.layers.37.mlp.up_proj.normalizer.norms.0', 'model.layers.37.mlp.up_proj.normalizer.norms.1', 'model.layers.37.mlp.up_proj.normalizer.zeros.0', 'model.layers.37.mlp.up_proj.normalizer.zeros.1', 'model.layers.37.mlp.down_proj.bias', 'model.layers.37.mlp.down_proj.codebook', 'model.layers.37.mlp.down_proj.assignments', 'model.layers.37.mlp.down_proj.normalizer.norms.0', 'model.layers.37.mlp.down_proj.normalizer.norms.1', 'model.layers.37.mlp.down_proj.normalizer.zeros.0', 'model.layers.37.mlp.down_proj.normalizer.zeros.1', 'model.layers.38.self_attn.q_proj.bias', 'model.layers.38.self_attn.q_proj.codebook', 'model.layers.38.self_attn.q_proj.assignments', 'model.layers.38.self_attn.q_proj.normalizer.norms.0', 'model.layers.38.self_attn.q_proj.normalizer.norms.1', 'model.layers.38.self_attn.q_proj.normalizer.zeros.0', 'model.layers.38.self_attn.q_proj.normalizer.zeros.1', 'model.layers.38.self_attn.k_proj.bias', 'model.layers.38.self_attn.k_proj.codebook', 'model.layers.38.self_attn.k_proj.assignments', 'model.layers.38.self_attn.k_proj.normalizer.norms.0', 'model.layers.38.self_attn.k_proj.normalizer.norms.1', 'model.layers.38.self_attn.k_proj.normalizer.zeros.0', 'model.layers.38.self_attn.k_proj.normalizer.zeros.1', 'model.layers.38.self_attn.v_proj.bias', 'model.layers.38.self_attn.v_proj.codebook', 'model.layers.38.self_attn.v_proj.assignments', 'model.layers.38.self_attn.v_proj.normalizer.norms.0', 'model.layers.38.self_attn.v_proj.normalizer.norms.1', 'model.layers.38.self_attn.v_proj.normalizer.zeros.0', 'model.layers.38.self_attn.v_proj.normalizer.zeros.1', 'model.layers.38.self_attn.o_proj.bias', 'model.layers.38.self_attn.o_proj.codebook', 'model.layers.38.self_attn.o_proj.assignments', 'model.layers.38.self_attn.o_proj.normalizer.norms.0', 'model.layers.38.self_attn.o_proj.normalizer.norms.1', 'model.layers.38.self_attn.o_proj.normalizer.zeros.0', 'model.layers.38.self_attn.o_proj.normalizer.zeros.1', 'model.layers.38.mlp.gate_proj.bias', 'model.layers.38.mlp.gate_proj.codebook', 'model.layers.38.mlp.gate_proj.assignments', 'model.layers.38.mlp.gate_proj.normalizer.norms.0', 'model.layers.38.mlp.gate_proj.normalizer.norms.1', 'model.layers.38.mlp.gate_proj.normalizer.zeros.0', 'model.layers.38.mlp.gate_proj.normalizer.zeros.1', 'model.layers.38.mlp.up_proj.bias', 'model.layers.38.mlp.up_proj.codebook', 'model.layers.38.mlp.up_proj.assignments', 'model.layers.38.mlp.up_proj.normalizer.norms.0', 'model.layers.38.mlp.up_proj.normalizer.norms.1', 'model.layers.38.mlp.up_proj.normalizer.zeros.0', 'model.layers.38.mlp.up_proj.normalizer.zeros.1', 'model.layers.38.mlp.down_proj.bias', 'model.layers.38.mlp.down_proj.codebook', 'model.layers.38.mlp.down_proj.assignments', 'model.layers.38.mlp.down_proj.normalizer.norms.0', 'model.layers.38.mlp.down_proj.normalizer.norms.1', 'model.layers.38.mlp.down_proj.normalizer.zeros.0', 'model.layers.38.mlp.down_proj.normalizer.zeros.1', 'model.layers.39.self_attn.q_proj.bias', 'model.layers.39.self_attn.q_proj.codebook', 'model.layers.39.self_attn.q_proj.assignments', 'model.layers.39.self_attn.q_proj.normalizer.norms.0', 'model.layers.39.self_attn.q_proj.normalizer.norms.1', 'model.layers.39.self_attn.q_proj.normalizer.zeros.0', 'model.layers.39.self_attn.q_proj.normalizer.zeros.1', 'model.layers.39.self_attn.k_proj.bias', 'model.layers.39.self_attn.k_proj.codebook', 'model.layers.39.self_attn.k_proj.assignments', 'model.layers.39.self_attn.k_proj.normalizer.norms.0', 'model.layers.39.self_attn.k_proj.normalizer.norms.1', 'model.layers.39.self_attn.k_proj.normalizer.zeros.0', 'model.layers.39.self_attn.k_proj.normalizer.zeros.1', 'model.layers.39.self_attn.v_proj.bias', 'model.layers.39.self_attn.v_proj.codebook', 'model.layers.39.self_attn.v_proj.assignments', 'model.layers.39.self_attn.v_proj.normalizer.norms.0', 'model.layers.39.self_attn.v_proj.normalizer.norms.1', 'model.layers.39.self_attn.v_proj.normalizer.zeros.0', 'model.layers.39.self_attn.v_proj.normalizer.zeros.1', 'model.layers.39.self_attn.o_proj.bias', 'model.layers.39.self_attn.o_proj.codebook', 'model.layers.39.self_attn.o_proj.assignments', 'model.layers.39.self_attn.o_proj.normalizer.norms.0', 'model.layers.39.self_attn.o_proj.normalizer.norms.1', 'model.layers.39.self_attn.o_proj.normalizer.zeros.0', 'model.layers.39.self_attn.o_proj.normalizer.zeros.1', 'model.layers.39.mlp.gate_proj.bias', 'model.layers.39.mlp.gate_proj.codebook', 'model.layers.39.mlp.gate_proj.assignments', 'model.layers.39.mlp.gate_proj.normalizer.norms.0', 'model.layers.39.mlp.gate_proj.normalizer.norms.1', 'model.layers.39.mlp.gate_proj.normalizer.zeros.0', 'model.layers.39.mlp.gate_proj.normalizer.zeros.1', 'model.layers.39.mlp.up_proj.bias', 'model.layers.39.mlp.up_proj.codebook', 'model.layers.39.mlp.up_proj.assignments', 'model.layers.39.mlp.up_proj.normalizer.norms.0', 'model.layers.39.mlp.up_proj.normalizer.norms.1', 'model.layers.39.mlp.up_proj.normalizer.zeros.0', 'model.layers.39.mlp.up_proj.normalizer.zeros.1', 'model.layers.39.mlp.down_proj.bias', 'model.layers.39.mlp.down_proj.codebook', 'model.layers.39.mlp.down_proj.assignments', 'model.layers.39.mlp.down_proj.normalizer.norms.0', 'model.layers.39.mlp.down_proj.normalizer.norms.1', 'model.layers.39.mlp.down_proj.normalizer.zeros.0', 'model.layers.39.mlp.down_proj.normalizer.zeros.1', 'model.layers.40.self_attn.q_proj.bias', 'model.layers.40.self_attn.q_proj.codebook', 'model.layers.40.self_attn.q_proj.assignments', 'model.layers.40.self_attn.q_proj.normalizer.norms.0', 'model.layers.40.self_attn.q_proj.normalizer.norms.1', 'model.layers.40.self_attn.q_proj.normalizer.zeros.0', 'model.layers.40.self_attn.q_proj.normalizer.zeros.1', 'model.layers.40.self_attn.k_proj.bias', 'model.layers.40.self_attn.k_proj.codebook', 'model.layers.40.self_attn.k_proj.assignments', 'model.layers.40.self_attn.k_proj.normalizer.norms.0', 'model.layers.40.self_attn.k_proj.normalizer.norms.1', 'model.layers.40.self_attn.k_proj.normalizer.zeros.0', 'model.layers.40.self_attn.k_proj.normalizer.zeros.1', 'model.layers.40.self_attn.v_proj.bias', 'model.layers.40.self_attn.v_proj.codebook', 'model.layers.40.self_attn.v_proj.assignments', 'model.layers.40.self_attn.v_proj.normalizer.norms.0', 'model.layers.40.self_attn.v_proj.normalizer.norms.1', 'model.layers.40.self_attn.v_proj.normalizer.zeros.0', 'model.layers.40.self_attn.v_proj.normalizer.zeros.1', 'model.layers.40.self_attn.o_proj.bias', 'model.layers.40.self_attn.o_proj.codebook', 'model.layers.40.self_attn.o_proj.assignments', 'model.layers.40.self_attn.o_proj.normalizer.norms.0', 'model.layers.40.self_attn.o_proj.normalizer.norms.1', 'model.layers.40.self_attn.o_proj.normalizer.zeros.0', 'model.layers.40.self_attn.o_proj.normalizer.zeros.1', 'model.layers.40.mlp.gate_proj.bias', 'model.layers.40.mlp.gate_proj.codebook', 'model.layers.40.mlp.gate_proj.assignments', 'model.layers.40.mlp.gate_proj.normalizer.norms.0', 'model.layers.40.mlp.gate_proj.normalizer.norms.1', 'model.layers.40.mlp.gate_proj.normalizer.zeros.0', 'model.layers.40.mlp.gate_proj.normalizer.zeros.1', 'model.layers.40.mlp.up_proj.bias', 'model.layers.40.mlp.up_proj.codebook', 'model.layers.40.mlp.up_proj.assignments', 'model.layers.40.mlp.up_proj.normalizer.norms.0', 'model.layers.40.mlp.up_proj.normalizer.norms.1', 'model.layers.40.mlp.up_proj.normalizer.zeros.0', 'model.layers.40.mlp.up_proj.normalizer.zeros.1', 'model.layers.40.mlp.down_proj.bias', 'model.layers.40.mlp.down_proj.codebook', 'model.layers.40.mlp.down_proj.assignments', 'model.layers.40.mlp.down_proj.normalizer.norms.0', 'model.layers.40.mlp.down_proj.normalizer.norms.1', 'model.layers.40.mlp.down_proj.normalizer.zeros.0', 'model.layers.40.mlp.down_proj.normalizer.zeros.1', 'model.layers.41.self_attn.q_proj.bias', 'model.layers.41.self_attn.q_proj.codebook', 'model.layers.41.self_attn.q_proj.assignments', 'model.layers.41.self_attn.q_proj.normalizer.norms.0', 'model.layers.41.self_attn.q_proj.normalizer.norms.1', 'model.layers.41.self_attn.q_proj.normalizer.zeros.0', 'model.layers.41.self_attn.q_proj.normalizer.zeros.1', 'model.layers.41.self_attn.k_proj.bias', 'model.layers.41.self_attn.k_proj.codebook', 'model.layers.41.self_attn.k_proj.assignments', 'model.layers.41.self_attn.k_proj.normalizer.norms.0', 'model.layers.41.self_attn.k_proj.normalizer.norms.1', 'model.layers.41.self_attn.k_proj.normalizer.zeros.0', 'model.layers.41.self_attn.k_proj.normalizer.zeros.1', 'model.layers.41.self_attn.v_proj.bias', 'model.layers.41.self_attn.v_proj.codebook', 'model.layers.41.self_attn.v_proj.assignments', 'model.layers.41.self_attn.v_proj.normalizer.norms.0', 'model.layers.41.self_attn.v_proj.normalizer.norms.1', 'model.layers.41.self_attn.v_proj.normalizer.zeros.0', 'model.layers.41.self_attn.v_proj.normalizer.zeros.1', 'model.layers.41.self_attn.o_proj.bias', 'model.layers.41.self_attn.o_proj.codebook', 'model.layers.41.self_attn.o_proj.assignments', 'model.layers.41.self_attn.o_proj.normalizer.norms.0', 'model.layers.41.self_attn.o_proj.normalizer.norms.1', 'model.layers.41.self_attn.o_proj.normalizer.zeros.0', 'model.layers.41.self_attn.o_proj.normalizer.zeros.1', 'model.layers.41.mlp.gate_proj.bias', 'model.layers.41.mlp.gate_proj.codebook', 'model.layers.41.mlp.gate_proj.assignments', 'model.layers.41.mlp.gate_proj.normalizer.norms.0', 'model.layers.41.mlp.gate_proj.normalizer.norms.1', 'model.layers.41.mlp.gate_proj.normalizer.zeros.0', 'model.layers.41.mlp.gate_proj.normalizer.zeros.1', 'model.layers.41.mlp.up_proj.bias', 'model.layers.41.mlp.up_proj.codebook', 'model.layers.41.mlp.up_proj.assignments', 'model.layers.41.mlp.up_proj.normalizer.norms.0', 'model.layers.41.mlp.up_proj.normalizer.norms.1', 'model.layers.41.mlp.up_proj.normalizer.zeros.0', 'model.layers.41.mlp.up_proj.normalizer.zeros.1', 'model.layers.41.mlp.down_proj.bias', 'model.layers.41.mlp.down_proj.codebook', 'model.layers.41.mlp.down_proj.assignments', 'model.layers.41.mlp.down_proj.normalizer.norms.0', 'model.layers.41.mlp.down_proj.normalizer.norms.1', 'model.layers.41.mlp.down_proj.normalizer.zeros.0', 'model.layers.41.mlp.down_proj.normalizer.zeros.1', 'model.layers.42.self_attn.q_proj.bias', 'model.layers.42.self_attn.q_proj.codebook', 'model.layers.42.self_attn.q_proj.assignments', 'model.layers.42.self_attn.q_proj.normalizer.norms.0', 'model.layers.42.self_attn.q_proj.normalizer.norms.1', 'model.layers.42.self_attn.q_proj.normalizer.zeros.0', 'model.layers.42.self_attn.q_proj.normalizer.zeros.1', 'model.layers.42.self_attn.k_proj.bias', 'model.layers.42.self_attn.k_proj.codebook', 'model.layers.42.self_attn.k_proj.assignments', 'model.layers.42.self_attn.k_proj.normalizer.norms.0', 'model.layers.42.self_attn.k_proj.normalizer.norms.1', 'model.layers.42.self_attn.k_proj.normalizer.zeros.0', 'model.layers.42.self_attn.k_proj.normalizer.zeros.1', 'model.layers.42.self_attn.v_proj.bias', 'model.layers.42.self_attn.v_proj.codebook', 'model.layers.42.self_attn.v_proj.assignments', 'model.layers.42.self_attn.v_proj.normalizer.norms.0', 'model.layers.42.self_attn.v_proj.normalizer.norms.1', 'model.layers.42.self_attn.v_proj.normalizer.zeros.0', 'model.layers.42.self_attn.v_proj.normalizer.zeros.1', 'model.layers.42.self_attn.o_proj.bias', 'model.layers.42.self_attn.o_proj.codebook', 'model.layers.42.self_attn.o_proj.assignments', 'model.layers.42.self_attn.o_proj.normalizer.norms.0', 'model.layers.42.self_attn.o_proj.normalizer.norms.1', 'model.layers.42.self_attn.o_proj.normalizer.zeros.0', 'model.layers.42.self_attn.o_proj.normalizer.zeros.1', 'model.layers.42.mlp.gate_proj.bias', 'model.layers.42.mlp.gate_proj.codebook', 'model.layers.42.mlp.gate_proj.assignments', 'model.layers.42.mlp.gate_proj.normalizer.norms.0', 'model.layers.42.mlp.gate_proj.normalizer.norms.1', 'model.layers.42.mlp.gate_proj.normalizer.zeros.0', 'model.layers.42.mlp.gate_proj.normalizer.zeros.1', 'model.layers.42.mlp.up_proj.bias', 'model.layers.42.mlp.up_proj.codebook', 'model.layers.42.mlp.up_proj.assignments', 'model.layers.42.mlp.up_proj.normalizer.norms.0', 'model.layers.42.mlp.up_proj.normalizer.norms.1', 'model.layers.42.mlp.up_proj.normalizer.zeros.0', 'model.layers.42.mlp.up_proj.normalizer.zeros.1', 'model.layers.42.mlp.down_proj.bias', 'model.layers.42.mlp.down_proj.codebook', 'model.layers.42.mlp.down_proj.assignments', 'model.layers.42.mlp.down_proj.normalizer.norms.0', 'model.layers.42.mlp.down_proj.normalizer.norms.1', 'model.layers.42.mlp.down_proj.normalizer.zeros.0', 'model.layers.42.mlp.down_proj.normalizer.zeros.1', 'model.layers.43.self_attn.q_proj.bias', 'model.layers.43.self_attn.q_proj.codebook', 'model.layers.43.self_attn.q_proj.assignments', 'model.layers.43.self_attn.q_proj.normalizer.norms.0', 'model.layers.43.self_attn.q_proj.normalizer.norms.1', 'model.layers.43.self_attn.q_proj.normalizer.zeros.0', 'model.layers.43.self_attn.q_proj.normalizer.zeros.1', 'model.layers.43.self_attn.k_proj.bias', 'model.layers.43.self_attn.k_proj.codebook', 'model.layers.43.self_attn.k_proj.assignments', 'model.layers.43.self_attn.k_proj.normalizer.norms.0', 'model.layers.43.self_attn.k_proj.normalizer.norms.1', 'model.layers.43.self_attn.k_proj.normalizer.zeros.0', 'model.layers.43.self_attn.k_proj.normalizer.zeros.1', 'model.layers.43.self_attn.v_proj.bias', 'model.layers.43.self_attn.v_proj.codebook', 'model.layers.43.self_attn.v_proj.assignments', 'model.layers.43.self_attn.v_proj.normalizer.norms.0', 'model.layers.43.self_attn.v_proj.normalizer.norms.1', 'model.layers.43.self_attn.v_proj.normalizer.zeros.0', 'model.layers.43.self_attn.v_proj.normalizer.zeros.1', 'model.layers.43.self_attn.o_proj.bias', 'model.layers.43.self_attn.o_proj.codebook', 'model.layers.43.self_attn.o_proj.assignments', 'model.layers.43.self_attn.o_proj.normalizer.norms.0', 'model.layers.43.self_attn.o_proj.normalizer.norms.1', 'model.layers.43.self_attn.o_proj.normalizer.zeros.0', 'model.layers.43.self_attn.o_proj.normalizer.zeros.1', 'model.layers.43.mlp.gate_proj.bias', 'model.layers.43.mlp.gate_proj.codebook', 'model.layers.43.mlp.gate_proj.assignments', 'model.layers.43.mlp.gate_proj.normalizer.norms.0', 'model.layers.43.mlp.gate_proj.normalizer.norms.1', 'model.layers.43.mlp.gate_proj.normalizer.zeros.0', 'model.layers.43.mlp.gate_proj.normalizer.zeros.1', 'model.layers.43.mlp.up_proj.bias', 'model.layers.43.mlp.up_proj.codebook', 'model.layers.43.mlp.up_proj.assignments', 'model.layers.43.mlp.up_proj.normalizer.norms.0', 'model.layers.43.mlp.up_proj.normalizer.norms.1', 'model.layers.43.mlp.up_proj.normalizer.zeros.0', 'model.layers.43.mlp.up_proj.normalizer.zeros.1', 'model.layers.43.mlp.down_proj.bias', 'model.layers.43.mlp.down_proj.codebook', 'model.layers.43.mlp.down_proj.assignments', 'model.layers.43.mlp.down_proj.normalizer.norms.0', 'model.layers.43.mlp.down_proj.normalizer.norms.1', 'model.layers.43.mlp.down_proj.normalizer.zeros.0', 'model.layers.43.mlp.down_proj.normalizer.zeros.1', 'model.layers.44.self_attn.q_proj.bias', 'model.layers.44.self_attn.q_proj.codebook', 'model.layers.44.self_attn.q_proj.assignments', 'model.layers.44.self_attn.q_proj.normalizer.norms.0', 'model.layers.44.self_attn.q_proj.normalizer.norms.1', 'model.layers.44.self_attn.q_proj.normalizer.zeros.0', 'model.layers.44.self_attn.q_proj.normalizer.zeros.1', 'model.layers.44.self_attn.k_proj.bias', 'model.layers.44.self_attn.k_proj.codebook', 'model.layers.44.self_attn.k_proj.assignments', 'model.layers.44.self_attn.k_proj.normalizer.norms.0', 'model.layers.44.self_attn.k_proj.normalizer.norms.1', 'model.layers.44.self_attn.k_proj.normalizer.zeros.0', 'model.layers.44.self_attn.k_proj.normalizer.zeros.1', 'model.layers.44.self_attn.v_proj.bias', 'model.layers.44.self_attn.v_proj.codebook', 'model.layers.44.self_attn.v_proj.assignments', 'model.layers.44.self_attn.v_proj.normalizer.norms.0', 'model.layers.44.self_attn.v_proj.normalizer.norms.1', 'model.layers.44.self_attn.v_proj.normalizer.zeros.0', 'model.layers.44.self_attn.v_proj.normalizer.zeros.1', 'model.layers.44.self_attn.o_proj.bias', 'model.layers.44.self_attn.o_proj.codebook', 'model.layers.44.self_attn.o_proj.assignments', 'model.layers.44.self_attn.o_proj.normalizer.norms.0', 'model.layers.44.self_attn.o_proj.normalizer.norms.1', 'model.layers.44.self_attn.o_proj.normalizer.zeros.0', 'model.layers.44.self_attn.o_proj.normalizer.zeros.1', 'model.layers.44.mlp.gate_proj.bias', 'model.layers.44.mlp.gate_proj.codebook', 'model.layers.44.mlp.gate_proj.assignments', 'model.layers.44.mlp.gate_proj.normalizer.norms.0', 'model.layers.44.mlp.gate_proj.normalizer.norms.1', 'model.layers.44.mlp.gate_proj.normalizer.zeros.0', 'model.layers.44.mlp.gate_proj.normalizer.zeros.1', 'model.layers.44.mlp.up_proj.bias', 'model.layers.44.mlp.up_proj.codebook', 'model.layers.44.mlp.up_proj.assignments', 'model.layers.44.mlp.up_proj.normalizer.norms.0', 'model.layers.44.mlp.up_proj.normalizer.norms.1', 'model.layers.44.mlp.up_proj.normalizer.zeros.0', 'model.layers.44.mlp.up_proj.normalizer.zeros.1', 'model.layers.44.mlp.down_proj.bias', 'model.layers.44.mlp.down_proj.codebook', 'model.layers.44.mlp.down_proj.assignments', 'model.layers.44.mlp.down_proj.normalizer.norms.0', 'model.layers.44.mlp.down_proj.normalizer.norms.1', 'model.layers.44.mlp.down_proj.normalizer.zeros.0', 'model.layers.44.mlp.down_proj.normalizer.zeros.1', 'model.layers.45.self_attn.q_proj.bias', 'model.layers.45.self_attn.q_proj.codebook', 'model.layers.45.self_attn.q_proj.assignments', 'model.layers.45.self_attn.q_proj.normalizer.norms.0', 'model.layers.45.self_attn.q_proj.normalizer.norms.1', 'model.layers.45.self_attn.q_proj.normalizer.zeros.0', 'model.layers.45.self_attn.q_proj.normalizer.zeros.1', 'model.layers.45.self_attn.k_proj.bias', 'model.layers.45.self_attn.k_proj.codebook', 'model.layers.45.self_attn.k_proj.assignments', 'model.layers.45.self_attn.k_proj.normalizer.norms.0', 'model.layers.45.self_attn.k_proj.normalizer.norms.1', 'model.layers.45.self_attn.k_proj.normalizer.zeros.0', 'model.layers.45.self_attn.k_proj.normalizer.zeros.1', 'model.layers.45.self_attn.v_proj.bias', 'model.layers.45.self_attn.v_proj.codebook', 'model.layers.45.self_attn.v_proj.assignments', 'model.layers.45.self_attn.v_proj.normalizer.norms.0', 'model.layers.45.self_attn.v_proj.normalizer.norms.1', 'model.layers.45.self_attn.v_proj.normalizer.zeros.0', 'model.layers.45.self_attn.v_proj.normalizer.zeros.1', 'model.layers.45.self_attn.o_proj.bias', 'model.layers.45.self_attn.o_proj.codebook', 'model.layers.45.self_attn.o_proj.assignments', 'model.layers.45.self_attn.o_proj.normalizer.norms.0', 'model.layers.45.self_attn.o_proj.normalizer.norms.1', 'model.layers.45.self_attn.o_proj.normalizer.zeros.0', 'model.layers.45.self_attn.o_proj.normalizer.zeros.1', 'model.layers.45.mlp.gate_proj.bias', 'model.layers.45.mlp.gate_proj.codebook', 'model.layers.45.mlp.gate_proj.assignments', 'model.layers.45.mlp.gate_proj.normalizer.norms.0', 'model.layers.45.mlp.gate_proj.normalizer.norms.1', 'model.layers.45.mlp.gate_proj.normalizer.zeros.0', 'model.layers.45.mlp.gate_proj.normalizer.zeros.1', 'model.layers.45.mlp.up_proj.bias', 'model.layers.45.mlp.up_proj.codebook', 'model.layers.45.mlp.up_proj.assignments', 'model.layers.45.mlp.up_proj.normalizer.norms.0', 'model.layers.45.mlp.up_proj.normalizer.norms.1', 'model.layers.45.mlp.up_proj.normalizer.zeros.0', 'model.layers.45.mlp.up_proj.normalizer.zeros.1', 'model.layers.45.mlp.down_proj.bias', 'model.layers.45.mlp.down_proj.codebook', 'model.layers.45.mlp.down_proj.assignments', 'model.layers.45.mlp.down_proj.normalizer.norms.0', 'model.layers.45.mlp.down_proj.normalizer.norms.1', 'model.layers.45.mlp.down_proj.normalizer.zeros.0', 'model.layers.45.mlp.down_proj.normalizer.zeros.1', 'model.layers.46.self_attn.q_proj.bias', 'model.layers.46.self_attn.q_proj.codebook', 'model.layers.46.self_attn.q_proj.assignments', 'model.layers.46.self_attn.q_proj.normalizer.norms.0', 'model.layers.46.self_attn.q_proj.normalizer.norms.1', 'model.layers.46.self_attn.q_proj.normalizer.zeros.0', 'model.layers.46.self_attn.q_proj.normalizer.zeros.1', 'model.layers.46.self_attn.k_proj.bias', 'model.layers.46.self_attn.k_proj.codebook', 'model.layers.46.self_attn.k_proj.assignments', 'model.layers.46.self_attn.k_proj.normalizer.norms.0', 'model.layers.46.self_attn.k_proj.normalizer.norms.1', 'model.layers.46.self_attn.k_proj.normalizer.zeros.0', 'model.layers.46.self_attn.k_proj.normalizer.zeros.1', 'model.layers.46.self_attn.v_proj.bias', 'model.layers.46.self_attn.v_proj.codebook', 'model.layers.46.self_attn.v_proj.assignments', 'model.layers.46.self_attn.v_proj.normalizer.norms.0', 'model.layers.46.self_attn.v_proj.normalizer.norms.1', 'model.layers.46.self_attn.v_proj.normalizer.zeros.0', 'model.layers.46.self_attn.v_proj.normalizer.zeros.1', 'model.layers.46.self_attn.o_proj.bias', 'model.layers.46.self_attn.o_proj.codebook', 'model.layers.46.self_attn.o_proj.assignments', 'model.layers.46.self_attn.o_proj.normalizer.norms.0', 'model.layers.46.self_attn.o_proj.normalizer.norms.1', 'model.layers.46.self_attn.o_proj.normalizer.zeros.0', 'model.layers.46.self_attn.o_proj.normalizer.zeros.1', 'model.layers.46.mlp.gate_proj.bias', 'model.layers.46.mlp.gate_proj.codebook', 'model.layers.46.mlp.gate_proj.assignments', 'model.layers.46.mlp.gate_proj.normalizer.norms.0', 'model.layers.46.mlp.gate_proj.normalizer.norms.1', 'model.layers.46.mlp.gate_proj.normalizer.zeros.0', 'model.layers.46.mlp.gate_proj.normalizer.zeros.1', 'model.layers.46.mlp.up_proj.bias', 'model.layers.46.mlp.up_proj.codebook', 'model.layers.46.mlp.up_proj.assignments', 'model.layers.46.mlp.up_proj.normalizer.norms.0', 'model.layers.46.mlp.up_proj.normalizer.norms.1', 'model.layers.46.mlp.up_proj.normalizer.zeros.0', 'model.layers.46.mlp.up_proj.normalizer.zeros.1', 'model.layers.46.mlp.down_proj.bias', 'model.layers.46.mlp.down_proj.codebook', 'model.layers.46.mlp.down_proj.assignments', 'model.layers.46.mlp.down_proj.normalizer.norms.0', 'model.layers.46.mlp.down_proj.normalizer.norms.1', 'model.layers.46.mlp.down_proj.normalizer.zeros.0', 'model.layers.46.mlp.down_proj.normalizer.zeros.1', 'model.layers.47.self_attn.q_proj.bias', 'model.layers.47.self_attn.q_proj.codebook', 'model.layers.47.self_attn.q_proj.assignments', 'model.layers.47.self_attn.q_proj.normalizer.norms.0', 'model.layers.47.self_attn.q_proj.normalizer.norms.1', 'model.layers.47.self_attn.q_proj.normalizer.zeros.0', 'model.layers.47.self_attn.q_proj.normalizer.zeros.1', 'model.layers.47.self_attn.k_proj.bias', 'model.layers.47.self_attn.k_proj.codebook', 'model.layers.47.self_attn.k_proj.assignments', 'model.layers.47.self_attn.k_proj.normalizer.norms.0', 'model.layers.47.self_attn.k_proj.normalizer.norms.1', 'model.layers.47.self_attn.k_proj.normalizer.zeros.0', 'model.layers.47.self_attn.k_proj.normalizer.zeros.1', 'model.layers.47.self_attn.v_proj.bias', 'model.layers.47.self_attn.v_proj.codebook', 'model.layers.47.self_attn.v_proj.assignments', 'model.layers.47.self_attn.v_proj.normalizer.norms.0', 'model.layers.47.self_attn.v_proj.normalizer.norms.1', 'model.layers.47.self_attn.v_proj.normalizer.zeros.0', 'model.layers.47.self_attn.v_proj.normalizer.zeros.1', 'model.layers.47.self_attn.o_proj.bias', 'model.layers.47.self_attn.o_proj.codebook', 'model.layers.47.self_attn.o_proj.assignments', 'model.layers.47.self_attn.o_proj.normalizer.norms.0', 'model.layers.47.self_attn.o_proj.normalizer.norms.1', 'model.layers.47.self_attn.o_proj.normalizer.zeros.0', 'model.layers.47.self_attn.o_proj.normalizer.zeros.1', 'model.layers.47.mlp.gate_proj.bias', 'model.layers.47.mlp.gate_proj.codebook', 'model.layers.47.mlp.gate_proj.assignments', 'model.layers.47.mlp.gate_proj.normalizer.norms.0', 'model.layers.47.mlp.gate_proj.normalizer.norms.1', 'model.layers.47.mlp.gate_proj.normalizer.zeros.0', 'model.layers.47.mlp.gate_proj.normalizer.zeros.1', 'model.layers.47.mlp.up_proj.bias', 'model.layers.47.mlp.up_proj.codebook', 'model.layers.47.mlp.up_proj.assignments', 'model.layers.47.mlp.up_proj.normalizer.norms.0', 'model.layers.47.mlp.up_proj.normalizer.norms.1', 'model.layers.47.mlp.up_proj.normalizer.zeros.0', 'model.layers.47.mlp.up_proj.normalizer.zeros.1', 'model.layers.47.mlp.down_proj.bias', 'model.layers.47.mlp.down_proj.codebook', 'model.layers.47.mlp.down_proj.assignments', 'model.layers.47.mlp.down_proj.normalizer.norms.0', 'model.layers.47.mlp.down_proj.normalizer.norms.1', 'model.layers.47.mlp.down_proj.normalizer.zeros.0', 'model.layers.47.mlp.down_proj.normalizer.zeros.1', 'model.layers.48.self_attn.q_proj.bias', 'model.layers.48.self_attn.q_proj.codebook', 'model.layers.48.self_attn.q_proj.assignments', 'model.layers.48.self_attn.q_proj.normalizer.norms.0', 'model.layers.48.self_attn.q_proj.normalizer.norms.1', 'model.layers.48.self_attn.q_proj.normalizer.zeros.0', 'model.layers.48.self_attn.q_proj.normalizer.zeros.1', 'model.layers.48.self_attn.k_proj.bias', 'model.layers.48.self_attn.k_proj.codebook', 'model.layers.48.self_attn.k_proj.assignments', 'model.layers.48.self_attn.k_proj.normalizer.norms.0', 'model.layers.48.self_attn.k_proj.normalizer.norms.1', 'model.layers.48.self_attn.k_proj.normalizer.zeros.0', 'model.layers.48.self_attn.k_proj.normalizer.zeros.1', 'model.layers.48.self_attn.v_proj.bias', 'model.layers.48.self_attn.v_proj.codebook', 'model.layers.48.self_attn.v_proj.assignments', 'model.layers.48.self_attn.v_proj.normalizer.norms.0', 'model.layers.48.self_attn.v_proj.normalizer.norms.1', 'model.layers.48.self_attn.v_proj.normalizer.zeros.0', 'model.layers.48.self_attn.v_proj.normalizer.zeros.1', 'model.layers.48.self_attn.o_proj.bias', 'model.layers.48.self_attn.o_proj.codebook', 'model.layers.48.self_attn.o_proj.assignments', 'model.layers.48.self_attn.o_proj.normalizer.norms.0', 'model.layers.48.self_attn.o_proj.normalizer.norms.1', 'model.layers.48.self_attn.o_proj.normalizer.zeros.0', 'model.layers.48.self_attn.o_proj.normalizer.zeros.1', 'model.layers.48.mlp.gate_proj.bias', 'model.layers.48.mlp.gate_proj.codebook', 'model.layers.48.mlp.gate_proj.assignments', 'model.layers.48.mlp.gate_proj.normalizer.norms.0', 'model.layers.48.mlp.gate_proj.normalizer.norms.1', 'model.layers.48.mlp.gate_proj.normalizer.zeros.0', 'model.layers.48.mlp.gate_proj.normalizer.zeros.1', 'model.layers.48.mlp.up_proj.bias', 'model.layers.48.mlp.up_proj.codebook', 'model.layers.48.mlp.up_proj.assignments', 'model.layers.48.mlp.up_proj.normalizer.norms.0', 'model.layers.48.mlp.up_proj.normalizer.norms.1', 'model.layers.48.mlp.up_proj.normalizer.zeros.0', 'model.layers.48.mlp.up_proj.normalizer.zeros.1', 'model.layers.48.mlp.down_proj.bias', 'model.layers.48.mlp.down_proj.codebook', 'model.layers.48.mlp.down_proj.assignments', 'model.layers.48.mlp.down_proj.normalizer.norms.0', 'model.layers.48.mlp.down_proj.normalizer.norms.1', 'model.layers.48.mlp.down_proj.normalizer.zeros.0', 'model.layers.48.mlp.down_proj.normalizer.zeros.1', 'model.layers.49.self_attn.q_proj.bias', 'model.layers.49.self_attn.q_proj.codebook', 'model.layers.49.self_attn.q_proj.assignments', 'model.layers.49.self_attn.q_proj.normalizer.norms.0', 'model.layers.49.self_attn.q_proj.normalizer.norms.1', 'model.layers.49.self_attn.q_proj.normalizer.zeros.0', 'model.layers.49.self_attn.q_proj.normalizer.zeros.1', 'model.layers.49.self_attn.k_proj.bias', 'model.layers.49.self_attn.k_proj.codebook', 'model.layers.49.self_attn.k_proj.assignments', 'model.layers.49.self_attn.k_proj.normalizer.norms.0', 'model.layers.49.self_attn.k_proj.normalizer.norms.1', 'model.layers.49.self_attn.k_proj.normalizer.zeros.0', 'model.layers.49.self_attn.k_proj.normalizer.zeros.1', 'model.layers.49.self_attn.v_proj.bias', 'model.layers.49.self_attn.v_proj.codebook', 'model.layers.49.self_attn.v_proj.assignments', 'model.layers.49.self_attn.v_proj.normalizer.norms.0', 'model.layers.49.self_attn.v_proj.normalizer.norms.1', 'model.layers.49.self_attn.v_proj.normalizer.zeros.0', 'model.layers.49.self_attn.v_proj.normalizer.zeros.1', 'model.layers.49.self_attn.o_proj.bias', 'model.layers.49.self_attn.o_proj.codebook', 'model.layers.49.self_attn.o_proj.assignments', 'model.layers.49.self_attn.o_proj.normalizer.norms.0', 'model.layers.49.self_attn.o_proj.normalizer.norms.1', 'model.layers.49.self_attn.o_proj.normalizer.zeros.0', 'model.layers.49.self_attn.o_proj.normalizer.zeros.1', 'model.layers.49.mlp.gate_proj.bias', 'model.layers.49.mlp.gate_proj.codebook', 'model.layers.49.mlp.gate_proj.assignments', 'model.layers.49.mlp.gate_proj.normalizer.norms.0', 'model.layers.49.mlp.gate_proj.normalizer.norms.1', 'model.layers.49.mlp.gate_proj.normalizer.zeros.0', 'model.layers.49.mlp.gate_proj.normalizer.zeros.1', 'model.layers.49.mlp.up_proj.bias', 'model.layers.49.mlp.up_proj.codebook', 'model.layers.49.mlp.up_proj.assignments', 'model.layers.49.mlp.up_proj.normalizer.norms.0', 'model.layers.49.mlp.up_proj.normalizer.norms.1', 'model.layers.49.mlp.up_proj.normalizer.zeros.0', 'model.layers.49.mlp.up_proj.normalizer.zeros.1', 'model.layers.49.mlp.down_proj.bias', 'model.layers.49.mlp.down_proj.codebook', 'model.layers.49.mlp.down_proj.assignments', 'model.layers.49.mlp.down_proj.normalizer.norms.0', 'model.layers.49.mlp.down_proj.normalizer.norms.1', 'model.layers.49.mlp.down_proj.normalizer.zeros.0', 'model.layers.49.mlp.down_proj.normalizer.zeros.1', 'model.layers.50.self_attn.q_proj.bias', 'model.layers.50.self_attn.q_proj.codebook', 'model.layers.50.self_attn.q_proj.assignments', 'model.layers.50.self_attn.q_proj.normalizer.norms.0', 'model.layers.50.self_attn.q_proj.normalizer.norms.1', 'model.layers.50.self_attn.q_proj.normalizer.zeros.0', 'model.layers.50.self_attn.q_proj.normalizer.zeros.1', 'model.layers.50.self_attn.k_proj.bias', 'model.layers.50.self_attn.k_proj.codebook', 'model.layers.50.self_attn.k_proj.assignments', 'model.layers.50.self_attn.k_proj.normalizer.norms.0', 'model.layers.50.self_attn.k_proj.normalizer.norms.1', 'model.layers.50.self_attn.k_proj.normalizer.zeros.0', 'model.layers.50.self_attn.k_proj.normalizer.zeros.1', 'model.layers.50.self_attn.v_proj.bias', 'model.layers.50.self_attn.v_proj.codebook', 'model.layers.50.self_attn.v_proj.assignments', 'model.layers.50.self_attn.v_proj.normalizer.norms.0', 'model.layers.50.self_attn.v_proj.normalizer.norms.1', 'model.layers.50.self_attn.v_proj.normalizer.zeros.0', 'model.layers.50.self_attn.v_proj.normalizer.zeros.1', 'model.layers.50.self_attn.o_proj.bias', 'model.layers.50.self_attn.o_proj.codebook', 'model.layers.50.self_attn.o_proj.assignments', 'model.layers.50.self_attn.o_proj.normalizer.norms.0', 'model.layers.50.self_attn.o_proj.normalizer.norms.1', 'model.layers.50.self_attn.o_proj.normalizer.zeros.0', 'model.layers.50.self_attn.o_proj.normalizer.zeros.1', 'model.layers.50.mlp.gate_proj.bias', 'model.layers.50.mlp.gate_proj.codebook', 'model.layers.50.mlp.gate_proj.assignments', 'model.layers.50.mlp.gate_proj.normalizer.norms.0', 'model.layers.50.mlp.gate_proj.normalizer.norms.1', 'model.layers.50.mlp.gate_proj.normalizer.zeros.0', 'model.layers.50.mlp.gate_proj.normalizer.zeros.1', 'model.layers.50.mlp.up_proj.bias', 'model.layers.50.mlp.up_proj.codebook', 'model.layers.50.mlp.up_proj.assignments', 'model.layers.50.mlp.up_proj.normalizer.norms.0', 'model.layers.50.mlp.up_proj.normalizer.norms.1', 'model.layers.50.mlp.up_proj.normalizer.zeros.0', 'model.layers.50.mlp.up_proj.normalizer.zeros.1', 'model.layers.50.mlp.down_proj.bias', 'model.layers.50.mlp.down_proj.codebook', 'model.layers.50.mlp.down_proj.assignments', 'model.layers.50.mlp.down_proj.normalizer.norms.0', 'model.layers.50.mlp.down_proj.normalizer.norms.1', 'model.layers.50.mlp.down_proj.normalizer.zeros.0', 'model.layers.50.mlp.down_proj.normalizer.zeros.1', 'model.layers.51.self_attn.q_proj.bias', 'model.layers.51.self_attn.q_proj.codebook', 'model.layers.51.self_attn.q_proj.assignments', 'model.layers.51.self_attn.q_proj.normalizer.norms.0', 'model.layers.51.self_attn.q_proj.normalizer.norms.1', 'model.layers.51.self_attn.q_proj.normalizer.zeros.0', 'model.layers.51.self_attn.q_proj.normalizer.zeros.1', 'model.layers.51.self_attn.k_proj.bias', 'model.layers.51.self_attn.k_proj.codebook', 'model.layers.51.self_attn.k_proj.assignments', 'model.layers.51.self_attn.k_proj.normalizer.norms.0', 'model.layers.51.self_attn.k_proj.normalizer.norms.1', 'model.layers.51.self_attn.k_proj.normalizer.zeros.0', 'model.layers.51.self_attn.k_proj.normalizer.zeros.1', 'model.layers.51.self_attn.v_proj.bias', 'model.layers.51.self_attn.v_proj.codebook', 'model.layers.51.self_attn.v_proj.assignments', 'model.layers.51.self_attn.v_proj.normalizer.norms.0', 'model.layers.51.self_attn.v_proj.normalizer.norms.1', 'model.layers.51.self_attn.v_proj.normalizer.zeros.0', 'model.layers.51.self_attn.v_proj.normalizer.zeros.1', 'model.layers.51.self_attn.o_proj.bias', 'model.layers.51.self_attn.o_proj.codebook', 'model.layers.51.self_attn.o_proj.assignments', 'model.layers.51.self_attn.o_proj.normalizer.norms.0', 'model.layers.51.self_attn.o_proj.normalizer.norms.1', 'model.layers.51.self_attn.o_proj.normalizer.zeros.0', 'model.layers.51.self_attn.o_proj.normalizer.zeros.1', 'model.layers.51.mlp.gate_proj.bias', 'model.layers.51.mlp.gate_proj.codebook', 'model.layers.51.mlp.gate_proj.assignments', 'model.layers.51.mlp.gate_proj.normalizer.norms.0', 'model.layers.51.mlp.gate_proj.normalizer.norms.1', 'model.layers.51.mlp.gate_proj.normalizer.zeros.0', 'model.layers.51.mlp.gate_proj.normalizer.zeros.1', 'model.layers.51.mlp.up_proj.bias', 'model.layers.51.mlp.up_proj.codebook', 'model.layers.51.mlp.up_proj.assignments', 'model.layers.51.mlp.up_proj.normalizer.norms.0', 'model.layers.51.mlp.up_proj.normalizer.norms.1', 'model.layers.51.mlp.up_proj.normalizer.zeros.0', 'model.layers.51.mlp.up_proj.normalizer.zeros.1', 'model.layers.51.mlp.down_proj.bias', 'model.layers.51.mlp.down_proj.codebook', 'model.layers.51.mlp.down_proj.assignments', 'model.layers.51.mlp.down_proj.normalizer.norms.0', 'model.layers.51.mlp.down_proj.normalizer.norms.1', 'model.layers.51.mlp.down_proj.normalizer.zeros.0', 'model.layers.51.mlp.down_proj.normalizer.zeros.1', 'model.layers.52.self_attn.q_proj.bias', 'model.layers.52.self_attn.q_proj.codebook', 'model.layers.52.self_attn.q_proj.assignments', 'model.layers.52.self_attn.q_proj.normalizer.norms.0', 'model.layers.52.self_attn.q_proj.normalizer.norms.1', 'model.layers.52.self_attn.q_proj.normalizer.zeros.0', 'model.layers.52.self_attn.q_proj.normalizer.zeros.1', 'model.layers.52.self_attn.k_proj.bias', 'model.layers.52.self_attn.k_proj.codebook', 'model.layers.52.self_attn.k_proj.assignments', 'model.layers.52.self_attn.k_proj.normalizer.norms.0', 'model.layers.52.self_attn.k_proj.normalizer.norms.1', 'model.layers.52.self_attn.k_proj.normalizer.zeros.0', 'model.layers.52.self_attn.k_proj.normalizer.zeros.1', 'model.layers.52.self_attn.v_proj.bias', 'model.layers.52.self_attn.v_proj.codebook', 'model.layers.52.self_attn.v_proj.assignments', 'model.layers.52.self_attn.v_proj.normalizer.norms.0', 'model.layers.52.self_attn.v_proj.normalizer.norms.1', 'model.layers.52.self_attn.v_proj.normalizer.zeros.0', 'model.layers.52.self_attn.v_proj.normalizer.zeros.1', 'model.layers.52.self_attn.o_proj.bias', 'model.layers.52.self_attn.o_proj.codebook', 'model.layers.52.self_attn.o_proj.assignments', 'model.layers.52.self_attn.o_proj.normalizer.norms.0', 'model.layers.52.self_attn.o_proj.normalizer.norms.1', 'model.layers.52.self_attn.o_proj.normalizer.zeros.0', 'model.layers.52.self_attn.o_proj.normalizer.zeros.1', 'model.layers.52.mlp.gate_proj.bias', 'model.layers.52.mlp.gate_proj.codebook', 'model.layers.52.mlp.gate_proj.assignments', 'model.layers.52.mlp.gate_proj.normalizer.norms.0', 'model.layers.52.mlp.gate_proj.normalizer.norms.1', 'model.layers.52.mlp.gate_proj.normalizer.zeros.0', 'model.layers.52.mlp.gate_proj.normalizer.zeros.1', 'model.layers.52.mlp.up_proj.bias', 'model.layers.52.mlp.up_proj.codebook', 'model.layers.52.mlp.up_proj.assignments', 'model.layers.52.mlp.up_proj.normalizer.norms.0', 'model.layers.52.mlp.up_proj.normalizer.norms.1', 'model.layers.52.mlp.up_proj.normalizer.zeros.0', 'model.layers.52.mlp.up_proj.normalizer.zeros.1', 'model.layers.52.mlp.down_proj.bias', 'model.layers.52.mlp.down_proj.codebook', 'model.layers.52.mlp.down_proj.assignments', 'model.layers.52.mlp.down_proj.normalizer.norms.0', 'model.layers.52.mlp.down_proj.normalizer.norms.1', 'model.layers.52.mlp.down_proj.normalizer.zeros.0', 'model.layers.52.mlp.down_proj.normalizer.zeros.1', 'model.layers.53.self_attn.q_proj.bias', 'model.layers.53.self_attn.q_proj.codebook', 'model.layers.53.self_attn.q_proj.assignments', 'model.layers.53.self_attn.q_proj.normalizer.norms.0', 'model.layers.53.self_attn.q_proj.normalizer.norms.1', 'model.layers.53.self_attn.q_proj.normalizer.zeros.0', 'model.layers.53.self_attn.q_proj.normalizer.zeros.1', 'model.layers.53.self_attn.k_proj.bias', 'model.layers.53.self_attn.k_proj.codebook', 'model.layers.53.self_attn.k_proj.assignments', 'model.layers.53.self_attn.k_proj.normalizer.norms.0', 'model.layers.53.self_attn.k_proj.normalizer.norms.1', 'model.layers.53.self_attn.k_proj.normalizer.zeros.0', 'model.layers.53.self_attn.k_proj.normalizer.zeros.1', 'model.layers.53.self_attn.v_proj.bias', 'model.layers.53.self_attn.v_proj.codebook', 'model.layers.53.self_attn.v_proj.assignments', 'model.layers.53.self_attn.v_proj.normalizer.norms.0', 'model.layers.53.self_attn.v_proj.normalizer.norms.1', 'model.layers.53.self_attn.v_proj.normalizer.zeros.0', 'model.layers.53.self_attn.v_proj.normalizer.zeros.1', 'model.layers.53.self_attn.o_proj.bias', 'model.layers.53.self_attn.o_proj.codebook', 'model.layers.53.self_attn.o_proj.assignments', 'model.layers.53.self_attn.o_proj.normalizer.norms.0', 'model.layers.53.self_attn.o_proj.normalizer.norms.1', 'model.layers.53.self_attn.o_proj.normalizer.zeros.0', 'model.layers.53.self_attn.o_proj.normalizer.zeros.1', 'model.layers.53.mlp.gate_proj.bias', 'model.layers.53.mlp.gate_proj.codebook', 'model.layers.53.mlp.gate_proj.assignments', 'model.layers.53.mlp.gate_proj.normalizer.norms.0', 'model.layers.53.mlp.gate_proj.normalizer.norms.1', 'model.layers.53.mlp.gate_proj.normalizer.zeros.0', 'model.layers.53.mlp.gate_proj.normalizer.zeros.1', 'model.layers.53.mlp.up_proj.bias', 'model.layers.53.mlp.up_proj.codebook', 'model.layers.53.mlp.up_proj.assignments', 'model.layers.53.mlp.up_proj.normalizer.norms.0', 'model.layers.53.mlp.up_proj.normalizer.norms.1', 'model.layers.53.mlp.up_proj.normalizer.zeros.0', 'model.layers.53.mlp.up_proj.normalizer.zeros.1', 'model.layers.53.mlp.down_proj.bias', 'model.layers.53.mlp.down_proj.codebook', 'model.layers.53.mlp.down_proj.assignments', 'model.layers.53.mlp.down_proj.normalizer.norms.0', 'model.layers.53.mlp.down_proj.normalizer.norms.1', 'model.layers.53.mlp.down_proj.normalizer.zeros.0', 'model.layers.53.mlp.down_proj.normalizer.zeros.1', 'model.layers.54.self_attn.q_proj.bias', 'model.layers.54.self_attn.q_proj.codebook', 'model.layers.54.self_attn.q_proj.assignments', 'model.layers.54.self_attn.q_proj.normalizer.norms.0', 'model.layers.54.self_attn.q_proj.normalizer.norms.1', 'model.layers.54.self_attn.q_proj.normalizer.zeros.0', 'model.layers.54.self_attn.q_proj.normalizer.zeros.1', 'model.layers.54.self_attn.k_proj.bias', 'model.layers.54.self_attn.k_proj.codebook', 'model.layers.54.self_attn.k_proj.assignments', 'model.layers.54.self_attn.k_proj.normalizer.norms.0', 'model.layers.54.self_attn.k_proj.normalizer.norms.1', 'model.layers.54.self_attn.k_proj.normalizer.zeros.0', 'model.layers.54.self_attn.k_proj.normalizer.zeros.1', 'model.layers.54.self_attn.v_proj.bias', 'model.layers.54.self_attn.v_proj.codebook', 'model.layers.54.self_attn.v_proj.assignments', 'model.layers.54.self_attn.v_proj.normalizer.norms.0', 'model.layers.54.self_attn.v_proj.normalizer.norms.1', 'model.layers.54.self_attn.v_proj.normalizer.zeros.0', 'model.layers.54.self_attn.v_proj.normalizer.zeros.1', 'model.layers.54.self_attn.o_proj.bias', 'model.layers.54.self_attn.o_proj.codebook', 'model.layers.54.self_attn.o_proj.assignments', 'model.layers.54.self_attn.o_proj.normalizer.norms.0', 'model.layers.54.self_attn.o_proj.normalizer.norms.1', 'model.layers.54.self_attn.o_proj.normalizer.zeros.0', 'model.layers.54.self_attn.o_proj.normalizer.zeros.1', 'model.layers.54.mlp.gate_proj.bias', 'model.layers.54.mlp.gate_proj.codebook', 'model.layers.54.mlp.gate_proj.assignments', 'model.layers.54.mlp.gate_proj.normalizer.norms.0', 'model.layers.54.mlp.gate_proj.normalizer.norms.1', 'model.layers.54.mlp.gate_proj.normalizer.zeros.0', 'model.layers.54.mlp.gate_proj.normalizer.zeros.1', 'model.layers.54.mlp.up_proj.bias', 'model.layers.54.mlp.up_proj.codebook', 'model.layers.54.mlp.up_proj.assignments', 'model.layers.54.mlp.up_proj.normalizer.norms.0', 'model.layers.54.mlp.up_proj.normalizer.norms.1', 'model.layers.54.mlp.up_proj.normalizer.zeros.0', 'model.layers.54.mlp.up_proj.normalizer.zeros.1', 'model.layers.54.mlp.down_proj.bias', 'model.layers.54.mlp.down_proj.codebook', 'model.layers.54.mlp.down_proj.assignments', 'model.layers.54.mlp.down_proj.normalizer.norms.0', 'model.layers.54.mlp.down_proj.normalizer.norms.1', 'model.layers.54.mlp.down_proj.normalizer.zeros.0', 'model.layers.54.mlp.down_proj.normalizer.zeros.1', 'model.layers.55.self_attn.q_proj.bias', 'model.layers.55.self_attn.q_proj.codebook', 'model.layers.55.self_attn.q_proj.assignments', 'model.layers.55.self_attn.q_proj.normalizer.norms.0', 'model.layers.55.self_attn.q_proj.normalizer.norms.1', 'model.layers.55.self_attn.q_proj.normalizer.zeros.0', 'model.layers.55.self_attn.q_proj.normalizer.zeros.1', 'model.layers.55.self_attn.k_proj.bias', 'model.layers.55.self_attn.k_proj.codebook', 'model.layers.55.self_attn.k_proj.assignments', 'model.layers.55.self_attn.k_proj.normalizer.norms.0', 'model.layers.55.self_attn.k_proj.normalizer.norms.1', 'model.layers.55.self_attn.k_proj.normalizer.zeros.0', 'model.layers.55.self_attn.k_proj.normalizer.zeros.1', 'model.layers.55.self_attn.v_proj.bias', 'model.layers.55.self_attn.v_proj.codebook', 'model.layers.55.self_attn.v_proj.assignments', 'model.layers.55.self_attn.v_proj.normalizer.norms.0', 'model.layers.55.self_attn.v_proj.normalizer.norms.1', 'model.layers.55.self_attn.v_proj.normalizer.zeros.0', 'model.layers.55.self_attn.v_proj.normalizer.zeros.1', 'model.layers.55.self_attn.o_proj.bias', 'model.layers.55.self_attn.o_proj.codebook', 'model.layers.55.self_attn.o_proj.assignments', 'model.layers.55.self_attn.o_proj.normalizer.norms.0', 'model.layers.55.self_attn.o_proj.normalizer.norms.1', 'model.layers.55.self_attn.o_proj.normalizer.zeros.0', 'model.layers.55.self_attn.o_proj.normalizer.zeros.1', 'model.layers.55.mlp.gate_proj.bias', 'model.layers.55.mlp.gate_proj.codebook', 'model.layers.55.mlp.gate_proj.assignments', 'model.layers.55.mlp.gate_proj.normalizer.norms.0', 'model.layers.55.mlp.gate_proj.normalizer.norms.1', 'model.layers.55.mlp.gate_proj.normalizer.zeros.0', 'model.layers.55.mlp.gate_proj.normalizer.zeros.1', 'model.layers.55.mlp.up_proj.bias', 'model.layers.55.mlp.up_proj.codebook', 'model.layers.55.mlp.up_proj.assignments', 'model.layers.55.mlp.up_proj.normalizer.norms.0', 'model.layers.55.mlp.up_proj.normalizer.norms.1', 'model.layers.55.mlp.up_proj.normalizer.zeros.0', 'model.layers.55.mlp.up_proj.normalizer.zeros.1', 'model.layers.55.mlp.down_proj.bias', 'model.layers.55.mlp.down_proj.codebook', 'model.layers.55.mlp.down_proj.assignments', 'model.layers.55.mlp.down_proj.normalizer.norms.0', 'model.layers.55.mlp.down_proj.normalizer.norms.1', 'model.layers.55.mlp.down_proj.normalizer.zeros.0', 'model.layers.55.mlp.down_proj.normalizer.zeros.1', 'model.layers.56.self_attn.q_proj.bias', 'model.layers.56.self_attn.q_proj.codebook', 'model.layers.56.self_attn.q_proj.assignments', 'model.layers.56.self_attn.q_proj.normalizer.norms.0', 'model.layers.56.self_attn.q_proj.normalizer.norms.1', 'model.layers.56.self_attn.q_proj.normalizer.zeros.0', 'model.layers.56.self_attn.q_proj.normalizer.zeros.1', 'model.layers.56.self_attn.k_proj.bias', 'model.layers.56.self_attn.k_proj.codebook', 'model.layers.56.self_attn.k_proj.assignments', 'model.layers.56.self_attn.k_proj.normalizer.norms.0', 'model.layers.56.self_attn.k_proj.normalizer.norms.1', 'model.layers.56.self_attn.k_proj.normalizer.zeros.0', 'model.layers.56.self_attn.k_proj.normalizer.zeros.1', 'model.layers.56.self_attn.v_proj.bias', 'model.layers.56.self_attn.v_proj.codebook', 'model.layers.56.self_attn.v_proj.assignments', 'model.layers.56.self_attn.v_proj.normalizer.norms.0', 'model.layers.56.self_attn.v_proj.normalizer.norms.1', 'model.layers.56.self_attn.v_proj.normalizer.zeros.0', 'model.layers.56.self_attn.v_proj.normalizer.zeros.1', 'model.layers.56.self_attn.o_proj.bias', 'model.layers.56.self_attn.o_proj.codebook', 'model.layers.56.self_attn.o_proj.assignments', 'model.layers.56.self_attn.o_proj.normalizer.norms.0', 'model.layers.56.self_attn.o_proj.normalizer.norms.1', 'model.layers.56.self_attn.o_proj.normalizer.zeros.0', 'model.layers.56.self_attn.o_proj.normalizer.zeros.1', 'model.layers.56.mlp.gate_proj.bias', 'model.layers.56.mlp.gate_proj.codebook', 'model.layers.56.mlp.gate_proj.assignments', 'model.layers.56.mlp.gate_proj.normalizer.norms.0', 'model.layers.56.mlp.gate_proj.normalizer.norms.1', 'model.layers.56.mlp.gate_proj.normalizer.zeros.0', 'model.layers.56.mlp.gate_proj.normalizer.zeros.1', 'model.layers.56.mlp.up_proj.bias', 'model.layers.56.mlp.up_proj.codebook', 'model.layers.56.mlp.up_proj.assignments', 'model.layers.56.mlp.up_proj.normalizer.norms.0', 'model.layers.56.mlp.up_proj.normalizer.norms.1', 'model.layers.56.mlp.up_proj.normalizer.zeros.0', 'model.layers.56.mlp.up_proj.normalizer.zeros.1', 'model.layers.56.mlp.down_proj.bias', 'model.layers.56.mlp.down_proj.codebook', 'model.layers.56.mlp.down_proj.assignments', 'model.layers.56.mlp.down_proj.normalizer.norms.0', 'model.layers.56.mlp.down_proj.normalizer.norms.1', 'model.layers.56.mlp.down_proj.normalizer.zeros.0', 'model.layers.56.mlp.down_proj.normalizer.zeros.1', 'model.layers.57.self_attn.q_proj.bias', 'model.layers.57.self_attn.q_proj.codebook', 'model.layers.57.self_attn.q_proj.assignments', 'model.layers.57.self_attn.q_proj.normalizer.norms.0', 'model.layers.57.self_attn.q_proj.normalizer.norms.1', 'model.layers.57.self_attn.q_proj.normalizer.zeros.0', 'model.layers.57.self_attn.q_proj.normalizer.zeros.1', 'model.layers.57.self_attn.k_proj.bias', 'model.layers.57.self_attn.k_proj.codebook', 'model.layers.57.self_attn.k_proj.assignments', 'model.layers.57.self_attn.k_proj.normalizer.norms.0', 'model.layers.57.self_attn.k_proj.normalizer.norms.1', 'model.layers.57.self_attn.k_proj.normalizer.zeros.0', 'model.layers.57.self_attn.k_proj.normalizer.zeros.1', 'model.layers.57.self_attn.v_proj.bias', 'model.layers.57.self_attn.v_proj.codebook', 'model.layers.57.self_attn.v_proj.assignments', 'model.layers.57.self_attn.v_proj.normalizer.norms.0', 'model.layers.57.self_attn.v_proj.normalizer.norms.1', 'model.layers.57.self_attn.v_proj.normalizer.zeros.0', 'model.layers.57.self_attn.v_proj.normalizer.zeros.1', 'model.layers.57.self_attn.o_proj.bias', 'model.layers.57.self_attn.o_proj.codebook', 'model.layers.57.self_attn.o_proj.assignments', 'model.layers.57.self_attn.o_proj.normalizer.norms.0', 'model.layers.57.self_attn.o_proj.normalizer.norms.1', 'model.layers.57.self_attn.o_proj.normalizer.zeros.0', 'model.layers.57.self_attn.o_proj.normalizer.zeros.1', 'model.layers.57.mlp.gate_proj.bias', 'model.layers.57.mlp.gate_proj.codebook', 'model.layers.57.mlp.gate_proj.assignments', 'model.layers.57.mlp.gate_proj.normalizer.norms.0', 'model.layers.57.mlp.gate_proj.normalizer.norms.1', 'model.layers.57.mlp.gate_proj.normalizer.zeros.0', 'model.layers.57.mlp.gate_proj.normalizer.zeros.1', 'model.layers.57.mlp.up_proj.bias', 'model.layers.57.mlp.up_proj.codebook', 'model.layers.57.mlp.up_proj.assignments', 'model.layers.57.mlp.up_proj.normalizer.norms.0', 'model.layers.57.mlp.up_proj.normalizer.norms.1', 'model.layers.57.mlp.up_proj.normalizer.zeros.0', 'model.layers.57.mlp.up_proj.normalizer.zeros.1', 'model.layers.57.mlp.down_proj.bias', 'model.layers.57.mlp.down_proj.codebook', 'model.layers.57.mlp.down_proj.assignments', 'model.layers.57.mlp.down_proj.normalizer.norms.0', 'model.layers.57.mlp.down_proj.normalizer.norms.1', 'model.layers.57.mlp.down_proj.normalizer.zeros.0', 'model.layers.57.mlp.down_proj.normalizer.zeros.1', 'model.layers.58.self_attn.q_proj.bias', 'model.layers.58.self_attn.q_proj.codebook', 'model.layers.58.self_attn.q_proj.assignments', 'model.layers.58.self_attn.q_proj.normalizer.norms.0', 'model.layers.58.self_attn.q_proj.normalizer.norms.1', 'model.layers.58.self_attn.q_proj.normalizer.zeros.0', 'model.layers.58.self_attn.q_proj.normalizer.zeros.1', 'model.layers.58.self_attn.k_proj.bias', 'model.layers.58.self_attn.k_proj.codebook', 'model.layers.58.self_attn.k_proj.assignments', 'model.layers.58.self_attn.k_proj.normalizer.norms.0', 'model.layers.58.self_attn.k_proj.normalizer.norms.1', 'model.layers.58.self_attn.k_proj.normalizer.zeros.0', 'model.layers.58.self_attn.k_proj.normalizer.zeros.1', 'model.layers.58.self_attn.v_proj.bias', 'model.layers.58.self_attn.v_proj.codebook', 'model.layers.58.self_attn.v_proj.assignments', 'model.layers.58.self_attn.v_proj.normalizer.norms.0', 'model.layers.58.self_attn.v_proj.normalizer.norms.1', 'model.layers.58.self_attn.v_proj.normalizer.zeros.0', 'model.layers.58.self_attn.v_proj.normalizer.zeros.1', 'model.layers.58.self_attn.o_proj.bias', 'model.layers.58.self_attn.o_proj.codebook', 'model.layers.58.self_attn.o_proj.assignments', 'model.layers.58.self_attn.o_proj.normalizer.norms.0', 'model.layers.58.self_attn.o_proj.normalizer.norms.1', 'model.layers.58.self_attn.o_proj.normalizer.zeros.0', 'model.layers.58.self_attn.o_proj.normalizer.zeros.1', 'model.layers.58.mlp.gate_proj.bias', 'model.layers.58.mlp.gate_proj.codebook', 'model.layers.58.mlp.gate_proj.assignments', 'model.layers.58.mlp.gate_proj.normalizer.norms.0', 'model.layers.58.mlp.gate_proj.normalizer.norms.1', 'model.layers.58.mlp.gate_proj.normalizer.zeros.0', 'model.layers.58.mlp.gate_proj.normalizer.zeros.1', 'model.layers.58.mlp.up_proj.bias', 'model.layers.58.mlp.up_proj.codebook', 'model.layers.58.mlp.up_proj.assignments', 'model.layers.58.mlp.up_proj.normalizer.norms.0', 'model.layers.58.mlp.up_proj.normalizer.norms.1', 'model.layers.58.mlp.up_proj.normalizer.zeros.0', 'model.layers.58.mlp.up_proj.normalizer.zeros.1', 'model.layers.58.mlp.down_proj.bias', 'model.layers.58.mlp.down_proj.codebook', 'model.layers.58.mlp.down_proj.assignments', 'model.layers.58.mlp.down_proj.normalizer.norms.0', 'model.layers.58.mlp.down_proj.normalizer.norms.1', 'model.layers.58.mlp.down_proj.normalizer.zeros.0', 'model.layers.58.mlp.down_proj.normalizer.zeros.1', 'model.layers.59.self_attn.q_proj.bias', 'model.layers.59.self_attn.q_proj.codebook', 'model.layers.59.self_attn.q_proj.assignments', 'model.layers.59.self_attn.q_proj.normalizer.norms.0', 'model.layers.59.self_attn.q_proj.normalizer.norms.1', 'model.layers.59.self_attn.q_proj.normalizer.zeros.0', 'model.layers.59.self_attn.q_proj.normalizer.zeros.1', 'model.layers.59.self_attn.k_proj.bias', 'model.layers.59.self_attn.k_proj.codebook', 'model.layers.59.self_attn.k_proj.assignments', 'model.layers.59.self_attn.k_proj.normalizer.norms.0', 'model.layers.59.self_attn.k_proj.normalizer.norms.1', 'model.layers.59.self_attn.k_proj.normalizer.zeros.0', 'model.layers.59.self_attn.k_proj.normalizer.zeros.1', 'model.layers.59.self_attn.v_proj.bias', 'model.layers.59.self_attn.v_proj.codebook', 'model.layers.59.self_attn.v_proj.assignments', 'model.layers.59.self_attn.v_proj.normalizer.norms.0', 'model.layers.59.self_attn.v_proj.normalizer.norms.1', 'model.layers.59.self_attn.v_proj.normalizer.zeros.0', 'model.layers.59.self_attn.v_proj.normalizer.zeros.1', 'model.layers.59.self_attn.o_proj.bias', 'model.layers.59.self_attn.o_proj.codebook', 'model.layers.59.self_attn.o_proj.assignments', 'model.layers.59.self_attn.o_proj.normalizer.norms.0', 'model.layers.59.self_attn.o_proj.normalizer.norms.1', 'model.layers.59.self_attn.o_proj.normalizer.zeros.0', 'model.layers.59.self_attn.o_proj.normalizer.zeros.1', 'model.layers.59.mlp.gate_proj.bias', 'model.layers.59.mlp.gate_proj.codebook', 'model.layers.59.mlp.gate_proj.assignments', 'model.layers.59.mlp.gate_proj.normalizer.norms.0', 'model.layers.59.mlp.gate_proj.normalizer.norms.1', 'model.layers.59.mlp.gate_proj.normalizer.zeros.0', 'model.layers.59.mlp.gate_proj.normalizer.zeros.1', 'model.layers.59.mlp.up_proj.bias', 'model.layers.59.mlp.up_proj.codebook', 'model.layers.59.mlp.up_proj.assignments', 'model.layers.59.mlp.up_proj.normalizer.norms.0', 'model.layers.59.mlp.up_proj.normalizer.norms.1', 'model.layers.59.mlp.up_proj.normalizer.zeros.0', 'model.layers.59.mlp.up_proj.normalizer.zeros.1', 'model.layers.59.mlp.down_proj.bias', 'model.layers.59.mlp.down_proj.codebook', 'model.layers.59.mlp.down_proj.assignments', 'model.layers.59.mlp.down_proj.normalizer.norms.0', 'model.layers.59.mlp.down_proj.normalizer.norms.1', 'model.layers.59.mlp.down_proj.normalizer.zeros.0', 'model.layers.59.mlp.down_proj.normalizer.zeros.1', 'model.layers.60.self_attn.q_proj.bias', 'model.layers.60.self_attn.q_proj.codebook', 'model.layers.60.self_attn.q_proj.assignments', 'model.layers.60.self_attn.q_proj.normalizer.norms.0', 'model.layers.60.self_attn.q_proj.normalizer.norms.1', 'model.layers.60.self_attn.q_proj.normalizer.zeros.0', 'model.layers.60.self_attn.q_proj.normalizer.zeros.1', 'model.layers.60.self_attn.k_proj.bias', 'model.layers.60.self_attn.k_proj.codebook', 'model.layers.60.self_attn.k_proj.assignments', 'model.layers.60.self_attn.k_proj.normalizer.norms.0', 'model.layers.60.self_attn.k_proj.normalizer.norms.1', 'model.layers.60.self_attn.k_proj.normalizer.zeros.0', 'model.layers.60.self_attn.k_proj.normalizer.zeros.1', 'model.layers.60.self_attn.v_proj.bias', 'model.layers.60.self_attn.v_proj.codebook', 'model.layers.60.self_attn.v_proj.assignments', 'model.layers.60.self_attn.v_proj.normalizer.norms.0', 'model.layers.60.self_attn.v_proj.normalizer.norms.1', 'model.layers.60.self_attn.v_proj.normalizer.zeros.0', 'model.layers.60.self_attn.v_proj.normalizer.zeros.1', 'model.layers.60.self_attn.o_proj.bias', 'model.layers.60.self_attn.o_proj.codebook', 'model.layers.60.self_attn.o_proj.assignments', 'model.layers.60.self_attn.o_proj.normalizer.norms.0', 'model.layers.60.self_attn.o_proj.normalizer.norms.1', 'model.layers.60.self_attn.o_proj.normalizer.zeros.0', 'model.layers.60.self_attn.o_proj.normalizer.zeros.1', 'model.layers.60.mlp.gate_proj.bias', 'model.layers.60.mlp.gate_proj.codebook', 'model.layers.60.mlp.gate_proj.assignments', 'model.layers.60.mlp.gate_proj.normalizer.norms.0', 'model.layers.60.mlp.gate_proj.normalizer.norms.1', 'model.layers.60.mlp.gate_proj.normalizer.zeros.0', 'model.layers.60.mlp.gate_proj.normalizer.zeros.1', 'model.layers.60.mlp.up_proj.bias', 'model.layers.60.mlp.up_proj.codebook', 'model.layers.60.mlp.up_proj.assignments', 'model.layers.60.mlp.up_proj.normalizer.norms.0', 'model.layers.60.mlp.up_proj.normalizer.norms.1', 'model.layers.60.mlp.up_proj.normalizer.zeros.0', 'model.layers.60.mlp.up_proj.normalizer.zeros.1', 'model.layers.60.mlp.down_proj.bias', 'model.layers.60.mlp.down_proj.codebook', 'model.layers.60.mlp.down_proj.assignments', 'model.layers.60.mlp.down_proj.normalizer.norms.0', 'model.layers.60.mlp.down_proj.normalizer.norms.1', 'model.layers.60.mlp.down_proj.normalizer.zeros.0', 'model.layers.60.mlp.down_proj.normalizer.zeros.1', 'model.layers.61.self_attn.q_proj.bias', 'model.layers.61.self_attn.q_proj.codebook', 'model.layers.61.self_attn.q_proj.assignments', 'model.layers.61.self_attn.q_proj.normalizer.norms.0', 'model.layers.61.self_attn.q_proj.normalizer.norms.1', 'model.layers.61.self_attn.q_proj.normalizer.zeros.0', 'model.layers.61.self_attn.q_proj.normalizer.zeros.1', 'model.layers.61.self_attn.k_proj.bias', 'model.layers.61.self_attn.k_proj.codebook', 'model.layers.61.self_attn.k_proj.assignments', 'model.layers.61.self_attn.k_proj.normalizer.norms.0', 'model.layers.61.self_attn.k_proj.normalizer.norms.1', 'model.layers.61.self_attn.k_proj.normalizer.zeros.0', 'model.layers.61.self_attn.k_proj.normalizer.zeros.1', 'model.layers.61.self_attn.v_proj.bias', 'model.layers.61.self_attn.v_proj.codebook', 'model.layers.61.self_attn.v_proj.assignments', 'model.layers.61.self_attn.v_proj.normalizer.norms.0', 'model.layers.61.self_attn.v_proj.normalizer.norms.1', 'model.layers.61.self_attn.v_proj.normalizer.zeros.0', 'model.layers.61.self_attn.v_proj.normalizer.zeros.1', 'model.layers.61.self_attn.o_proj.bias', 'model.layers.61.self_attn.o_proj.codebook', 'model.layers.61.self_attn.o_proj.assignments', 'model.layers.61.self_attn.o_proj.normalizer.norms.0', 'model.layers.61.self_attn.o_proj.normalizer.norms.1', 'model.layers.61.self_attn.o_proj.normalizer.zeros.0', 'model.layers.61.self_attn.o_proj.normalizer.zeros.1', 'model.layers.61.mlp.gate_proj.bias', 'model.layers.61.mlp.gate_proj.codebook', 'model.layers.61.mlp.gate_proj.assignments', 'model.layers.61.mlp.gate_proj.normalizer.norms.0', 'model.layers.61.mlp.gate_proj.normalizer.norms.1', 'model.layers.61.mlp.gate_proj.normalizer.zeros.0', 'model.layers.61.mlp.gate_proj.normalizer.zeros.1', 'model.layers.61.mlp.up_proj.bias', 'model.layers.61.mlp.up_proj.codebook', 'model.layers.61.mlp.up_proj.assignments', 'model.layers.61.mlp.up_proj.normalizer.norms.0', 'model.layers.61.mlp.up_proj.normalizer.norms.1', 'model.layers.61.mlp.up_proj.normalizer.zeros.0', 'model.layers.61.mlp.up_proj.normalizer.zeros.1', 'model.layers.61.mlp.down_proj.bias', 'model.layers.61.mlp.down_proj.codebook', 'model.layers.61.mlp.down_proj.assignments', 'model.layers.61.mlp.down_proj.normalizer.norms.0', 'model.layers.61.mlp.down_proj.normalizer.norms.1', 'model.layers.61.mlp.down_proj.normalizer.zeros.0', 'model.layers.61.mlp.down_proj.normalizer.zeros.1', 'model.layers.62.self_attn.q_proj.bias', 'model.layers.62.self_attn.q_proj.codebook', 'model.layers.62.self_attn.q_proj.assignments', 'model.layers.62.self_attn.q_proj.normalizer.norms.0', 'model.layers.62.self_attn.q_proj.normalizer.norms.1', 'model.layers.62.self_attn.q_proj.normalizer.zeros.0', 'model.layers.62.self_attn.q_proj.normalizer.zeros.1', 'model.layers.62.self_attn.k_proj.bias', 'model.layers.62.self_attn.k_proj.codebook', 'model.layers.62.self_attn.k_proj.assignments', 'model.layers.62.self_attn.k_proj.normalizer.norms.0', 'model.layers.62.self_attn.k_proj.normalizer.norms.1', 'model.layers.62.self_attn.k_proj.normalizer.zeros.0', 'model.layers.62.self_attn.k_proj.normalizer.zeros.1', 'model.layers.62.self_attn.v_proj.bias', 'model.layers.62.self_attn.v_proj.codebook', 'model.layers.62.self_attn.v_proj.assignments', 'model.layers.62.self_attn.v_proj.normalizer.norms.0', 'model.layers.62.self_attn.v_proj.normalizer.norms.1', 'model.layers.62.self_attn.v_proj.normalizer.zeros.0', 'model.layers.62.self_attn.v_proj.normalizer.zeros.1', 'model.layers.62.self_attn.o_proj.bias', 'model.layers.62.self_attn.o_proj.codebook', 'model.layers.62.self_attn.o_proj.assignments', 'model.layers.62.self_attn.o_proj.normalizer.norms.0', 'model.layers.62.self_attn.o_proj.normalizer.norms.1', 'model.layers.62.self_attn.o_proj.normalizer.zeros.0', 'model.layers.62.self_attn.o_proj.normalizer.zeros.1', 'model.layers.62.mlp.gate_proj.bias', 'model.layers.62.mlp.gate_proj.codebook', 'model.layers.62.mlp.gate_proj.assignments', 'model.layers.62.mlp.gate_proj.normalizer.norms.0', 'model.layers.62.mlp.gate_proj.normalizer.norms.1', 'model.layers.62.mlp.gate_proj.normalizer.zeros.0', 'model.layers.62.mlp.gate_proj.normalizer.zeros.1', 'model.layers.62.mlp.up_proj.bias', 'model.layers.62.mlp.up_proj.codebook', 'model.layers.62.mlp.up_proj.assignments', 'model.layers.62.mlp.up_proj.normalizer.norms.0', 'model.layers.62.mlp.up_proj.normalizer.norms.1', 'model.layers.62.mlp.up_proj.normalizer.zeros.0', 'model.layers.62.mlp.up_proj.normalizer.zeros.1', 'model.layers.62.mlp.down_proj.bias', 'model.layers.62.mlp.down_proj.codebook', 'model.layers.62.mlp.down_proj.assignments', 'model.layers.62.mlp.down_proj.normalizer.norms.0', 'model.layers.62.mlp.down_proj.normalizer.norms.1', 'model.layers.62.mlp.down_proj.normalizer.zeros.0', 'model.layers.62.mlp.down_proj.normalizer.zeros.1', 'model.layers.63.self_attn.q_proj.bias', 'model.layers.63.self_attn.q_proj.codebook', 'model.layers.63.self_attn.q_proj.assignments', 'model.layers.63.self_attn.q_proj.normalizer.norms.0', 'model.layers.63.self_attn.q_proj.normalizer.norms.1', 'model.layers.63.self_attn.q_proj.normalizer.zeros.0', 'model.layers.63.self_attn.q_proj.normalizer.zeros.1', 'model.layers.63.self_attn.k_proj.bias', 'model.layers.63.self_attn.k_proj.codebook', 'model.layers.63.self_attn.k_proj.assignments', 'model.layers.63.self_attn.k_proj.normalizer.norms.0', 'model.layers.63.self_attn.k_proj.normalizer.norms.1', 'model.layers.63.self_attn.k_proj.normalizer.zeros.0', 'model.layers.63.self_attn.k_proj.normalizer.zeros.1', 'model.layers.63.self_attn.v_proj.bias', 'model.layers.63.self_attn.v_proj.codebook', 'model.layers.63.self_attn.v_proj.assignments', 'model.layers.63.self_attn.v_proj.normalizer.norms.0', 'model.layers.63.self_attn.v_proj.normalizer.norms.1', 'model.layers.63.self_attn.v_proj.normalizer.zeros.0', 'model.layers.63.self_attn.v_proj.normalizer.zeros.1', 'model.layers.63.self_attn.o_proj.bias', 'model.layers.63.self_attn.o_proj.codebook', 'model.layers.63.self_attn.o_proj.assignments', 'model.layers.63.self_attn.o_proj.normalizer.norms.0', 'model.layers.63.self_attn.o_proj.normalizer.norms.1', 'model.layers.63.self_attn.o_proj.normalizer.zeros.0', 'model.layers.63.self_attn.o_proj.normalizer.zeros.1', 'model.layers.63.mlp.gate_proj.bias', 'model.layers.63.mlp.gate_proj.codebook', 'model.layers.63.mlp.gate_proj.assignments', 'model.layers.63.mlp.gate_proj.normalizer.norms.0', 'model.layers.63.mlp.gate_proj.normalizer.norms.1', 'model.layers.63.mlp.gate_proj.normalizer.zeros.0', 'model.layers.63.mlp.gate_proj.normalizer.zeros.1', 'model.layers.63.mlp.up_proj.bias', 'model.layers.63.mlp.up_proj.codebook', 'model.layers.63.mlp.up_proj.assignments', 'model.layers.63.mlp.up_proj.normalizer.norms.0', 'model.layers.63.mlp.up_proj.normalizer.norms.1', 'model.layers.63.mlp.up_proj.normalizer.zeros.0', 'model.layers.63.mlp.up_proj.normalizer.zeros.1', 'model.layers.63.mlp.down_proj.bias', 'model.layers.63.mlp.down_proj.codebook', 'model.layers.63.mlp.down_proj.assignments', 'model.layers.63.mlp.down_proj.normalizer.norms.0', 'model.layers.63.mlp.down_proj.normalizer.norms.1', 'model.layers.63.mlp.down_proj.normalizer.zeros.0', 'model.layers.63.mlp.down_proj.normalizer.zeros.1', 'model.layers.64.self_attn.q_proj.bias', 'model.layers.64.self_attn.q_proj.codebook', 'model.layers.64.self_attn.q_proj.assignments', 'model.layers.64.self_attn.q_proj.normalizer.norms.0', 'model.layers.64.self_attn.q_proj.normalizer.norms.1', 'model.layers.64.self_attn.q_proj.normalizer.zeros.0', 'model.layers.64.self_attn.q_proj.normalizer.zeros.1', 'model.layers.64.self_attn.k_proj.bias', 'model.layers.64.self_attn.k_proj.codebook', 'model.layers.64.self_attn.k_proj.assignments', 'model.layers.64.self_attn.k_proj.normalizer.norms.0', 'model.layers.64.self_attn.k_proj.normalizer.norms.1', 'model.layers.64.self_attn.k_proj.normalizer.zeros.0', 'model.layers.64.self_attn.k_proj.normalizer.zeros.1', 'model.layers.64.self_attn.v_proj.bias', 'model.layers.64.self_attn.v_proj.codebook', 'model.layers.64.self_attn.v_proj.assignments', 'model.layers.64.self_attn.v_proj.normalizer.norms.0', 'model.layers.64.self_attn.v_proj.normalizer.norms.1', 'model.layers.64.self_attn.v_proj.normalizer.zeros.0', 'model.layers.64.self_attn.v_proj.normalizer.zeros.1', 'model.layers.64.self_attn.o_proj.bias', 'model.layers.64.self_attn.o_proj.codebook', 'model.layers.64.self_attn.o_proj.assignments', 'model.layers.64.self_attn.o_proj.normalizer.norms.0', 'model.layers.64.self_attn.o_proj.normalizer.norms.1', 'model.layers.64.self_attn.o_proj.normalizer.zeros.0', 'model.layers.64.self_attn.o_proj.normalizer.zeros.1', 'model.layers.64.mlp.gate_proj.bias', 'model.layers.64.mlp.gate_proj.codebook', 'model.layers.64.mlp.gate_proj.assignments', 'model.layers.64.mlp.gate_proj.normalizer.norms.0', 'model.layers.64.mlp.gate_proj.normalizer.norms.1', 'model.layers.64.mlp.gate_proj.normalizer.zeros.0', 'model.layers.64.mlp.gate_proj.normalizer.zeros.1', 'model.layers.64.mlp.up_proj.bias', 'model.layers.64.mlp.up_proj.codebook', 'model.layers.64.mlp.up_proj.assignments', 'model.layers.64.mlp.up_proj.normalizer.norms.0', 'model.layers.64.mlp.up_proj.normalizer.norms.1', 'model.layers.64.mlp.up_proj.normalizer.zeros.0', 'model.layers.64.mlp.up_proj.normalizer.zeros.1', 'model.layers.64.mlp.down_proj.bias', 'model.layers.64.mlp.down_proj.codebook', 'model.layers.64.mlp.down_proj.assignments', 'model.layers.64.mlp.down_proj.normalizer.norms.0', 'model.layers.64.mlp.down_proj.normalizer.norms.1', 'model.layers.64.mlp.down_proj.normalizer.zeros.0', 'model.layers.64.mlp.down_proj.normalizer.zeros.1', 'model.layers.65.self_attn.q_proj.bias', 'model.layers.65.self_attn.q_proj.codebook', 'model.layers.65.self_attn.q_proj.assignments', 'model.layers.65.self_attn.q_proj.normalizer.norms.0', 'model.layers.65.self_attn.q_proj.normalizer.norms.1', 'model.layers.65.self_attn.q_proj.normalizer.zeros.0', 'model.layers.65.self_attn.q_proj.normalizer.zeros.1', 'model.layers.65.self_attn.k_proj.bias', 'model.layers.65.self_attn.k_proj.codebook', 'model.layers.65.self_attn.k_proj.assignments', 'model.layers.65.self_attn.k_proj.normalizer.norms.0', 'model.layers.65.self_attn.k_proj.normalizer.norms.1', 'model.layers.65.self_attn.k_proj.normalizer.zeros.0', 'model.layers.65.self_attn.k_proj.normalizer.zeros.1', 'model.layers.65.self_attn.v_proj.bias', 'model.layers.65.self_attn.v_proj.codebook', 'model.layers.65.self_attn.v_proj.assignments', 'model.layers.65.self_attn.v_proj.normalizer.norms.0', 'model.layers.65.self_attn.v_proj.normalizer.norms.1', 'model.layers.65.self_attn.v_proj.normalizer.zeros.0', 'model.layers.65.self_attn.v_proj.normalizer.zeros.1', 'model.layers.65.self_attn.o_proj.bias', 'model.layers.65.self_attn.o_proj.codebook', 'model.layers.65.self_attn.o_proj.assignments', 'model.layers.65.self_attn.o_proj.normalizer.norms.0', 'model.layers.65.self_attn.o_proj.normalizer.norms.1', 'model.layers.65.self_attn.o_proj.normalizer.zeros.0', 'model.layers.65.self_attn.o_proj.normalizer.zeros.1', 'model.layers.65.mlp.gate_proj.bias', 'model.layers.65.mlp.gate_proj.codebook', 'model.layers.65.mlp.gate_proj.assignments', 'model.layers.65.mlp.gate_proj.normalizer.norms.0', 'model.layers.65.mlp.gate_proj.normalizer.norms.1', 'model.layers.65.mlp.gate_proj.normalizer.zeros.0', 'model.layers.65.mlp.gate_proj.normalizer.zeros.1', 'model.layers.65.mlp.up_proj.bias', 'model.layers.65.mlp.up_proj.codebook', 'model.layers.65.mlp.up_proj.assignments', 'model.layers.65.mlp.up_proj.normalizer.norms.0', 'model.layers.65.mlp.up_proj.normalizer.norms.1', 'model.layers.65.mlp.up_proj.normalizer.zeros.0', 'model.layers.65.mlp.up_proj.normalizer.zeros.1', 'model.layers.65.mlp.down_proj.bias', 'model.layers.65.mlp.down_proj.codebook', 'model.layers.65.mlp.down_proj.assignments', 'model.layers.65.mlp.down_proj.normalizer.norms.0', 'model.layers.65.mlp.down_proj.normalizer.norms.1', 'model.layers.65.mlp.down_proj.normalizer.zeros.0', 'model.layers.65.mlp.down_proj.normalizer.zeros.1', 'model.layers.66.self_attn.q_proj.bias', 'model.layers.66.self_attn.q_proj.codebook', 'model.layers.66.self_attn.q_proj.assignments', 'model.layers.66.self_attn.q_proj.normalizer.norms.0', 'model.layers.66.self_attn.q_proj.normalizer.norms.1', 'model.layers.66.self_attn.q_proj.normalizer.zeros.0', 'model.layers.66.self_attn.q_proj.normalizer.zeros.1', 'model.layers.66.self_attn.k_proj.bias', 'model.layers.66.self_attn.k_proj.codebook', 'model.layers.66.self_attn.k_proj.assignments', 'model.layers.66.self_attn.k_proj.normalizer.norms.0', 'model.layers.66.self_attn.k_proj.normalizer.norms.1', 'model.layers.66.self_attn.k_proj.normalizer.zeros.0', 'model.layers.66.self_attn.k_proj.normalizer.zeros.1', 'model.layers.66.self_attn.v_proj.bias', 'model.layers.66.self_attn.v_proj.codebook', 'model.layers.66.self_attn.v_proj.assignments', 'model.layers.66.self_attn.v_proj.normalizer.norms.0', 'model.layers.66.self_attn.v_proj.normalizer.norms.1', 'model.layers.66.self_attn.v_proj.normalizer.zeros.0', 'model.layers.66.self_attn.v_proj.normalizer.zeros.1', 'model.layers.66.self_attn.o_proj.bias', 'model.layers.66.self_attn.o_proj.codebook', 'model.layers.66.self_attn.o_proj.assignments', 'model.layers.66.self_attn.o_proj.normalizer.norms.0', 'model.layers.66.self_attn.o_proj.normalizer.norms.1', 'model.layers.66.self_attn.o_proj.normalizer.zeros.0', 'model.layers.66.self_attn.o_proj.normalizer.zeros.1', 'model.layers.66.mlp.gate_proj.bias', 'model.layers.66.mlp.gate_proj.codebook', 'model.layers.66.mlp.gate_proj.assignments', 'model.layers.66.mlp.gate_proj.normalizer.norms.0', 'model.layers.66.mlp.gate_proj.normalizer.norms.1', 'model.layers.66.mlp.gate_proj.normalizer.zeros.0', 'model.layers.66.mlp.gate_proj.normalizer.zeros.1', 'model.layers.66.mlp.up_proj.bias', 'model.layers.66.mlp.up_proj.codebook', 'model.layers.66.mlp.up_proj.assignments', 'model.layers.66.mlp.up_proj.normalizer.norms.0', 'model.layers.66.mlp.up_proj.normalizer.norms.1', 'model.layers.66.mlp.up_proj.normalizer.zeros.0', 'model.layers.66.mlp.up_proj.normalizer.zeros.1', 'model.layers.66.mlp.down_proj.bias', 'model.layers.66.mlp.down_proj.codebook', 'model.layers.66.mlp.down_proj.assignments', 'model.layers.66.mlp.down_proj.normalizer.norms.0', 'model.layers.66.mlp.down_proj.normalizer.norms.1', 'model.layers.66.mlp.down_proj.normalizer.zeros.0', 'model.layers.66.mlp.down_proj.normalizer.zeros.1', 'model.layers.67.self_attn.q_proj.bias', 'model.layers.67.self_attn.q_proj.codebook', 'model.layers.67.self_attn.q_proj.assignments', 'model.layers.67.self_attn.q_proj.normalizer.norms.0', 'model.layers.67.self_attn.q_proj.normalizer.norms.1', 'model.layers.67.self_attn.q_proj.normalizer.zeros.0', 'model.layers.67.self_attn.q_proj.normalizer.zeros.1', 'model.layers.67.self_attn.k_proj.bias', 'model.layers.67.self_attn.k_proj.codebook', 'model.layers.67.self_attn.k_proj.assignments', 'model.layers.67.self_attn.k_proj.normalizer.norms.0', 'model.layers.67.self_attn.k_proj.normalizer.norms.1', 'model.layers.67.self_attn.k_proj.normalizer.zeros.0', 'model.layers.67.self_attn.k_proj.normalizer.zeros.1', 'model.layers.67.self_attn.v_proj.bias', 'model.layers.67.self_attn.v_proj.codebook', 'model.layers.67.self_attn.v_proj.assignments', 'model.layers.67.self_attn.v_proj.normalizer.norms.0', 'model.layers.67.self_attn.v_proj.normalizer.norms.1', 'model.layers.67.self_attn.v_proj.normalizer.zeros.0', 'model.layers.67.self_attn.v_proj.normalizer.zeros.1', 'model.layers.67.self_attn.o_proj.bias', 'model.layers.67.self_attn.o_proj.codebook', 'model.layers.67.self_attn.o_proj.assignments', 'model.layers.67.self_attn.o_proj.normalizer.norms.0', 'model.layers.67.self_attn.o_proj.normalizer.norms.1', 'model.layers.67.self_attn.o_proj.normalizer.zeros.0', 'model.layers.67.self_attn.o_proj.normalizer.zeros.1', 'model.layers.67.mlp.gate_proj.bias', 'model.layers.67.mlp.gate_proj.codebook', 'model.layers.67.mlp.gate_proj.assignments', 'model.layers.67.mlp.gate_proj.normalizer.norms.0', 'model.layers.67.mlp.gate_proj.normalizer.norms.1', 'model.layers.67.mlp.gate_proj.normalizer.zeros.0', 'model.layers.67.mlp.gate_proj.normalizer.zeros.1', 'model.layers.67.mlp.up_proj.bias', 'model.layers.67.mlp.up_proj.codebook', 'model.layers.67.mlp.up_proj.assignments', 'model.layers.67.mlp.up_proj.normalizer.norms.0', 'model.layers.67.mlp.up_proj.normalizer.norms.1', 'model.layers.67.mlp.up_proj.normalizer.zeros.0', 'model.layers.67.mlp.up_proj.normalizer.zeros.1', 'model.layers.67.mlp.down_proj.bias', 'model.layers.67.mlp.down_proj.codebook', 'model.layers.67.mlp.down_proj.assignments', 'model.layers.67.mlp.down_proj.normalizer.norms.0', 'model.layers.67.mlp.down_proj.normalizer.norms.1', 'model.layers.67.mlp.down_proj.normalizer.zeros.0', 'model.layers.67.mlp.down_proj.normalizer.zeros.1', 'model.layers.68.self_attn.q_proj.bias', 'model.layers.68.self_attn.q_proj.codebook', 'model.layers.68.self_attn.q_proj.assignments', 'model.layers.68.self_attn.q_proj.normalizer.norms.0', 'model.layers.68.self_attn.q_proj.normalizer.norms.1', 'model.layers.68.self_attn.q_proj.normalizer.zeros.0', 'model.layers.68.self_attn.q_proj.normalizer.zeros.1', 'model.layers.68.self_attn.k_proj.bias', 'model.layers.68.self_attn.k_proj.codebook', 'model.layers.68.self_attn.k_proj.assignments', 'model.layers.68.self_attn.k_proj.normalizer.norms.0', 'model.layers.68.self_attn.k_proj.normalizer.norms.1', 'model.layers.68.self_attn.k_proj.normalizer.zeros.0', 'model.layers.68.self_attn.k_proj.normalizer.zeros.1', 'model.layers.68.self_attn.v_proj.bias', 'model.layers.68.self_attn.v_proj.codebook', 'model.layers.68.self_attn.v_proj.assignments', 'model.layers.68.self_attn.v_proj.normalizer.norms.0', 'model.layers.68.self_attn.v_proj.normalizer.norms.1', 'model.layers.68.self_attn.v_proj.normalizer.zeros.0', 'model.layers.68.self_attn.v_proj.normalizer.zeros.1', 'model.layers.68.self_attn.o_proj.bias', 'model.layers.68.self_attn.o_proj.codebook', 'model.layers.68.self_attn.o_proj.assignments', 'model.layers.68.self_attn.o_proj.normalizer.norms.0', 'model.layers.68.self_attn.o_proj.normalizer.norms.1', 'model.layers.68.self_attn.o_proj.normalizer.zeros.0', 'model.layers.68.self_attn.o_proj.normalizer.zeros.1', 'model.layers.68.mlp.gate_proj.bias', 'model.layers.68.mlp.gate_proj.codebook', 'model.layers.68.mlp.gate_proj.assignments', 'model.layers.68.mlp.gate_proj.normalizer.norms.0', 'model.layers.68.mlp.gate_proj.normalizer.norms.1', 'model.layers.68.mlp.gate_proj.normalizer.zeros.0', 'model.layers.68.mlp.gate_proj.normalizer.zeros.1', 'model.layers.68.mlp.up_proj.bias', 'model.layers.68.mlp.up_proj.codebook', 'model.layers.68.mlp.up_proj.assignments', 'model.layers.68.mlp.up_proj.normalizer.norms.0', 'model.layers.68.mlp.up_proj.normalizer.norms.1', 'model.layers.68.mlp.up_proj.normalizer.zeros.0', 'model.layers.68.mlp.up_proj.normalizer.zeros.1', 'model.layers.68.mlp.down_proj.bias', 'model.layers.68.mlp.down_proj.codebook', 'model.layers.68.mlp.down_proj.assignments', 'model.layers.68.mlp.down_proj.normalizer.norms.0', 'model.layers.68.mlp.down_proj.normalizer.norms.1', 'model.layers.68.mlp.down_proj.normalizer.zeros.0', 'model.layers.68.mlp.down_proj.normalizer.zeros.1', 'model.layers.69.self_attn.q_proj.bias', 'model.layers.69.self_attn.q_proj.codebook', 'model.layers.69.self_attn.q_proj.assignments', 'model.layers.69.self_attn.q_proj.normalizer.norms.0', 'model.layers.69.self_attn.q_proj.normalizer.norms.1', 'model.layers.69.self_attn.q_proj.normalizer.zeros.0', 'model.layers.69.self_attn.q_proj.normalizer.zeros.1', 'model.layers.69.self_attn.k_proj.bias', 'model.layers.69.self_attn.k_proj.codebook', 'model.layers.69.self_attn.k_proj.assignments', 'model.layers.69.self_attn.k_proj.normalizer.norms.0', 'model.layers.69.self_attn.k_proj.normalizer.norms.1', 'model.layers.69.self_attn.k_proj.normalizer.zeros.0', 'model.layers.69.self_attn.k_proj.normalizer.zeros.1', 'model.layers.69.self_attn.v_proj.bias', 'model.layers.69.self_attn.v_proj.codebook', 'model.layers.69.self_attn.v_proj.assignments', 'model.layers.69.self_attn.v_proj.normalizer.norms.0', 'model.layers.69.self_attn.v_proj.normalizer.norms.1', 'model.layers.69.self_attn.v_proj.normalizer.zeros.0', 'model.layers.69.self_attn.v_proj.normalizer.zeros.1', 'model.layers.69.self_attn.o_proj.bias', 'model.layers.69.self_attn.o_proj.codebook', 'model.layers.69.self_attn.o_proj.assignments', 'model.layers.69.self_attn.o_proj.normalizer.norms.0', 'model.layers.69.self_attn.o_proj.normalizer.norms.1', 'model.layers.69.self_attn.o_proj.normalizer.zeros.0', 'model.layers.69.self_attn.o_proj.normalizer.zeros.1', 'model.layers.69.mlp.gate_proj.bias', 'model.layers.69.mlp.gate_proj.codebook', 'model.layers.69.mlp.gate_proj.assignments', 'model.layers.69.mlp.gate_proj.normalizer.norms.0', 'model.layers.69.mlp.gate_proj.normalizer.norms.1', 'model.layers.69.mlp.gate_proj.normalizer.zeros.0', 'model.layers.69.mlp.gate_proj.normalizer.zeros.1', 'model.layers.69.mlp.up_proj.bias', 'model.layers.69.mlp.up_proj.codebook', 'model.layers.69.mlp.up_proj.assignments', 'model.layers.69.mlp.up_proj.normalizer.norms.0', 'model.layers.69.mlp.up_proj.normalizer.norms.1', 'model.layers.69.mlp.up_proj.normalizer.zeros.0', 'model.layers.69.mlp.up_proj.normalizer.zeros.1', 'model.layers.69.mlp.down_proj.bias', 'model.layers.69.mlp.down_proj.codebook', 'model.layers.69.mlp.down_proj.assignments', 'model.layers.69.mlp.down_proj.normalizer.norms.0', 'model.layers.69.mlp.down_proj.normalizer.norms.1', 'model.layers.69.mlp.down_proj.normalizer.zeros.0', 'model.layers.69.mlp.down_proj.normalizer.zeros.1', 'model.layers.70.self_attn.q_proj.bias', 'model.layers.70.self_attn.q_proj.codebook', 'model.layers.70.self_attn.q_proj.assignments', 'model.layers.70.self_attn.q_proj.normalizer.norms.0', 'model.layers.70.self_attn.q_proj.normalizer.norms.1', 'model.layers.70.self_attn.q_proj.normalizer.zeros.0', 'model.layers.70.self_attn.q_proj.normalizer.zeros.1', 'model.layers.70.self_attn.k_proj.bias', 'model.layers.70.self_attn.k_proj.codebook', 'model.layers.70.self_attn.k_proj.assignments', 'model.layers.70.self_attn.k_proj.normalizer.norms.0', 'model.layers.70.self_attn.k_proj.normalizer.norms.1', 'model.layers.70.self_attn.k_proj.normalizer.zeros.0', 'model.layers.70.self_attn.k_proj.normalizer.zeros.1', 'model.layers.70.self_attn.v_proj.bias', 'model.layers.70.self_attn.v_proj.codebook', 'model.layers.70.self_attn.v_proj.assignments', 'model.layers.70.self_attn.v_proj.normalizer.norms.0', 'model.layers.70.self_attn.v_proj.normalizer.norms.1', 'model.layers.70.self_attn.v_proj.normalizer.zeros.0', 'model.layers.70.self_attn.v_proj.normalizer.zeros.1', 'model.layers.70.self_attn.o_proj.bias', 'model.layers.70.self_attn.o_proj.codebook', 'model.layers.70.self_attn.o_proj.assignments', 'model.layers.70.self_attn.o_proj.normalizer.norms.0', 'model.layers.70.self_attn.o_proj.normalizer.norms.1', 'model.layers.70.self_attn.o_proj.normalizer.zeros.0', 'model.layers.70.self_attn.o_proj.normalizer.zeros.1', 'model.layers.70.mlp.gate_proj.bias', 'model.layers.70.mlp.gate_proj.codebook', 'model.layers.70.mlp.gate_proj.assignments', 'model.layers.70.mlp.gate_proj.normalizer.norms.0', 'model.layers.70.mlp.gate_proj.normalizer.norms.1', 'model.layers.70.mlp.gate_proj.normalizer.zeros.0', 'model.layers.70.mlp.gate_proj.normalizer.zeros.1', 'model.layers.70.mlp.up_proj.bias', 'model.layers.70.mlp.up_proj.codebook', 'model.layers.70.mlp.up_proj.assignments', 'model.layers.70.mlp.up_proj.normalizer.norms.0', 'model.layers.70.mlp.up_proj.normalizer.norms.1', 'model.layers.70.mlp.up_proj.normalizer.zeros.0', 'model.layers.70.mlp.up_proj.normalizer.zeros.1', 'model.layers.70.mlp.down_proj.bias', 'model.layers.70.mlp.down_proj.codebook', 'model.layers.70.mlp.down_proj.assignments', 'model.layers.70.mlp.down_proj.normalizer.norms.0', 'model.layers.70.mlp.down_proj.normalizer.norms.1', 'model.layers.70.mlp.down_proj.normalizer.zeros.0', 'model.layers.70.mlp.down_proj.normalizer.zeros.1', 'model.layers.71.self_attn.q_proj.bias', 'model.layers.71.self_attn.q_proj.codebook', 'model.layers.71.self_attn.q_proj.assignments', 'model.layers.71.self_attn.q_proj.normalizer.norms.0', 'model.layers.71.self_attn.q_proj.normalizer.norms.1', 'model.layers.71.self_attn.q_proj.normalizer.zeros.0', 'model.layers.71.self_attn.q_proj.normalizer.zeros.1', 'model.layers.71.self_attn.k_proj.bias', 'model.layers.71.self_attn.k_proj.codebook', 'model.layers.71.self_attn.k_proj.assignments', 'model.layers.71.self_attn.k_proj.normalizer.norms.0', 'model.layers.71.self_attn.k_proj.normalizer.norms.1', 'model.layers.71.self_attn.k_proj.normalizer.zeros.0', 'model.layers.71.self_attn.k_proj.normalizer.zeros.1', 'model.layers.71.self_attn.v_proj.bias', 'model.layers.71.self_attn.v_proj.codebook', 'model.layers.71.self_attn.v_proj.assignments', 'model.layers.71.self_attn.v_proj.normalizer.norms.0', 'model.layers.71.self_attn.v_proj.normalizer.norms.1', 'model.layers.71.self_attn.v_proj.normalizer.zeros.0', 'model.layers.71.self_attn.v_proj.normalizer.zeros.1', 'model.layers.71.self_attn.o_proj.bias', 'model.layers.71.self_attn.o_proj.codebook', 'model.layers.71.self_attn.o_proj.assignments', 'model.layers.71.self_attn.o_proj.normalizer.norms.0', 'model.layers.71.self_attn.o_proj.normalizer.norms.1', 'model.layers.71.self_attn.o_proj.normalizer.zeros.0', 'model.layers.71.self_attn.o_proj.normalizer.zeros.1', 'model.layers.71.mlp.gate_proj.bias', 'model.layers.71.mlp.gate_proj.codebook', 'model.layers.71.mlp.gate_proj.assignments', 'model.layers.71.mlp.gate_proj.normalizer.norms.0', 'model.layers.71.mlp.gate_proj.normalizer.norms.1', 'model.layers.71.mlp.gate_proj.normalizer.zeros.0', 'model.layers.71.mlp.gate_proj.normalizer.zeros.1', 'model.layers.71.mlp.up_proj.bias', 'model.layers.71.mlp.up_proj.codebook', 'model.layers.71.mlp.up_proj.assignments', 'model.layers.71.mlp.up_proj.normalizer.norms.0', 'model.layers.71.mlp.up_proj.normalizer.norms.1', 'model.layers.71.mlp.up_proj.normalizer.zeros.0', 'model.layers.71.mlp.up_proj.normalizer.zeros.1', 'model.layers.71.mlp.down_proj.bias', 'model.layers.71.mlp.down_proj.codebook', 'model.layers.71.mlp.down_proj.assignments', 'model.layers.71.mlp.down_proj.normalizer.norms.0', 'model.layers.71.mlp.down_proj.normalizer.norms.1', 'model.layers.71.mlp.down_proj.normalizer.zeros.0', 'model.layers.71.mlp.down_proj.normalizer.zeros.1', 'model.layers.72.self_attn.q_proj.bias', 'model.layers.72.self_attn.q_proj.codebook', 'model.layers.72.self_attn.q_proj.assignments', 'model.layers.72.self_attn.q_proj.normalizer.norms.0', 'model.layers.72.self_attn.q_proj.normalizer.norms.1', 'model.layers.72.self_attn.q_proj.normalizer.zeros.0', 'model.layers.72.self_attn.q_proj.normalizer.zeros.1', 'model.layers.72.self_attn.k_proj.bias', 'model.layers.72.self_attn.k_proj.codebook', 'model.layers.72.self_attn.k_proj.assignments', 'model.layers.72.self_attn.k_proj.normalizer.norms.0', 'model.layers.72.self_attn.k_proj.normalizer.norms.1', 'model.layers.72.self_attn.k_proj.normalizer.zeros.0', 'model.layers.72.self_attn.k_proj.normalizer.zeros.1', 'model.layers.72.self_attn.v_proj.bias', 'model.layers.72.self_attn.v_proj.codebook', 'model.layers.72.self_attn.v_proj.assignments', 'model.layers.72.self_attn.v_proj.normalizer.norms.0', 'model.layers.72.self_attn.v_proj.normalizer.norms.1', 'model.layers.72.self_attn.v_proj.normalizer.zeros.0', 'model.layers.72.self_attn.v_proj.normalizer.zeros.1', 'model.layers.72.self_attn.o_proj.bias', 'model.layers.72.self_attn.o_proj.codebook', 'model.layers.72.self_attn.o_proj.assignments', 'model.layers.72.self_attn.o_proj.normalizer.norms.0', 'model.layers.72.self_attn.o_proj.normalizer.norms.1', 'model.layers.72.self_attn.o_proj.normalizer.zeros.0', 'model.layers.72.self_attn.o_proj.normalizer.zeros.1', 'model.layers.72.mlp.gate_proj.bias', 'model.layers.72.mlp.gate_proj.codebook', 'model.layers.72.mlp.gate_proj.assignments', 'model.layers.72.mlp.gate_proj.normalizer.norms.0', 'model.layers.72.mlp.gate_proj.normalizer.norms.1', 'model.layers.72.mlp.gate_proj.normalizer.zeros.0', 'model.layers.72.mlp.gate_proj.normalizer.zeros.1', 'model.layers.72.mlp.up_proj.bias', 'model.layers.72.mlp.up_proj.codebook', 'model.layers.72.mlp.up_proj.assignments', 'model.layers.72.mlp.up_proj.normalizer.norms.0', 'model.layers.72.mlp.up_proj.normalizer.norms.1', 'model.layers.72.mlp.up_proj.normalizer.zeros.0', 'model.layers.72.mlp.up_proj.normalizer.zeros.1', 'model.layers.72.mlp.down_proj.bias', 'model.layers.72.mlp.down_proj.codebook', 'model.layers.72.mlp.down_proj.assignments', 'model.layers.72.mlp.down_proj.normalizer.norms.0', 'model.layers.72.mlp.down_proj.normalizer.norms.1', 'model.layers.72.mlp.down_proj.normalizer.zeros.0', 'model.layers.72.mlp.down_proj.normalizer.zeros.1', 'model.layers.73.self_attn.q_proj.bias', 'model.layers.73.self_attn.q_proj.codebook', 'model.layers.73.self_attn.q_proj.assignments', 'model.layers.73.self_attn.q_proj.normalizer.norms.0', 'model.layers.73.self_attn.q_proj.normalizer.norms.1', 'model.layers.73.self_attn.q_proj.normalizer.zeros.0', 'model.layers.73.self_attn.q_proj.normalizer.zeros.1', 'model.layers.73.self_attn.k_proj.bias', 'model.layers.73.self_attn.k_proj.codebook', 'model.layers.73.self_attn.k_proj.assignments', 'model.layers.73.self_attn.k_proj.normalizer.norms.0', 'model.layers.73.self_attn.k_proj.normalizer.norms.1', 'model.layers.73.self_attn.k_proj.normalizer.zeros.0', 'model.layers.73.self_attn.k_proj.normalizer.zeros.1', 'model.layers.73.self_attn.v_proj.bias', 'model.layers.73.self_attn.v_proj.codebook', 'model.layers.73.self_attn.v_proj.assignments', 'model.layers.73.self_attn.v_proj.normalizer.norms.0', 'model.layers.73.self_attn.v_proj.normalizer.norms.1', 'model.layers.73.self_attn.v_proj.normalizer.zeros.0', 'model.layers.73.self_attn.v_proj.normalizer.zeros.1', 'model.layers.73.self_attn.o_proj.bias', 'model.layers.73.self_attn.o_proj.codebook', 'model.layers.73.self_attn.o_proj.assignments', 'model.layers.73.self_attn.o_proj.normalizer.norms.0', 'model.layers.73.self_attn.o_proj.normalizer.norms.1', 'model.layers.73.self_attn.o_proj.normalizer.zeros.0', 'model.layers.73.self_attn.o_proj.normalizer.zeros.1', 'model.layers.73.mlp.gate_proj.bias', 'model.layers.73.mlp.gate_proj.codebook', 'model.layers.73.mlp.gate_proj.assignments', 'model.layers.73.mlp.gate_proj.normalizer.norms.0', 'model.layers.73.mlp.gate_proj.normalizer.norms.1', 'model.layers.73.mlp.gate_proj.normalizer.zeros.0', 'model.layers.73.mlp.gate_proj.normalizer.zeros.1', 'model.layers.73.mlp.up_proj.bias', 'model.layers.73.mlp.up_proj.codebook', 'model.layers.73.mlp.up_proj.assignments', 'model.layers.73.mlp.up_proj.normalizer.norms.0', 'model.layers.73.mlp.up_proj.normalizer.norms.1', 'model.layers.73.mlp.up_proj.normalizer.zeros.0', 'model.layers.73.mlp.up_proj.normalizer.zeros.1', 'model.layers.73.mlp.down_proj.bias', 'model.layers.73.mlp.down_proj.codebook', 'model.layers.73.mlp.down_proj.assignments', 'model.layers.73.mlp.down_proj.normalizer.norms.0', 'model.layers.73.mlp.down_proj.normalizer.norms.1', 'model.layers.73.mlp.down_proj.normalizer.zeros.0', 'model.layers.73.mlp.down_proj.normalizer.zeros.1', 'model.layers.74.self_attn.q_proj.bias', 'model.layers.74.self_attn.q_proj.codebook', 'model.layers.74.self_attn.q_proj.assignments', 'model.layers.74.self_attn.q_proj.normalizer.norms.0', 'model.layers.74.self_attn.q_proj.normalizer.norms.1', 'model.layers.74.self_attn.q_proj.normalizer.zeros.0', 'model.layers.74.self_attn.q_proj.normalizer.zeros.1', 'model.layers.74.self_attn.k_proj.bias', 'model.layers.74.self_attn.k_proj.codebook', 'model.layers.74.self_attn.k_proj.assignments', 'model.layers.74.self_attn.k_proj.normalizer.norms.0', 'model.layers.74.self_attn.k_proj.normalizer.norms.1', 'model.layers.74.self_attn.k_proj.normalizer.zeros.0', 'model.layers.74.self_attn.k_proj.normalizer.zeros.1', 'model.layers.74.self_attn.v_proj.bias', 'model.layers.74.self_attn.v_proj.codebook', 'model.layers.74.self_attn.v_proj.assignments', 'model.layers.74.self_attn.v_proj.normalizer.norms.0', 'model.layers.74.self_attn.v_proj.normalizer.norms.1', 'model.layers.74.self_attn.v_proj.normalizer.zeros.0', 'model.layers.74.self_attn.v_proj.normalizer.zeros.1', 'model.layers.74.self_attn.o_proj.bias', 'model.layers.74.self_attn.o_proj.codebook', 'model.layers.74.self_attn.o_proj.assignments', 'model.layers.74.self_attn.o_proj.normalizer.norms.0', 'model.layers.74.self_attn.o_proj.normalizer.norms.1', 'model.layers.74.self_attn.o_proj.normalizer.zeros.0', 'model.layers.74.self_attn.o_proj.normalizer.zeros.1', 'model.layers.74.mlp.gate_proj.bias', 'model.layers.74.mlp.gate_proj.codebook', 'model.layers.74.mlp.gate_proj.assignments', 'model.layers.74.mlp.gate_proj.normalizer.norms.0', 'model.layers.74.mlp.gate_proj.normalizer.norms.1', 'model.layers.74.mlp.gate_proj.normalizer.zeros.0', 'model.layers.74.mlp.gate_proj.normalizer.zeros.1', 'model.layers.74.mlp.up_proj.bias', 'model.layers.74.mlp.up_proj.codebook', 'model.layers.74.mlp.up_proj.assignments', 'model.layers.74.mlp.up_proj.normalizer.norms.0', 'model.layers.74.mlp.up_proj.normalizer.norms.1', 'model.layers.74.mlp.up_proj.normalizer.zeros.0', 'model.layers.74.mlp.up_proj.normalizer.zeros.1', 'model.layers.74.mlp.down_proj.bias', 'model.layers.74.mlp.down_proj.codebook', 'model.layers.74.mlp.down_proj.assignments', 'model.layers.74.mlp.down_proj.normalizer.norms.0', 'model.layers.74.mlp.down_proj.normalizer.norms.1', 'model.layers.74.mlp.down_proj.normalizer.zeros.0', 'model.layers.74.mlp.down_proj.normalizer.zeros.1', 'model.layers.75.self_attn.q_proj.bias', 'model.layers.75.self_attn.q_proj.codebook', 'model.layers.75.self_attn.q_proj.assignments', 'model.layers.75.self_attn.q_proj.normalizer.norms.0', 'model.layers.75.self_attn.q_proj.normalizer.norms.1', 'model.layers.75.self_attn.q_proj.normalizer.zeros.0', 'model.layers.75.self_attn.q_proj.normalizer.zeros.1', 'model.layers.75.self_attn.k_proj.bias', 'model.layers.75.self_attn.k_proj.codebook', 'model.layers.75.self_attn.k_proj.assignments', 'model.layers.75.self_attn.k_proj.normalizer.norms.0', 'model.layers.75.self_attn.k_proj.normalizer.norms.1', 'model.layers.75.self_attn.k_proj.normalizer.zeros.0', 'model.layers.75.self_attn.k_proj.normalizer.zeros.1', 'model.layers.75.self_attn.v_proj.bias', 'model.layers.75.self_attn.v_proj.codebook', 'model.layers.75.self_attn.v_proj.assignments', 'model.layers.75.self_attn.v_proj.normalizer.norms.0', 'model.layers.75.self_attn.v_proj.normalizer.norms.1', 'model.layers.75.self_attn.v_proj.normalizer.zeros.0', 'model.layers.75.self_attn.v_proj.normalizer.zeros.1', 'model.layers.75.self_attn.o_proj.bias', 'model.layers.75.self_attn.o_proj.codebook', 'model.layers.75.self_attn.o_proj.assignments', 'model.layers.75.self_attn.o_proj.normalizer.norms.0', 'model.layers.75.self_attn.o_proj.normalizer.norms.1', 'model.layers.75.self_attn.o_proj.normalizer.zeros.0', 'model.layers.75.self_attn.o_proj.normalizer.zeros.1', 'model.layers.75.mlp.gate_proj.bias', 'model.layers.75.mlp.gate_proj.codebook', 'model.layers.75.mlp.gate_proj.assignments', 'model.layers.75.mlp.gate_proj.normalizer.norms.0', 'model.layers.75.mlp.gate_proj.normalizer.norms.1', 'model.layers.75.mlp.gate_proj.normalizer.zeros.0', 'model.layers.75.mlp.gate_proj.normalizer.zeros.1', 'model.layers.75.mlp.up_proj.bias', 'model.layers.75.mlp.up_proj.codebook', 'model.layers.75.mlp.up_proj.assignments', 'model.layers.75.mlp.up_proj.normalizer.norms.0', 'model.layers.75.mlp.up_proj.normalizer.norms.1', 'model.layers.75.mlp.up_proj.normalizer.zeros.0', 'model.layers.75.mlp.up_proj.normalizer.zeros.1', 'model.layers.75.mlp.down_proj.bias', 'model.layers.75.mlp.down_proj.codebook', 'model.layers.75.mlp.down_proj.assignments', 'model.layers.75.mlp.down_proj.normalizer.norms.0', 'model.layers.75.mlp.down_proj.normalizer.norms.1', 'model.layers.75.mlp.down_proj.normalizer.zeros.0', 'model.layers.75.mlp.down_proj.normalizer.zeros.1', 'model.layers.76.self_attn.q_proj.bias', 'model.layers.76.self_attn.q_proj.codebook', 'model.layers.76.self_attn.q_proj.assignments', 'model.layers.76.self_attn.q_proj.normalizer.norms.0', 'model.layers.76.self_attn.q_proj.normalizer.norms.1', 'model.layers.76.self_attn.q_proj.normalizer.zeros.0', 'model.layers.76.self_attn.q_proj.normalizer.zeros.1', 'model.layers.76.self_attn.k_proj.bias', 'model.layers.76.self_attn.k_proj.codebook', 'model.layers.76.self_attn.k_proj.assignments', 'model.layers.76.self_attn.k_proj.normalizer.norms.0', 'model.layers.76.self_attn.k_proj.normalizer.norms.1', 'model.layers.76.self_attn.k_proj.normalizer.zeros.0', 'model.layers.76.self_attn.k_proj.normalizer.zeros.1', 'model.layers.76.self_attn.v_proj.bias', 'model.layers.76.self_attn.v_proj.codebook', 'model.layers.76.self_attn.v_proj.assignments', 'model.layers.76.self_attn.v_proj.normalizer.norms.0', 'model.layers.76.self_attn.v_proj.normalizer.norms.1', 'model.layers.76.self_attn.v_proj.normalizer.zeros.0', 'model.layers.76.self_attn.v_proj.normalizer.zeros.1', 'model.layers.76.self_attn.o_proj.bias', 'model.layers.76.self_attn.o_proj.codebook', 'model.layers.76.self_attn.o_proj.assignments', 'model.layers.76.self_attn.o_proj.normalizer.norms.0', 'model.layers.76.self_attn.o_proj.normalizer.norms.1', 'model.layers.76.self_attn.o_proj.normalizer.zeros.0', 'model.layers.76.self_attn.o_proj.normalizer.zeros.1', 'model.layers.76.mlp.gate_proj.bias', 'model.layers.76.mlp.gate_proj.codebook', 'model.layers.76.mlp.gate_proj.assignments', 'model.layers.76.mlp.gate_proj.normalizer.norms.0', 'model.layers.76.mlp.gate_proj.normalizer.norms.1', 'model.layers.76.mlp.gate_proj.normalizer.zeros.0', 'model.layers.76.mlp.gate_proj.normalizer.zeros.1', 'model.layers.76.mlp.up_proj.bias', 'model.layers.76.mlp.up_proj.codebook', 'model.layers.76.mlp.up_proj.assignments', 'model.layers.76.mlp.up_proj.normalizer.norms.0', 'model.layers.76.mlp.up_proj.normalizer.norms.1', 'model.layers.76.mlp.up_proj.normalizer.zeros.0', 'model.layers.76.mlp.up_proj.normalizer.zeros.1', 'model.layers.76.mlp.down_proj.bias', 'model.layers.76.mlp.down_proj.codebook', 'model.layers.76.mlp.down_proj.assignments', 'model.layers.76.mlp.down_proj.normalizer.norms.0', 'model.layers.76.mlp.down_proj.normalizer.norms.1', 'model.layers.76.mlp.down_proj.normalizer.zeros.0', 'model.layers.76.mlp.down_proj.normalizer.zeros.1', 'model.layers.77.self_attn.q_proj.bias', 'model.layers.77.self_attn.q_proj.codebook', 'model.layers.77.self_attn.q_proj.assignments', 'model.layers.77.self_attn.q_proj.normalizer.norms.0', 'model.layers.77.self_attn.q_proj.normalizer.norms.1', 'model.layers.77.self_attn.q_proj.normalizer.zeros.0', 'model.layers.77.self_attn.q_proj.normalizer.zeros.1', 'model.layers.77.self_attn.k_proj.bias', 'model.layers.77.self_attn.k_proj.codebook', 'model.layers.77.self_attn.k_proj.assignments', 'model.layers.77.self_attn.k_proj.normalizer.norms.0', 'model.layers.77.self_attn.k_proj.normalizer.norms.1', 'model.layers.77.self_attn.k_proj.normalizer.zeros.0', 'model.layers.77.self_attn.k_proj.normalizer.zeros.1', 'model.layers.77.self_attn.v_proj.bias', 'model.layers.77.self_attn.v_proj.codebook', 'model.layers.77.self_attn.v_proj.assignments', 'model.layers.77.self_attn.v_proj.normalizer.norms.0', 'model.layers.77.self_attn.v_proj.normalizer.norms.1', 'model.layers.77.self_attn.v_proj.normalizer.zeros.0', 'model.layers.77.self_attn.v_proj.normalizer.zeros.1', 'model.layers.77.self_attn.o_proj.bias', 'model.layers.77.self_attn.o_proj.codebook', 'model.layers.77.self_attn.o_proj.assignments', 'model.layers.77.self_attn.o_proj.normalizer.norms.0', 'model.layers.77.self_attn.o_proj.normalizer.norms.1', 'model.layers.77.self_attn.o_proj.normalizer.zeros.0', 'model.layers.77.self_attn.o_proj.normalizer.zeros.1', 'model.layers.77.mlp.gate_proj.bias', 'model.layers.77.mlp.gate_proj.codebook', 'model.layers.77.mlp.gate_proj.assignments', 'model.layers.77.mlp.gate_proj.normalizer.norms.0', 'model.layers.77.mlp.gate_proj.normalizer.norms.1', 'model.layers.77.mlp.gate_proj.normalizer.zeros.0', 'model.layers.77.mlp.gate_proj.normalizer.zeros.1', 'model.layers.77.mlp.up_proj.bias', 'model.layers.77.mlp.up_proj.codebook', 'model.layers.77.mlp.up_proj.assignments', 'model.layers.77.mlp.up_proj.normalizer.norms.0', 'model.layers.77.mlp.up_proj.normalizer.norms.1', 'model.layers.77.mlp.up_proj.normalizer.zeros.0', 'model.layers.77.mlp.up_proj.normalizer.zeros.1', 'model.layers.77.mlp.down_proj.bias', 'model.layers.77.mlp.down_proj.codebook', 'model.layers.77.mlp.down_proj.assignments', 'model.layers.77.mlp.down_proj.normalizer.norms.0', 'model.layers.77.mlp.down_proj.normalizer.norms.1', 'model.layers.77.mlp.down_proj.normalizer.zeros.0', 'model.layers.77.mlp.down_proj.normalizer.zeros.1', 'model.layers.78.self_attn.q_proj.bias', 'model.layers.78.self_attn.q_proj.codebook', 'model.layers.78.self_attn.q_proj.assignments', 'model.layers.78.self_attn.q_proj.normalizer.norms.0', 'model.layers.78.self_attn.q_proj.normalizer.norms.1', 'model.layers.78.self_attn.q_proj.normalizer.zeros.0', 'model.layers.78.self_attn.q_proj.normalizer.zeros.1', 'model.layers.78.self_attn.k_proj.bias', 'model.layers.78.self_attn.k_proj.codebook', 'model.layers.78.self_attn.k_proj.assignments', 'model.layers.78.self_attn.k_proj.normalizer.norms.0', 'model.layers.78.self_attn.k_proj.normalizer.norms.1', 'model.layers.78.self_attn.k_proj.normalizer.zeros.0', 'model.layers.78.self_attn.k_proj.normalizer.zeros.1', 'model.layers.78.self_attn.v_proj.bias', 'model.layers.78.self_attn.v_proj.codebook', 'model.layers.78.self_attn.v_proj.assignments', 'model.layers.78.self_attn.v_proj.normalizer.norms.0', 'model.layers.78.self_attn.v_proj.normalizer.norms.1', 'model.layers.78.self_attn.v_proj.normalizer.zeros.0', 'model.layers.78.self_attn.v_proj.normalizer.zeros.1', 'model.layers.78.self_attn.o_proj.bias', 'model.layers.78.self_attn.o_proj.codebook', 'model.layers.78.self_attn.o_proj.assignments', 'model.layers.78.self_attn.o_proj.normalizer.norms.0', 'model.layers.78.self_attn.o_proj.normalizer.norms.1', 'model.layers.78.self_attn.o_proj.normalizer.zeros.0', 'model.layers.78.self_attn.o_proj.normalizer.zeros.1', 'model.layers.78.mlp.gate_proj.bias', 'model.layers.78.mlp.gate_proj.codebook', 'model.layers.78.mlp.gate_proj.assignments', 'model.layers.78.mlp.gate_proj.normalizer.norms.0', 'model.layers.78.mlp.gate_proj.normalizer.norms.1', 'model.layers.78.mlp.gate_proj.normalizer.zeros.0', 'model.layers.78.mlp.gate_proj.normalizer.zeros.1', 'model.layers.78.mlp.up_proj.bias', 'model.layers.78.mlp.up_proj.codebook', 'model.layers.78.mlp.up_proj.assignments', 'model.layers.78.mlp.up_proj.normalizer.norms.0', 'model.layers.78.mlp.up_proj.normalizer.norms.1', 'model.layers.78.mlp.up_proj.normalizer.zeros.0', 'model.layers.78.mlp.up_proj.normalizer.zeros.1', 'model.layers.78.mlp.down_proj.bias', 'model.layers.78.mlp.down_proj.codebook', 'model.layers.78.mlp.down_proj.assignments', 'model.layers.78.mlp.down_proj.normalizer.norms.0', 'model.layers.78.mlp.down_proj.normalizer.norms.1', 'model.layers.78.mlp.down_proj.normalizer.zeros.0', 'model.layers.78.mlp.down_proj.normalizer.zeros.1', 'model.layers.79.self_attn.q_proj.bias', 'model.layers.79.self_attn.q_proj.codebook', 'model.layers.79.self_attn.q_proj.assignments', 'model.layers.79.self_attn.q_proj.normalizer.norms.0', 'model.layers.79.self_attn.q_proj.normalizer.norms.1', 'model.layers.79.self_attn.q_proj.normalizer.zeros.0', 'model.layers.79.self_attn.q_proj.normalizer.zeros.1', 'model.layers.79.self_attn.k_proj.bias', 'model.layers.79.self_attn.k_proj.codebook', 'model.layers.79.self_attn.k_proj.assignments', 'model.layers.79.self_attn.k_proj.normalizer.norms.0', 'model.layers.79.self_attn.k_proj.normalizer.norms.1', 'model.layers.79.self_attn.k_proj.normalizer.zeros.0', 'model.layers.79.self_attn.k_proj.normalizer.zeros.1', 'model.layers.79.self_attn.v_proj.bias', 'model.layers.79.self_attn.v_proj.codebook', 'model.layers.79.self_attn.v_proj.assignments', 'model.layers.79.self_attn.v_proj.normalizer.norms.0', 'model.layers.79.self_attn.v_proj.normalizer.norms.1', 'model.layers.79.self_attn.v_proj.normalizer.zeros.0', 'model.layers.79.self_attn.v_proj.normalizer.zeros.1', 'model.layers.79.self_attn.o_proj.bias', 'model.layers.79.self_attn.o_proj.codebook', 'model.layers.79.self_attn.o_proj.assignments', 'model.layers.79.self_attn.o_proj.normalizer.norms.0', 'model.layers.79.self_attn.o_proj.normalizer.norms.1', 'model.layers.79.self_attn.o_proj.normalizer.zeros.0', 'model.layers.79.self_attn.o_proj.normalizer.zeros.1', 'model.layers.79.mlp.gate_proj.bias', 'model.layers.79.mlp.gate_proj.codebook', 'model.layers.79.mlp.gate_proj.assignments', 'model.layers.79.mlp.gate_proj.normalizer.norms.0', 'model.layers.79.mlp.gate_proj.normalizer.norms.1', 'model.layers.79.mlp.gate_proj.normalizer.zeros.0', 'model.layers.79.mlp.gate_proj.normalizer.zeros.1', 'model.layers.79.mlp.up_proj.bias', 'model.layers.79.mlp.up_proj.codebook', 'model.layers.79.mlp.up_proj.assignments', 'model.layers.79.mlp.up_proj.normalizer.norms.0', 'model.layers.79.mlp.up_proj.normalizer.norms.1', 'model.layers.79.mlp.up_proj.normalizer.zeros.0', 'model.layers.79.mlp.up_proj.normalizer.zeros.1', 'model.layers.79.mlp.down_proj.bias', 'model.layers.79.mlp.down_proj.codebook', 'model.layers.79.mlp.down_proj.assignments', 'model.layers.79.mlp.down_proj.normalizer.norms.0', 'model.layers.79.mlp.down_proj.normalizer.norms.1', 'model.layers.79.mlp.down_proj.normalizer.zeros.0', 'model.layers.79.mlp.down_proj.normalizer.zeros.1'], unexpected_keys=['model.layers.0.self_attn.q_proj.weight', 'model.layers.0.self_attn.k_proj.weight', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.0.self_attn.o_proj.weight', 'model.layers.0.mlp.gate_proj.weight', 'model.layers.0.mlp.up_proj.weight', 'model.layers.0.mlp.down_proj.weight', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.1.self_attn.o_proj.weight', 'model.layers.1.mlp.gate_proj.weight', 'model.layers.1.mlp.up_proj.weight', 'model.layers.1.mlp.down_proj.weight', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.2.self_attn.o_proj.weight', 'model.layers.2.mlp.gate_proj.weight', 'model.layers.2.mlp.up_proj.weight', 'model.layers.2.mlp.down_proj.weight', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.3.self_attn.o_proj.weight', 'model.layers.3.mlp.gate_proj.weight', 'model.layers.3.mlp.up_proj.weight', 'model.layers.3.mlp.down_proj.weight', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.4.self_attn.o_proj.weight', 'model.layers.4.mlp.gate_proj.weight', 'model.layers.4.mlp.up_proj.weight', 'model.layers.4.mlp.down_proj.weight', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.5.self_attn.o_proj.weight', 'model.layers.5.mlp.gate_proj.weight', 'model.layers.5.mlp.up_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.6.self_attn.o_proj.weight', 'model.layers.6.mlp.gate_proj.weight', 'model.layers.6.mlp.up_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.7.self_attn.o_proj.weight', 'model.layers.7.mlp.gate_proj.weight', 'model.layers.7.mlp.up_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.8.self_attn.o_proj.weight', 'model.layers.8.mlp.gate_proj.weight', 'model.layers.8.mlp.up_proj.weight', 'model.layers.8.mlp.down_proj.weight', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.9.self_attn.v_proj.weight', 'model.layers.9.self_attn.o_proj.weight', 'model.layers.9.mlp.gate_proj.weight', 'model.layers.9.mlp.up_proj.weight', 'model.layers.9.mlp.down_proj.weight', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.10.self_attn.o_proj.weight', 'model.layers.10.mlp.gate_proj.weight', 'model.layers.10.mlp.up_proj.weight', 'model.layers.10.mlp.down_proj.weight', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.11.self_attn.o_proj.weight', 'model.layers.11.mlp.gate_proj.weight', 'model.layers.11.mlp.up_proj.weight', 'model.layers.11.mlp.down_proj.weight', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.12.self_attn.k_proj.weight', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.12.self_attn.o_proj.weight', 'model.layers.12.mlp.gate_proj.weight', 'model.layers.12.mlp.up_proj.weight', 'model.layers.12.mlp.down_proj.weight', 'model.layers.13.self_attn.q_proj.weight', 'model.layers.13.self_attn.k_proj.weight', 'model.layers.13.self_attn.v_proj.weight', 'model.layers.13.self_attn.o_proj.weight', 'model.layers.13.mlp.gate_proj.weight', 'model.layers.13.mlp.up_proj.weight', 'model.layers.13.mlp.down_proj.weight', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.14.self_attn.k_proj.weight', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.14.self_attn.o_proj.weight', 'model.layers.14.mlp.gate_proj.weight', 'model.layers.14.mlp.up_proj.weight', 'model.layers.14.mlp.down_proj.weight', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.15.self_attn.k_proj.weight', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.15.self_attn.o_proj.weight', 'model.layers.15.mlp.gate_proj.weight', 'model.layers.15.mlp.up_proj.weight', 'model.layers.15.mlp.down_proj.weight', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.16.self_attn.k_proj.weight', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.16.self_attn.o_proj.weight', 'model.layers.16.mlp.gate_proj.weight', 'model.layers.16.mlp.up_proj.weight', 'model.layers.16.mlp.down_proj.weight', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.17.self_attn.k_proj.weight', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.17.self_attn.o_proj.weight', 'model.layers.17.mlp.gate_proj.weight', 'model.layers.17.mlp.up_proj.weight', 'model.layers.17.mlp.down_proj.weight', 'model.layers.18.self_attn.q_proj.weight', 'model.layers.18.self_attn.k_proj.weight', 'model.layers.18.self_attn.v_proj.weight', 'model.layers.18.self_attn.o_proj.weight', 'model.layers.18.mlp.gate_proj.weight', 'model.layers.18.mlp.up_proj.weight', 'model.layers.18.mlp.down_proj.weight', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.19.self_attn.k_proj.weight', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.19.self_attn.o_proj.weight', 'model.layers.19.mlp.gate_proj.weight', 'model.layers.19.mlp.up_proj.weight', 'model.layers.19.mlp.down_proj.weight', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.20.self_attn.k_proj.weight', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.20.self_attn.o_proj.weight', 'model.layers.20.mlp.gate_proj.weight', 'model.layers.20.mlp.up_proj.weight', 'model.layers.20.mlp.down_proj.weight', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.21.self_attn.k_proj.weight', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.21.self_attn.o_proj.weight', 'model.layers.21.mlp.gate_proj.weight', 'model.layers.21.mlp.up_proj.weight', 'model.layers.21.mlp.down_proj.weight', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.22.self_attn.k_proj.weight', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.22.self_attn.o_proj.weight', 'model.layers.22.mlp.gate_proj.weight', 'model.layers.22.mlp.up_proj.weight', 'model.layers.22.mlp.down_proj.weight', 'model.layers.23.self_attn.q_proj.weight', 'model.layers.23.self_attn.k_proj.weight', 'model.layers.23.self_attn.v_proj.weight', 'model.layers.23.self_attn.o_proj.weight', 'model.layers.23.mlp.gate_proj.weight', 'model.layers.23.mlp.up_proj.weight', 'model.layers.23.mlp.down_proj.weight', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.24.self_attn.k_proj.weight', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.24.self_attn.o_proj.weight', 'model.layers.24.mlp.gate_proj.weight', 'model.layers.24.mlp.up_proj.weight', 'model.layers.24.mlp.down_proj.weight', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.25.self_attn.k_proj.weight', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.25.self_attn.o_proj.weight', 'model.layers.25.mlp.gate_proj.weight', 'model.layers.25.mlp.up_proj.weight', 'model.layers.25.mlp.down_proj.weight', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.26.self_attn.k_proj.weight', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.26.self_attn.o_proj.weight', 'model.layers.26.mlp.gate_proj.weight', 'model.layers.26.mlp.up_proj.weight', 'model.layers.26.mlp.down_proj.weight', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.27.self_attn.k_proj.weight', 'model.layers.27.self_attn.v_proj.weight', 'model.layers.27.self_attn.o_proj.weight', 'model.layers.27.mlp.gate_proj.weight', 'model.layers.27.mlp.up_proj.weight', 'model.layers.27.mlp.down_proj.weight', 'model.layers.28.self_attn.q_proj.weight', 'model.layers.28.self_attn.k_proj.weight', 'model.layers.28.self_attn.v_proj.weight', 'model.layers.28.self_attn.o_proj.weight', 'model.layers.28.mlp.gate_proj.weight', 'model.layers.28.mlp.up_proj.weight', 'model.layers.28.mlp.down_proj.weight', 'model.layers.29.self_attn.q_proj.weight', 'model.layers.29.self_attn.k_proj.weight', 'model.layers.29.self_attn.v_proj.weight', 'model.layers.29.self_attn.o_proj.weight', 'model.layers.29.mlp.gate_proj.weight', 'model.layers.29.mlp.up_proj.weight', 'model.layers.29.mlp.down_proj.weight', 'model.layers.30.self_attn.q_proj.weight', 'model.layers.30.self_attn.k_proj.weight', 'model.layers.30.self_attn.v_proj.weight', 'model.layers.30.self_attn.o_proj.weight', 'model.layers.30.mlp.gate_proj.weight', 'model.layers.30.mlp.up_proj.weight', 'model.layers.30.mlp.down_proj.weight', 'model.layers.31.self_attn.q_proj.weight', 'model.layers.31.self_attn.k_proj.weight', 'model.layers.31.self_attn.v_proj.weight', 'model.layers.31.self_attn.o_proj.weight', 'model.layers.31.mlp.gate_proj.weight', 'model.layers.31.mlp.up_proj.weight', 'model.layers.31.mlp.down_proj.weight', 'model.layers.32.self_attn.q_proj.weight', 'model.layers.32.self_attn.k_proj.weight', 'model.layers.32.self_attn.v_proj.weight', 'model.layers.32.self_attn.o_proj.weight', 'model.layers.32.mlp.gate_proj.weight', 'model.layers.32.mlp.up_proj.weight', 'model.layers.32.mlp.down_proj.weight', 'model.layers.33.self_attn.q_proj.weight', 'model.layers.33.self_attn.k_proj.weight', 'model.layers.33.self_attn.v_proj.weight', 'model.layers.33.self_attn.o_proj.weight', 'model.layers.33.mlp.gate_proj.weight', 'model.layers.33.mlp.up_proj.weight', 'model.layers.33.mlp.down_proj.weight', 'model.layers.34.self_attn.q_proj.weight', 'model.layers.34.self_attn.k_proj.weight', 'model.layers.34.self_attn.v_proj.weight', 'model.layers.34.self_attn.o_proj.weight', 'model.layers.34.mlp.gate_proj.weight', 'model.layers.34.mlp.up_proj.weight', 'model.layers.34.mlp.down_proj.weight', 'model.layers.35.self_attn.q_proj.weight', 'model.layers.35.self_attn.k_proj.weight', 'model.layers.35.self_attn.v_proj.weight', 'model.layers.35.self_attn.o_proj.weight', 'model.layers.35.mlp.gate_proj.weight', 'model.layers.35.mlp.up_proj.weight', 'model.layers.35.mlp.down_proj.weight', 'model.layers.36.self_attn.q_proj.weight', 'model.layers.36.self_attn.k_proj.weight', 'model.layers.36.self_attn.v_proj.weight', 'model.layers.36.self_attn.o_proj.weight', 'model.layers.36.mlp.gate_proj.weight', 'model.layers.36.mlp.up_proj.weight', 'model.layers.36.mlp.down_proj.weight', 'model.layers.37.self_attn.q_proj.weight', 'model.layers.37.self_attn.k_proj.weight', 'model.layers.37.self_attn.v_proj.weight', 'model.layers.37.self_attn.o_proj.weight', 'model.layers.37.mlp.gate_proj.weight', 'model.layers.37.mlp.up_proj.weight', 'model.layers.37.mlp.down_proj.weight', 'model.layers.38.self_attn.q_proj.weight', 'model.layers.38.self_attn.k_proj.weight', 'model.layers.38.self_attn.v_proj.weight', 'model.layers.38.self_attn.o_proj.weight', 'model.layers.38.mlp.gate_proj.weight', 'model.layers.38.mlp.up_proj.weight', 'model.layers.38.mlp.down_proj.weight', 'model.layers.39.self_attn.q_proj.weight', 'model.layers.39.self_attn.k_proj.weight', 'model.layers.39.self_attn.v_proj.weight', 'model.layers.39.self_attn.o_proj.weight', 'model.layers.39.mlp.gate_proj.weight', 'model.layers.39.mlp.up_proj.weight', 'model.layers.39.mlp.down_proj.weight', 'model.layers.40.self_attn.q_proj.weight', 'model.layers.40.self_attn.k_proj.weight', 'model.layers.40.self_attn.v_proj.weight', 'model.layers.40.self_attn.o_proj.weight', 'model.layers.40.mlp.gate_proj.weight', 'model.layers.40.mlp.up_proj.weight', 'model.layers.40.mlp.down_proj.weight', 'model.layers.41.self_attn.q_proj.weight', 'model.layers.41.self_attn.k_proj.weight', 'model.layers.41.self_attn.v_proj.weight', 'model.layers.41.self_attn.o_proj.weight', 'model.layers.41.mlp.gate_proj.weight', 'model.layers.41.mlp.up_proj.weight', 'model.layers.41.mlp.down_proj.weight', 'model.layers.42.self_attn.q_proj.weight', 'model.layers.42.self_attn.k_proj.weight', 'model.layers.42.self_attn.v_proj.weight', 'model.layers.42.self_attn.o_proj.weight', 'model.layers.42.mlp.gate_proj.weight', 'model.layers.42.mlp.up_proj.weight', 'model.layers.42.mlp.down_proj.weight', 'model.layers.43.self_attn.q_proj.weight', 'model.layers.43.self_attn.k_proj.weight', 'model.layers.43.self_attn.v_proj.weight', 'model.layers.43.self_attn.o_proj.weight', 'model.layers.43.mlp.gate_proj.weight', 'model.layers.43.mlp.up_proj.weight', 'model.layers.43.mlp.down_proj.weight', 'model.layers.44.self_attn.q_proj.weight', 'model.layers.44.self_attn.k_proj.weight', 'model.layers.44.self_attn.v_proj.weight', 'model.layers.44.self_attn.o_proj.weight', 'model.layers.44.mlp.gate_proj.weight', 'model.layers.44.mlp.up_proj.weight', 'model.layers.44.mlp.down_proj.weight', 'model.layers.45.self_attn.q_proj.weight', 'model.layers.45.self_attn.k_proj.weight', 'model.layers.45.self_attn.v_proj.weight', 'model.layers.45.self_attn.o_proj.weight', 'model.layers.45.mlp.gate_proj.weight', 'model.layers.45.mlp.up_proj.weight', 'model.layers.45.mlp.down_proj.weight', 'model.layers.46.self_attn.q_proj.weight', 'model.layers.46.self_attn.k_proj.weight', 'model.layers.46.self_attn.v_proj.weight', 'model.layers.46.self_attn.o_proj.weight', 'model.layers.46.mlp.gate_proj.weight', 'model.layers.46.mlp.up_proj.weight', 'model.layers.46.mlp.down_proj.weight', 'model.layers.47.self_attn.q_proj.weight', 'model.layers.47.self_attn.k_proj.weight', 'model.layers.47.self_attn.v_proj.weight', 'model.layers.47.self_attn.o_proj.weight', 'model.layers.47.mlp.gate_proj.weight', 'model.layers.47.mlp.up_proj.weight', 'model.layers.47.mlp.down_proj.weight', 'model.layers.48.self_attn.q_proj.weight', 'model.layers.48.self_attn.k_proj.weight', 'model.layers.48.self_attn.v_proj.weight', 'model.layers.48.self_attn.o_proj.weight', 'model.layers.48.mlp.gate_proj.weight', 'model.layers.48.mlp.up_proj.weight', 'model.layers.48.mlp.down_proj.weight', 'model.layers.49.self_attn.q_proj.weight', 'model.layers.49.self_attn.k_proj.weight', 'model.layers.49.self_attn.v_proj.weight', 'model.layers.49.self_attn.o_proj.weight', 'model.layers.49.mlp.gate_proj.weight', 'model.layers.49.mlp.up_proj.weight', 'model.layers.49.mlp.down_proj.weight', 'model.layers.50.self_attn.q_proj.weight', 'model.layers.50.self_attn.k_proj.weight', 'model.layers.50.self_attn.v_proj.weight', 'model.layers.50.self_attn.o_proj.weight', 'model.layers.50.mlp.gate_proj.weight', 'model.layers.50.mlp.up_proj.weight', 'model.layers.50.mlp.down_proj.weight', 'model.layers.51.self_attn.q_proj.weight', 'model.layers.51.self_attn.k_proj.weight', 'model.layers.51.self_attn.v_proj.weight', 'model.layers.51.self_attn.o_proj.weight', 'model.layers.51.mlp.gate_proj.weight', 'model.layers.51.mlp.up_proj.weight', 'model.layers.51.mlp.down_proj.weight', 'model.layers.52.self_attn.q_proj.weight', 'model.layers.52.self_attn.k_proj.weight', 'model.layers.52.self_attn.v_proj.weight', 'model.layers.52.self_attn.o_proj.weight', 'model.layers.52.mlp.gate_proj.weight', 'model.layers.52.mlp.up_proj.weight', 'model.layers.52.mlp.down_proj.weight', 'model.layers.53.self_attn.q_proj.weight', 'model.layers.53.self_attn.k_proj.weight', 'model.layers.53.self_attn.v_proj.weight', 'model.layers.53.self_attn.o_proj.weight', 'model.layers.53.mlp.gate_proj.weight', 'model.layers.53.mlp.up_proj.weight', 'model.layers.53.mlp.down_proj.weight', 'model.layers.54.self_attn.q_proj.weight', 'model.layers.54.self_attn.k_proj.weight', 'model.layers.54.self_attn.v_proj.weight', 'model.layers.54.self_attn.o_proj.weight', 'model.layers.54.mlp.gate_proj.weight', 'model.layers.54.mlp.up_proj.weight', 'model.layers.54.mlp.down_proj.weight', 'model.layers.55.self_attn.q_proj.weight', 'model.layers.55.self_attn.k_proj.weight', 'model.layers.55.self_attn.v_proj.weight', 'model.layers.55.self_attn.o_proj.weight', 'model.layers.55.mlp.gate_proj.weight', 'model.layers.55.mlp.up_proj.weight', 'model.layers.55.mlp.down_proj.weight', 'model.layers.56.self_attn.q_proj.weight', 'model.layers.56.self_attn.k_proj.weight', 'model.layers.56.self_attn.v_proj.weight', 'model.layers.56.self_attn.o_proj.weight', 'model.layers.56.mlp.gate_proj.weight', 'model.layers.56.mlp.up_proj.weight', 'model.layers.56.mlp.down_proj.weight', 'model.layers.57.self_attn.q_proj.weight', 'model.layers.57.self_attn.k_proj.weight', 'model.layers.57.self_attn.v_proj.weight', 'model.layers.57.self_attn.o_proj.weight', 'model.layers.57.mlp.gate_proj.weight', 'model.layers.57.mlp.up_proj.weight', 'model.layers.57.mlp.down_proj.weight', 'model.layers.58.self_attn.q_proj.weight', 'model.layers.58.self_attn.k_proj.weight', 'model.layers.58.self_attn.v_proj.weight', 'model.layers.58.self_attn.o_proj.weight', 'model.layers.58.mlp.gate_proj.weight', 'model.layers.58.mlp.up_proj.weight', 'model.layers.58.mlp.down_proj.weight', 'model.layers.59.self_attn.q_proj.weight', 'model.layers.59.self_attn.k_proj.weight', 'model.layers.59.self_attn.v_proj.weight', 'model.layers.59.self_attn.o_proj.weight', 'model.layers.59.mlp.gate_proj.weight', 'model.layers.59.mlp.up_proj.weight', 'model.layers.59.mlp.down_proj.weight', 'model.layers.60.self_attn.q_proj.weight', 'model.layers.60.self_attn.k_proj.weight', 'model.layers.60.self_attn.v_proj.weight', 'model.layers.60.self_attn.o_proj.weight', 'model.layers.60.mlp.gate_proj.weight', 'model.layers.60.mlp.up_proj.weight', 'model.layers.60.mlp.down_proj.weight', 'model.layers.61.self_attn.q_proj.weight', 'model.layers.61.self_attn.k_proj.weight', 'model.layers.61.self_attn.v_proj.weight', 'model.layers.61.self_attn.o_proj.weight', 'model.layers.61.mlp.gate_proj.weight', 'model.layers.61.mlp.up_proj.weight', 'model.layers.61.mlp.down_proj.weight', 'model.layers.62.self_attn.q_proj.weight', 'model.layers.62.self_attn.k_proj.weight', 'model.layers.62.self_attn.v_proj.weight', 'model.layers.62.self_attn.o_proj.weight', 'model.layers.62.mlp.gate_proj.weight', 'model.layers.62.mlp.up_proj.weight', 'model.layers.62.mlp.down_proj.weight', 'model.layers.63.self_attn.q_proj.weight', 'model.layers.63.self_attn.k_proj.weight', 'model.layers.63.self_attn.v_proj.weight', 'model.layers.63.self_attn.o_proj.weight', 'model.layers.63.mlp.gate_proj.weight', 'model.layers.63.mlp.up_proj.weight', 'model.layers.63.mlp.down_proj.weight', 'model.layers.64.self_attn.q_proj.weight', 'model.layers.64.self_attn.k_proj.weight', 'model.layers.64.self_attn.v_proj.weight', 'model.layers.64.self_attn.o_proj.weight', 'model.layers.64.mlp.gate_proj.weight', 'model.layers.64.mlp.up_proj.weight', 'model.layers.64.mlp.down_proj.weight', 'model.layers.65.self_attn.q_proj.weight', 'model.layers.65.self_attn.k_proj.weight', 'model.layers.65.self_attn.v_proj.weight', 'model.layers.65.self_attn.o_proj.weight', 'model.layers.65.mlp.gate_proj.weight', 'model.layers.65.mlp.up_proj.weight', 'model.layers.65.mlp.down_proj.weight', 'model.layers.66.self_attn.q_proj.weight', 'model.layers.66.self_attn.k_proj.weight', 'model.layers.66.self_attn.v_proj.weight', 'model.layers.66.self_attn.o_proj.weight', 'model.layers.66.mlp.gate_proj.weight', 'model.layers.66.mlp.up_proj.weight', 'model.layers.66.mlp.down_proj.weight', 'model.layers.67.self_attn.q_proj.weight', 'model.layers.67.self_attn.k_proj.weight', 'model.layers.67.self_attn.v_proj.weight', 'model.layers.67.self_attn.o_proj.weight', 'model.layers.67.mlp.gate_proj.weight', 'model.layers.67.mlp.up_proj.weight', 'model.layers.67.mlp.down_proj.weight', 'model.layers.68.self_attn.q_proj.weight', 'model.layers.68.self_attn.k_proj.weight', 'model.layers.68.self_attn.v_proj.weight', 'model.layers.68.self_attn.o_proj.weight', 'model.layers.68.mlp.gate_proj.weight', 'model.layers.68.mlp.up_proj.weight', 'model.layers.68.mlp.down_proj.weight', 'model.layers.69.self_attn.q_proj.weight', 'model.layers.69.self_attn.k_proj.weight', 'model.layers.69.self_attn.v_proj.weight', 'model.layers.69.self_attn.o_proj.weight', 'model.layers.69.mlp.gate_proj.weight', 'model.layers.69.mlp.up_proj.weight', 'model.layers.69.mlp.down_proj.weight', 'model.layers.70.self_attn.q_proj.weight', 'model.layers.70.self_attn.k_proj.weight', 'model.layers.70.self_attn.v_proj.weight', 'model.layers.70.self_attn.o_proj.weight', 'model.layers.70.mlp.gate_proj.weight', 'model.layers.70.mlp.up_proj.weight', 'model.layers.70.mlp.down_proj.weight', 'model.layers.71.self_attn.q_proj.weight', 'model.layers.71.self_attn.k_proj.weight', 'model.layers.71.self_attn.v_proj.weight', 'model.layers.71.self_attn.o_proj.weight', 'model.layers.71.mlp.gate_proj.weight', 'model.layers.71.mlp.up_proj.weight', 'model.layers.71.mlp.down_proj.weight', 'model.layers.72.self_attn.q_proj.weight', 'model.layers.72.self_attn.k_proj.weight', 'model.layers.72.self_attn.v_proj.weight', 'model.layers.72.self_attn.o_proj.weight', 'model.layers.72.mlp.gate_proj.weight', 'model.layers.72.mlp.up_proj.weight', 'model.layers.72.mlp.down_proj.weight', 'model.layers.73.self_attn.q_proj.weight', 'model.layers.73.self_attn.k_proj.weight', 'model.layers.73.self_attn.v_proj.weight', 'model.layers.73.self_attn.o_proj.weight', 'model.layers.73.mlp.gate_proj.weight', 'model.layers.73.mlp.up_proj.weight', 'model.layers.73.mlp.down_proj.weight', 'model.layers.74.self_attn.q_proj.weight', 'model.layers.74.self_attn.k_proj.weight', 'model.layers.74.self_attn.v_proj.weight', 'model.layers.74.self_attn.o_proj.weight', 'model.layers.74.mlp.gate_proj.weight', 'model.layers.74.mlp.up_proj.weight', 'model.layers.74.mlp.down_proj.weight', 'model.layers.75.self_attn.q_proj.weight', 'model.layers.75.self_attn.k_proj.weight', 'model.layers.75.self_attn.v_proj.weight', 'model.layers.75.self_attn.o_proj.weight', 'model.layers.75.mlp.gate_proj.weight', 'model.layers.75.mlp.up_proj.weight', 'model.layers.75.mlp.down_proj.weight', 'model.layers.76.self_attn.q_proj.weight', 'model.layers.76.self_attn.k_proj.weight', 'model.layers.76.self_attn.v_proj.weight', 'model.layers.76.self_attn.o_proj.weight', 'model.layers.76.mlp.gate_proj.weight', 'model.layers.76.mlp.up_proj.weight', 'model.layers.76.mlp.down_proj.weight', 'model.layers.77.self_attn.q_proj.weight', 'model.layers.77.self_attn.k_proj.weight', 'model.layers.77.self_attn.v_proj.weight', 'model.layers.77.self_attn.o_proj.weight', 'model.layers.77.mlp.gate_proj.weight', 'model.layers.77.mlp.up_proj.weight', 'model.layers.77.mlp.down_proj.weight', 'model.layers.78.self_attn.q_proj.weight', 'model.layers.78.self_attn.k_proj.weight', 'model.layers.78.self_attn.v_proj.weight', 'model.layers.78.self_attn.o_proj.weight', 'model.layers.78.mlp.gate_proj.weight', 'model.layers.78.mlp.up_proj.weight', 'model.layers.78.mlp.down_proj.weight', 'model.layers.79.self_attn.q_proj.weight', 'model.layers.79.self_attn.k_proj.weight', 'model.layers.79.self_attn.v_proj.weight', 'model.layers.79.self_attn.o_proj.weight', 'model.layers.79.mlp.gate_proj.weight', 'model.layers.79.mlp.up_proj.weight', 'model.layers.79.mlp.down_proj.weight'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LlamaForCausalLM(orig_config)\n",
    "model.to(orig_config.torch_dtype)\n",
    "#iterate through all parameters and assert that they are fp16\n",
    "for name, param in model.named_parameters():\n",
    "    assert param.dtype == torch.float16, f\"{name} is not fp16, it is {param.dtype}\"\n",
    "model.load_state_dict(orig_model.state_dict(), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta-llama/Llama-2-70b-hf/layer_0/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_0/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_0/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_0/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_0/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_0/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_0/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_1/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_1/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_1/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_1/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_1/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_1/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_1/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_10/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_10/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_10/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_10/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_10/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_10/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_10/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_11/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_11/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_11/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_11/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_11/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_11/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_11/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_12/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_12/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_12/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_12/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_12/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_12/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_12/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_13/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_13/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_13/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_13/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_13/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_13/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_13/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_14/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_14/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_14/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_14/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_14/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_14/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_14/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_15/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_15/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_15/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_15/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_15/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_15/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_15/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_16/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_16/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_16/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_16/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_16/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_16/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_16/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_17/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_17/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_17/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_17/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_17/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_17/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_17/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_18/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_18/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_18/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_18/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_18/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_18/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_18/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_19/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_19/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_19/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_19/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_19/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_19/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_19/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_2/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_2/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_2/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_2/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_2/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_2/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_2/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_20/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_20/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_20/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_20/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_20/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_20/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_20/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_21/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_21/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_21/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_21/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_21/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_21/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_21/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_22/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_22/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_22/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_22/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_22/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_22/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_22/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_23/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_23/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_23/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_23/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_23/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_23/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_23/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_24/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_24/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_24/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_24/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_24/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_24/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_24/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_25/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_25/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_25/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_25/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_25/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_25/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_25/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_26/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_26/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_26/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_26/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_26/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_26/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_26/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_27/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_27/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_27/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_27/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_27/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_27/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_27/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_28/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_28/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_28/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_28/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_28/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_28/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_28/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_29/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_29/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_29/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_29/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_29/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_29/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_29/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_3/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_3/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_3/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_3/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_3/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_3/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_3/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_30/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_30/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_30/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_30/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_30/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_30/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_30/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_31/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_31/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_31/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_31/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_31/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_31/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_31/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_32/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_32/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_32/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_32/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_32/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_32/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_32/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_33/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_33/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_33/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_33/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_33/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_33/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_33/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_34/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_34/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_34/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_34/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_34/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_34/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_34/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_35/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_35/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_35/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_35/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_35/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_35/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_35/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_36/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_36/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_36/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_36/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_36/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_36/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_36/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_37/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_37/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_37/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_37/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_37/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_37/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_37/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_38/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_38/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_38/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_38/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_38/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_38/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_38/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_39/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_39/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_39/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_39/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_39/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_39/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_39/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_4/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_4/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_4/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_4/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_4/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_4/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_4/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_40/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_40/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_40/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_40/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_40/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_40/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_40/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_41/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_41/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_41/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_41/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_41/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_41/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_41/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_42/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_42/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_42/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_42/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_42/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_42/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_42/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_43/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_43/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_43/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_43/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_43/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_43/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_43/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_44/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_44/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_44/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_44/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_44/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_44/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_44/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_45/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_45/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_45/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_45/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_45/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_45/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_45/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_46/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_46/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_46/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_46/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_46/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_46/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_46/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_47/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_47/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_47/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_47/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_47/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_47/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_47/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_48/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_48/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_48/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_48/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_48/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_48/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_48/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_49/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_49/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_49/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_49/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_49/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_49/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_49/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_5/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_5/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_5/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_5/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_5/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_5/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_5/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_50/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_50/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_50/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_50/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_50/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_50/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_50/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_51/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_51/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_51/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_51/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_51/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_51/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_51/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_52/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_52/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_52/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_52/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_52/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_52/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_52/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_53/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_53/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_53/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_53/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_53/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_53/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_53/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_54/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_54/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_54/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_54/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_54/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_54/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_54/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_55/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_55/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_55/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_55/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_55/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_55/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_55/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_56/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_56/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_56/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_56/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_56/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_56/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_56/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_57/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_57/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_57/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_57/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_57/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_57/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_57/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_58/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_58/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_58/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_58/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_58/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_58/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_58/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_59/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_59/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_59/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_59/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_59/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_59/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_59/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_6/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_6/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_6/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_6/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_6/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_6/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_6/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_60/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_60/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_60/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_60/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_60/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_60/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_60/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_61/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_61/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_61/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_61/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_61/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_61/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_61/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_62/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_62/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_62/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_62/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_62/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_62/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_62/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_63/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_63/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_63/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_63/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_63/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_63/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_63/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_64/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_64/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_64/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_64/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_64/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_64/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_64/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_65/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_65/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_65/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_65/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_65/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_65/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_65/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_66/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_66/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_66/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_66/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_66/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_66/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_66/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_67/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_67/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_67/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_67/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_67/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_67/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_67/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_68/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_68/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_68/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_68/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_68/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_68/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_68/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_69/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_69/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_69/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_69/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_69/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_69/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_69/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_7/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_7/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_7/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_7/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_7/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_7/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_7/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_70/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_70/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_70/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_70/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_70/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_70/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_70/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_71/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_71/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_71/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_71/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_71/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_71/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_71/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_72/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_72/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_72/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_72/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_72/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_72/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_72/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_73/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_73/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_73/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_73/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_73/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_73/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_73/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_74/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_74/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_74/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_74/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_74/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_74/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_74/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_75/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_75/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_75/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_75/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_75/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_75/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_75/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_76/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_76/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_76/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_76/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_76/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_76/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_76/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_77/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_77/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_77/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_77/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_77/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_77/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_77/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_78/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_78/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_78/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_78/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_78/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_78/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_78/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_79/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_79/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_79/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_79/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_79/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_79/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_79/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_8/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_8/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_8/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_8/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_8/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_8/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_8/self_attn.v_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_9/mlp.down_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_9/mlp.gate_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_9/mlp.up_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_9/self_attn.k_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_9/self_attn.o_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_9/self_attn.q_proj\n",
      "torch.float16 cpu\n",
      "meta-llama/Llama-2-70b-hf/layer_9/self_attn.v_proj\n",
      "torch.float16 cpu\n"
     ]
    }
   ],
   "source": [
    "#for each checkpoint, load the right weight\n",
    "for checkpoint_name,checkpoint_path in checkpoints_dict.items():\n",
    "    print(checkpoint_name)\n",
    "    #first remove the base_model name from it\n",
    "    checkpoint_name = checkpoint_name.replace(base_model, \"\")\n",
    "    #now split by /\n",
    "    checkpoint_name = checkpoint_name.split(\"/\")[-2:]\n",
    "    #from the first part, we can get which layer it is\n",
    "    i_layer = int(checkpoint_name[0].replace(\"layer_\", \"\"))\n",
    "    #from the second part we can get which module (self_attn, mlp, etc) and which layer it is\n",
    "    submodule_name, linear_name = checkpoint_name[1].split(\".\")\n",
    "    \n",
    "    #now we get the right module\n",
    "    layer = getattr(getattr(model.model.layers[i_layer], submodule_name), linear_name)\n",
    "    #record the original dtype\n",
    "    orig_dtype = layer.codebook.dtype\n",
    "    orig_device = layer.codebook.device\n",
    "    print(orig_dtype, orig_device)\n",
    "    #load the state dict\n",
    "    layer.load_state_dict(torch.load(checkpoint_path, map_location=orig_device), strict=False)\n",
    "    #convert to the right dtype\n",
    "    layer.to(orig_dtype)\n",
    "    # raise ValueError(\"stop here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate through all parameters and assert that they are fp16\n",
    "for name, param in model.named_parameters():\n",
    "    assert param.dtype == torch.float16, f\"{name} is not fp16, it is {param.dtype}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67ae00976a2d4096b8ad3aeb21e75490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_model = OrigLlama.from_pretrained(base_model, device_map=\"cpu\", torch_dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'float16'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.torch_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "model.save_pretrained(hf_model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.layers[0].self_attn.q_proj.reconstruct().dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n",
      "device None dtype torch.float16\n",
      "kwargs {'d': 6, 'ignore_norms': True, 'initialize_kwargs': {'deterministic': False, 'multiple_each_time': 1.0}, 'initialize_method': 'kmeans++', 'n_bits': 2, 'n_inits': 1, 'n_iters': 100, 'normalizer_kwargs': {'norm_order': [0, 1], 'p': 2, 'zero': [False, False]}}\n",
      "codebook shape:  torch.Size([4096, 6]) device:  meta dtype:  torch.float16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.66it/s]\n"
     ]
    }
   ],
   "source": [
    "#try to load the model\n",
    "loaded_model = LlamaForCausalLM.from_pretrained(hf_model_save_path,\n",
    "                                                torch_dtype = 'auto',\n",
    "                                                low_cpu_mem_usage=True,\n",
    "                                                attn_implementation='sdpa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.model.layers[0].self_attn.q_proj.reconstruct().dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2513,  0.5720,  0.5787,  ...,  0.3616, -0.9614,  0.5276]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1, 1, 4096).cpu()\n",
    "loaded_model.model.layers[0].self_attn.q_proj(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2513,  0.5720,  0.5787,  ...,  0.3616, -0.9614,  0.5276]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.model.layers[0].self_attn.q_proj.cache_reconstruct()\n",
    "loaded_model.model.layers[0].self_attn.q_proj(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.02it/s]\n"
     ]
    }
   ],
   "source": [
    "original_model = OrigLlama.from_pretrained(base_model, device_map=\"cpu\", torch_dtype=\"auto\",\n",
    "                                             attn_implementation='sdpa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try to save the model to a temp dir\n",
    "temp_dir = \"/data/lliu/huffman/temp/Llama-2-7b-hf/\"\n",
    "original_model.save_pretrained(temp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n"
     ]
    }
   ],
   "source": [
    "loaded_orig_llama = OrigLlama.from_pretrained(temp_dir, device_map=\"cpu\", torch_dtype=\"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_orig_llama.model.layers[0].self_attn.q_proj.weight.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate through all parameters and assert that they are fp16\n",
    "for name, param in loaded_orig_llama.named_parameters():\n",
    "    assert param.dtype == torch.float16, f\"{name} is not fp16, it is {param.dtype}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NoWAC-VQ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
