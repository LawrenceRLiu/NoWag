Namespace(models_to_compress=['meta-llama/Llama-2-7b-hf'], seqlens=[4096], batch_size=1, hessian_path='/data/lliu/huffman/models/{model_name}/hessians_new/seed_0/pajama/128', discrete_update_hessian_path='/data/lliu/huffman/models/{model_name}/hessians_new/seed_42/pajama/128', weights_path='/data/lliu/huffman/models/{model_name}/original_weights', save_path='/data/lliu/huffman/models/{model_name}/compressed', self_attn_compression_algorithm='quantize', mlp_compression_algorithm='quantize', devices=['cuda:6', 'cuda:5', 'cuda:4', 'cuda:3', 'cuda:2'], yaml_path='/data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml', self_attn_yaml_path=None, mlp_yaml_path=None, use_already_done=False, use_wandb=True, resume_wandb=True, wandb_id='g87eipl0', wandb_project='compression_no_finetune', ppl_eval=True)
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: m6481. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /data/lliu/huffman/wandb/run-20250107_171357-g87eipl0
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run desert-galaxy-76
wandb: ‚≠êÔ∏è View project at https://wandb.ai/m6481/compression_no_finetune
wandb: üöÄ View run at https://wandb.ai/m6481/compression_no_finetune/runs/g87eipl0
  0%|          | 0/224 [00:00<?, ?it/s]path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_3/mlp.gate_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_3/mlp.gate_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_3/mlp.gate_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_3/mlp.gate_proj/compressed.log
best_loss 36.851314544677734 running bpv: 2.005723
already done with  meta-llama/Llama-2-7b-hf/layer_3/mlp.gate_proj
path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_3/mlp.up_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_3/mlp.up_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_3/mlp.up_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_3/mlp.up_proj/compressed.log
best_loss 31.452659606933594 running bpv: 2.005723
already done with  meta-llama/Llama-2-7b-hf/layer_3/mlp.up_proj
path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_3/self_attn.q_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_3/self_attn.q_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_3/self_attn.q_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_3/self_attn.q_proj/compressed.log
best_loss 83.00355529785156 running bpv: 2.006204
already done with  meta-llama/Llama-2-7b-hf/layer_3/self_attn.q_proj
path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_3/self_attn.k_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_3/self_attn.k_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_3/self_attn.k_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_3/self_attn.k_proj/compressed.log
best_loss 92.5238037109375 running bpv: 2.006555
already done with  meta-llama/Llama-2-7b-hf/layer_3/self_attn.k_proj
path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_3/self_attn.o_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_3/self_attn.o_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_3/self_attn.o_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_3/self_attn.o_proj/compressed.log
best_loss 0.21167629957199097 running bpv: 2.006821
already done with  meta-llama/Llama-2-7b-hf/layer_3/self_attn.o_proj
path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_3/mlp.down_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_3/mlp.down_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_3/mlp.down_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_3/mlp.down_proj/compressed.log
best_loss 0.8072618246078491 running bpv: 2.006555
already done with  meta-llama/Llama-2-7b-hf/layer_3/mlp.down_proj
path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_3/self_attn.v_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_3/self_attn.v_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_3/self_attn.v_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_3/self_attn.v_proj/compressed.log
best_loss 22.92733383178711 running bpv: 2.00674
already done with  meta-llama/Llama-2-7b-hf/layer_3/self_attn.v_proj
path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_5/mlp.gate_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_5/mlp.gate_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_5/mlp.gate_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_5/mlp.gate_proj/compressed.log
best_loss 68.33273315429688 running bpv: 2.006555
already done with  meta-llama/Llama-2-7b-hf/layer_5/mlp.gate_proj
path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_5/mlp.up_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_5/mlp.up_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_5/mlp.up_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_5/mlp.up_proj/compressed.log
best_loss 54.48064041137695 running bpv: 2.006426
already done with  meta-llama/Llama-2-7b-hf/layer_5/mlp.up_proj
path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_5/self_attn.q_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_5/self_attn.q_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_5/self_attn.q_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_5/self_attn.q_proj/compressed.log
best_loss 95.58329010009766 running bpv: 2.006555
already done with  meta-llama/Llama-2-7b-hf/layer_5/self_attn.q_proj
path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_5/self_attn.k_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_5/self_attn.k_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_5/self_attn.k_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_5/self_attn.k_proj/compressed.log
best_loss 106.54869079589844 running bpv: 2.00667
already done with  meta-llama/Llama-2-7b-hf/layer_5/self_attn.k_proj
path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_5/self_attn.o_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_5/self_attn.o_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_5/self_attn.o_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_5/self_attn.o_proj/compressed.log
best_loss 0.7277671098709106 running bpv: 2.006773
already done with  meta-llama/Llama-2-7b-hf/layer_5/self_attn.o_proj
path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_5/mlp.down_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_5/mlp.down_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_5/mlp.down_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_5/mlp.down_proj/compressed.log
best_loss 2.1368637084960938 running bpv: 2.006651
already done with  meta-llama/Llama-2-7b-hf/layer_5/mlp.down_proj
path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_5/self_attn.v_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_5/self_attn.v_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_5/self_attn.v_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_5/self_attn.v_proj/compressed.log
best_loss 28.365232467651367 running bpv: 2.00674
already done with  meta-llama/Llama-2-7b-hf/layer_5/self_attn.v_proj
path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_8/mlp.gate_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_8/mlp.gate_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_8/mlp.gate_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_8/mlp.gate_proj/compressed.log
best_loss 106.67100524902344 running bpv: 2.006638
already done with  meta-llama/Llama-2-7b-hf/layer_8/mlp.gate_proj
path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_8/mlp.up_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_8/mlp.up_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_8/mlp.up_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_8/mlp.up_proj/compressed.log
best_loss 87.48828887939453 running bpv: 2.006555
already done with  meta-llama/Llama-2-7b-hf/layer_8/mlp.up_proj
path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_8/self_attn.q_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_8/self_attn.q_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_8/self_attn.q_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_8/self_attn.q_proj/compressed.log
best_loss 155.6551055908203 running bpv: 2.006628
already done with  meta-llama/Llama-2-7b-hf/layer_8/self_attn.q_proj
path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_8/self_attn.k_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_8/self_attn.k_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_8/self_attn.k_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_8/self_attn.k_proj/compressed.log
best_loss 158.32089233398438 running bpv: 2.006696
  8%|‚ñä         | 18/224 [00:00<00:01, 172.78it/s]already done with  meta-llama/Llama-2-7b-hf/layer_8/self_attn.k_proj
path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_8/self_attn.o_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_8/self_attn.o_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_8/self_attn.o_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_8/self_attn.o_proj/compressed.log
best_loss 2.4172372817993164 running bpv: 2.006761
already done with  meta-llama/Llama-2-7b-hf/layer_8/self_attn.o_proj
path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_8/mlp.down_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_8/mlp.down_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_8/mlp.down_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_8/mlp.down_proj/compressed.log
best_loss 5.041171073913574 running bpv: 2.006682
already done with  meta-llama/Llama-2-7b-hf/layer_8/mlp.down_proj
path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_8/self_attn.v_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_8/self_attn.v_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_8/self_attn.v_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_8/self_attn.v_proj/compressed.log
best_loss 47.56711196899414 running bpv: 2.00674
already done with  meta-llama/Llama-2-7b-hf/layer_8/self_attn.v_proj
path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_12/mlp.gate_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_12/mlp.gate_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_12/mlp.gate_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_12/mlp.gate_proj/compressed.log
best_loss 135.95762634277344 running bpv: 2.00667
already done with  meta-llama/Llama-2-7b-hf/layer_12/mlp.gate_proj
path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_12/mlp.up_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_12/mlp.up_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_12/mlp.up_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_12/mlp.up_proj/compressed.log
best_loss 125.14822387695312 running bpv: 2.006608
already done with  meta-llama/Llama-2-7b-hf/layer_12/mlp.up_proj
path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_12/self_attn.q_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_12/self_attn.q_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_12/self_attn.q_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_12/self_attn.q_proj/compressed.log
best_loss 203.02130126953125 running bpv: 2.00666
already done with  meta-llama/Llama-2-7b-hf/layer_12/self_attn.q_proj
path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_12/self_attn.k_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_12/self_attn.k_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_12/self_attn.k_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_12/self_attn.k_proj/compressed.log
best_loss 217.55514526367188 running bpv: 2.006708
already done with  meta-llama/Llama-2-7b-hf/layer_12/self_attn.k_proj
path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_12/self_attn.o_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_12/self_attn.o_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_12/self_attn.o_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_12/self_attn.o_proj/compressed.log
best_loss 5.171182632446289 running bpv: 2.006755
already done with  meta-llama/Llama-2-7b-hf/layer_12/self_attn.o_proj
path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_12/mlp.down_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_12/mlp.down_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_12/mlp.down_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_12/mlp.down_proj/compressed.log
best_loss 8.992213249206543 running bpv: 2.006696
already done with  meta-llama/Llama-2-7b-hf/layer_12/mlp.down_proj
path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_12/self_attn.v_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_12/self_attn.v_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_12/self_attn.v_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_12/self_attn.v_proj/compressed.log
best_loss 71.64300537109375 running bpv: 2.00674
already done with  meta-llama/Llama-2-7b-hf/layer_12/self_attn.v_proj
path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_1/mlp.gate_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_1/mlp.gate_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_1/mlp.gate_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_1/mlp.gate_proj/compressed.log
best_loss 7.807470321655273 running bpv: 2.006686
already done with  meta-llama/Llama-2-7b-hf/layer_1/mlp.gate_proj
path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_1/mlp.up_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_1/mlp.up_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_1/mlp.up_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_1/mlp.up_proj/compressed.log
best_loss 6.786705017089844 running bpv: 2.006638
already done with  meta-llama/Llama-2-7b-hf/layer_1/mlp.up_proj
path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_1/self_attn.q_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_1/self_attn.q_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_1/self_attn.q_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_1/self_attn.q_proj/compressed.log
best_loss 3.7910776138305664 running bpv: 2.006677
already done with  meta-llama/Llama-2-7b-hf/layer_1/self_attn.q_proj
path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_1/self_attn.k_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_1/self_attn.k_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_1/self_attn.k_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_1/self_attn.k_proj/compressed.log
best_loss 3.8073854446411133 running bpv: 2.006715
already done with  meta-llama/Llama-2-7b-hf/layer_1/self_attn.k_proj
path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_1/self_attn.o_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_1/self_attn.o_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_1/self_attn.o_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_1/self_attn.o_proj/compressed.log
best_loss 0.046175505965948105 running bpv: 2.006752
already done with  meta-llama/Llama-2-7b-hf/layer_1/self_attn.o_proj
path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_1/mlp.down_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_1/mlp.down_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_1/mlp.down_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_1/mlp.down_proj/compressed.log
best_loss 0.1719738394021988 running bpv: 2.006705
already done with  meta-llama/Llama-2-7b-hf/layer_1/mlp.down_proj
path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_1/self_attn.v_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_1/self_attn.v_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_1/self_attn.v_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_1/self_attn.v_proj/compressed.log
best_loss 0.36653316020965576 running bpv: 2.00674
already done with  meta-llama/Llama-2-7b-hf/layer_1/self_attn.v_proj
path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_7/mlp.gate_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_7/mlp.gate_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_7/mlp.gate_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_7/mlp.gate_proj/compressed.log
best_loss 103.07699584960938 running bpv: 2.006696
 16%|‚ñà‚ñå        | 36/224 [00:00<00:01, 174.63it/s]already done with  meta-llama/Llama-2-7b-hf/layer_7/mlp.gate_proj
path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_7/self_attn.q_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_7/self_attn.q_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_7/self_attn.q_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_7/self_attn.q_proj/compressed.log
best_loss 159.08236694335938 running bpv: 2.006729
already done with  meta-llama/Llama-2-7b-hf/layer_7/self_attn.q_proj
path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_7/self_attn.k_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_7/self_attn.k_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_7/self_attn.k_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_7/self_attn.k_proj/compressed.log
best_loss 161.68557739257812 running bpv: 2.006761
already done with  meta-llama/Llama-2-7b-hf/layer_7/self_attn.k_proj
path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_7/self_attn.o_proj/compressed_args.yaml
yaml_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
other_args {'alignment_kwargs': {'clip_grad': 0.1, 'discrete_update_every': 1, 'eps': 0.001, 'low_bound': 1e-05, 'lr': 0.001, 'lr_multiplier': 0.333333, 'n_iters': 100, 'patience': 10, 'patience_scheduler': 1000, 'reinitailize_optimizer': False, 'verbose': 1}, 'compression_type': 'quantized', 'quantizer_kwargs': {'cluster_ignore_norms': True, 'd': 4, 'initialize_method': 'kmeans', 'n_bits': 2, 'n_iters': 100, 'norm_order': [0, 1], 'zero': [False, False]}, 'quantizer_type': '1st_order', 'seed': 0}
is_same True
already done with  meta-llama/Llama-2-7b-hf/layer_7/self_attn.o_proj
loading from /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_7/self_attn.o_proj/compressed.pt
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_7/self_attn.o_proj/compressed.log
best_loss 1.5186851024627686 running bpv: 2.006792
already done with  meta-llama/Llama-2-7b-hf/layer_7/self_attn.o_proj
n_commands 185
sample command python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_7/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_7/mlp.up_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_7/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_7/mlp.up_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_7/mlp.up_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_7/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_7/mlp.down_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_7/mlp.down_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_7/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_7/self_attn.v_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_7/self_attn.v_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_0/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_0/mlp.gate_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_0/mlp.gate_proj/compressed.log 2>&1 &
 17%|‚ñà‚ñã        | 39/224 [00:20<00:01, 174.63it/s]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_0/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_0/mlp.up_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_0/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_7/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_7/self_attn.v_proj/compressed.log
best_loss 46.58490753173828 running bpv: 2.006821
 18%|‚ñà‚ñä        | 40/224 [02:25<17:30,  5.71s/it] COMMANDS_FINISHED 1 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_0/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_0/self_attn.q_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_0/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_0/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_0/self_attn.q_proj/compressed.log
best_loss 0.12953819334506989 running bpv: 2.00685
 18%|‚ñà‚ñä        | 41/224 [04:10<33:32, 10.99s/it]COMMANDS_FINISHED 2 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_0/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_0/self_attn.k_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_0/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_7/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_7/mlp.down_proj/compressed.log
best_loss 4.137826919555664 running bpv: 2.006807
 19%|‚ñà‚ñâ        | 42/224 [04:35<36:21, 11.98s/it]COMMANDS_FINISHED 3 n_commands 185
meta-llama/Llama-2-7b-hf/layer_0/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_0/mlp.up_proj/compressed.log
best_loss 1.7601529359817505 running bpv: 2.006768
COMMANDS_FINISHED 4 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_0/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_0/self_attn.o_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_0/self_attn.o_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_0/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_0/mlp.down_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_0/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_0/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_0/mlp.gate_proj/compressed.log
best_loss 1.8431870937347412 running bpv: 2.006731
 20%|‚ñà‚ñâ        | 44/224 [04:55<34:57, 11.65s/it]COMMANDS_FINISHED 5 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_0/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_0/self_attn.v_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_0/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_7/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_7/mlp.up_proj/compressed.log
best_loss 79.53524017333984 running bpv: 2.006696
 20%|‚ñà‚ñà        | 45/224 [05:20<39:01, 13.08s/it]COMMANDS_FINISHED 6 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_31/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_31/mlp.gate_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_31/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_0/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_0/self_attn.o_proj/compressed.log
best_loss 0.003017761744558811 running bpv: 2.006723
 21%|‚ñà‚ñà        | 46/224 [05:45<43:30, 14.67s/it]COMMANDS_FINISHED 7 n_commands 185
meta-llama/Llama-2-7b-hf/layer_0/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_0/self_attn.k_proj/compressed.log
best_loss 0.10760671645402908 running bpv: 2.006748
COMMANDS_FINISHED 8 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_31/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_31/mlp.up_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_31/mlp.up_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_31/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_31/self_attn.q_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_31/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_0/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_0/self_attn.v_proj/compressed.log
best_loss 0.03134968504309654 running bpv: 2.006773
 21%|‚ñà‚ñà‚ñè       | 48/224 [06:15<43:17, 14.76s/it]COMMANDS_FINISHED 9 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_31/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_31/self_attn.k_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_31/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_0/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_0/mlp.down_proj/compressed.log
best_loss 0.018090246245265007 running bpv: 2.00674
 22%|‚ñà‚ñà‚ñè       | 49/224 [06:50<52:44, 18.08s/it]COMMANDS_FINISHED 10 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_31/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_31/self_attn.o_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_31/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_31/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_31/self_attn.q_proj/compressed.log
best_loss 218.38340759277344 running bpv: 2.006764
 22%|‚ñà‚ñà‚ñè       | 50/224 [08:35<1:40:19, 34.59s/it]COMMANDS_FINISHED 11 n_commands 185
meta-llama/Llama-2-7b-hf/layer_31/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_31/self_attn.o_proj/compressed.log
best_loss 59.54880142211914 running bpv: 2.006787
COMMANDS_FINISHED 12 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_31/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_31/mlp.down_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_31/mlp.down_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_31/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_31/self_attn.v_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_31/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_31/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_31/self_attn.k_proj/compressed.log
best_loss 238.5161590576172 running bpv: 2.00681
 23%|‚ñà‚ñà‚ñé       | 52/224 [09:05<1:19:25, 27.70s/it]COMMANDS_FINISHED 13 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_21/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_21/mlp.gate_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_21/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_31/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_31/self_attn.v_proj/compressed.log
best_loss 166.25665283203125 running bpv: 2.006832
 24%|‚ñà‚ñà‚ñé       | 53/224 [11:10<2:14:39, 47.25s/it]COMMANDS_FINISHED 14 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_21/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_21/mlp.up_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_21/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_31/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_31/mlp.gate_proj/compressed.log
best_loss 464.2099609375 running bpv: 2.0068
 24%|‚ñà‚ñà‚ñç       | 54/224 [12:15<2:25:05, 51.21s/it]COMMANDS_FINISHED 15 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_21/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_21/self_attn.q_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_21/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_31/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_31/mlp.up_proj/compressed.log
best_loss 413.3924560546875 running bpv: 2.006769
 25%|‚ñà‚ñà‚ñç       | 55/224 [12:40<2:06:24, 44.88s/it]COMMANDS_FINISHED 16 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_21/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_21/self_attn.k_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_21/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_21/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_21/self_attn.q_proj/compressed.log
best_loss 270.81390380859375 running bpv: 2.00679
 25%|‚ñà‚ñà‚ñå       | 56/224 [15:05<3:17:35, 70.57s/it]COMMANDS_FINISHED 17 n_commands 185
meta-llama/Llama-2-7b-hf/layer_21/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_21/mlp.gate_proj/compressed.log
best_loss 348.98333740234375 running bpv: 2.006761
COMMANDS_FINISHED 18 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_21/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_21/self_attn.o_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_21/self_attn.o_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_21/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_21/mlp.down_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_21/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_21/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_21/self_attn.k_proj/compressed.log
best_loss 279.6807556152344 running bpv: 2.006781
 26%|‚ñà‚ñà‚ñå       | 58/224 [15:25<2:04:22, 44.95s/it]COMMANDS_FINISHED 19 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_21/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_21/self_attn.v_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_21/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_31/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_31/mlp.down_proj/compressed.log
best_loss 218.39463806152344 running bpv: 2.006753
 26%|‚ñà‚ñà‚ñã       | 59/224 [15:50<1:50:53, 40.33s/it]COMMANDS_FINISHED 20 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_26/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_26/mlp.gate_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_26/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_21/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_21/mlp.up_proj/compressed.log
best_loss 297.824951171875 running bpv: 2.006727
 27%|‚ñà‚ñà‚ñã       | 60/224 [16:45<2:00:13, 43.98s/it]COMMANDS_FINISHED 21 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_26/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_26/mlp.up_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_26/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_21/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_21/self_attn.o_proj/compressed.log
best_loss 11.162282943725586 running bpv: 2.006746
 27%|‚ñà‚ñà‚ñã       | 61/224 [17:00<1:38:50, 36.38s/it]COMMANDS_FINISHED 22 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_26/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_26/self_attn.q_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_26/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_21/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_21/self_attn.v_proj/compressed.log
best_loss 170.1057891845703 running bpv: 2.006766
 28%|‚ñà‚ñà‚ñä       | 62/224 [17:35<1:37:13, 36.01s/it]COMMANDS_FINISHED 23 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_26/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_26/self_attn.k_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_26/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_26/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_26/self_attn.q_proj/compressed.log
best_loss 334.6365966796875 running bpv: 2.006785
 28%|‚ñà‚ñà‚ñä       | 63/224 [19:10<2:20:59, 52.55s/it]COMMANDS_FINISHED 24 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_26/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_26/self_attn.o_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_26/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_26/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_26/self_attn.k_proj/compressed.log
best_loss 343.49688720703125 running bpv: 2.006803
 29%|‚ñà‚ñà‚ñä       | 64/224 [20:05<2:21:59, 53.25s/it]COMMANDS_FINISHED 25 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_26/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_26/mlp.down_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_26/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_26/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_26/mlp.gate_proj/compressed.log
best_loss 491.91143798828125 running bpv: 2.006777
 29%|‚ñà‚ñà‚ñâ       | 65/224 [21:00<2:22:27, 53.76s/it]COMMANDS_FINISHED 26 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_26/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_26/self_attn.v_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_26/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_26/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_26/self_attn.o_proj/compressed.log
best_loss 27.044483184814453 running bpv: 2.006795
 29%|‚ñà‚ñà‚ñâ       | 66/224 [21:15<1:51:40, 42.41s/it]COMMANDS_FINISHED 27 n_commands 185
meta-llama/Llama-2-7b-hf/layer_21/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_21/mlp.down_proj/compressed.log
best_loss 44.4230842590332 running bpv: 2.00677
COMMANDS_FINISHED 28 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_14/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_14/mlp.gate_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_14/mlp.gate_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_14/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_14/mlp.up_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_14/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_26/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_26/mlp.up_proj/compressed.log
best_loss 422.67413330078125 running bpv: 2.006746
 30%|‚ñà‚ñà‚ñà       | 68/224 [22:35<1:47:25, 41.31s/it]COMMANDS_FINISHED 29 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_14/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_14/self_attn.q_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_14/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_26/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_26/self_attn.v_proj/compressed.log
best_loss 268.0369873046875 running bpv: 2.006763
 31%|‚ñà‚ñà‚ñà       | 69/224 [23:30<1:55:25, 44.68s/it]COMMANDS_FINISHED 30 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_14/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_14/self_attn.k_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_14/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_14/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_14/self_attn.q_proj/compressed.log
best_loss 213.95169067382812 running bpv: 2.00678
 31%|‚ñà‚ñà‚ñà‚ñè      | 70/224 [25:05<2:28:13, 57.75s/it]COMMANDS_FINISHED 31 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_14/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_14/self_attn.o_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_14/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_26/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_26/mlp.down_proj/compressed.log
best_loss 66.7978744506836 running bpv: 2.006757
 32%|‚ñà‚ñà‚ñà‚ñè      | 71/224 [25:30<2:04:40, 48.89s/it]COMMANDS_FINISHED 32 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_14/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_14/mlp.down_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_14/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_14/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_14/self_attn.k_proj/compressed.log
best_loss 224.7210235595703 running bpv: 2.006773
 32%|‚ñà‚ñà‚ñà‚ñè      | 72/224 [26:15<2:01:06, 47.81s/it]COMMANDS_FINISHED 33 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_14/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_14/self_attn.v_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_14/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_14/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_14/mlp.gate_proj/compressed.log
best_loss 156.8980712890625 running bpv: 2.006751
 33%|‚ñà‚ñà‚ñà‚ñé      | 73/224 [26:30<1:36:48, 38.47s/it]COMMANDS_FINISHED 34 n_commands 185
meta-llama/Llama-2-7b-hf/layer_14/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_14/mlp.up_proj/compressed.log
best_loss 149.01129150390625 running bpv: 2.006729
COMMANDS_FINISHED 35 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_15/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_15/mlp.gate_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_15/mlp.gate_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_15/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_15/mlp.up_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_15/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_14/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_14/self_attn.o_proj/compressed.log
best_loss 7.310055732727051 running bpv: 2.006745
 33%|‚ñà‚ñà‚ñà‚ñé      | 75/224 [27:10<1:14:57, 30.18s/it]COMMANDS_FINISHED 36 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_15/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_15/self_attn.q_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_15/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_14/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_14/self_attn.v_proj/compressed.log
best_loss 80.04331970214844 running bpv: 2.006761
 34%|‚ñà‚ñà‚ñà‚ñç      | 76/224 [28:35<1:47:16, 43.49s/it]COMMANDS_FINISHED 37 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_15/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_15/self_attn.k_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_15/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_15/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_15/self_attn.q_proj/compressed.log
best_loss 202.87522888183594 running bpv: 2.006776
 34%|‚ñà‚ñà‚ñà‚ñç      | 77/224 [29:50<2:06:26, 51.61s/it]COMMANDS_FINISHED 38 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_15/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_15/self_attn.o_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_15/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_14/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_14/mlp.down_proj/compressed.log
best_loss 13.041084289550781 running bpv: 2.006755
 35%|‚ñà‚ñà‚ñà‚ñç      | 78/224 [30:45<2:07:48, 52.52s/it]COMMANDS_FINISHED 39 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_15/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_15/mlp.down_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_15/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_15/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_15/self_attn.k_proj/compressed.log
best_loss 220.40640258789062 running bpv: 2.00677
 35%|‚ñà‚ñà‚ñà‚ñå      | 79/224 [31:30<2:01:53, 50.44s/it]COMMANDS_FINISHED 40 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_15/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_15/self_attn.v_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_15/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_15/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_15/mlp.gate_proj/compressed.log
best_loss 171.50498962402344 running bpv: 2.00675
 36%|‚ñà‚ñà‚ñà‚ñå      | 80/224 [31:45<1:36:54, 40.38s/it]COMMANDS_FINISHED 41 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_4/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_4/mlp.gate_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_4/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_15/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_15/mlp.up_proj/compressed.log
best_loss 163.03199768066406 running bpv: 2.00673
 36%|‚ñà‚ñà‚ñà‚ñå      | 81/224 [32:00<1:18:47, 33.06s/it]COMMANDS_FINISHED 42 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_4/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_4/mlp.up_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_4/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_15/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_15/self_attn.o_proj/compressed.log
best_loss 7.656688690185547 running bpv: 2.006745
 37%|‚ñà‚ñà‚ñà‚ñã      | 82/224 [32:15<1:05:45, 27.79s/it]COMMANDS_FINISHED 43 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_4/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_4/self_attn.q_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_4/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_15/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_15/self_attn.v_proj/compressed.log
best_loss 84.83146667480469 running bpv: 2.006759
 37%|‚ñà‚ñà‚ñà‚ñã      | 83/224 [33:40<1:44:52, 44.63s/it]COMMANDS_FINISHED 44 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_4/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_4/self_attn.k_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_4/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_4/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_4/self_attn.q_proj/compressed.log
best_loss 81.9626693725586 running bpv: 2.006773
 38%|‚ñà‚ñà‚ñà‚ñä      | 84/224 [34:45<1:58:12, 50.66s/it]COMMANDS_FINISHED 45 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_4/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_4/self_attn.o_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_4/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_15/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_15/mlp.down_proj/compressed.log
best_loss 16.344451904296875 running bpv: 2.006754
 38%|‚ñà‚ñà‚ñà‚ñä      | 85/224 [36:20<2:27:54, 63.84s/it]COMMANDS_FINISHED 46 n_commands 185
meta-llama/Llama-2-7b-hf/layer_4/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_4/self_attn.k_proj/compressed.log
best_loss 87.04180908203125 running bpv: 2.006768
COMMANDS_FINISHED 47 n_commands 185
meta-llama/Llama-2-7b-hf/layer_4/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_4/self_attn.o_proj/compressed.log
best_loss 0.45371291041374207 running bpv: 2.006781
COMMANDS_FINISHED 48 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_4/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_4/mlp.down_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_4/mlp.down_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_4/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_4/self_attn.v_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_4/self_attn.v_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_27/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_27/mlp.gate_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_27/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_4/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_4/mlp.gate_proj/compressed.log
best_loss 53.47580337524414 running bpv: 2.006763
 39%|‚ñà‚ñà‚ñà‚ñâ      | 88/224 [36:45<1:14:14, 32.75s/it]COMMANDS_FINISHED 49 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_27/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_27/mlp.up_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_27/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_4/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_4/mlp.up_proj/compressed.log
best_loss 43.03978729248047 running bpv: 2.006744
 40%|‚ñà‚ñà‚ñà‚ñâ      | 89/224 [37:00<1:05:16, 29.01s/it]COMMANDS_FINISHED 50 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_27/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_27/self_attn.q_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_27/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_4/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_4/self_attn.v_proj/compressed.log
best_loss 23.0347957611084 running bpv: 2.006758
 40%|‚ñà‚ñà‚ñà‚ñà      | 90/224 [38:25<1:33:43, 41.96s/it]COMMANDS_FINISHED 51 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_27/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_27/self_attn.k_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_27/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_27/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_27/self_attn.q_proj/compressed.log
best_loss 371.0684814453125 running bpv: 2.006771
 41%|‚ñà‚ñà‚ñà‚ñà      | 91/224 [39:20<1:40:12, 45.20s/it]COMMANDS_FINISHED 52 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_27/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_27/self_attn.o_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_27/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_4/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_4/mlp.down_proj/compressed.log
best_loss 1.4677131175994873 running bpv: 2.006753
 41%|‚ñà‚ñà‚ñà‚ñà      | 92/224 [39:35<1:22:03, 37.30s/it]COMMANDS_FINISHED 53 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_27/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_27/mlp.down_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_27/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_27/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_27/self_attn.k_proj/compressed.log
best_loss 382.12701416015625 running bpv: 2.006766
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 93/224 [40:50<1:43:50, 47.56s/it]COMMANDS_FINISHED 54 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_27/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_27/self_attn.v_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_27/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_27/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_27/self_attn.o_proj/compressed.log
best_loss 18.57282257080078 running bpv: 2.006778
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 94/224 [41:05<1:23:18, 38.45s/it]COMMANDS_FINISHED 55 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_2/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_2/mlp.gate_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_2/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_27/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_27/mlp.gate_proj/compressed.log
best_loss 518.9451904296875 running bpv: 2.006761
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 95/224 [41:20<1:08:15, 31.75s/it]COMMANDS_FINISHED 56 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_2/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_2/mlp.up_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_2/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_27/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_27/mlp.up_proj/compressed.log
best_loss 450.29705810546875 running bpv: 2.006744
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 96/224 [41:55<1:09:44, 32.69s/it]COMMANDS_FINISHED 57 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_2/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_2/self_attn.q_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_2/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_27/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_27/self_attn.v_proj/compressed.log
best_loss 278.2059020996094 running bpv: 2.006756
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 97/224 [43:10<1:35:25, 45.08s/it]COMMANDS_FINISHED 58 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_2/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_2/self_attn.k_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_2/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_2/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_2/self_attn.q_proj/compressed.log
best_loss 27.246185302734375 running bpv: 2.006768
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 98/224 [44:35<1:59:24, 56.86s/it]COMMANDS_FINISHED 59 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_2/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_2/self_attn.o_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_2/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_27/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_27/mlp.down_proj/compressed.log
best_loss 75.12257385253906 running bpv: 2.006752
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 99/224 [44:50<1:32:36, 44.45s/it]COMMANDS_FINISHED 60 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_2/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_2/mlp.down_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_2/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_2/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_2/self_attn.k_proj/compressed.log
best_loss 30.9400577545166 running bpv: 2.006764
 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 100/224 [45:45<1:38:21, 47.59s/it]COMMANDS_FINISHED 61 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_2/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_2/self_attn.v_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_2/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_2/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_2/self_attn.o_proj/compressed.log
best_loss 0.12146825343370438 running bpv: 2.006776
 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 101/224 [46:00<1:17:38, 37.87s/it]COMMANDS_FINISHED 62 n_commands 185
meta-llama/Llama-2-7b-hf/layer_2/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_2/mlp.gate_proj/compressed.log
best_loss 19.720924377441406 running bpv: 2.006759
COMMANDS_FINISHED 63 n_commands 185
meta-llama/Llama-2-7b-hf/layer_2/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_2/mlp.up_proj/compressed.log
best_loss 16.98550033569336 running bpv: 2.006744
COMMANDS_FINISHED 64 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_28/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_28/mlp.gate_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_28/mlp.gate_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_28/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_28/mlp.up_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_28/mlp.up_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_28/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_28/self_attn.q_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_28/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_2/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_2/mlp.down_proj/compressed.log
best_loss 0.3919578194618225 running bpv: 2.006728
 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 104/224 [47:25<1:05:02, 32.52s/it]COMMANDS_FINISHED 65 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_28/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_28/self_attn.k_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_28/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_2/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_2/self_attn.v_proj/compressed.log
best_loss 7.308991432189941 running bpv: 2.00674
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 105/224 [47:50<1:01:21, 30.94s/it]COMMANDS_FINISHED 66 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_28/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_28/self_attn.o_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_28/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_28/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_28/self_attn.q_proj/compressed.log
best_loss 357.6356201171875 running bpv: 2.006751
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 106/224 [48:25<1:02:41, 31.88s/it]COMMANDS_FINISHED 67 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_28/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_28/mlp.down_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_28/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_28/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_28/self_attn.o_proj/compressed.log
best_loss 27.361045837402344 running bpv: 2.006762
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 107/224 [49:50<1:27:54, 45.08s/it]COMMANDS_FINISHED 68 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_28/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_28/self_attn.v_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_28/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_28/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_28/self_attn.k_proj/compressed.log
best_loss 370.2275085449219 running bpv: 2.006773
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 108/224 [50:05<1:11:55, 37.20s/it]COMMANDS_FINISHED 69 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_18/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_18/mlp.gate_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_18/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_28/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_28/mlp.up_proj/compressed.log
best_loss 479.291748046875 running bpv: 2.006758
 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 109/224 [51:10<1:25:49, 44.78s/it]COMMANDS_FINISHED 70 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_18/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_18/mlp.up_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_18/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_28/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_28/mlp.gate_proj/compressed.log
best_loss 535.379150390625 running bpv: 2.006743
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 110/224 [51:25<1:09:13, 36.44s/it]COMMANDS_FINISHED 71 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_18/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_18/self_attn.q_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_18/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_28/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_28/self_attn.v_proj/compressed.log
best_loss 301.50006103515625 running bpv: 2.006754
 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 111/224 [52:00<1:07:51, 36.03s/it]COMMANDS_FINISHED 72 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_18/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_18/self_attn.k_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_18/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_18/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_18/self_attn.q_proj/compressed.log
best_loss 247.62200927734375 running bpv: 2.006765
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 112/224 [53:55<1:49:59, 58.93s/it]COMMANDS_FINISHED 73 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_18/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_18/self_attn.o_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_18/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_28/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_28/mlp.down_proj/compressed.log
best_loss 90.62083435058594 running bpv: 2.00675
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 113/224 [54:10<1:25:13, 46.07s/it]COMMANDS_FINISHED 74 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_18/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_18/mlp.down_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_18/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_18/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_18/self_attn.k_proj/compressed.log
best_loss 261.62445068359375 running bpv: 2.006761
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 114/224 [54:25<1:07:39, 36.90s/it]COMMANDS_FINISHED 75 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_18/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_18/self_attn.v_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_18/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_18/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_18/mlp.gate_proj/compressed.log
best_loss 268.7345275878906 running bpv: 2.006747
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 115/224 [55:30<1:22:10, 45.24s/it]COMMANDS_FINISHED 76 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_25/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_25/mlp.gate_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_25/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_18/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_18/self_attn.o_proj/compressed.log
best_loss 9.474753379821777 running bpv: 2.006757
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 116/224 [55:55<1:10:35, 39.22s/it]COMMANDS_FINISHED 77 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_25/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_25/mlp.up_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_25/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_18/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_18/self_attn.v_proj/compressed.log
best_loss 132.18063354492188 running bpv: 2.006767
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 117/224 [56:40<1:13:01, 40.94s/it]COMMANDS_FINISHED 78 n_commands 185
meta-llama/Llama-2-7b-hf/layer_18/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_18/mlp.up_proj/compressed.log
best_loss 237.692138671875 running bpv: 2.006753
COMMANDS_FINISHED 79 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_25/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_25/self_attn.q_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_25/self_attn.q_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_25/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_25/self_attn.k_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_25/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_25/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_25/self_attn.q_proj/compressed.log
best_loss 361.50439453125 running bpv: 2.006763
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 119/224 [59:00<1:35:03, 54.32s/it]COMMANDS_FINISHED 80 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_25/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_25/self_attn.o_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_25/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_25/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_25/self_attn.k_proj/compressed.log
best_loss 366.8282470703125 running bpv: 2.006773
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 120/224 [59:15<1:17:17, 44.59s/it]COMMANDS_FINISHED 81 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_25/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_25/mlp.down_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_25/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_18/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_18/mlp.down_proj/compressed.log
best_loss 30.93621826171875 running bpv: 2.00676
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 121/224 [59:50<1:12:15, 42.09s/it]COMMANDS_FINISHED 82 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_25/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_25/self_attn.v_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_25/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_25/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_25/mlp.gate_proj/compressed.log
best_loss 463.50067138671875 running bpv: 2.006746
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 122/224 [1:00:55<1:22:08, 48.32s/it]COMMANDS_FINISHED 83 n_commands 185
meta-llama/Llama-2-7b-hf/layer_25/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_25/self_attn.o_proj/compressed.log
best_loss 13.888437271118164 running bpv: 2.006756
COMMANDS_FINISHED 84 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_30/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_30/mlp.gate_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_30/mlp.gate_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_30/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_30/mlp.up_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_30/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_25/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_25/mlp.up_proj/compressed.log
best_loss 397.89105224609375 running bpv: 2.006743
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 124/224 [1:01:25<56:16, 33.76s/it]  COMMANDS_FINISHED 85 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_30/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_30/self_attn.q_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_30/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_25/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_25/self_attn.v_proj/compressed.log
best_loss 270.3373718261719 running bpv: 2.006753
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 125/224 [1:01:51<52:16, 31.68s/it]COMMANDS_FINISHED 86 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_30/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_30/self_attn.k_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_30/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_30/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_30/self_attn.q_proj/compressed.log
best_loss 330.25433349609375 running bpv: 2.006762
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 126/224 [1:04:06<1:34:33, 57.89s/it]COMMANDS_FINISHED 87 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_30/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_30/self_attn.o_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_30/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_30/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_30/self_attn.k_proj/compressed.log
best_loss 344.01983642578125 running bpv: 2.006771
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 127/224 [1:04:51<1:28:02, 54.46s/it]COMMANDS_FINISHED 88 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_30/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_30/mlp.down_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_30/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_25/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_25/mlp.down_proj/compressed.log
best_loss 61.03361511230469 running bpv: 2.006759
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 128/224 [1:05:16<1:14:09, 46.35s/it]COMMANDS_FINISHED 89 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_30/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_30/self_attn.v_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_30/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_30/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_30/self_attn.o_proj/compressed.log
best_loss 35.682247161865234 running bpv: 2.006768
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 129/224 [1:05:41<1:03:51, 40.33s/it]COMMANDS_FINISHED 90 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_29/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_29/mlp.gate_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_29/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_30/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_30/mlp.up_proj/compressed.log
best_loss 503.8459167480469 running bpv: 2.006755
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 130/224 [1:06:06<56:16, 35.92s/it]  COMMANDS_FINISHED 91 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_29/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_29/mlp.up_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_29/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_30/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_30/mlp.gate_proj/compressed.log
best_loss 565.1041259765625 running bpv: 2.006743
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 131/224 [1:07:01<1:04:17, 41.48s/it]COMMANDS_FINISHED 92 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_29/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_29/self_attn.q_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_29/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_30/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_30/self_attn.v_proj/compressed.log
best_loss 308.6436767578125 running bpv: 2.006752
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 132/224 [1:07:36<1:00:41, 39.58s/it]COMMANDS_FINISHED 93 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_29/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_29/self_attn.k_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_29/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_29/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_29/self_attn.q_proj/compressed.log
best_loss 312.15203857421875 running bpv: 2.006761
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 133/224 [1:09:41<1:38:19, 64.83s/it]COMMANDS_FINISHED 94 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_29/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_29/self_attn.o_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_29/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_29/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_29/self_attn.k_proj/compressed.log
best_loss 323.4407958984375 running bpv: 2.00677
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 134/224 [1:10:36<1:32:52, 61.92s/it]COMMANDS_FINISHED 95 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_29/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_29/mlp.down_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_29/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_29/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_29/mlp.gate_proj/compressed.log
best_loss 551.3949584960938 running bpv: 2.006758
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 135/224 [1:11:01<1:15:32, 50.93s/it]COMMANDS_FINISHED 96 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_29/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_29/self_attn.v_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_29/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_29/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_29/self_attn.o_proj/compressed.log
best_loss 26.196121215820312 running bpv: 2.006766
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 136/224 [1:11:46<1:12:06, 49.16s/it]COMMANDS_FINISHED 97 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_16/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_16/mlp.gate_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_16/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_29/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_29/mlp.up_proj/compressed.log
best_loss 500.4429626464844 running bpv: 2.006754
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 137/224 [1:12:21<1:05:08, 44.93s/it]COMMANDS_FINISHED 98 n_commands 185
meta-llama/Llama-2-7b-hf/layer_30/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_30/mlp.down_proj/compressed.log
best_loss 139.41311645507812 running bpv: 2.006743
COMMANDS_FINISHED 99 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_16/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_16/mlp.up_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_16/mlp.up_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_16/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_16/self_attn.q_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_16/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_29/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_29/self_attn.v_proj/compressed.log
best_loss 279.01519775390625 running bpv: 2.006751
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 139/224 [1:13:21<53:54, 38.06s/it]  COMMANDS_FINISHED 100 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_16/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_16/self_attn.k_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_16/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_16/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_16/self_attn.q_proj/compressed.log
best_loss 210.02940368652344 running bpv: 2.00676
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 140/224 [1:15:06<1:16:29, 54.63s/it]COMMANDS_FINISHED 101 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_16/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_16/self_attn.o_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_16/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_16/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_16/self_attn.k_proj/compressed.log
best_loss 224.8513641357422 running bpv: 2.006768
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 141/224 [1:16:01<1:15:42, 54.73s/it]COMMANDS_FINISHED 102 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_16/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_16/mlp.down_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_16/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_29/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_29/mlp.down_proj/compressed.log
best_loss 106.17180633544922 running bpv: 2.006757
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 142/224 [1:16:46<1:11:11, 52.09s/it]COMMANDS_FINISHED 103 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_16/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_16/self_attn.v_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_16/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_16/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_16/self_attn.o_proj/compressed.log
best_loss 10.910207748413086 running bpv: 2.006765
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 143/224 [1:17:11<1:00:05, 44.52s/it]COMMANDS_FINISHED 104 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_13/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_13/mlp.gate_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_13/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_16/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_16/mlp.gate_proj/compressed.log
best_loss 196.48654174804688 running bpv: 2.006754
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 144/224 [1:17:26<48:07, 36.09s/it]  COMMANDS_FINISHED 105 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_13/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_13/mlp.up_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_13/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_16/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_16/mlp.up_proj/compressed.log
best_loss 183.64657592773438 running bpv: 2.006743
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 145/224 [1:17:51<43:17, 32.88s/it]COMMANDS_FINISHED 106 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_13/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_13/self_attn.q_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_13/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_16/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_16/self_attn.v_proj/compressed.log
best_loss 96.41324615478516 running bpv: 2.006751
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 146/224 [1:18:56<54:58, 42.29s/it]COMMANDS_FINISHED 107 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_13/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_13/self_attn.k_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_13/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_13/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_13/self_attn.q_proj/compressed.log
best_loss 208.2058868408203 running bpv: 2.006759
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 147/224 [1:20:31<1:14:13, 57.83s/it]COMMANDS_FINISHED 108 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_13/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_13/self_attn.o_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_13/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_13/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_13/self_attn.k_proj/compressed.log
best_loss 217.59608459472656 running bpv: 2.006767
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 148/224 [1:21:36<1:15:56, 59.96s/it]COMMANDS_FINISHED 109 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_13/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_13/mlp.down_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_13/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_16/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_16/mlp.down_proj/compressed.log
best_loss 22.69849967956543 running bpv: 2.006756
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 149/224 [1:21:51<58:14, 46.59s/it]  COMMANDS_FINISHED 110 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_13/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_13/self_attn.v_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_13/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_13/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_13/mlp.gate_proj/compressed.log
best_loss 143.2604522705078 running bpv: 2.006745
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 150/224 [1:22:16<49:31, 40.15s/it]COMMANDS_FINISHED 111 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_10/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_10/mlp.gate_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_10/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_13/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_13/self_attn.o_proj/compressed.log
best_loss 5.971685409545898 running bpv: 2.006753
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 151/224 [1:22:31<39:42, 32.64s/it]COMMANDS_FINISHED 112 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_10/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_10/mlp.up_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_10/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_13/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_13/mlp.up_proj/compressed.log
best_loss 135.14288330078125 running bpv: 2.006742
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 152/224 [1:22:46<32:50, 27.37s/it]COMMANDS_FINISHED 113 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_10/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_10/self_attn.q_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_10/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_13/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_13/self_attn.v_proj/compressed.log
best_loss 80.7279281616211 running bpv: 2.00675
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 153/224 [1:24:01<49:15, 41.63s/it]COMMANDS_FINISHED 114 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_10/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_10/self_attn.k_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_10/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_10/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_10/self_attn.q_proj/compressed.log
best_loss 169.98175048828125 running bpv: 2.006758
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 154/224 [1:25:16<1:00:14, 51.63s/it]COMMANDS_FINISHED 115 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_10/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_10/self_attn.o_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_10/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_10/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_10/self_attn.k_proj/compressed.log
best_loss 183.02587890625 running bpv: 2.006766
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 155/224 [1:26:41<1:10:52, 61.64s/it]COMMANDS_FINISHED 116 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_10/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_10/mlp.down_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_10/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_13/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_13/mlp.down_proj/compressed.log
best_loss 11.153130531311035 running bpv: 2.006755
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 156/224 [1:26:56<54:00, 47.66s/it]  COMMANDS_FINISHED 117 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_10/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_10/self_attn.v_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_10/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_10/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_10/self_attn.o_proj/compressed.log
best_loss 4.661892890930176 running bpv: 2.006763
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 157/224 [1:27:21<45:37, 40.87s/it]COMMANDS_FINISHED 118 n_commands 185
meta-llama/Llama-2-7b-hf/layer_10/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_10/mlp.gate_proj/compressed.log
best_loss 117.7877426147461 running bpv: 2.006752
COMMANDS_FINISHED 119 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_19/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_19/mlp.gate_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_19/mlp.gate_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_19/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_19/mlp.up_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_19/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_10/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_10/mlp.up_proj/compressed.log
best_loss 102.24578857421875 running bpv: 2.006742
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 159/224 [1:27:41<28:50, 26.63s/it]COMMANDS_FINISHED 120 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_19/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_19/self_attn.q_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_19/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_10/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_10/self_attn.v_proj/compressed.log
best_loss 53.187347412109375 running bpv: 2.00675
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 160/224 [1:29:06<43:50, 41.10s/it]COMMANDS_FINISHED 121 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_19/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_19/self_attn.k_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_19/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_19/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_19/self_attn.q_proj/compressed.log
best_loss 240.96792602539062 running bpv: 2.006757
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 161/224 [1:30:11<49:43, 47.35s/it]COMMANDS_FINISHED 122 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_19/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_19/self_attn.o_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_19/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_10/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_10/mlp.down_proj/compressed.log
best_loss 6.951462745666504 running bpv: 2.006747
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 162/224 [1:31:46<1:02:19, 60.32s/it]COMMANDS_FINISHED 123 n_commands 185
meta-llama/Llama-2-7b-hf/layer_19/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_19/self_attn.k_proj/compressed.log
best_loss 252.955810546875 running bpv: 2.006754
COMMANDS_FINISHED 124 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_19/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_19/mlp.down_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_19/mlp.down_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_19/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_19/self_attn.v_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_19/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_19/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_19/self_attn.o_proj/compressed.log
best_loss 8.930432319641113 running bpv: 2.006762
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 164/224 [1:32:06<38:18, 38.32s/it]  COMMANDS_FINISHED 125 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_6/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_6/mlp.gate_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_6/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_19/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_19/mlp.up_proj/compressed.log
best_loss 256.7301025390625 running bpv: 2.006752
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 165/224 [1:32:21<32:13, 32.77s/it]COMMANDS_FINISHED 126 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_6/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_6/mlp.up_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_6/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_19/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_19/mlp.gate_proj/compressed.log
best_loss 291.4942932128906 running bpv: 2.006742
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 166/224 [1:32:46<29:46, 30.80s/it]COMMANDS_FINISHED 127 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_6/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_6/self_attn.q_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_6/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_19/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_19/self_attn.v_proj/compressed.log
best_loss 135.08038330078125 running bpv: 2.006749
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 167/224 [1:34:11<42:57, 45.22s/it]COMMANDS_FINISHED 128 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_6/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_6/self_attn.k_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_6/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_6/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_6/self_attn.q_proj/compressed.log
best_loss 142.6158905029297 running bpv: 2.006756
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 168/224 [1:35:36<52:26, 56.18s/it]COMMANDS_FINISHED 129 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_6/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_6/self_attn.o_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_6/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_6/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_6/self_attn.k_proj/compressed.log
best_loss 150.4103546142578 running bpv: 2.006763
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 169/224 [1:37:01<58:57, 64.32s/it]COMMANDS_FINISHED 130 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_6/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_6/mlp.down_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_6/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_6/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_6/self_attn.o_proj/compressed.log
best_loss 1.103530764579773 running bpv: 2.00677
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 170/224 [1:37:26<47:43, 53.02s/it]COMMANDS_FINISHED 131 n_commands 185
meta-llama/Llama-2-7b-hf/layer_6/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_6/mlp.gate_proj/compressed.log
best_loss 88.50703430175781 running bpv: 2.006761
COMMANDS_FINISHED 132 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_6/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_6/self_attn.v_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_6/self_attn.v_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_11/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_11/mlp.gate_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_11/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_19/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_19/mlp.down_proj/compressed.log
best_loss 34.18609619140625 running bpv: 2.006751
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 172/224 [1:37:46<29:08, 33.63s/it]COMMANDS_FINISHED 133 n_commands 185
meta-llama/Llama-2-7b-hf/layer_6/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_6/mlp.up_proj/compressed.log
best_loss 67.63082885742188 running bpv: 2.006742
COMMANDS_FINISHED 134 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_11/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_11/mlp.up_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_11/mlp.up_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_11/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_11/self_attn.q_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_11/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_6/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_6/self_attn.v_proj/compressed.log
best_loss 41.04217529296875 running bpv: 2.006749
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 174/224 [1:39:36<35:00, 42.01s/it]COMMANDS_FINISHED 135 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_11/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_11/self_attn.k_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_11/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_11/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_11/self_attn.q_proj/compressed.log
best_loss 191.5291748046875 running bpv: 2.006756
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 175/224 [1:40:31<36:37, 44.85s/it]COMMANDS_FINISHED 136 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_11/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_11/self_attn.o_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_11/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_6/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_6/mlp.down_proj/compressed.log
best_loss 3.1748149394989014 running bpv: 2.006747
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 176/224 [1:41:16<35:54, 44.89s/it]COMMANDS_FINISHED 137 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_11/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_11/mlp.down_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_11/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_11/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_11/self_attn.k_proj/compressed.log
best_loss 191.2792205810547 running bpv: 2.006753
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 177/224 [1:42:21<39:09, 49.99s/it]COMMANDS_FINISHED 138 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_11/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_11/self_attn.v_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_11/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_11/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_11/self_attn.o_proj/compressed.log
best_loss 4.870911598205566 running bpv: 2.00676
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 178/224 [1:42:36<31:11, 40.69s/it]COMMANDS_FINISHED 139 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_20/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_20/mlp.gate_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_20/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_11/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_11/mlp.up_proj/compressed.log
best_loss 114.64007568359375 running bpv: 2.006751
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 179/224 [1:42:51<25:12, 33.61s/it]COMMANDS_FINISHED 140 n_commands 185
meta-llama/Llama-2-7b-hf/layer_11/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_11/mlp.gate_proj/compressed.log
best_loss 128.81556701660156 running bpv: 2.006742
COMMANDS_FINISHED 141 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_20/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_20/mlp.up_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_20/mlp.up_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_20/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_20/self_attn.q_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_20/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_11/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_11/self_attn.v_proj/compressed.log
best_loss 72.04061889648438 running bpv: 2.006749
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 181/224 [1:44:31<29:15, 40.83s/it]COMMANDS_FINISHED 142 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_20/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_20/self_attn.k_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_20/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_20/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_20/self_attn.q_proj/compressed.log
best_loss 249.66685485839844 running bpv: 2.006755
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 182/224 [1:45:06<27:36, 39.44s/it]COMMANDS_FINISHED 143 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_20/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_20/self_attn.o_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_20/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_11/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_11/mlp.down_proj/compressed.log
best_loss 7.845561504364014 running bpv: 2.006746
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 183/224 [1:46:01<29:39, 43.41s/it]COMMANDS_FINISHED 144 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_20/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_20/mlp.down_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_20/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_20/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_20/self_attn.o_proj/compressed.log
best_loss 13.250387191772461 running bpv: 2.006753
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 184/224 [1:46:46<29:13, 43.83s/it]COMMANDS_FINISHED 145 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_20/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_20/self_attn.v_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_20/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_20/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_20/self_attn.k_proj/compressed.log
best_loss 261.23822021484375 running bpv: 2.006759
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 185/224 [1:47:01<23:19, 35.88s/it]COMMANDS_FINISHED 146 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_23/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_23/mlp.gate_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_23/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_20/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_20/mlp.gate_proj/compressed.log
best_loss 315.4194641113281 running bpv: 2.00675
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 186/224 [1:47:56<26:08, 41.29s/it]COMMANDS_FINISHED 147 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_23/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_23/mlp.up_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_23/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_20/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_20/mlp.up_proj/compressed.log
best_loss 274.6654052734375 running bpv: 2.006742
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 187/224 [1:48:11<20:47, 33.73s/it]COMMANDS_FINISHED 148 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_23/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_23/self_attn.q_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_23/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_20/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_20/self_attn.v_proj/compressed.log
best_loss 140.4783935546875 running bpv: 2.006748
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 188/224 [1:48:46<20:27, 34.10s/it]COMMANDS_FINISHED 149 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_23/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_23/self_attn.k_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_23/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_23/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_23/self_attn.q_proj/compressed.log
best_loss 329.567138671875 running bpv: 2.006755
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 189/224 [1:50:21<30:19, 52.00s/it]COMMANDS_FINISHED 150 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_23/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_23/self_attn.o_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_23/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_23/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_23/self_attn.k_proj/compressed.log
best_loss 337.3396911621094 running bpv: 2.006761
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 190/224 [1:50:56<26:37, 46.97s/it]COMMANDS_FINISHED 151 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_23/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_23/mlp.down_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_23/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_23/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_23/self_attn.o_proj/compressed.log
best_loss 12.807504653930664 running bpv: 2.006767
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 191/224 [1:51:51<27:08, 49.36s/it]COMMANDS_FINISHED 152 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_23/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_23/self_attn.v_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_23/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_23/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_23/mlp.gate_proj/compressed.log
best_loss 405.0431823730469 running bpv: 2.006759
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 192/224 [1:52:06<20:52, 39.13s/it]COMMANDS_FINISHED 153 n_commands 185
meta-llama/Llama-2-7b-hf/layer_20/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_20/mlp.down_proj/compressed.log
best_loss 42.19581604003906 running bpv: 2.00675
COMMANDS_FINISHED 154 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_17/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_17/mlp.gate_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_17/mlp.gate_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_17/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_17/mlp.up_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_17/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_23/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_23/mlp.up_proj/compressed.log
best_loss 345.6103210449219 running bpv: 2.006742
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 194/224 [1:52:56<16:19, 32.64s/it]COMMANDS_FINISHED 155 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_17/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_17/self_attn.q_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_17/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_23/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_23/self_attn.v_proj/compressed.log
best_loss 222.84878540039062 running bpv: 2.006748
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 195/224 [1:53:51<18:26, 38.17s/it]COMMANDS_FINISHED 156 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_17/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_17/self_attn.k_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_17/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_17/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_17/self_attn.q_proj/compressed.log
best_loss 224.5572967529297 running bpv: 2.006754
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 196/224 [1:55:26<24:44, 53.00s/it]COMMANDS_FINISHED 157 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_17/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_17/self_attn.o_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_17/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_23/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_23/mlp.down_proj/compressed.log
best_loss 53.81710433959961 running bpv: 2.006746
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 197/224 [1:56:01<21:39, 48.12s/it]COMMANDS_FINISHED 158 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_17/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_17/mlp.down_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_17/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_17/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_17/self_attn.k_proj/compressed.log
best_loss 238.46307373046875 running bpv: 2.006752
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 198/224 [1:56:16<16:50, 38.86s/it]COMMANDS_FINISHED 159 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_17/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_17/self_attn.v_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_17/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_17/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_17/mlp.up_proj/compressed.log
best_loss 210.7689666748047 running bpv: 2.006744
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 199/224 [1:57:01<16:55, 40.61s/it]COMMANDS_FINISHED 160 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_9/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_9/mlp.gate_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_9/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_17/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_17/mlp.gate_proj/compressed.log
best_loss 232.28530883789062 running bpv: 2.006736
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 200/224 [1:57:16<13:16, 33.20s/it]COMMANDS_FINISHED 161 n_commands 185
meta-llama/Llama-2-7b-hf/layer_17/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_17/self_attn.o_proj/compressed.log
best_loss 8.418363571166992 running bpv: 2.006742
COMMANDS_FINISHED 162 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_9/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_9/mlp.up_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_9/mlp.up_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_9/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_9/self_attn.q_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_9/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_17/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_17/self_attn.v_proj/compressed.log
best_loss 104.61309814453125 running bpv: 2.006748
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 202/224 [1:58:26<12:28, 34.02s/it]COMMANDS_FINISHED 163 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_9/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_9/self_attn.k_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_9/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_9/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_9/self_attn.q_proj/compressed.log
best_loss 164.52871704101562 running bpv: 2.006754
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 203/224 [1:59:31<14:33, 41.59s/it]COMMANDS_FINISHED 164 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_9/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_9/self_attn.o_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_9/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_9/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_9/self_attn.k_proj/compressed.log
best_loss 174.6686553955078 running bpv: 2.006759
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 204/224 [2:00:56<17:36, 52.83s/it]COMMANDS_FINISHED 165 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_9/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_9/mlp.down_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_9/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_9/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_9/self_attn.o_proj/compressed.log
best_loss 3.1172261238098145 running bpv: 2.006765
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 205/224 [2:01:11<13:29, 42.62s/it]COMMANDS_FINISHED 166 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_9/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_9/self_attn.v_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_9/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_17/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_17/mlp.down_proj/compressed.log
best_loss 25.789857864379883 running bpv: 2.006757
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 206/224 [2:01:26<10:28, 34.94s/it]COMMANDS_FINISHED 167 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_22/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_22/mlp.gate_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_22/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_9/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_9/mlp.gate_proj/compressed.log
best_loss 113.17536926269531 running bpv: 2.006749
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 207/224 [2:01:41<08:17, 29.27s/it]COMMANDS_FINISHED 168 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_22/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_22/mlp.up_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_22/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_9/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_9/mlp.up_proj/compressed.log
best_loss 96.18701934814453 running bpv: 2.006742
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 208/224 [2:01:56<06:42, 25.15s/it]COMMANDS_FINISHED 169 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_22/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_22/self_attn.q_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_22/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_9/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_9/self_attn.v_proj/compressed.log
best_loss 52.42116165161133 running bpv: 2.006747
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 209/224 [2:03:11<09:55, 39.72s/it]COMMANDS_FINISHED 170 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_22/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_22/self_attn.k_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_22/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_22/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_22/self_attn.q_proj/compressed.log
best_loss 295.52789306640625 running bpv: 2.006753
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 210/224 [2:04:06<10:19, 44.22s/it]COMMANDS_FINISHED 171 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_22/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_22/self_attn.o_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_22/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_9/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_9/mlp.down_proj/compressed.log
best_loss 5.920958995819092 running bpv: 2.006745
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 211/224 [2:05:41<12:50, 59.26s/it]COMMANDS_FINISHED 172 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_22/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_22/mlp.down_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_22/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_22/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_22/self_attn.o_proj/compressed.log
best_loss 19.29244041442871 running bpv: 2.006751
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 212/224 [2:05:56<09:13, 46.10s/it]COMMANDS_FINISHED 173 n_commands 185
meta-llama/Llama-2-7b-hf/layer_22/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_22/self_attn.k_proj/compressed.log
best_loss 306.3883056640625 running bpv: 2.006757
COMMANDS_FINISHED 174 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_22/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_22/self_attn.v_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_22/self_attn.v_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_24/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_24/mlp.gate_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_24/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_22/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_22/mlp.gate_proj/compressed.log
best_loss 377.2744140625 running bpv: 2.006749
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 214/224 [2:06:36<05:41, 34.12s/it]COMMANDS_FINISHED 175 n_commands 185
meta-llama/Llama-2-7b-hf/layer_22/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_22/mlp.up_proj/compressed.log
best_loss 318.04632568359375 running bpv: 2.006742
COMMANDS_FINISHED 176 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_24/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_24/mlp.up_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_24/mlp.up_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_24/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_24/self_attn.q_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_24/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_22/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_22/self_attn.v_proj/compressed.log
best_loss 179.0663604736328 running bpv: 2.006747
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 216/224 [2:08:16<05:23, 40.41s/it]COMMANDS_FINISHED 177 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_24/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_24/self_attn.k_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_24/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_24/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_24/self_attn.q_proj/compressed.log
best_loss 304.15618896484375 running bpv: 2.006753
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 217/224 [2:08:51<04:34, 39.22s/it]COMMANDS_FINISHED 178 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_24/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_24/self_attn.o_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_24/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_24/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_24/self_attn.o_proj/compressed.log
best_loss 20.034454345703125 running bpv: 2.006758
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 218/224 [2:10:26<05:15, 52.59s/it]COMMANDS_FINISHED 179 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_24/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_24/mlp.down_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_24/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_24/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_24/self_attn.k_proj/compressed.log
best_loss 310.15118408203125 running bpv: 2.006764
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 219/224 [2:10:41<03:35, 43.00s/it]COMMANDS_FINISHED 180 n_commands 185
meta-llama/Llama-2-7b-hf/layer_24/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_24/mlp.gate_proj/compressed.log
best_loss 431.8279724121094 running bpv: 2.006756
COMMANDS_FINISHED 181 n_commands 185
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_24/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_24/self_attn.v_proj/compressed.pt --yaml_path tmp/desert-galaxy-76/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_24/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_22/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_22/mlp.down_proj/compressed.log
best_loss 50.02736282348633 running bpv: 2.006749
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 221/224 [2:11:06<01:30, 30.15s/it]COMMANDS_FINISHED 182 n_commands 185
meta-llama/Llama-2-7b-hf/layer_24/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_24/mlp.up_proj/compressed.log
best_loss 368.6147155761719 running bpv: 2.006742
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 222/224 [2:11:36<01:00, 30.12s/it]COMMANDS_FINISHED 183 n_commands 185
meta-llama/Llama-2-7b-hf/layer_24/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_24/self_attn.v_proj/compressed.log
best_loss 215.01014709472656 running bpv: 2.006747
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 223/224 [2:12:56<00:42, 42.51s/it]COMMANDS_FINISHED 184 n_commands 185
meta-llama/Llama-2-7b-hf/layer_24/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_24/mlp.down_proj/compressed.log
best_loss 57.290679931640625 running bpv: 2.00674
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 224/224 [2:15:36<00:00, 73.29s/it]COMMANDS_FINISHED 185 n_commands 185
done with meta-llama/Llama-2-7b-hf
done with {'meta-llama/Llama-2-7b-hf/layer_3/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_3/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_3/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_3/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_3/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_3/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_3/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_3/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_3/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_3/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_3/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_3/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_3/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_3/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_5/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_5/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_5/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_5/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_5/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_5/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_5/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_5/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_5/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_5/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_5/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_5/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_5/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_5/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_8/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_8/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_8/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_8/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_8/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_8/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_8/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_8/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_8/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_8/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_8/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_8/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_8/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_8/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_12/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_12/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_12/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_12/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_12/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_12/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_12/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_12/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_12/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_12/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_12/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_12/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_12/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_12/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_1/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_1/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_1/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_1/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_1/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_1/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_1/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_1/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_1/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_1/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_1/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_1/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_1/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_1/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_7/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_7/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_7/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_7/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_7/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_7/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_7/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_7/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_7/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_7/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_0/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_0/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_7/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_7/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_0/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_0/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_0/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_0/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_7/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_7/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_0/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_0/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_0/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_0/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_0/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_0/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_0/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_0/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_31/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_31/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_31/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_31/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_31/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_31/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_31/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_31/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_31/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_31/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_31/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_31/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_21/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_21/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_21/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_21/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_21/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_21/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_31/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_31/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_21/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_21/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_21/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_21/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_21/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_21/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_26/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_26/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_26/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_26/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_26/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_26/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_26/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_26/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_21/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_21/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_26/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_26/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_26/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_26/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_14/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_14/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_26/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_26/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_14/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_14/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_14/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_14/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_14/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_14/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_14/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_14/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_14/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_14/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_15/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_15/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_14/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_14/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_15/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_15/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_15/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_15/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_15/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_15/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_15/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_15/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_15/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_15/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_4/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_4/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_15/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_15/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_4/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_4/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_4/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_4/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_4/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_4/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_4/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_4/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_4/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_4/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_27/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_27/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_4/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_4/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_27/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_27/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_27/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_27/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_27/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_27/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_27/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_27/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_27/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_27/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_2/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_2/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_27/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_27/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_2/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_2/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_2/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_2/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_2/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_2/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_2/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_2/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_2/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_2/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_2/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_2/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_28/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_28/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_28/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_28/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_28/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_28/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_28/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_28/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_28/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_28/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_28/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_28/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_18/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_18/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_28/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_28/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_18/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_18/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_18/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_18/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_18/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_18/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_18/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_18/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_18/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_18/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_25/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_25/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_25/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_25/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_18/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_18/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_25/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_25/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_25/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_25/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_25/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_25/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_25/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_25/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_30/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_30/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_30/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_30/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_25/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_25/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_30/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_30/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_30/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_30/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_30/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_30/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_30/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_30/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_29/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_29/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_29/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_29/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_29/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_29/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_29/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_29/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_29/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_29/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_30/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_30/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_29/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_29/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_16/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_16/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_16/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_16/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_29/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_29/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_16/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_16/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_16/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_16/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_16/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_16/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_16/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_16/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_13/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_13/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_13/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_13/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_16/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_16/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_13/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_13/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_13/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_13/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_13/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_13/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_13/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_13/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_10/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_10/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_10/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_10/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_13/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_13/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_10/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_10/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_10/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_10/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_10/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_10/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_10/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_10/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_19/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_19/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_10/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_10/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_19/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_19/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_19/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_19/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_19/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_19/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_19/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_19/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_19/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_19/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_6/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_6/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_6/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_6/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_6/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_6/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_6/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_6/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_19/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_19/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_6/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_6/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_6/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_6/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_11/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_11/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_6/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_6/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_11/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_11/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_11/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_11/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_11/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_11/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_11/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_11/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_11/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_11/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_20/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_20/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_11/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_11/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_20/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_20/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_20/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_20/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_20/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_20/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_20/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_20/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_20/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_20/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_23/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_23/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_23/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_23/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_23/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_23/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_23/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_23/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_20/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_20/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_23/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_23/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_23/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_23/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_17/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_17/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_23/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_23/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_17/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_17/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_17/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_17/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_17/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_17/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_17/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_17/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_17/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_17/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_9/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_9/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_9/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_9/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_9/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_9/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_17/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_17/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_9/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_9/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_9/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_9/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_9/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_9/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_22/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_22/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_9/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_9/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_22/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_22/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_22/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_22/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_22/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_22/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_22/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_22/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_22/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_22/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_24/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_24/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_24/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_24/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_24/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_24/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_24/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_24/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_22/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_22/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_24/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_24/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_24/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_24/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_24/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/meta-llama/Llama-2-7b-hf/layer_24/mlp.down_proj/compressed.pt'}
/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/checkpoints.yaml
perplexity_inference_command:
 python -u perplexity_eval.py --base_model meta-llama/Llama-2-7b-hf --seqlen 4096 --checkpoint_list_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/checkpoints.yaml --log_wandb --wandb_project compression_no_finetune --wandb_id g87eipl0
running: nohup python -u perplexity_eval.py --base_model meta-llama/Llama-2-7b-hf --seqlen 4096 --checkpoint_list_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/checkpoints.yaml --log_wandb --wandb_project compression_no_finetune --wandb_id g87eipl0 --device cuda:6 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/desert-galaxy-76/ppl_eval.log 2>&1 &
Terminated
