/home/lliu/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.68s/it]
Model loaded. LlamaForCausalLM(
  (model): LlamaModel(
    (embed_tokens): Embedding(32000, 4096)
    (layers): ModuleList(
      (0-31): 32 x LlamaDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LlamaMLP(
          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
          (act_fn): SiLUActivation()
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)
4096
Loading tokenizer for meta-llama/Llama-2-7b-hf
Starting...
position_ids torch.Size([1, 4096])
attention_mask torch.Size([1, 1, 4096, 4096])
Ready.
Layer 0
layer original dtype torch.float16
Performing low rank approximation
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
Pre fine tuning: 24203 MiB free out of 48676 MiB total
Found 20 differentiable parameters
differentiable parameters: dict_keys(['q_proj.A', 'q_proj.B', 'q_proj.weights_norms_rowwise', 'q_proj.sparse_weights1', 'q_proj.sparse_weights2', 'k_proj.A', 'k_proj.B', 'k_proj.weights_norms_rowwise', 'k_proj.sparse_weights1', 'k_proj.sparse_weights2', 'v_proj.A', 'v_proj.B', 'v_proj.weights_norms_rowwise', 'v_proj.sparse_weights1', 'v_proj.sparse_weights2', 'o_proj.A', 'o_proj.B', 'o_proj.weights_norms_rowwise', 'o_proj.sparse_weights1', 'o_proj.sparse_weights2'])
Fine-tuning 7495312 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=7.16e-04	
11887 MiB free out of 48676 MiB total
----------
epoch=1
train loss=6.26e-04	
11887 MiB free out of 48676 MiB total
----------
epoch=2
train loss=5.30e-04	
11887 MiB free out of 48676 MiB total
----------
epoch=3
train loss=4.66e-04	
11887 MiB free out of 48676 MiB total
----------
epoch=4
train loss=4.52e-04	
11887 MiB free out of 48676 MiB total
post_fine_tuning 11887 MiB free out of 48676 MiB total
total size:  202375168 total Megabytes:  tensor(272.3271, device='cuda:6') bits per value:  tensor(11.2882, device='cuda:6')
Quantizing ...
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
weights.shape =  torch.Size([4096, 11008])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
Pre fine tuning: 11887 MiB free out of 48676 MiB total
Found 25 differentiable parameters
differentiable parameters: dict_keys(['self_attn.q_proj.weights_norms_rowwise', 'self_attn.q_proj.sparse_weights1', 'self_attn.q_proj.sparse_weights2', 'self_attn.q_proj.A.centriods', 'self_attn.q_proj.B.centriods', 'self_attn.k_proj.weights_norms_rowwise', 'self_attn.k_proj.sparse_weights1', 'self_attn.k_proj.sparse_weights2', 'self_attn.k_proj.A.centriods', 'self_attn.k_proj.B.centriods', 'self_attn.v_proj.weights_norms_rowwise', 'self_attn.v_proj.sparse_weights1', 'self_attn.v_proj.sparse_weights2', 'self_attn.v_proj.A.centriods', 'self_attn.v_proj.B.centriods', 'self_attn.o_proj.weights_norms_rowwise', 'self_attn.o_proj.sparse_weights1', 'self_attn.o_proj.sparse_weights2', 'self_attn.o_proj.A.centriods', 'self_attn.o_proj.B.centriods', 'mlp.w1.centriods', 'mlp.w2.centriods', 'mlp.w3.centriods', 'input_layernorm.weight', 'post_attention_layernorm.weight'])
Fine-tuning 1145552 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=4.42e-03	
9839 MiB free out of 48676 MiB total
----------
epoch=1
train loss=1.53e-03	
9839 MiB free out of 48676 MiB total
----------
epoch=2
train loss=3.25e-04	
9839 MiB free out of 48676 MiB total
----------
epoch=3
train loss=6.13e-05	
9839 MiB free out of 48676 MiB total
----------
epoch=4
train loss=3.03e-05	
9839 MiB free out of 48676 MiB total
post_fine_tuning 9839 MiB free out of 48676 MiB total
9839 MiB free out of 48676 MiB total
trying to convert back to original dtype
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
9833 MiB free out of 48676 MiB total
layer: 0
done in 0:12:08.428490 overall time: 0:12:08.428528 estimated time left: 6:16:21.284378
after cast to cpu
39287 MiB free out of 48676 MiB total
Layer 1
layer original dtype torch.float16
Performing low rank approximation
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
Pre fine tuning: 23725 MiB free out of 48676 MiB total
Found 20 differentiable parameters
differentiable parameters: dict_keys(['q_proj.A', 'q_proj.B', 'q_proj.weights_norms_rowwise', 'q_proj.sparse_weights1', 'q_proj.sparse_weights2', 'k_proj.A', 'k_proj.B', 'k_proj.weights_norms_rowwise', 'k_proj.sparse_weights1', 'k_proj.sparse_weights2', 'v_proj.A', 'v_proj.B', 'v_proj.weights_norms_rowwise', 'v_proj.sparse_weights1', 'v_proj.sparse_weights2', 'o_proj.A', 'o_proj.B', 'o_proj.weights_norms_rowwise', 'o_proj.sparse_weights1', 'o_proj.sparse_weights2'])
Fine-tuning 7495312 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=1.36e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=1.36e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=1.36e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=1.35e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=1.35e-01	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
total size:  202375168 total Megabytes:  tensor(272.3271, device='cuda:6') bits per value:  tensor(11.2882, device='cuda:6')
Quantizing ...
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
weights.shape =  torch.Size([4096, 11008])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
Pre fine tuning: 11417 MiB free out of 48676 MiB total
Found 25 differentiable parameters
differentiable parameters: dict_keys(['self_attn.q_proj.weights_norms_rowwise', 'self_attn.q_proj.sparse_weights1', 'self_attn.q_proj.sparse_weights2', 'self_attn.q_proj.A.centriods', 'self_attn.q_proj.B.centriods', 'self_attn.k_proj.weights_norms_rowwise', 'self_attn.k_proj.sparse_weights1', 'self_attn.k_proj.sparse_weights2', 'self_attn.k_proj.A.centriods', 'self_attn.k_proj.B.centriods', 'self_attn.v_proj.weights_norms_rowwise', 'self_attn.v_proj.sparse_weights1', 'self_attn.v_proj.sparse_weights2', 'self_attn.v_proj.A.centriods', 'self_attn.v_proj.B.centriods', 'self_attn.o_proj.weights_norms_rowwise', 'self_attn.o_proj.sparse_weights1', 'self_attn.o_proj.sparse_weights2', 'self_attn.o_proj.A.centriods', 'self_attn.o_proj.B.centriods', 'mlp.w1.centriods', 'mlp.w2.centriods', 'mlp.w3.centriods', 'input_layernorm.weight', 'post_attention_layernorm.weight'])
Fine-tuning 1145552 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=1.24e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=8.92e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=5.87e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=3.56e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=2.17e-02	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
11417 MiB free out of 48676 MiB total
trying to convert back to original dtype
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
11417 MiB free out of 48676 MiB total
layer: 1
done in 0:12:13.920850 overall time: 0:24:22.568102 estimated time left: 6:05:38.521532
after cast to cpu
39287 MiB free out of 48676 MiB total
Layer 2
layer original dtype torch.float16
Performing low rank approximation
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
Pre fine tuning: 23725 MiB free out of 48676 MiB total
Found 20 differentiable parameters
differentiable parameters: dict_keys(['q_proj.A', 'q_proj.B', 'q_proj.weights_norms_rowwise', 'q_proj.sparse_weights1', 'q_proj.sparse_weights2', 'k_proj.A', 'k_proj.B', 'k_proj.weights_norms_rowwise', 'k_proj.sparse_weights1', 'k_proj.sparse_weights2', 'v_proj.A', 'v_proj.B', 'v_proj.weights_norms_rowwise', 'v_proj.sparse_weights1', 'v_proj.sparse_weights2', 'o_proj.A', 'o_proj.B', 'o_proj.weights_norms_rowwise', 'o_proj.sparse_weights1', 'o_proj.sparse_weights2'])
Fine-tuning 7495312 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=4.27e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=1.06e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=8.86e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=8.69e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=8.65e-02	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
total size:  202375168 total Megabytes:  tensor(272.3271, device='cuda:6') bits per value:  tensor(11.2882, device='cuda:6')
Quantizing ...
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
weights.shape =  torch.Size([4096, 11008])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
Pre fine tuning: 11417 MiB free out of 48676 MiB total
Found 25 differentiable parameters
differentiable parameters: dict_keys(['self_attn.q_proj.weights_norms_rowwise', 'self_attn.q_proj.sparse_weights1', 'self_attn.q_proj.sparse_weights2', 'self_attn.q_proj.A.centriods', 'self_attn.q_proj.B.centriods', 'self_attn.k_proj.weights_norms_rowwise', 'self_attn.k_proj.sparse_weights1', 'self_attn.k_proj.sparse_weights2', 'self_attn.k_proj.A.centriods', 'self_attn.k_proj.B.centriods', 'self_attn.v_proj.weights_norms_rowwise', 'self_attn.v_proj.sparse_weights1', 'self_attn.v_proj.sparse_weights2', 'self_attn.v_proj.A.centriods', 'self_attn.v_proj.B.centriods', 'self_attn.o_proj.weights_norms_rowwise', 'self_attn.o_proj.sparse_weights1', 'self_attn.o_proj.sparse_weights2', 'self_attn.o_proj.A.centriods', 'self_attn.o_proj.B.centriods', 'mlp.w1.centriods', 'mlp.w2.centriods', 'mlp.w3.centriods', 'input_layernorm.weight', 'post_attention_layernorm.weight'])
Fine-tuning 1145552 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=1.26e-04	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=8.48e-05	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=7.16e-05	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=6.27e-05	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=5.69e-05	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
11417 MiB free out of 48676 MiB total
trying to convert back to original dtype
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
11417 MiB free out of 48676 MiB total
layer: 2
done in 0:12:11.718470 overall time: 0:36:34.530785 estimated time left: 5:53:33.797587
after cast to cpu
39287 MiB free out of 48676 MiB total
Layer 3
layer original dtype torch.float16
Performing low rank approximation
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
Pre fine tuning: 23725 MiB free out of 48676 MiB total
Found 20 differentiable parameters
differentiable parameters: dict_keys(['q_proj.A', 'q_proj.B', 'q_proj.weights_norms_rowwise', 'q_proj.sparse_weights1', 'q_proj.sparse_weights2', 'k_proj.A', 'k_proj.B', 'k_proj.weights_norms_rowwise', 'k_proj.sparse_weights1', 'k_proj.sparse_weights2', 'v_proj.A', 'v_proj.B', 'v_proj.weights_norms_rowwise', 'v_proj.sparse_weights1', 'v_proj.sparse_weights2', 'o_proj.A', 'o_proj.B', 'o_proj.weights_norms_rowwise', 'o_proj.sparse_weights1', 'o_proj.sparse_weights2'])
Fine-tuning 7495312 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=6.98e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=1.21e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=9.03e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=8.68e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=8.63e-02	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
total size:  202375168 total Megabytes:  tensor(272.3271, device='cuda:6') bits per value:  tensor(11.2882, device='cuda:6')
Quantizing ...
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
weights.shape =  torch.Size([4096, 11008])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
Pre fine tuning: 11417 MiB free out of 48676 MiB total
Found 25 differentiable parameters
differentiable parameters: dict_keys(['self_attn.q_proj.weights_norms_rowwise', 'self_attn.q_proj.sparse_weights1', 'self_attn.q_proj.sparse_weights2', 'self_attn.q_proj.A.centriods', 'self_attn.q_proj.B.centriods', 'self_attn.k_proj.weights_norms_rowwise', 'self_attn.k_proj.sparse_weights1', 'self_attn.k_proj.sparse_weights2', 'self_attn.k_proj.A.centriods', 'self_attn.k_proj.B.centriods', 'self_attn.v_proj.weights_norms_rowwise', 'self_attn.v_proj.sparse_weights1', 'self_attn.v_proj.sparse_weights2', 'self_attn.v_proj.A.centriods', 'self_attn.v_proj.B.centriods', 'self_attn.o_proj.weights_norms_rowwise', 'self_attn.o_proj.sparse_weights1', 'self_attn.o_proj.sparse_weights2', 'self_attn.o_proj.A.centriods', 'self_attn.o_proj.B.centriods', 'mlp.w1.centriods', 'mlp.w2.centriods', 'mlp.w3.centriods', 'input_layernorm.weight', 'post_attention_layernorm.weight'])
Fine-tuning 1145552 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=4.57e-04	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=2.65e-04	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=2.16e-04	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=1.86e-04	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=1.65e-04	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
11417 MiB free out of 48676 MiB total
trying to convert back to original dtype
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
11417 MiB free out of 48676 MiB total
layer: 3
done in 0:12:12.786237 overall time: 0:48:47.572099 estimated time left: 5:41:33.004694
after cast to cpu
39287 MiB free out of 48676 MiB total
Layer 4
layer original dtype torch.float16
Performing low rank approximation
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
Pre fine tuning: 23725 MiB free out of 48676 MiB total
Found 20 differentiable parameters
differentiable parameters: dict_keys(['q_proj.A', 'q_proj.B', 'q_proj.weights_norms_rowwise', 'q_proj.sparse_weights1', 'q_proj.sparse_weights2', 'k_proj.A', 'k_proj.B', 'k_proj.weights_norms_rowwise', 'k_proj.sparse_weights1', 'k_proj.sparse_weights2', 'v_proj.A', 'v_proj.B', 'v_proj.weights_norms_rowwise', 'v_proj.sparse_weights1', 'v_proj.sparse_weights2', 'o_proj.A', 'o_proj.B', 'o_proj.weights_norms_rowwise', 'o_proj.sparse_weights1', 'o_proj.sparse_weights2'])
Fine-tuning 7495312 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=7.99e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=1.31e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=9.46e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=8.99e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=8.93e-02	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
total size:  202375168 total Megabytes:  tensor(272.3271, device='cuda:6') bits per value:  tensor(11.2882, device='cuda:6')
Quantizing ...
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
weights.shape =  torch.Size([4096, 11008])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
Pre fine tuning: 11417 MiB free out of 48676 MiB total
Found 25 differentiable parameters
differentiable parameters: dict_keys(['self_attn.q_proj.weights_norms_rowwise', 'self_attn.q_proj.sparse_weights1', 'self_attn.q_proj.sparse_weights2', 'self_attn.q_proj.A.centriods', 'self_attn.q_proj.B.centriods', 'self_attn.k_proj.weights_norms_rowwise', 'self_attn.k_proj.sparse_weights1', 'self_attn.k_proj.sparse_weights2', 'self_attn.k_proj.A.centriods', 'self_attn.k_proj.B.centriods', 'self_attn.v_proj.weights_norms_rowwise', 'self_attn.v_proj.sparse_weights1', 'self_attn.v_proj.sparse_weights2', 'self_attn.v_proj.A.centriods', 'self_attn.v_proj.B.centriods', 'self_attn.o_proj.weights_norms_rowwise', 'self_attn.o_proj.sparse_weights1', 'self_attn.o_proj.sparse_weights2', 'self_attn.o_proj.A.centriods', 'self_attn.o_proj.B.centriods', 'mlp.w1.centriods', 'mlp.w2.centriods', 'mlp.w3.centriods', 'input_layernorm.weight', 'post_attention_layernorm.weight'])
Fine-tuning 1145552 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=1.40e-03	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=7.54e-04	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=6.13e-04	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=5.37e-04	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=4.86e-04	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
11417 MiB free out of 48676 MiB total
trying to convert back to original dtype
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
11417 MiB free out of 48676 MiB total
layer: 4
done in 0:12:14.631964 overall time: 1:01:02.448159 estimated time left: 5:29:37.220058
after cast to cpu
39287 MiB free out of 48676 MiB total
Layer 5
layer original dtype torch.float16
Performing low rank approximation
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
Pre fine tuning: 23725 MiB free out of 48676 MiB total
Found 20 differentiable parameters
differentiable parameters: dict_keys(['q_proj.A', 'q_proj.B', 'q_proj.weights_norms_rowwise', 'q_proj.sparse_weights1', 'q_proj.sparse_weights2', 'k_proj.A', 'k_proj.B', 'k_proj.weights_norms_rowwise', 'k_proj.sparse_weights1', 'k_proj.sparse_weights2', 'v_proj.A', 'v_proj.B', 'v_proj.weights_norms_rowwise', 'v_proj.sparse_weights1', 'v_proj.sparse_weights2', 'o_proj.A', 'o_proj.B', 'o_proj.weights_norms_rowwise', 'o_proj.sparse_weights1', 'o_proj.sparse_weights2'])
Fine-tuning 7495312 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=4.82e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=1.29e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=9.65e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=9.40e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=9.35e-02	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
total size:  202375168 total Megabytes:  tensor(272.3271, device='cuda:6') bits per value:  tensor(11.2882, device='cuda:6')
Quantizing ...
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
weights.shape =  torch.Size([4096, 11008])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
Pre fine tuning: 11417 MiB free out of 48676 MiB total
Found 25 differentiable parameters
differentiable parameters: dict_keys(['self_attn.q_proj.weights_norms_rowwise', 'self_attn.q_proj.sparse_weights1', 'self_attn.q_proj.sparse_weights2', 'self_attn.q_proj.A.centriods', 'self_attn.q_proj.B.centriods', 'self_attn.k_proj.weights_norms_rowwise', 'self_attn.k_proj.sparse_weights1', 'self_attn.k_proj.sparse_weights2', 'self_attn.k_proj.A.centriods', 'self_attn.k_proj.B.centriods', 'self_attn.v_proj.weights_norms_rowwise', 'self_attn.v_proj.sparse_weights1', 'self_attn.v_proj.sparse_weights2', 'self_attn.v_proj.A.centriods', 'self_attn.v_proj.B.centriods', 'self_attn.o_proj.weights_norms_rowwise', 'self_attn.o_proj.sparse_weights1', 'self_attn.o_proj.sparse_weights2', 'self_attn.o_proj.A.centriods', 'self_attn.o_proj.B.centriods', 'mlp.w1.centriods', 'mlp.w2.centriods', 'mlp.w3.centriods', 'input_layernorm.weight', 'post_attention_layernorm.weight'])
Fine-tuning 1145552 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=5.00e-03	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=3.39e-03	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=2.54e-03	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=1.96e-03	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=1.60e-03	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
11417 MiB free out of 48676 MiB total
trying to convert back to original dtype
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
11417 MiB free out of 48676 MiB total
layer: 5
done in 0:12:10.968199 overall time: 1:13:13.659763 estimated time left: 5:17:19.192306
after cast to cpu
39287 MiB free out of 48676 MiB total
Layer 6
layer original dtype torch.float16
Performing low rank approximation
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
Pre fine tuning: 23725 MiB free out of 48676 MiB total
Found 20 differentiable parameters
differentiable parameters: dict_keys(['q_proj.A', 'q_proj.B', 'q_proj.weights_norms_rowwise', 'q_proj.sparse_weights1', 'q_proj.sparse_weights2', 'k_proj.A', 'k_proj.B', 'k_proj.weights_norms_rowwise', 'k_proj.sparse_weights1', 'k_proj.sparse_weights2', 'v_proj.A', 'v_proj.B', 'v_proj.weights_norms_rowwise', 'v_proj.sparse_weights1', 'v_proj.sparse_weights2', 'o_proj.A', 'o_proj.B', 'o_proj.weights_norms_rowwise', 'o_proj.sparse_weights1', 'o_proj.sparse_weights2'])
Fine-tuning 7495312 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=5.02e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=1.34e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=9.98e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=9.63e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=9.54e-02	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
total size:  202375168 total Megabytes:  tensor(272.3271, device='cuda:6') bits per value:  tensor(11.2882, device='cuda:6')
Quantizing ...
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
weights.shape =  torch.Size([4096, 11008])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
Pre fine tuning: 11417 MiB free out of 48676 MiB total
Found 25 differentiable parameters
differentiable parameters: dict_keys(['self_attn.q_proj.weights_norms_rowwise', 'self_attn.q_proj.sparse_weights1', 'self_attn.q_proj.sparse_weights2', 'self_attn.q_proj.A.centriods', 'self_attn.q_proj.B.centriods', 'self_attn.k_proj.weights_norms_rowwise', 'self_attn.k_proj.sparse_weights1', 'self_attn.k_proj.sparse_weights2', 'self_attn.k_proj.A.centriods', 'self_attn.k_proj.B.centriods', 'self_attn.v_proj.weights_norms_rowwise', 'self_attn.v_proj.sparse_weights1', 'self_attn.v_proj.sparse_weights2', 'self_attn.v_proj.A.centriods', 'self_attn.v_proj.B.centriods', 'self_attn.o_proj.weights_norms_rowwise', 'self_attn.o_proj.sparse_weights1', 'self_attn.o_proj.sparse_weights2', 'self_attn.o_proj.A.centriods', 'self_attn.o_proj.B.centriods', 'mlp.w1.centriods', 'mlp.w2.centriods', 'mlp.w3.centriods', 'input_layernorm.weight', 'post_attention_layernorm.weight'])
Fine-tuning 1145552 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=8.05e-03	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=4.83e-03	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=2.96e-03	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=2.08e-03	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=1.69e-03	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
11417 MiB free out of 48676 MiB total
trying to convert back to original dtype
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
11417 MiB free out of 48676 MiB total
layer: 6
done in 0:12:12.307207 overall time: 1:25:26.218816 estimated time left: 5:05:07.924344
after cast to cpu
39287 MiB free out of 48676 MiB total
Layer 7
layer original dtype torch.float16
Performing low rank approximation
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
Pre fine tuning: 23725 MiB free out of 48676 MiB total
Found 20 differentiable parameters
differentiable parameters: dict_keys(['q_proj.A', 'q_proj.B', 'q_proj.weights_norms_rowwise', 'q_proj.sparse_weights1', 'q_proj.sparse_weights2', 'k_proj.A', 'k_proj.B', 'k_proj.weights_norms_rowwise', 'k_proj.sparse_weights1', 'k_proj.sparse_weights2', 'v_proj.A', 'v_proj.B', 'v_proj.weights_norms_rowwise', 'v_proj.sparse_weights1', 'v_proj.sparse_weights2', 'o_proj.A', 'o_proj.B', 'o_proj.weights_norms_rowwise', 'o_proj.sparse_weights1', 'o_proj.sparse_weights2'])
Fine-tuning 7495312 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=4.32e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=1.22e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=9.89e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=9.67e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=9.61e-02	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
total size:  202375168 total Megabytes:  tensor(272.3271, device='cuda:6') bits per value:  tensor(11.2882, device='cuda:6')
Quantizing ...
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
weights.shape =  torch.Size([4096, 11008])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
Pre fine tuning: 11417 MiB free out of 48676 MiB total
Found 25 differentiable parameters
differentiable parameters: dict_keys(['self_attn.q_proj.weights_norms_rowwise', 'self_attn.q_proj.sparse_weights1', 'self_attn.q_proj.sparse_weights2', 'self_attn.q_proj.A.centriods', 'self_attn.q_proj.B.centriods', 'self_attn.k_proj.weights_norms_rowwise', 'self_attn.k_proj.sparse_weights1', 'self_attn.k_proj.sparse_weights2', 'self_attn.k_proj.A.centriods', 'self_attn.k_proj.B.centriods', 'self_attn.v_proj.weights_norms_rowwise', 'self_attn.v_proj.sparse_weights1', 'self_attn.v_proj.sparse_weights2', 'self_attn.v_proj.A.centriods', 'self_attn.v_proj.B.centriods', 'self_attn.o_proj.weights_norms_rowwise', 'self_attn.o_proj.sparse_weights1', 'self_attn.o_proj.sparse_weights2', 'self_attn.o_proj.A.centriods', 'self_attn.o_proj.B.centriods', 'mlp.w1.centriods', 'mlp.w2.centriods', 'mlp.w3.centriods', 'input_layernorm.weight', 'post_attention_layernorm.weight'])
Fine-tuning 1145552 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=4.71e-03	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=3.18e-03	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=2.34e-03	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=1.83e-03	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=1.54e-03	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
11417 MiB free out of 48676 MiB total
trying to convert back to original dtype
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
11417 MiB free out of 48676 MiB total
layer: 7
done in 0:12:13.485652 overall time: 1:37:39.953571 estimated time left: 4:52:59.860713
after cast to cpu
39287 MiB free out of 48676 MiB total
Layer 8
layer original dtype torch.float16
Performing low rank approximation
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
Pre fine tuning: 23725 MiB free out of 48676 MiB total
Found 20 differentiable parameters
differentiable parameters: dict_keys(['q_proj.A', 'q_proj.B', 'q_proj.weights_norms_rowwise', 'q_proj.sparse_weights1', 'q_proj.sparse_weights2', 'k_proj.A', 'k_proj.B', 'k_proj.weights_norms_rowwise', 'k_proj.sparse_weights1', 'k_proj.sparse_weights2', 'v_proj.A', 'v_proj.B', 'v_proj.weights_norms_rowwise', 'v_proj.sparse_weights1', 'v_proj.sparse_weights2', 'o_proj.A', 'o_proj.B', 'o_proj.weights_norms_rowwise', 'o_proj.sparse_weights1', 'o_proj.sparse_weights2'])
Fine-tuning 7495312 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=5.85e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=1.40e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=1.02e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=9.88e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=9.80e-02	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
total size:  202375168 total Megabytes:  tensor(272.3271, device='cuda:6') bits per value:  tensor(11.2882, device='cuda:6')
Quantizing ...
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
weights.shape =  torch.Size([4096, 11008])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
Pre fine tuning: 11417 MiB free out of 48676 MiB total
Found 25 differentiable parameters
differentiable parameters: dict_keys(['self_attn.q_proj.weights_norms_rowwise', 'self_attn.q_proj.sparse_weights1', 'self_attn.q_proj.sparse_weights2', 'self_attn.q_proj.A.centriods', 'self_attn.q_proj.B.centriods', 'self_attn.k_proj.weights_norms_rowwise', 'self_attn.k_proj.sparse_weights1', 'self_attn.k_proj.sparse_weights2', 'self_attn.k_proj.A.centriods', 'self_attn.k_proj.B.centriods', 'self_attn.v_proj.weights_norms_rowwise', 'self_attn.v_proj.sparse_weights1', 'self_attn.v_proj.sparse_weights2', 'self_attn.v_proj.A.centriods', 'self_attn.v_proj.B.centriods', 'self_attn.o_proj.weights_norms_rowwise', 'self_attn.o_proj.sparse_weights1', 'self_attn.o_proj.sparse_weights2', 'self_attn.o_proj.A.centriods', 'self_attn.o_proj.B.centriods', 'mlp.w1.centriods', 'mlp.w2.centriods', 'mlp.w3.centriods', 'input_layernorm.weight', 'post_attention_layernorm.weight'])
Fine-tuning 1145552 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=7.60e-03	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=5.11e-03	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=3.70e-03	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=2.81e-03	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=2.31e-03	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
11417 MiB free out of 48676 MiB total
trying to convert back to original dtype
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
11417 MiB free out of 48676 MiB total
layer: 8
done in 0:12:13.418681 overall time: 1:49:53.618958 estimated time left: 4:40:50.359560
after cast to cpu
39287 MiB free out of 48676 MiB total
Layer 9
layer original dtype torch.float16
Performing low rank approximation
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
Pre fine tuning: 23725 MiB free out of 48676 MiB total
Found 20 differentiable parameters
differentiable parameters: dict_keys(['q_proj.A', 'q_proj.B', 'q_proj.weights_norms_rowwise', 'q_proj.sparse_weights1', 'q_proj.sparse_weights2', 'k_proj.A', 'k_proj.B', 'k_proj.weights_norms_rowwise', 'k_proj.sparse_weights1', 'k_proj.sparse_weights2', 'v_proj.A', 'v_proj.B', 'v_proj.weights_norms_rowwise', 'v_proj.sparse_weights1', 'v_proj.sparse_weights2', 'o_proj.A', 'o_proj.B', 'o_proj.weights_norms_rowwise', 'o_proj.sparse_weights1', 'o_proj.sparse_weights2'])
Fine-tuning 7495312 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=5.16e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=1.35e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=1.08e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=1.03e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=1.02e-01	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
total size:  202375168 total Megabytes:  tensor(272.3271, device='cuda:6') bits per value:  tensor(11.2882, device='cuda:6')
Quantizing ...
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
weights.shape =  torch.Size([4096, 11008])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
Pre fine tuning: 11417 MiB free out of 48676 MiB total
Found 25 differentiable parameters
differentiable parameters: dict_keys(['self_attn.q_proj.weights_norms_rowwise', 'self_attn.q_proj.sparse_weights1', 'self_attn.q_proj.sparse_weights2', 'self_attn.q_proj.A.centriods', 'self_attn.q_proj.B.centriods', 'self_attn.k_proj.weights_norms_rowwise', 'self_attn.k_proj.sparse_weights1', 'self_attn.k_proj.sparse_weights2', 'self_attn.k_proj.A.centriods', 'self_attn.k_proj.B.centriods', 'self_attn.v_proj.weights_norms_rowwise', 'self_attn.v_proj.sparse_weights1', 'self_attn.v_proj.sparse_weights2', 'self_attn.v_proj.A.centriods', 'self_attn.v_proj.B.centriods', 'self_attn.o_proj.weights_norms_rowwise', 'self_attn.o_proj.sparse_weights1', 'self_attn.o_proj.sparse_weights2', 'self_attn.o_proj.A.centriods', 'self_attn.o_proj.B.centriods', 'mlp.w1.centriods', 'mlp.w2.centriods', 'mlp.w3.centriods', 'input_layernorm.weight', 'post_attention_layernorm.weight'])
Fine-tuning 1145552 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=7.31e-03	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=5.37e-03	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=4.29e-03	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=3.50e-03	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=2.93e-03	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
11417 MiB free out of 48676 MiB total
trying to convert back to original dtype
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
11417 MiB free out of 48676 MiB total
layer: 9
done in 0:12:13.116161 overall time: 2:02:06.983135 estimated time left: 4:28:39.362896
after cast to cpu
39287 MiB free out of 48676 MiB total
Layer 10
layer original dtype torch.float16
Performing low rank approximation
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
Pre fine tuning: 23725 MiB free out of 48676 MiB total
Found 20 differentiable parameters
differentiable parameters: dict_keys(['q_proj.A', 'q_proj.B', 'q_proj.weights_norms_rowwise', 'q_proj.sparse_weights1', 'q_proj.sparse_weights2', 'k_proj.A', 'k_proj.B', 'k_proj.weights_norms_rowwise', 'k_proj.sparse_weights1', 'k_proj.sparse_weights2', 'v_proj.A', 'v_proj.B', 'v_proj.weights_norms_rowwise', 'v_proj.sparse_weights1', 'v_proj.sparse_weights2', 'o_proj.A', 'o_proj.B', 'o_proj.weights_norms_rowwise', 'o_proj.sparse_weights1', 'o_proj.sparse_weights2'])
Fine-tuning 7495312 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=3.65e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=1.37e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=1.15e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=1.09e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=1.06e-01	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
total size:  202375168 total Megabytes:  tensor(272.3271, device='cuda:6') bits per value:  tensor(11.2882, device='cuda:6')
Quantizing ...
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
weights.shape =  torch.Size([4096, 11008])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
Pre fine tuning: 11417 MiB free out of 48676 MiB total
Found 25 differentiable parameters
differentiable parameters: dict_keys(['self_attn.q_proj.weights_norms_rowwise', 'self_attn.q_proj.sparse_weights1', 'self_attn.q_proj.sparse_weights2', 'self_attn.q_proj.A.centriods', 'self_attn.q_proj.B.centriods', 'self_attn.k_proj.weights_norms_rowwise', 'self_attn.k_proj.sparse_weights1', 'self_attn.k_proj.sparse_weights2', 'self_attn.k_proj.A.centriods', 'self_attn.k_proj.B.centriods', 'self_attn.v_proj.weights_norms_rowwise', 'self_attn.v_proj.sparse_weights1', 'self_attn.v_proj.sparse_weights2', 'self_attn.v_proj.A.centriods', 'self_attn.v_proj.B.centriods', 'self_attn.o_proj.weights_norms_rowwise', 'self_attn.o_proj.sparse_weights1', 'self_attn.o_proj.sparse_weights2', 'self_attn.o_proj.A.centriods', 'self_attn.o_proj.B.centriods', 'mlp.w1.centriods', 'mlp.w2.centriods', 'mlp.w3.centriods', 'input_layernorm.weight', 'post_attention_layernorm.weight'])
Fine-tuning 1145552 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=1.74e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=1.19e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=8.57e-03	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=6.40e-03	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=5.20e-03	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
11417 MiB free out of 48676 MiB total
trying to convert back to original dtype
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
11417 MiB free out of 48676 MiB total
layer: 10
done in 0:12:14.463252 overall time: 2:14:21.705597 estimated time left: 4:16:30.528867
after cast to cpu
39287 MiB free out of 48676 MiB total
Layer 11
layer original dtype torch.float16
Performing low rank approximation
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
Pre fine tuning: 23725 MiB free out of 48676 MiB total
Found 20 differentiable parameters
differentiable parameters: dict_keys(['q_proj.A', 'q_proj.B', 'q_proj.weights_norms_rowwise', 'q_proj.sparse_weights1', 'q_proj.sparse_weights2', 'k_proj.A', 'k_proj.B', 'k_proj.weights_norms_rowwise', 'k_proj.sparse_weights1', 'k_proj.sparse_weights2', 'v_proj.A', 'v_proj.B', 'v_proj.weights_norms_rowwise', 'v_proj.sparse_weights1', 'v_proj.sparse_weights2', 'o_proj.A', 'o_proj.B', 'o_proj.weights_norms_rowwise', 'o_proj.sparse_weights1', 'o_proj.sparse_weights2'])
Fine-tuning 7495312 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=4.47e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=1.46e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=1.21e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=1.12e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=1.10e-01	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
total size:  202375168 total Megabytes:  tensor(272.3271, device='cuda:6') bits per value:  tensor(11.2882, device='cuda:6')
Quantizing ...
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
weights.shape =  torch.Size([4096, 11008])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
Pre fine tuning: 11417 MiB free out of 48676 MiB total
Found 25 differentiable parameters
differentiable parameters: dict_keys(['self_attn.q_proj.weights_norms_rowwise', 'self_attn.q_proj.sparse_weights1', 'self_attn.q_proj.sparse_weights2', 'self_attn.q_proj.A.centriods', 'self_attn.q_proj.B.centriods', 'self_attn.k_proj.weights_norms_rowwise', 'self_attn.k_proj.sparse_weights1', 'self_attn.k_proj.sparse_weights2', 'self_attn.k_proj.A.centriods', 'self_attn.k_proj.B.centriods', 'self_attn.v_proj.weights_norms_rowwise', 'self_attn.v_proj.sparse_weights1', 'self_attn.v_proj.sparse_weights2', 'self_attn.v_proj.A.centriods', 'self_attn.v_proj.B.centriods', 'self_attn.o_proj.weights_norms_rowwise', 'self_attn.o_proj.sparse_weights1', 'self_attn.o_proj.sparse_weights2', 'self_attn.o_proj.A.centriods', 'self_attn.o_proj.B.centriods', 'mlp.w1.centriods', 'mlp.w2.centriods', 'mlp.w3.centriods', 'input_layernorm.weight', 'post_attention_layernorm.weight'])
Fine-tuning 1145552 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=1.74e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=1.36e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=1.05e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=7.31e-03	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=5.34e-03	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
11417 MiB free out of 48676 MiB total
trying to convert back to original dtype
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
11417 MiB free out of 48676 MiB total
layer: 11
done in 0:12:11.424706 overall time: 2:26:33.379068 estimated time left: 4:04:15.631779
after cast to cpu
39287 MiB free out of 48676 MiB total
Layer 12
layer original dtype torch.float16
Performing low rank approximation
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
Pre fine tuning: 23725 MiB free out of 48676 MiB total
Found 20 differentiable parameters
differentiable parameters: dict_keys(['q_proj.A', 'q_proj.B', 'q_proj.weights_norms_rowwise', 'q_proj.sparse_weights1', 'q_proj.sparse_weights2', 'k_proj.A', 'k_proj.B', 'k_proj.weights_norms_rowwise', 'k_proj.sparse_weights1', 'k_proj.sparse_weights2', 'v_proj.A', 'v_proj.B', 'v_proj.weights_norms_rowwise', 'v_proj.sparse_weights1', 'v_proj.sparse_weights2', 'o_proj.A', 'o_proj.B', 'o_proj.weights_norms_rowwise', 'o_proj.sparse_weights1', 'o_proj.sparse_weights2'])
Fine-tuning 7495312 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=8.25e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=1.59e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=1.27e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=1.17e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=1.14e-01	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
total size:  202375168 total Megabytes:  tensor(272.3271, device='cuda:6') bits per value:  tensor(11.2882, device='cuda:6')
Quantizing ...
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
weights.shape =  torch.Size([4096, 11008])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
Pre fine tuning: 11417 MiB free out of 48676 MiB total
Found 25 differentiable parameters
differentiable parameters: dict_keys(['self_attn.q_proj.weights_norms_rowwise', 'self_attn.q_proj.sparse_weights1', 'self_attn.q_proj.sparse_weights2', 'self_attn.q_proj.A.centriods', 'self_attn.q_proj.B.centriods', 'self_attn.k_proj.weights_norms_rowwise', 'self_attn.k_proj.sparse_weights1', 'self_attn.k_proj.sparse_weights2', 'self_attn.k_proj.A.centriods', 'self_attn.k_proj.B.centriods', 'self_attn.v_proj.weights_norms_rowwise', 'self_attn.v_proj.sparse_weights1', 'self_attn.v_proj.sparse_weights2', 'self_attn.v_proj.A.centriods', 'self_attn.v_proj.B.centriods', 'self_attn.o_proj.weights_norms_rowwise', 'self_attn.o_proj.sparse_weights1', 'self_attn.o_proj.sparse_weights2', 'self_attn.o_proj.A.centriods', 'self_attn.o_proj.B.centriods', 'mlp.w1.centriods', 'mlp.w2.centriods', 'mlp.w3.centriods', 'input_layernorm.weight', 'post_attention_layernorm.weight'])
Fine-tuning 1145552 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=1.26e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=8.81e-03	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=6.36e-03	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=4.82e-03	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=3.97e-03	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
11417 MiB free out of 48676 MiB total
trying to convert back to original dtype
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
11417 MiB free out of 48676 MiB total
layer: 12
done in 0:12:13.447701 overall time: 2:38:47.074111 estimated time left: 3:52:04.185238
after cast to cpu
39287 MiB free out of 48676 MiB total
Layer 13
layer original dtype torch.float16
Performing low rank approximation
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
Pre fine tuning: 23725 MiB free out of 48676 MiB total
Found 20 differentiable parameters
differentiable parameters: dict_keys(['q_proj.A', 'q_proj.B', 'q_proj.weights_norms_rowwise', 'q_proj.sparse_weights1', 'q_proj.sparse_weights2', 'k_proj.A', 'k_proj.B', 'k_proj.weights_norms_rowwise', 'k_proj.sparse_weights1', 'k_proj.sparse_weights2', 'v_proj.A', 'v_proj.B', 'v_proj.weights_norms_rowwise', 'v_proj.sparse_weights1', 'v_proj.sparse_weights2', 'o_proj.A', 'o_proj.B', 'o_proj.weights_norms_rowwise', 'o_proj.sparse_weights1', 'o_proj.sparse_weights2'])
Fine-tuning 7495312 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=1.06e+00	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=1.91e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=1.45e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=1.29e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=1.24e-01	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
total size:  202375168 total Megabytes:  tensor(272.3271, device='cuda:6') bits per value:  tensor(11.2882, device='cuda:6')
Quantizing ...
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
weights.shape =  torch.Size([4096, 11008])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
Pre fine tuning: 11417 MiB free out of 48676 MiB total
Found 25 differentiable parameters
differentiable parameters: dict_keys(['self_attn.q_proj.weights_norms_rowwise', 'self_attn.q_proj.sparse_weights1', 'self_attn.q_proj.sparse_weights2', 'self_attn.q_proj.A.centriods', 'self_attn.q_proj.B.centriods', 'self_attn.k_proj.weights_norms_rowwise', 'self_attn.k_proj.sparse_weights1', 'self_attn.k_proj.sparse_weights2', 'self_attn.k_proj.A.centriods', 'self_attn.k_proj.B.centriods', 'self_attn.v_proj.weights_norms_rowwise', 'self_attn.v_proj.sparse_weights1', 'self_attn.v_proj.sparse_weights2', 'self_attn.v_proj.A.centriods', 'self_attn.v_proj.B.centriods', 'self_attn.o_proj.weights_norms_rowwise', 'self_attn.o_proj.sparse_weights1', 'self_attn.o_proj.sparse_weights2', 'self_attn.o_proj.A.centriods', 'self_attn.o_proj.B.centriods', 'mlp.w1.centriods', 'mlp.w2.centriods', 'mlp.w3.centriods', 'input_layernorm.weight', 'post_attention_layernorm.weight'])
Fine-tuning 1145552 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=1.30e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=9.47e-03	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=6.92e-03	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=5.36e-03	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=4.52e-03	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
11417 MiB free out of 48676 MiB total
trying to convert back to original dtype
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
11417 MiB free out of 48676 MiB total
layer: 13
done in 0:12:14.100633 overall time: 2:51:01.426198 estimated time left: 3:39:53.262255
after cast to cpu
39287 MiB free out of 48676 MiB total
Layer 14
layer original dtype torch.float16
Performing low rank approximation
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
Pre fine tuning: 23725 MiB free out of 48676 MiB total
Found 20 differentiable parameters
differentiable parameters: dict_keys(['q_proj.A', 'q_proj.B', 'q_proj.weights_norms_rowwise', 'q_proj.sparse_weights1', 'q_proj.sparse_weights2', 'k_proj.A', 'k_proj.B', 'k_proj.weights_norms_rowwise', 'k_proj.sparse_weights1', 'k_proj.sparse_weights2', 'v_proj.A', 'v_proj.B', 'v_proj.weights_norms_rowwise', 'v_proj.sparse_weights1', 'v_proj.sparse_weights2', 'o_proj.A', 'o_proj.B', 'o_proj.weights_norms_rowwise', 'o_proj.sparse_weights1', 'o_proj.sparse_weights2'])
Fine-tuning 7495312 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=1.10e+00	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=1.89e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=1.44e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=1.35e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=1.31e-01	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
total size:  202375168 total Megabytes:  tensor(272.3271, device='cuda:6') bits per value:  tensor(11.2882, device='cuda:6')
Quantizing ...
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
weights.shape =  torch.Size([4096, 11008])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
Pre fine tuning: 11417 MiB free out of 48676 MiB total
Found 25 differentiable parameters
differentiable parameters: dict_keys(['self_attn.q_proj.weights_norms_rowwise', 'self_attn.q_proj.sparse_weights1', 'self_attn.q_proj.sparse_weights2', 'self_attn.q_proj.A.centriods', 'self_attn.q_proj.B.centriods', 'self_attn.k_proj.weights_norms_rowwise', 'self_attn.k_proj.sparse_weights1', 'self_attn.k_proj.sparse_weights2', 'self_attn.k_proj.A.centriods', 'self_attn.k_proj.B.centriods', 'self_attn.v_proj.weights_norms_rowwise', 'self_attn.v_proj.sparse_weights1', 'self_attn.v_proj.sparse_weights2', 'self_attn.v_proj.A.centriods', 'self_attn.v_proj.B.centriods', 'self_attn.o_proj.weights_norms_rowwise', 'self_attn.o_proj.sparse_weights1', 'self_attn.o_proj.sparse_weights2', 'self_attn.o_proj.A.centriods', 'self_attn.o_proj.B.centriods', 'mlp.w1.centriods', 'mlp.w2.centriods', 'mlp.w3.centriods', 'input_layernorm.weight', 'post_attention_layernorm.weight'])
Fine-tuning 1145552 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=1.83e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=1.11e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=7.11e-03	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=5.12e-03	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=4.29e-03	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
11417 MiB free out of 48676 MiB total
trying to convert back to original dtype
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
11417 MiB free out of 48676 MiB total
layer: 14
done in 0:12:13.068979 overall time: 3:03:14.742862 estimated time left: 3:27:40.708577
after cast to cpu
39287 MiB free out of 48676 MiB total
Layer 15
layer original dtype torch.float16
Performing low rank approximation
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
Pre fine tuning: 23725 MiB free out of 48676 MiB total
Found 20 differentiable parameters
differentiable parameters: dict_keys(['q_proj.A', 'q_proj.B', 'q_proj.weights_norms_rowwise', 'q_proj.sparse_weights1', 'q_proj.sparse_weights2', 'k_proj.A', 'k_proj.B', 'k_proj.weights_norms_rowwise', 'k_proj.sparse_weights1', 'k_proj.sparse_weights2', 'v_proj.A', 'v_proj.B', 'v_proj.weights_norms_rowwise', 'v_proj.sparse_weights1', 'v_proj.sparse_weights2', 'o_proj.A', 'o_proj.B', 'o_proj.weights_norms_rowwise', 'o_proj.sparse_weights1', 'o_proj.sparse_weights2'])
Fine-tuning 7495312 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=2.40e+00	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=3.36e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=1.91e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=1.51e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=1.39e-01	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
total size:  202375168 total Megabytes:  tensor(272.3271, device='cuda:6') bits per value:  tensor(11.2882, device='cuda:6')
Quantizing ...
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
weights.shape =  torch.Size([4096, 11008])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
Pre fine tuning: 11417 MiB free out of 48676 MiB total
Found 25 differentiable parameters
differentiable parameters: dict_keys(['self_attn.q_proj.weights_norms_rowwise', 'self_attn.q_proj.sparse_weights1', 'self_attn.q_proj.sparse_weights2', 'self_attn.q_proj.A.centriods', 'self_attn.q_proj.B.centriods', 'self_attn.k_proj.weights_norms_rowwise', 'self_attn.k_proj.sparse_weights1', 'self_attn.k_proj.sparse_weights2', 'self_attn.k_proj.A.centriods', 'self_attn.k_proj.B.centriods', 'self_attn.v_proj.weights_norms_rowwise', 'self_attn.v_proj.sparse_weights1', 'self_attn.v_proj.sparse_weights2', 'self_attn.v_proj.A.centriods', 'self_attn.v_proj.B.centriods', 'self_attn.o_proj.weights_norms_rowwise', 'self_attn.o_proj.sparse_weights1', 'self_attn.o_proj.sparse_weights2', 'self_attn.o_proj.A.centriods', 'self_attn.o_proj.B.centriods', 'mlp.w1.centriods', 'mlp.w2.centriods', 'mlp.w3.centriods', 'input_layernorm.weight', 'post_attention_layernorm.weight'])
Fine-tuning 1145552 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=4.80e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=1.97e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=1.34e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=1.00e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=8.45e-03	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
11417 MiB free out of 48676 MiB total
trying to convert back to original dtype
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
11417 MiB free out of 48676 MiB total
layer: 15
done in 0:12:13.623343 overall time: 3:15:28.614791 estimated time left: 3:15:28.614791
after cast to cpu
39287 MiB free out of 48676 MiB total
Layer 16
layer original dtype torch.float16
Performing low rank approximation
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
Pre fine tuning: 23725 MiB free out of 48676 MiB total
Found 20 differentiable parameters
differentiable parameters: dict_keys(['q_proj.A', 'q_proj.B', 'q_proj.weights_norms_rowwise', 'q_proj.sparse_weights1', 'q_proj.sparse_weights2', 'k_proj.A', 'k_proj.B', 'k_proj.weights_norms_rowwise', 'k_proj.sparse_weights1', 'k_proj.sparse_weights2', 'v_proj.A', 'v_proj.B', 'v_proj.weights_norms_rowwise', 'v_proj.sparse_weights1', 'v_proj.sparse_weights2', 'o_proj.A', 'o_proj.B', 'o_proj.weights_norms_rowwise', 'o_proj.sparse_weights1', 'o_proj.sparse_weights2'])
Fine-tuning 7495312 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=3.10e+00	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=3.85e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=2.31e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=1.80e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=1.64e-01	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
total size:  202375168 total Megabytes:  tensor(272.3271, device='cuda:6') bits per value:  tensor(11.2882, device='cuda:6')
Quantizing ...
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
weights.shape =  torch.Size([4096, 11008])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
Pre fine tuning: 11417 MiB free out of 48676 MiB total
Found 25 differentiable parameters
differentiable parameters: dict_keys(['self_attn.q_proj.weights_norms_rowwise', 'self_attn.q_proj.sparse_weights1', 'self_attn.q_proj.sparse_weights2', 'self_attn.q_proj.A.centriods', 'self_attn.q_proj.B.centriods', 'self_attn.k_proj.weights_norms_rowwise', 'self_attn.k_proj.sparse_weights1', 'self_attn.k_proj.sparse_weights2', 'self_attn.k_proj.A.centriods', 'self_attn.k_proj.B.centriods', 'self_attn.v_proj.weights_norms_rowwise', 'self_attn.v_proj.sparse_weights1', 'self_attn.v_proj.sparse_weights2', 'self_attn.v_proj.A.centriods', 'self_attn.v_proj.B.centriods', 'self_attn.o_proj.weights_norms_rowwise', 'self_attn.o_proj.sparse_weights1', 'self_attn.o_proj.sparse_weights2', 'self_attn.o_proj.A.centriods', 'self_attn.o_proj.B.centriods', 'mlp.w1.centriods', 'mlp.w2.centriods', 'mlp.w3.centriods', 'input_layernorm.weight', 'post_attention_layernorm.weight'])
Fine-tuning 1145552 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=4.75e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=2.20e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=1.49e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=1.07e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=8.39e-03	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
11417 MiB free out of 48676 MiB total
trying to convert back to original dtype
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
11417 MiB free out of 48676 MiB total
layer: 16
done in 0:12:11.080405 overall time: 3:27:39.941973 estimated time left: 3:03:14.066447
after cast to cpu
39287 MiB free out of 48676 MiB total
Layer 17
layer original dtype torch.float16
Performing low rank approximation
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
Pre fine tuning: 23725 MiB free out of 48676 MiB total
Found 20 differentiable parameters
differentiable parameters: dict_keys(['q_proj.A', 'q_proj.B', 'q_proj.weights_norms_rowwise', 'q_proj.sparse_weights1', 'q_proj.sparse_weights2', 'k_proj.A', 'k_proj.B', 'k_proj.weights_norms_rowwise', 'k_proj.sparse_weights1', 'k_proj.sparse_weights2', 'v_proj.A', 'v_proj.B', 'v_proj.weights_norms_rowwise', 'v_proj.sparse_weights1', 'v_proj.sparse_weights2', 'o_proj.A', 'o_proj.B', 'o_proj.weights_norms_rowwise', 'o_proj.sparse_weights1', 'o_proj.sparse_weights2'])
Fine-tuning 7495312 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=1.51e+00	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=3.84e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=2.46e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=2.06e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=1.93e-01	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
total size:  202375168 total Megabytes:  tensor(272.3271, device='cuda:6') bits per value:  tensor(11.2882, device='cuda:6')
Quantizing ...
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
weights.shape =  torch.Size([4096, 11008])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
Pre fine tuning: 11417 MiB free out of 48676 MiB total
Found 25 differentiable parameters
differentiable parameters: dict_keys(['self_attn.q_proj.weights_norms_rowwise', 'self_attn.q_proj.sparse_weights1', 'self_attn.q_proj.sparse_weights2', 'self_attn.q_proj.A.centriods', 'self_attn.q_proj.B.centriods', 'self_attn.k_proj.weights_norms_rowwise', 'self_attn.k_proj.sparse_weights1', 'self_attn.k_proj.sparse_weights2', 'self_attn.k_proj.A.centriods', 'self_attn.k_proj.B.centriods', 'self_attn.v_proj.weights_norms_rowwise', 'self_attn.v_proj.sparse_weights1', 'self_attn.v_proj.sparse_weights2', 'self_attn.v_proj.A.centriods', 'self_attn.v_proj.B.centriods', 'self_attn.o_proj.weights_norms_rowwise', 'self_attn.o_proj.sparse_weights1', 'self_attn.o_proj.sparse_weights2', 'self_attn.o_proj.A.centriods', 'self_attn.o_proj.B.centriods', 'mlp.w1.centriods', 'mlp.w2.centriods', 'mlp.w3.centriods', 'input_layernorm.weight', 'post_attention_layernorm.weight'])
Fine-tuning 1145552 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=2.71e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=1.81e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=1.29e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=9.36e-03	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=7.37e-03	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
11417 MiB free out of 48676 MiB total
trying to convert back to original dtype
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
11417 MiB free out of 48676 MiB total
layer: 17
done in 0:12:11.580219 overall time: 3:39:51.770185 estimated time left: 2:51:00.265699
after cast to cpu
39287 MiB free out of 48676 MiB total
Layer 18
layer original dtype torch.float16
Performing low rank approximation
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
Pre fine tuning: 23725 MiB free out of 48676 MiB total
Found 20 differentiable parameters
differentiable parameters: dict_keys(['q_proj.A', 'q_proj.B', 'q_proj.weights_norms_rowwise', 'q_proj.sparse_weights1', 'q_proj.sparse_weights2', 'k_proj.A', 'k_proj.B', 'k_proj.weights_norms_rowwise', 'k_proj.sparse_weights1', 'k_proj.sparse_weights2', 'v_proj.A', 'v_proj.B', 'v_proj.weights_norms_rowwise', 'v_proj.sparse_weights1', 'v_proj.sparse_weights2', 'o_proj.A', 'o_proj.B', 'o_proj.weights_norms_rowwise', 'o_proj.sparse_weights1', 'o_proj.sparse_weights2'])
Fine-tuning 7495312 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=1.24e+00	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=3.78e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=2.58e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=2.22e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=2.09e-01	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
total size:  202375168 total Megabytes:  tensor(272.3271, device='cuda:6') bits per value:  tensor(11.2882, device='cuda:6')
Quantizing ...
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
weights.shape =  torch.Size([4096, 11008])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
Pre fine tuning: 11417 MiB free out of 48676 MiB total
Found 25 differentiable parameters
differentiable parameters: dict_keys(['self_attn.q_proj.weights_norms_rowwise', 'self_attn.q_proj.sparse_weights1', 'self_attn.q_proj.sparse_weights2', 'self_attn.q_proj.A.centriods', 'self_attn.q_proj.B.centriods', 'self_attn.k_proj.weights_norms_rowwise', 'self_attn.k_proj.sparse_weights1', 'self_attn.k_proj.sparse_weights2', 'self_attn.k_proj.A.centriods', 'self_attn.k_proj.B.centriods', 'self_attn.v_proj.weights_norms_rowwise', 'self_attn.v_proj.sparse_weights1', 'self_attn.v_proj.sparse_weights2', 'self_attn.v_proj.A.centriods', 'self_attn.v_proj.B.centriods', 'self_attn.o_proj.weights_norms_rowwise', 'self_attn.o_proj.sparse_weights1', 'self_attn.o_proj.sparse_weights2', 'self_attn.o_proj.A.centriods', 'self_attn.o_proj.B.centriods', 'mlp.w1.centriods', 'mlp.w2.centriods', 'mlp.w3.centriods', 'input_layernorm.weight', 'post_attention_layernorm.weight'])
Fine-tuning 1145552 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=2.62e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=1.66e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=1.21e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=9.25e-03	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=7.66e-03	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
11417 MiB free out of 48676 MiB total
trying to convert back to original dtype
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
11417 MiB free out of 48676 MiB total
layer: 18
done in 0:12:11.473202 overall time: 3:52:03.497839 estimated time left: 2:38:46.603785
after cast to cpu
39287 MiB free out of 48676 MiB total
Layer 19
layer original dtype torch.float16
Performing low rank approximation
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
Pre fine tuning: 23725 MiB free out of 48676 MiB total
Found 20 differentiable parameters
differentiable parameters: dict_keys(['q_proj.A', 'q_proj.B', 'q_proj.weights_norms_rowwise', 'q_proj.sparse_weights1', 'q_proj.sparse_weights2', 'k_proj.A', 'k_proj.B', 'k_proj.weights_norms_rowwise', 'k_proj.sparse_weights1', 'k_proj.sparse_weights2', 'v_proj.A', 'v_proj.B', 'v_proj.weights_norms_rowwise', 'v_proj.sparse_weights1', 'v_proj.sparse_weights2', 'o_proj.A', 'o_proj.B', 'o_proj.weights_norms_rowwise', 'o_proj.sparse_weights1', 'o_proj.sparse_weights2'])
Fine-tuning 7495312 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=9.80e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=4.17e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=2.80e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=2.33e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=2.16e-01	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
total size:  202375168 total Megabytes:  tensor(272.3271, device='cuda:6') bits per value:  tensor(11.2882, device='cuda:6')
Quantizing ...
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
weights.shape =  torch.Size([4096, 11008])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
Pre fine tuning: 11417 MiB free out of 48676 MiB total
Found 25 differentiable parameters
differentiable parameters: dict_keys(['self_attn.q_proj.weights_norms_rowwise', 'self_attn.q_proj.sparse_weights1', 'self_attn.q_proj.sparse_weights2', 'self_attn.q_proj.A.centriods', 'self_attn.q_proj.B.centriods', 'self_attn.k_proj.weights_norms_rowwise', 'self_attn.k_proj.sparse_weights1', 'self_attn.k_proj.sparse_weights2', 'self_attn.k_proj.A.centriods', 'self_attn.k_proj.B.centriods', 'self_attn.v_proj.weights_norms_rowwise', 'self_attn.v_proj.sparse_weights1', 'self_attn.v_proj.sparse_weights2', 'self_attn.v_proj.A.centriods', 'self_attn.v_proj.B.centriods', 'self_attn.o_proj.weights_norms_rowwise', 'self_attn.o_proj.sparse_weights1', 'self_attn.o_proj.sparse_weights2', 'self_attn.o_proj.A.centriods', 'self_attn.o_proj.B.centriods', 'mlp.w1.centriods', 'mlp.w2.centriods', 'mlp.w3.centriods', 'input_layernorm.weight', 'post_attention_layernorm.weight'])
Fine-tuning 1145552 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=3.60e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=2.16e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=1.48e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=1.03e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=7.94e-03	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
11417 MiB free out of 48676 MiB total
trying to convert back to original dtype
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
11417 MiB free out of 48676 MiB total
layer: 19
done in 0:12:13.302726 overall time: 4:04:17.048868 estimated time left: 2:26:34.229321
after cast to cpu
39287 MiB free out of 48676 MiB total
Layer 20
layer original dtype torch.float16
Performing low rank approximation
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
Pre fine tuning: 23725 MiB free out of 48676 MiB total
Found 20 differentiable parameters
differentiable parameters: dict_keys(['q_proj.A', 'q_proj.B', 'q_proj.weights_norms_rowwise', 'q_proj.sparse_weights1', 'q_proj.sparse_weights2', 'k_proj.A', 'k_proj.B', 'k_proj.weights_norms_rowwise', 'k_proj.sparse_weights1', 'k_proj.sparse_weights2', 'v_proj.A', 'v_proj.B', 'v_proj.weights_norms_rowwise', 'v_proj.sparse_weights1', 'v_proj.sparse_weights2', 'o_proj.A', 'o_proj.B', 'o_proj.weights_norms_rowwise', 'o_proj.sparse_weights1', 'o_proj.sparse_weights2'])
Fine-tuning 7495312 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=1.33e+00	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=4.75e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=3.15e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=2.57e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=2.35e-01	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
total size:  202375168 total Megabytes:  tensor(272.3271, device='cuda:6') bits per value:  tensor(11.2882, device='cuda:6')
Quantizing ...
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
weights.shape =  torch.Size([4096, 11008])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
Pre fine tuning: 11417 MiB free out of 48676 MiB total
Found 25 differentiable parameters
differentiable parameters: dict_keys(['self_attn.q_proj.weights_norms_rowwise', 'self_attn.q_proj.sparse_weights1', 'self_attn.q_proj.sparse_weights2', 'self_attn.q_proj.A.centriods', 'self_attn.q_proj.B.centriods', 'self_attn.k_proj.weights_norms_rowwise', 'self_attn.k_proj.sparse_weights1', 'self_attn.k_proj.sparse_weights2', 'self_attn.k_proj.A.centriods', 'self_attn.k_proj.B.centriods', 'self_attn.v_proj.weights_norms_rowwise', 'self_attn.v_proj.sparse_weights1', 'self_attn.v_proj.sparse_weights2', 'self_attn.v_proj.A.centriods', 'self_attn.v_proj.B.centriods', 'self_attn.o_proj.weights_norms_rowwise', 'self_attn.o_proj.sparse_weights1', 'self_attn.o_proj.sparse_weights2', 'self_attn.o_proj.A.centriods', 'self_attn.o_proj.B.centriods', 'mlp.w1.centriods', 'mlp.w2.centriods', 'mlp.w3.centriods', 'input_layernorm.weight', 'post_attention_layernorm.weight'])
Fine-tuning 1145552 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=3.97e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=1.48e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=1.00e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=7.62e-03	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=6.26e-03	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
11417 MiB free out of 48676 MiB total
trying to convert back to original dtype
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
11417 MiB free out of 48676 MiB total
layer: 20
done in 0:12:09.901482 overall time: 4:16:27.197993 estimated time left: 2:14:19.960853
after cast to cpu
39287 MiB free out of 48676 MiB total
Layer 21
layer original dtype torch.float16
Performing low rank approximation
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
Pre fine tuning: 23725 MiB free out of 48676 MiB total
Found 20 differentiable parameters
differentiable parameters: dict_keys(['q_proj.A', 'q_proj.B', 'q_proj.weights_norms_rowwise', 'q_proj.sparse_weights1', 'q_proj.sparse_weights2', 'k_proj.A', 'k_proj.B', 'k_proj.weights_norms_rowwise', 'k_proj.sparse_weights1', 'k_proj.sparse_weights2', 'v_proj.A', 'v_proj.B', 'v_proj.weights_norms_rowwise', 'v_proj.sparse_weights1', 'v_proj.sparse_weights2', 'o_proj.A', 'o_proj.B', 'o_proj.weights_norms_rowwise', 'o_proj.sparse_weights1', 'o_proj.sparse_weights2'])
Fine-tuning 7495312 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=9.50e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=4.98e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=3.29e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=2.68e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=2.45e-01	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
total size:  202375168 total Megabytes:  tensor(272.3271, device='cuda:6') bits per value:  tensor(11.2882, device='cuda:6')
Quantizing ...
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
weights.shape =  torch.Size([4096, 11008])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
Pre fine tuning: 11417 MiB free out of 48676 MiB total
Found 25 differentiable parameters
differentiable parameters: dict_keys(['self_attn.q_proj.weights_norms_rowwise', 'self_attn.q_proj.sparse_weights1', 'self_attn.q_proj.sparse_weights2', 'self_attn.q_proj.A.centriods', 'self_attn.q_proj.B.centriods', 'self_attn.k_proj.weights_norms_rowwise', 'self_attn.k_proj.sparse_weights1', 'self_attn.k_proj.sparse_weights2', 'self_attn.k_proj.A.centriods', 'self_attn.k_proj.B.centriods', 'self_attn.v_proj.weights_norms_rowwise', 'self_attn.v_proj.sparse_weights1', 'self_attn.v_proj.sparse_weights2', 'self_attn.v_proj.A.centriods', 'self_attn.v_proj.B.centriods', 'self_attn.o_proj.weights_norms_rowwise', 'self_attn.o_proj.sparse_weights1', 'self_attn.o_proj.sparse_weights2', 'self_attn.o_proj.A.centriods', 'self_attn.o_proj.B.centriods', 'mlp.w1.centriods', 'mlp.w2.centriods', 'mlp.w3.centriods', 'input_layernorm.weight', 'post_attention_layernorm.weight'])
Fine-tuning 1145552 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=5.12e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=2.57e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=1.80e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=1.30e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=1.03e-02	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
11417 MiB free out of 48676 MiB total
trying to convert back to original dtype
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
11417 MiB free out of 48676 MiB total
layer: 21
done in 0:12:09.965352 overall time: 4:28:37.410912 estimated time left: 2:02:06.095869
after cast to cpu
39287 MiB free out of 48676 MiB total
Layer 22
layer original dtype torch.float16
Performing low rank approximation
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
Pre fine tuning: 23725 MiB free out of 48676 MiB total
Found 20 differentiable parameters
differentiable parameters: dict_keys(['q_proj.A', 'q_proj.B', 'q_proj.weights_norms_rowwise', 'q_proj.sparse_weights1', 'q_proj.sparse_weights2', 'k_proj.A', 'k_proj.B', 'k_proj.weights_norms_rowwise', 'k_proj.sparse_weights1', 'k_proj.sparse_weights2', 'v_proj.A', 'v_proj.B', 'v_proj.weights_norms_rowwise', 'v_proj.sparse_weights1', 'v_proj.sparse_weights2', 'o_proj.A', 'o_proj.B', 'o_proj.weights_norms_rowwise', 'o_proj.sparse_weights1', 'o_proj.sparse_weights2'])
Fine-tuning 7495312 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=8.18e+00	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=7.38e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=4.22e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=3.14e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=2.77e-01	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
total size:  202375168 total Megabytes:  tensor(272.3271, device='cuda:6') bits per value:  tensor(11.2882, device='cuda:6')
Quantizing ...
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
weights.shape =  torch.Size([4096, 11008])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
Pre fine tuning: 11417 MiB free out of 48676 MiB total
Found 25 differentiable parameters
differentiable parameters: dict_keys(['self_attn.q_proj.weights_norms_rowwise', 'self_attn.q_proj.sparse_weights1', 'self_attn.q_proj.sparse_weights2', 'self_attn.q_proj.A.centriods', 'self_attn.q_proj.B.centriods', 'self_attn.k_proj.weights_norms_rowwise', 'self_attn.k_proj.sparse_weights1', 'self_attn.k_proj.sparse_weights2', 'self_attn.k_proj.A.centriods', 'self_attn.k_proj.B.centriods', 'self_attn.v_proj.weights_norms_rowwise', 'self_attn.v_proj.sparse_weights1', 'self_attn.v_proj.sparse_weights2', 'self_attn.v_proj.A.centriods', 'self_attn.v_proj.B.centriods', 'self_attn.o_proj.weights_norms_rowwise', 'self_attn.o_proj.sparse_weights1', 'self_attn.o_proj.sparse_weights2', 'self_attn.o_proj.A.centriods', 'self_attn.o_proj.B.centriods', 'mlp.w1.centriods', 'mlp.w2.centriods', 'mlp.w3.centriods', 'input_layernorm.weight', 'post_attention_layernorm.weight'])
Fine-tuning 1145552 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=4.64e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=2.67e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=1.87e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=1.34e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=1.05e-02	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
11417 MiB free out of 48676 MiB total
trying to convert back to original dtype
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
11417 MiB free out of 48676 MiB total
layer: 22
done in 0:12:13.764349 overall time: 4:40:51.430593 estimated time left: 1:49:54.038058
after cast to cpu
39287 MiB free out of 48676 MiB total
Layer 23
layer original dtype torch.float16
Performing low rank approximation
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
Pre fine tuning: 23725 MiB free out of 48676 MiB total
Found 20 differentiable parameters
differentiable parameters: dict_keys(['q_proj.A', 'q_proj.B', 'q_proj.weights_norms_rowwise', 'q_proj.sparse_weights1', 'q_proj.sparse_weights2', 'k_proj.A', 'k_proj.B', 'k_proj.weights_norms_rowwise', 'k_proj.sparse_weights1', 'k_proj.sparse_weights2', 'v_proj.A', 'v_proj.B', 'v_proj.weights_norms_rowwise', 'v_proj.sparse_weights1', 'v_proj.sparse_weights2', 'o_proj.A', 'o_proj.B', 'o_proj.weights_norms_rowwise', 'o_proj.sparse_weights1', 'o_proj.sparse_weights2'])
Fine-tuning 7495312 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=1.00e+00	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=6.05e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=3.86e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=2.98e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=2.63e-01	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
total size:  202375168 total Megabytes:  tensor(272.3271, device='cuda:6') bits per value:  tensor(11.2882, device='cuda:6')
Quantizing ...
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
weights.shape =  torch.Size([4096, 11008])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
Pre fine tuning: 11417 MiB free out of 48676 MiB total
Found 25 differentiable parameters
differentiable parameters: dict_keys(['self_attn.q_proj.weights_norms_rowwise', 'self_attn.q_proj.sparse_weights1', 'self_attn.q_proj.sparse_weights2', 'self_attn.q_proj.A.centriods', 'self_attn.q_proj.B.centriods', 'self_attn.k_proj.weights_norms_rowwise', 'self_attn.k_proj.sparse_weights1', 'self_attn.k_proj.sparse_weights2', 'self_attn.k_proj.A.centriods', 'self_attn.k_proj.B.centriods', 'self_attn.v_proj.weights_norms_rowwise', 'self_attn.v_proj.sparse_weights1', 'self_attn.v_proj.sparse_weights2', 'self_attn.v_proj.A.centriods', 'self_attn.v_proj.B.centriods', 'self_attn.o_proj.weights_norms_rowwise', 'self_attn.o_proj.sparse_weights1', 'self_attn.o_proj.sparse_weights2', 'self_attn.o_proj.A.centriods', 'self_attn.o_proj.B.centriods', 'mlp.w1.centriods', 'mlp.w2.centriods', 'mlp.w3.centriods', 'input_layernorm.weight', 'post_attention_layernorm.weight'])
Fine-tuning 1145552 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=5.83e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=2.90e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=2.10e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=1.61e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=1.30e-02	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
11417 MiB free out of 48676 MiB total
trying to convert back to original dtype
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
11417 MiB free out of 48676 MiB total
layer: 23
done in 0:13:02.228380 overall time: 4:53:53.915199 estimated time left: 1:37:57.971733
after cast to cpu
39287 MiB free out of 48676 MiB total
Layer 24
layer original dtype torch.float16
Performing low rank approximation
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
Pre fine tuning: 23725 MiB free out of 48676 MiB total
Found 20 differentiable parameters
differentiable parameters: dict_keys(['q_proj.A', 'q_proj.B', 'q_proj.weights_norms_rowwise', 'q_proj.sparse_weights1', 'q_proj.sparse_weights2', 'k_proj.A', 'k_proj.B', 'k_proj.weights_norms_rowwise', 'k_proj.sparse_weights1', 'k_proj.sparse_weights2', 'v_proj.A', 'v_proj.B', 'v_proj.weights_norms_rowwise', 'v_proj.sparse_weights1', 'v_proj.sparse_weights2', 'o_proj.A', 'o_proj.B', 'o_proj.weights_norms_rowwise', 'o_proj.sparse_weights1', 'o_proj.sparse_weights2'])
Fine-tuning 7495312 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=1.27e+00	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=7.00e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=4.32e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=3.25e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=2.83e-01	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
total size:  202375168 total Megabytes:  tensor(272.3271, device='cuda:6') bits per value:  tensor(11.2882, device='cuda:6')
Quantizing ...
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
weights.shape =  torch.Size([4096, 11008])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
Pre fine tuning: 11417 MiB free out of 48676 MiB total
Found 25 differentiable parameters
differentiable parameters: dict_keys(['self_attn.q_proj.weights_norms_rowwise', 'self_attn.q_proj.sparse_weights1', 'self_attn.q_proj.sparse_weights2', 'self_attn.q_proj.A.centriods', 'self_attn.q_proj.B.centriods', 'self_attn.k_proj.weights_norms_rowwise', 'self_attn.k_proj.sparse_weights1', 'self_attn.k_proj.sparse_weights2', 'self_attn.k_proj.A.centriods', 'self_attn.k_proj.B.centriods', 'self_attn.v_proj.weights_norms_rowwise', 'self_attn.v_proj.sparse_weights1', 'self_attn.v_proj.sparse_weights2', 'self_attn.v_proj.A.centriods', 'self_attn.v_proj.B.centriods', 'self_attn.o_proj.weights_norms_rowwise', 'self_attn.o_proj.sparse_weights1', 'self_attn.o_proj.sparse_weights2', 'self_attn.o_proj.A.centriods', 'self_attn.o_proj.B.centriods', 'mlp.w1.centriods', 'mlp.w2.centriods', 'mlp.w3.centriods', 'input_layernorm.weight', 'post_attention_layernorm.weight'])
Fine-tuning 1145552 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=6.82e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=3.24e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=2.26e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=1.67e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=1.35e-02	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
11417 MiB free out of 48676 MiB total
trying to convert back to original dtype
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
11417 MiB free out of 48676 MiB total
layer: 24
done in 0:14:06.363145 overall time: 5:08:00.527443 estimated time left: 1:26:14.547684
after cast to cpu
39287 MiB free out of 48676 MiB total
Layer 25
layer original dtype torch.float16
Performing low rank approximation
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
Pre fine tuning: 23725 MiB free out of 48676 MiB total
Found 20 differentiable parameters
differentiable parameters: dict_keys(['q_proj.A', 'q_proj.B', 'q_proj.weights_norms_rowwise', 'q_proj.sparse_weights1', 'q_proj.sparse_weights2', 'k_proj.A', 'k_proj.B', 'k_proj.weights_norms_rowwise', 'k_proj.sparse_weights1', 'k_proj.sparse_weights2', 'v_proj.A', 'v_proj.B', 'v_proj.weights_norms_rowwise', 'v_proj.sparse_weights1', 'v_proj.sparse_weights2', 'o_proj.A', 'o_proj.B', 'o_proj.weights_norms_rowwise', 'o_proj.sparse_weights1', 'o_proj.sparse_weights2'])
Fine-tuning 7495312 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=1.29e+00	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=7.49e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=4.69e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=3.62e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=3.17e-01	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
total size:  202375168 total Megabytes:  tensor(272.3271, device='cuda:6') bits per value:  tensor(11.2882, device='cuda:6')
Quantizing ...
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
weights.shape =  torch.Size([4096, 11008])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
Pre fine tuning: 11417 MiB free out of 48676 MiB total
Found 25 differentiable parameters
differentiable parameters: dict_keys(['self_attn.q_proj.weights_norms_rowwise', 'self_attn.q_proj.sparse_weights1', 'self_attn.q_proj.sparse_weights2', 'self_attn.q_proj.A.centriods', 'self_attn.q_proj.B.centriods', 'self_attn.k_proj.weights_norms_rowwise', 'self_attn.k_proj.sparse_weights1', 'self_attn.k_proj.sparse_weights2', 'self_attn.k_proj.A.centriods', 'self_attn.k_proj.B.centriods', 'self_attn.v_proj.weights_norms_rowwise', 'self_attn.v_proj.sparse_weights1', 'self_attn.v_proj.sparse_weights2', 'self_attn.v_proj.A.centriods', 'self_attn.v_proj.B.centriods', 'self_attn.o_proj.weights_norms_rowwise', 'self_attn.o_proj.sparse_weights1', 'self_attn.o_proj.sparse_weights2', 'self_attn.o_proj.A.centriods', 'self_attn.o_proj.B.centriods', 'mlp.w1.centriods', 'mlp.w2.centriods', 'mlp.w3.centriods', 'input_layernorm.weight', 'post_attention_layernorm.weight'])
Fine-tuning 1145552 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=6.44e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=4.20e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=2.99e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=2.16e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=1.65e-02	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
11417 MiB free out of 48676 MiB total
trying to convert back to original dtype
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
11417 MiB free out of 48676 MiB total
layer: 25
done in 0:13:56.221848 overall time: 5:21:57.045704 estimated time left: 1:14:17.779778
after cast to cpu
39287 MiB free out of 48676 MiB total
Layer 26
layer original dtype torch.float16
Performing low rank approximation
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
Pre fine tuning: 23725 MiB free out of 48676 MiB total
Found 20 differentiable parameters
differentiable parameters: dict_keys(['q_proj.A', 'q_proj.B', 'q_proj.weights_norms_rowwise', 'q_proj.sparse_weights1', 'q_proj.sparse_weights2', 'k_proj.A', 'k_proj.B', 'k_proj.weights_norms_rowwise', 'k_proj.sparse_weights1', 'k_proj.sparse_weights2', 'v_proj.A', 'v_proj.B', 'v_proj.weights_norms_rowwise', 'v_proj.sparse_weights1', 'v_proj.sparse_weights2', 'o_proj.A', 'o_proj.B', 'o_proj.weights_norms_rowwise', 'o_proj.sparse_weights1', 'o_proj.sparse_weights2'])
Fine-tuning 7495312 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=1.62e+00	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=9.04e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=5.30e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=3.80e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=3.20e-01	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
total size:  202375168 total Megabytes:  tensor(272.3271, device='cuda:6') bits per value:  tensor(11.2882, device='cuda:6')
Quantizing ...
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
weights.shape =  torch.Size([4096, 11008])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
Pre fine tuning: 11417 MiB free out of 48676 MiB total
Found 25 differentiable parameters
differentiable parameters: dict_keys(['self_attn.q_proj.weights_norms_rowwise', 'self_attn.q_proj.sparse_weights1', 'self_attn.q_proj.sparse_weights2', 'self_attn.q_proj.A.centriods', 'self_attn.q_proj.B.centriods', 'self_attn.k_proj.weights_norms_rowwise', 'self_attn.k_proj.sparse_weights1', 'self_attn.k_proj.sparse_weights2', 'self_attn.k_proj.A.centriods', 'self_attn.k_proj.B.centriods', 'self_attn.v_proj.weights_norms_rowwise', 'self_attn.v_proj.sparse_weights1', 'self_attn.v_proj.sparse_weights2', 'self_attn.v_proj.A.centriods', 'self_attn.v_proj.B.centriods', 'self_attn.o_proj.weights_norms_rowwise', 'self_attn.o_proj.sparse_weights1', 'self_attn.o_proj.sparse_weights2', 'self_attn.o_proj.A.centriods', 'self_attn.o_proj.B.centriods', 'mlp.w1.centriods', 'mlp.w2.centriods', 'mlp.w3.centriods', 'input_layernorm.weight', 'post_attention_layernorm.weight'])
Fine-tuning 1145552 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=6.69e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=4.16e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=3.10e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=2.34e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=1.85e-02	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
11417 MiB free out of 48676 MiB total
trying to convert back to original dtype
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
11417 MiB free out of 48676 MiB total
layer: 26
done in 0:13:53.301186 overall time: 5:35:50.613559 estimated time left: 1:02:11.595104
after cast to cpu
39287 MiB free out of 48676 MiB total
Layer 27
layer original dtype torch.float16
Performing low rank approximation
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
Pre fine tuning: 23725 MiB free out of 48676 MiB total
Found 20 differentiable parameters
differentiable parameters: dict_keys(['q_proj.A', 'q_proj.B', 'q_proj.weights_norms_rowwise', 'q_proj.sparse_weights1', 'q_proj.sparse_weights2', 'k_proj.A', 'k_proj.B', 'k_proj.weights_norms_rowwise', 'k_proj.sparse_weights1', 'k_proj.sparse_weights2', 'v_proj.A', 'v_proj.B', 'v_proj.weights_norms_rowwise', 'v_proj.sparse_weights1', 'v_proj.sparse_weights2', 'o_proj.A', 'o_proj.B', 'o_proj.weights_norms_rowwise', 'o_proj.sparse_weights1', 'o_proj.sparse_weights2'])
Fine-tuning 7495312 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=2.52e+00	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=1.21e+00	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=7.03e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=4.94e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=4.06e-01	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
total size:  202375168 total Megabytes:  tensor(272.3271, device='cuda:6') bits per value:  tensor(11.2882, device='cuda:6')
Quantizing ...
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
weights.shape =  torch.Size([4096, 11008])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
Pre fine tuning: 11417 MiB free out of 48676 MiB total
Found 25 differentiable parameters
differentiable parameters: dict_keys(['self_attn.q_proj.weights_norms_rowwise', 'self_attn.q_proj.sparse_weights1', 'self_attn.q_proj.sparse_weights2', 'self_attn.q_proj.A.centriods', 'self_attn.q_proj.B.centriods', 'self_attn.k_proj.weights_norms_rowwise', 'self_attn.k_proj.sparse_weights1', 'self_attn.k_proj.sparse_weights2', 'self_attn.k_proj.A.centriods', 'self_attn.k_proj.B.centriods', 'self_attn.v_proj.weights_norms_rowwise', 'self_attn.v_proj.sparse_weights1', 'self_attn.v_proj.sparse_weights2', 'self_attn.v_proj.A.centriods', 'self_attn.v_proj.B.centriods', 'self_attn.o_proj.weights_norms_rowwise', 'self_attn.o_proj.sparse_weights1', 'self_attn.o_proj.sparse_weights2', 'self_attn.o_proj.A.centriods', 'self_attn.o_proj.B.centriods', 'mlp.w1.centriods', 'mlp.w2.centriods', 'mlp.w3.centriods', 'input_layernorm.weight', 'post_attention_layernorm.weight'])
Fine-tuning 1145552 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=4.03e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=2.76e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=2.18e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=1.79e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=1.52e-02	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
11417 MiB free out of 48676 MiB total
trying to convert back to original dtype
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
11417 MiB free out of 48676 MiB total
layer: 27
done in 0:13:59.445752 overall time: 5:49:50.317186 estimated time left: 0:49:58.616741
after cast to cpu
39287 MiB free out of 48676 MiB total
Layer 28
layer original dtype torch.float16
Performing low rank approximation
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
Pre fine tuning: 23725 MiB free out of 48676 MiB total
Found 20 differentiable parameters
differentiable parameters: dict_keys(['q_proj.A', 'q_proj.B', 'q_proj.weights_norms_rowwise', 'q_proj.sparse_weights1', 'q_proj.sparse_weights2', 'k_proj.A', 'k_proj.B', 'k_proj.weights_norms_rowwise', 'k_proj.sparse_weights1', 'k_proj.sparse_weights2', 'v_proj.A', 'v_proj.B', 'v_proj.weights_norms_rowwise', 'v_proj.sparse_weights1', 'v_proj.sparse_weights2', 'o_proj.A', 'o_proj.B', 'o_proj.weights_norms_rowwise', 'o_proj.sparse_weights1', 'o_proj.sparse_weights2'])
Fine-tuning 7495312 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=2.57e+00	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=1.15e+00	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=6.29e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=4.41e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=3.72e-01	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
total size:  202375168 total Megabytes:  tensor(272.3271, device='cuda:6') bits per value:  tensor(11.2882, device='cuda:6')
Quantizing ...
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
weights.shape =  torch.Size([4096, 11008])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
Pre fine tuning: 11417 MiB free out of 48676 MiB total
Found 25 differentiable parameters
differentiable parameters: dict_keys(['self_attn.q_proj.weights_norms_rowwise', 'self_attn.q_proj.sparse_weights1', 'self_attn.q_proj.sparse_weights2', 'self_attn.q_proj.A.centriods', 'self_attn.q_proj.B.centriods', 'self_attn.k_proj.weights_norms_rowwise', 'self_attn.k_proj.sparse_weights1', 'self_attn.k_proj.sparse_weights2', 'self_attn.k_proj.A.centriods', 'self_attn.k_proj.B.centriods', 'self_attn.v_proj.weights_norms_rowwise', 'self_attn.v_proj.sparse_weights1', 'self_attn.v_proj.sparse_weights2', 'self_attn.v_proj.A.centriods', 'self_attn.v_proj.B.centriods', 'self_attn.o_proj.weights_norms_rowwise', 'self_attn.o_proj.sparse_weights1', 'self_attn.o_proj.sparse_weights2', 'self_attn.o_proj.A.centriods', 'self_attn.o_proj.B.centriods', 'mlp.w1.centriods', 'mlp.w2.centriods', 'mlp.w3.centriods', 'input_layernorm.weight', 'post_attention_layernorm.weight'])
Fine-tuning 1145552 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=7.47e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=4.41e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=3.26e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=2.52e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=2.07e-02	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
11417 MiB free out of 48676 MiB total
trying to convert back to original dtype
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
11417 MiB free out of 48676 MiB total
layer: 28
done in 0:13:49.363531 overall time: 6:03:39.931865 estimated time left: 0:37:37.234331
after cast to cpu
39287 MiB free out of 48676 MiB total
Layer 29
layer original dtype torch.float16
Performing low rank approximation
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
Pre fine tuning: 23725 MiB free out of 48676 MiB total
Found 20 differentiable parameters
differentiable parameters: dict_keys(['q_proj.A', 'q_proj.B', 'q_proj.weights_norms_rowwise', 'q_proj.sparse_weights1', 'q_proj.sparse_weights2', 'k_proj.A', 'k_proj.B', 'k_proj.weights_norms_rowwise', 'k_proj.sparse_weights1', 'k_proj.sparse_weights2', 'v_proj.A', 'v_proj.B', 'v_proj.weights_norms_rowwise', 'v_proj.sparse_weights1', 'v_proj.sparse_weights2', 'o_proj.A', 'o_proj.B', 'o_proj.weights_norms_rowwise', 'o_proj.sparse_weights1', 'o_proj.sparse_weights2'])
Fine-tuning 7495312 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=2.02e+01	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=1.85e+00	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=9.13e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=5.84e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=4.67e-01	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
total size:  202375168 total Megabytes:  tensor(272.3271, device='cuda:6') bits per value:  tensor(11.2882, device='cuda:6')
Quantizing ...
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
weights.shape =  torch.Size([4096, 11008])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
Pre fine tuning: 11417 MiB free out of 48676 MiB total
Found 25 differentiable parameters
differentiable parameters: dict_keys(['self_attn.q_proj.weights_norms_rowwise', 'self_attn.q_proj.sparse_weights1', 'self_attn.q_proj.sparse_weights2', 'self_attn.q_proj.A.centriods', 'self_attn.q_proj.B.centriods', 'self_attn.k_proj.weights_norms_rowwise', 'self_attn.k_proj.sparse_weights1', 'self_attn.k_proj.sparse_weights2', 'self_attn.k_proj.A.centriods', 'self_attn.k_proj.B.centriods', 'self_attn.v_proj.weights_norms_rowwise', 'self_attn.v_proj.sparse_weights1', 'self_attn.v_proj.sparse_weights2', 'self_attn.v_proj.A.centriods', 'self_attn.v_proj.B.centriods', 'self_attn.o_proj.weights_norms_rowwise', 'self_attn.o_proj.sparse_weights1', 'self_attn.o_proj.sparse_weights2', 'self_attn.o_proj.A.centriods', 'self_attn.o_proj.B.centriods', 'mlp.w1.centriods', 'mlp.w2.centriods', 'mlp.w3.centriods', 'input_layernorm.weight', 'post_attention_layernorm.weight'])
Fine-tuning 1145552 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=1.17e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=8.20e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=6.30e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=4.83e-02	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=3.72e-02	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
11417 MiB free out of 48676 MiB total
trying to convert back to original dtype
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
11417 MiB free out of 48676 MiB total
layer: 29
done in 0:14:00.018979 overall time: 6:17:40.241411 estimated time left: 0:25:10.682761
after cast to cpu
39287 MiB free out of 48676 MiB total
Layer 30
layer original dtype torch.float16
Performing low rank approximation
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
Pre fine tuning: 23725 MiB free out of 48676 MiB total
Found 20 differentiable parameters
differentiable parameters: dict_keys(['q_proj.A', 'q_proj.B', 'q_proj.weights_norms_rowwise', 'q_proj.sparse_weights1', 'q_proj.sparse_weights2', 'k_proj.A', 'k_proj.B', 'k_proj.weights_norms_rowwise', 'k_proj.sparse_weights1', 'k_proj.sparse_weights2', 'v_proj.A', 'v_proj.B', 'v_proj.weights_norms_rowwise', 'v_proj.sparse_weights1', 'v_proj.sparse_weights2', 'o_proj.A', 'o_proj.B', 'o_proj.weights_norms_rowwise', 'o_proj.sparse_weights1', 'o_proj.sparse_weights2'])
Fine-tuning 7495312 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=3.65e+01	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=4.57e+00	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=2.76e+00	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=2.13e+00	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=1.94e+00	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
total size:  202375168 total Megabytes:  tensor(272.3271, device='cuda:6') bits per value:  tensor(11.2882, device='cuda:6')
Quantizing ...
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
weights.shape =  torch.Size([4096, 11008])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
Pre fine tuning: 11417 MiB free out of 48676 MiB total
Found 25 differentiable parameters
differentiable parameters: dict_keys(['self_attn.q_proj.weights_norms_rowwise', 'self_attn.q_proj.sparse_weights1', 'self_attn.q_proj.sparse_weights2', 'self_attn.q_proj.A.centriods', 'self_attn.q_proj.B.centriods', 'self_attn.k_proj.weights_norms_rowwise', 'self_attn.k_proj.sparse_weights1', 'self_attn.k_proj.sparse_weights2', 'self_attn.k_proj.A.centriods', 'self_attn.k_proj.B.centriods', 'self_attn.v_proj.weights_norms_rowwise', 'self_attn.v_proj.sparse_weights1', 'self_attn.v_proj.sparse_weights2', 'self_attn.v_proj.A.centriods', 'self_attn.v_proj.B.centriods', 'self_attn.o_proj.weights_norms_rowwise', 'self_attn.o_proj.sparse_weights1', 'self_attn.o_proj.sparse_weights2', 'self_attn.o_proj.A.centriods', 'self_attn.o_proj.B.centriods', 'mlp.w1.centriods', 'mlp.w2.centriods', 'mlp.w3.centriods', 'input_layernorm.weight', 'post_attention_layernorm.weight'])
Fine-tuning 1145552 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=1.73e+00	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=1.65e+00	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=1.61e+00	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=1.59e+00	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=1.58e+00	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
11417 MiB free out of 48676 MiB total
trying to convert back to original dtype
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
11417 MiB free out of 48676 MiB total
layer: 30
done in 0:13:35.188459 overall time: 6:31:15.681267 estimated time left: 0:12:37.280041
after cast to cpu
39287 MiB free out of 48676 MiB total
Layer 31
layer original dtype torch.float16
Performing low rank approximation
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
using low rank =  196
row mask =  4072 column mask =  4052
Pre fine tuning: 23725 MiB free out of 48676 MiB total
Found 20 differentiable parameters
differentiable parameters: dict_keys(['q_proj.A', 'q_proj.B', 'q_proj.weights_norms_rowwise', 'q_proj.sparse_weights1', 'q_proj.sparse_weights2', 'k_proj.A', 'k_proj.B', 'k_proj.weights_norms_rowwise', 'k_proj.sparse_weights1', 'k_proj.sparse_weights2', 'v_proj.A', 'v_proj.B', 'v_proj.weights_norms_rowwise', 'v_proj.sparse_weights1', 'v_proj.sparse_weights2', 'o_proj.A', 'o_proj.B', 'o_proj.weights_norms_rowwise', 'o_proj.sparse_weights1', 'o_proj.sparse_weights2'])
Fine-tuning 7495312 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=1.79e+03	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=7.40e+01	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=4.66e+01	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=4.46e+01	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=3.08e+01	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
total size:  202375168 total Megabytes:  tensor(272.3271, device='cuda:6') bits per value:  tensor(11.2882, device='cuda:6')
Quantizing ...
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
A.shape =  torch.Size([4072, 196]) B.shape =  torch.Size([196, 4052])
weights.shape =  torch.Size([4072, 196])
quantized
weights.shape =  torch.Size([196, 4052])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
weights.shape =  torch.Size([4096, 11008])
quantized
weights.shape =  torch.Size([11008, 4096])
quantized
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
Pre fine tuning: 11417 MiB free out of 48676 MiB total
Found 25 differentiable parameters
differentiable parameters: dict_keys(['self_attn.q_proj.weights_norms_rowwise', 'self_attn.q_proj.sparse_weights1', 'self_attn.q_proj.sparse_weights2', 'self_attn.q_proj.A.centriods', 'self_attn.q_proj.B.centriods', 'self_attn.k_proj.weights_norms_rowwise', 'self_attn.k_proj.sparse_weights1', 'self_attn.k_proj.sparse_weights2', 'self_attn.k_proj.A.centriods', 'self_attn.k_proj.B.centriods', 'self_attn.v_proj.weights_norms_rowwise', 'self_attn.v_proj.sparse_weights1', 'self_attn.v_proj.sparse_weights2', 'self_attn.v_proj.A.centriods', 'self_attn.v_proj.B.centriods', 'self_attn.o_proj.weights_norms_rowwise', 'self_attn.o_proj.sparse_weights1', 'self_attn.o_proj.sparse_weights2', 'self_attn.o_proj.A.centriods', 'self_attn.o_proj.B.centriods', 'mlp.w1.centriods', 'mlp.w2.centriods', 'mlp.w3.centriods', 'input_layernorm.weight', 'post_attention_layernorm.weight'])
Fine-tuning 1145552 parameters
train_inps[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
train_outs[0] torch.Size([128, 4096, 4096]) cuda:6 torch.float32
----------
epoch=0
train loss=2.23e+00	
11417 MiB free out of 48676 MiB total
----------
epoch=1
train loss=7.21e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=2
train loss=4.15e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=3
train loss=3.15e-01	
11417 MiB free out of 48676 MiB total
----------
epoch=4
train loss=2.57e-01	
11417 MiB free out of 48676 MiB total
post_fine_tuning 11417 MiB free out of 48676 MiB total
11417 MiB free out of 48676 MiB total
trying to convert back to original dtype
total size:  202375168 total Megabytes:  tensor(35.9689, device='cuda:6') bits per value:  tensor(1.4909, device='cuda:6')
11417 MiB free out of 48676 MiB total
layer: 31
done in 0:13:40.561931 overall time: 6:44:56.505378 estimated time left: 0:00:00
after cast to cpu
39287 MiB free out of 48676 MiB total
Total bits: tensor(19310641152, device='cuda:6') Total params: 12952010752
average bits per value: tensor(1.4909, device='cuda:6')
24298.640424013138
Loading tokenizer for meta-llama/Llama-2-7b-hf
/home/lliu/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Dataset: wikitext2
Evaluating ...
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
Perplexity: 2762.129395
