/home/lliu/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.32it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.21it/s]
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Token indices sequence length is longer than the specified maximum sequence length for this model (2824491 > 2048). Running this sequence through the model will result in indexing errors
Starting...
Ready.
0 self_attn.q_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
83 H_error tensor(2.1266, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3915, device='cuda:6', grad_fn=<DivBackward0>)
37602 MiB free out of 48676 MiB total
0 self_attn.k_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
80 H_error tensor(2.0421, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3844, device='cuda:6', grad_fn=<DivBackward0>)
37666 MiB free out of 48676 MiB total
0 self_attn.v_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
80 H_error tensor(0.2076, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3458, device='cuda:6', grad_fn=<DivBackward0>)
37698 MiB free out of 48676 MiB total
0 self_attn.o_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
84 H_error tensor(0.0153, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3823, device='cuda:6', grad_fn=<DivBackward0>)
36798 MiB free out of 48676 MiB total
0 mlp.gate_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
200 H_error tensor(2.3010, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3143, device='cuda:6', grad_fn=<DivBackward0>)
36860 MiB free out of 48676 MiB total
0 mlp.up_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
198 H_error tensor(2.1516, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3133, device='cuda:6', grad_fn=<DivBackward0>)
36944 MiB free out of 48676 MiB total
0 mlp.down_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 2752])
215 H_error tensor(0.0221, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3183, device='cuda:6', grad_fn=<DivBackward0>)
36796 MiB free out of 48676 MiB total
1 self_attn.q_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
82 H_error tensor(14.2213, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3741, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
1 self_attn.k_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
81 H_error tensor(15.7783, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3769, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
1 self_attn.v_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
79 H_error tensor(0.9507, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3416, device='cuda:6', grad_fn=<DivBackward0>)
37460 MiB free out of 48676 MiB total
1 self_attn.o_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
90 H_error tensor(0.0947, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3689, device='cuda:6', grad_fn=<DivBackward0>)
36634 MiB free out of 48676 MiB total
1 mlp.gate_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
200 H_error tensor(9.0006, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3074, device='cuda:6', grad_fn=<DivBackward0>)
36786 MiB free out of 48676 MiB total
1 mlp.up_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
200 H_error tensor(7.9593, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3055, device='cuda:6', grad_fn=<DivBackward0>)
36740 MiB free out of 48676 MiB total
1 mlp.down_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 2752])
217 H_error tensor(0.0851, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3082, device='cuda:6', grad_fn=<DivBackward0>)
36644 MiB free out of 48676 MiB total
2 self_attn.q_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
80 H_error tensor(24.2359, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3415, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
2 self_attn.k_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
80 H_error tensor(27.1277, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3479, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
2 self_attn.v_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
reducing lr to  3.8152042447694614e-05
reducing lr to  3.433683820292515e-05
reducing lr to  3.090315438263264e-05
reducing lr to  2.7812838944369376e-05
reducing lr to  2.503155504993244e-05
reducing lr to  2.2528399544939195e-05
reducing lr to  2.0275559590445276e-05
reducing lr to  1.8248003631400748e-05
reducing lr to  1.6423203268260675e-05
reducing lr to  1.4780882941434607e-05
reducing lr to  1.3302794647291146e-05
78 H_error tensor(2.5452, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3130, device='cuda:6', grad_fn=<DivBackward0>)
37460 MiB free out of 48676 MiB total
2 self_attn.o_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
80 H_error tensor(0.2178, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3155, device='cuda:6', grad_fn=<DivBackward0>)
36634 MiB free out of 48676 MiB total
2 mlp.gate_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
200 H_error tensor(19.3672, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3056, device='cuda:6', grad_fn=<DivBackward0>)
36784 MiB free out of 48676 MiB total
2 mlp.up_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
197 H_error tensor(15.8613, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3037, device='cuda:6', grad_fn=<DivBackward0>)
36740 MiB free out of 48676 MiB total
2 mlp.down_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 2752])
reducing lr to  0.0009000000000000001
217 H_error tensor(-56.2420, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.4354, device='cuda:6', grad_fn=<DivBackward0>)
36644 MiB free out of 48676 MiB total
3 self_attn.q_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
79 H_error tensor(44.4679, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3319, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
3 self_attn.k_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
80 H_error tensor(52.0619, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3387, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
3 self_attn.v_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
79 H_error tensor(11.1264, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3096, device='cuda:6', grad_fn=<DivBackward0>)
37460 MiB free out of 48676 MiB total
3 self_attn.o_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
80 H_error tensor(0.5565, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3457, device='cuda:6', grad_fn=<DivBackward0>)
36634 MiB free out of 48676 MiB total
3 mlp.gate_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
200 H_error tensor(33.9200, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3068, device='cuda:6', grad_fn=<DivBackward0>)
36784 MiB free out of 48676 MiB total
3 mlp.up_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
197 H_error tensor(27.9486, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3049, device='cuda:6', grad_fn=<DivBackward0>)
36740 MiB free out of 48676 MiB total
3 mlp.down_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 2752])
215 H_error tensor(0.3704, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3092, device='cuda:6', grad_fn=<DivBackward0>)
36644 MiB free out of 48676 MiB total
4 self_attn.q_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
79 H_error tensor(67.8196, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3328, device='cuda:6', grad_fn=<DivBackward0>)
37394 MiB free out of 48676 MiB total
4 self_attn.k_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
80 H_error tensor(73.3331, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3373, device='cuda:6', grad_fn=<DivBackward0>)
37394 MiB free out of 48676 MiB total
4 self_attn.v_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
79 H_error tensor(17.0578, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3140, device='cuda:6', grad_fn=<DivBackward0>)
37460 MiB free out of 48676 MiB total
4 self_attn.o_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
79 H_error tensor(0.8449, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3448, device='cuda:6', grad_fn=<DivBackward0>)
36634 MiB free out of 48676 MiB total
4 mlp.gate_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
196 H_error tensor(44.3450, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3093, device='cuda:6', grad_fn=<DivBackward0>)
36786 MiB free out of 48676 MiB total
4 mlp.up_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
199 H_error tensor(35.9639, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3066, device='cuda:6', grad_fn=<DivBackward0>)
36740 MiB free out of 48676 MiB total
4 mlp.down_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 2752])
214 H_error tensor(0.5264, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3116, device='cuda:6', grad_fn=<DivBackward0>)
36644 MiB free out of 48676 MiB total
5 self_attn.q_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
79 H_error tensor(96.0716, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3324, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
5 self_attn.k_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
80 H_error tensor(101.3313, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3343, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
5 self_attn.v_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
79 H_error tensor(28.0780, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3125, device='cuda:6', grad_fn=<DivBackward0>)
37460 MiB free out of 48676 MiB total
5 self_attn.o_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
79 H_error tensor(1.2117, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3464, device='cuda:6', grad_fn=<DivBackward0>)
36636 MiB free out of 48676 MiB total
5 mlp.gate_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
199 H_error tensor(58.1952, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3113, device='cuda:6', grad_fn=<DivBackward0>)
36784 MiB free out of 48676 MiB total
5 mlp.up_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
198 H_error tensor(44.4347, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3069, device='cuda:6', grad_fn=<DivBackward0>)
36740 MiB free out of 48676 MiB total
5 mlp.down_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 2752])
215 H_error tensor(0.7069, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3129, device='cuda:6', grad_fn=<DivBackward0>)
36644 MiB free out of 48676 MiB total
6 self_attn.q_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
79 H_error tensor(97.3523, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3308, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
6 self_attn.k_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
80 H_error tensor(102.6830, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3329, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
6 self_attn.v_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
79 H_error tensor(28.9839, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3136, device='cuda:6', grad_fn=<DivBackward0>)
37460 MiB free out of 48676 MiB total
6 self_attn.o_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
79 H_error tensor(1.4083, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3462, device='cuda:6', grad_fn=<DivBackward0>)
36634 MiB free out of 48676 MiB total
6 mlp.gate_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
200 H_error tensor(65.5520, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3109, device='cuda:6', grad_fn=<DivBackward0>)
36784 MiB free out of 48676 MiB total
6 mlp.up_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
197 H_error tensor(52.7625, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3072, device='cuda:6', grad_fn=<DivBackward0>)
36740 MiB free out of 48676 MiB total
6 mlp.down_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 2752])
216 H_error tensor(0.8813, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3141, device='cuda:6', grad_fn=<DivBackward0>)
36644 MiB free out of 48676 MiB total
7 self_attn.q_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
79 H_error tensor(102.7193, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3338, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
7 self_attn.k_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
80 H_error tensor(107.6163, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3355, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
7 self_attn.v_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
79 H_error tensor(33.2708, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3149, device='cuda:6', grad_fn=<DivBackward0>)
37460 MiB free out of 48676 MiB total
7 self_attn.o_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
79 H_error tensor(2.7396, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3328, device='cuda:6', grad_fn=<DivBackward0>)
36634 MiB free out of 48676 MiB total
7 mlp.gate_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
200 H_error tensor(68.0608, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3118, device='cuda:6', grad_fn=<DivBackward0>)
36784 MiB free out of 48676 MiB total
7 mlp.up_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
198 H_error tensor(55.8347, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3073, device='cuda:6', grad_fn=<DivBackward0>)
36740 MiB free out of 48676 MiB total
7 mlp.down_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 2752])
213 H_error tensor(1.0880, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3152, device='cuda:6', grad_fn=<DivBackward0>)
36644 MiB free out of 48676 MiB total
8 self_attn.q_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
80 H_error tensor(112.9916, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3351, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
8 self_attn.k_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
80 H_error tensor(116.5001, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3364, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
8 self_attn.v_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
reducing lr to  3.8152042447694614e-05
reducing lr to  3.433683820292515e-05
79 H_error tensor(37.2244, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3139, device='cuda:6', grad_fn=<DivBackward0>)
37460 MiB free out of 48676 MiB total
8 self_attn.o_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
79 H_error tensor(3.9929, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3313, device='cuda:6', grad_fn=<DivBackward0>)
36636 MiB free out of 48676 MiB total
8 mlp.gate_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
201 H_error tensor(72.2592, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3132, device='cuda:6', grad_fn=<DivBackward0>)
36786 MiB free out of 48676 MiB total
8 mlp.up_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
200 H_error tensor(60.0238, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3074, device='cuda:6', grad_fn=<DivBackward0>)
36742 MiB free out of 48676 MiB total
8 mlp.down_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 2752])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
215 H_error tensor(1.2756, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3176, device='cuda:6', grad_fn=<DivBackward0>)
36644 MiB free out of 48676 MiB total
9 self_attn.q_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
79 H_error tensor(126.0269, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3363, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
9 self_attn.k_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
80 H_error tensor(128.6176, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3372, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
9 self_attn.v_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
79 H_error tensor(41.5303, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3128, device='cuda:6', grad_fn=<DivBackward0>)
37460 MiB free out of 48676 MiB total
9 self_attn.o_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
79 H_error tensor(5.7294, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3264, device='cuda:6', grad_fn=<DivBackward0>)
36636 MiB free out of 48676 MiB total
9 mlp.gate_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
201 H_error tensor(74.2680, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3124, device='cuda:6', grad_fn=<DivBackward0>)
36784 MiB free out of 48676 MiB total
9 mlp.up_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
198 H_error tensor(64.2077, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3070, device='cuda:6', grad_fn=<DivBackward0>)
36740 MiB free out of 48676 MiB total
9 mlp.down_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 2752])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
215 H_error tensor(1.5157, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3192, device='cuda:6', grad_fn=<DivBackward0>)
36644 MiB free out of 48676 MiB total
10 self_attn.q_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
79 H_error tensor(113.4476, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3746, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
10 self_attn.k_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
80 H_error tensor(129.4998, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3452, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
10 self_attn.v_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
78 H_error tensor(40.2243, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3277, device='cuda:6', grad_fn=<DivBackward0>)
37460 MiB free out of 48676 MiB total
10 self_attn.o_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
80 H_error tensor(9.2807, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3254, device='cuda:6', grad_fn=<DivBackward0>)
36634 MiB free out of 48676 MiB total
10 mlp.gate_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
198 H_error tensor(78.1051, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3122, device='cuda:6', grad_fn=<DivBackward0>)
36786 MiB free out of 48676 MiB total
10 mlp.up_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
199 H_error tensor(69.8350, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3071, device='cuda:6', grad_fn=<DivBackward0>)
36742 MiB free out of 48676 MiB total
10 mlp.down_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 2752])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
213 H_error tensor(1.6881, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3202, device='cuda:6', grad_fn=<DivBackward0>)
36644 MiB free out of 48676 MiB total
11 self_attn.q_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
79 H_error tensor(107.2966, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3473, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
11 self_attn.k_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
80 H_error tensor(116.4388, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3321, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
11 self_attn.v_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
79 H_error tensor(41.0608, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3215, device='cuda:6', grad_fn=<DivBackward0>)
37458 MiB free out of 48676 MiB total
11 self_attn.o_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
79 H_error tensor(9.8650, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3182, device='cuda:6', grad_fn=<DivBackward0>)
36634 MiB free out of 48676 MiB total
11 mlp.gate_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
200 H_error tensor(78.8414, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3131, device='cuda:6', grad_fn=<DivBackward0>)
36786 MiB free out of 48676 MiB total
11 mlp.up_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
199 H_error tensor(72.3736, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3073, device='cuda:6', grad_fn=<DivBackward0>)
36740 MiB free out of 48676 MiB total
11 mlp.down_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 2752])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
213 H_error tensor(2.0753, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3207, device='cuda:6', grad_fn=<DivBackward0>)
36644 MiB free out of 48676 MiB total
12 self_attn.q_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
79 H_error tensor(138.9016, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3318, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
12 self_attn.k_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
80 H_error tensor(146.7226, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3343, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
12 self_attn.v_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
79 H_error tensor(54.7653, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3113, device='cuda:6', grad_fn=<DivBackward0>)
37460 MiB free out of 48676 MiB total
12 self_attn.o_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
79 H_error tensor(12.4253, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3225, device='cuda:6', grad_fn=<DivBackward0>)
36634 MiB free out of 48676 MiB total
12 mlp.gate_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
200 H_error tensor(92.7847, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3130, device='cuda:6', grad_fn=<DivBackward0>)
36786 MiB free out of 48676 MiB total
12 mlp.up_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
199 H_error tensor(84.3388, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3066, device='cuda:6', grad_fn=<DivBackward0>)
36740 MiB free out of 48676 MiB total
12 mlp.down_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 2752])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
214 H_error tensor(2.4119, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3186, device='cuda:6', grad_fn=<DivBackward0>)
36644 MiB free out of 48676 MiB total
13 self_attn.q_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
79 H_error tensor(130.2893, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3842, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
13 self_attn.k_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
80 H_error tensor(151.2785, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3436, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
13 self_attn.v_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
79 H_error tensor(29.7654, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3837, device='cuda:6', grad_fn=<DivBackward0>)
37460 MiB free out of 48676 MiB total
13 self_attn.o_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
79 H_error tensor(12.5995, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3243, device='cuda:6', grad_fn=<DivBackward0>)
36636 MiB free out of 48676 MiB total
13 mlp.gate_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
200 H_error tensor(97.4135, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3111, device='cuda:6', grad_fn=<DivBackward0>)
36784 MiB free out of 48676 MiB total
13 mlp.up_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
198 H_error tensor(92.3351, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3063, device='cuda:6', grad_fn=<DivBackward0>)
36740 MiB free out of 48676 MiB total
13 mlp.down_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 2752])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
215 H_error tensor(2.6059, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3185, device='cuda:6', grad_fn=<DivBackward0>)
36644 MiB free out of 48676 MiB total
14 self_attn.q_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
79 H_error tensor(139.6863, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3308, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
14 self_attn.k_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
79 H_error tensor(146.1285, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3328, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
14 self_attn.v_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
79 H_error tensor(63.8581, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3118, device='cuda:6', grad_fn=<DivBackward0>)
37460 MiB free out of 48676 MiB total
14 self_attn.o_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
79 H_error tensor(13.0086, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3249, device='cuda:6', grad_fn=<DivBackward0>)
36636 MiB free out of 48676 MiB total
14 mlp.gate_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
200 H_error tensor(108.4073, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3114, device='cuda:6', grad_fn=<DivBackward0>)
36784 MiB free out of 48676 MiB total
14 mlp.up_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
199 H_error tensor(104.1682, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3069, device='cuda:6', grad_fn=<DivBackward0>)
36740 MiB free out of 48676 MiB total
14 mlp.down_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 2752])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
215 H_error tensor(3.0127, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3197, device='cuda:6', grad_fn=<DivBackward0>)
36644 MiB free out of 48676 MiB total
15 self_attn.q_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
79 H_error tensor(147.1204, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3320, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
15 self_attn.k_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
80 H_error tensor(154.7241, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3352, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
15 self_attn.v_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
reducing lr to  3.8152042447694614e-05
reducing lr to  3.433683820292515e-05
reducing lr to  3.090315438263264e-05
79 H_error tensor(64.8684, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3108, device='cuda:6', grad_fn=<DivBackward0>)
37460 MiB free out of 48676 MiB total
15 self_attn.o_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
79 H_error tensor(12.0933, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3195, device='cuda:6', grad_fn=<DivBackward0>)
36634 MiB free out of 48676 MiB total
15 mlp.gate_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
198 H_error tensor(118.2553, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3100, device='cuda:6', grad_fn=<DivBackward0>)
36784 MiB free out of 48676 MiB total
15 mlp.up_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
198 H_error tensor(113.7462, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3056, device='cuda:6', grad_fn=<DivBackward0>)
36740 MiB free out of 48676 MiB total
15 mlp.down_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 2752])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
212 H_error tensor(3.8013, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3175, device='cuda:6', grad_fn=<DivBackward0>)
36644 MiB free out of 48676 MiB total
16 self_attn.q_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
79 H_error tensor(135.3477, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3251, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
16 self_attn.k_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
79 H_error tensor(145.0680, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3288, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
16 self_attn.v_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
reducing lr to  3.8152042447694614e-05
reducing lr to  3.433683820292515e-05
reducing lr to  3.090315438263264e-05
79 H_error tensor(72.4963, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3089, device='cuda:6', grad_fn=<DivBackward0>)
37460 MiB free out of 48676 MiB total
16 self_attn.o_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
79 H_error tensor(12.2925, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3207, device='cuda:6', grad_fn=<DivBackward0>)
36636 MiB free out of 48676 MiB total
16 mlp.gate_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
199 H_error tensor(134.2545, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3104, device='cuda:6', grad_fn=<DivBackward0>)
36784 MiB free out of 48676 MiB total
16 mlp.up_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
198 H_error tensor(126.3800, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3056, device='cuda:6', grad_fn=<DivBackward0>)
36740 MiB free out of 48676 MiB total
16 mlp.down_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 2752])
213 H_error tensor(5.1670, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3178, device='cuda:6', grad_fn=<DivBackward0>)
36644 MiB free out of 48676 MiB total
17 self_attn.q_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
79 H_error tensor(146.0322, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3259, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
17 self_attn.k_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
80 H_error tensor(155.5710, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3287, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
17 self_attn.v_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
reducing lr to  3.8152042447694614e-05
79 H_error tensor(81.6553, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3089, device='cuda:6', grad_fn=<DivBackward0>)
37460 MiB free out of 48676 MiB total
17 self_attn.o_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
80 H_error tensor(16.0115, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3185, device='cuda:6', grad_fn=<DivBackward0>)
36636 MiB free out of 48676 MiB total
17 mlp.gate_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
198 H_error tensor(147.9645, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3086, device='cuda:6', grad_fn=<DivBackward0>)
36784 MiB free out of 48676 MiB total
17 mlp.up_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
reducing lr to  3.8152042447694614e-05
reducing lr to  3.433683820292515e-05
reducing lr to  3.090315438263264e-05
197 H_error tensor(139.3185, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3049, device='cuda:6', grad_fn=<DivBackward0>)
36742 MiB free out of 48676 MiB total
17 mlp.down_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 2752])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
212 H_error tensor(6.2561, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3157, device='cuda:6', grad_fn=<DivBackward0>)
36644 MiB free out of 48676 MiB total
18 self_attn.q_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
80 H_error tensor(149.6095, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3299, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
18 self_attn.k_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
80 H_error tensor(155.2055, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3313, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
18 self_attn.v_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
reducing lr to  3.8152042447694614e-05
reducing lr to  3.433683820292515e-05
reducing lr to  3.090315438263264e-05
79 H_error tensor(83.1576, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3084, device='cuda:6', grad_fn=<DivBackward0>)
37460 MiB free out of 48676 MiB total
18 self_attn.o_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
79 H_error tensor(20.7638, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3126, device='cuda:6', grad_fn=<DivBackward0>)
36636 MiB free out of 48676 MiB total
18 mlp.gate_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
200 H_error tensor(164.8170, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3077, device='cuda:6', grad_fn=<DivBackward0>)
36786 MiB free out of 48676 MiB total
18 mlp.up_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
198 H_error tensor(151.8766, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3040, device='cuda:6', grad_fn=<DivBackward0>)
36742 MiB free out of 48676 MiB total
18 mlp.down_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 2752])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
215 H_error tensor(7.3196, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3134, device='cuda:6', grad_fn=<DivBackward0>)
36644 MiB free out of 48676 MiB total
19 self_attn.q_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
79 H_error tensor(91.1408, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.4263, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
19 self_attn.k_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
80 H_error tensor(114.7607, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.4091, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
19 self_attn.v_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
79 H_error tensor(41.1204, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3630, device='cuda:6', grad_fn=<DivBackward0>)
37460 MiB free out of 48676 MiB total
19 self_attn.o_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
79 H_error tensor(20.7381, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3169, device='cuda:6', grad_fn=<DivBackward0>)
36636 MiB free out of 48676 MiB total
19 mlp.gate_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
199 H_error tensor(176.1917, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3075, device='cuda:6', grad_fn=<DivBackward0>)
36786 MiB free out of 48676 MiB total
19 mlp.up_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
199 H_error tensor(159.6137, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3040, device='cuda:6', grad_fn=<DivBackward0>)
36742 MiB free out of 48676 MiB total
19 mlp.down_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 2752])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
213 H_error tensor(8.1785, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3133, device='cuda:6', grad_fn=<DivBackward0>)
36644 MiB free out of 48676 MiB total
20 self_attn.q_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
79 H_error tensor(125.2897, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3663, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
20 self_attn.k_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
79 H_error tensor(139.5208, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3590, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
20 self_attn.v_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
79 H_error tensor(54.9062, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3679, device='cuda:6', grad_fn=<DivBackward0>)
37460 MiB free out of 48676 MiB total
20 self_attn.o_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
79 H_error tensor(19.7856, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3172, device='cuda:6', grad_fn=<DivBackward0>)
36634 MiB free out of 48676 MiB total
20 mlp.gate_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
198 H_error tensor(186.9796, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3070, device='cuda:6', grad_fn=<DivBackward0>)
36786 MiB free out of 48676 MiB total
20 mlp.up_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
198 H_error tensor(168.6003, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3038, device='cuda:6', grad_fn=<DivBackward0>)
36742 MiB free out of 48676 MiB total
20 mlp.down_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 2752])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
214 H_error tensor(9.4079, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3122, device='cuda:6', grad_fn=<DivBackward0>)
36644 MiB free out of 48676 MiB total
21 self_attn.q_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
80 H_error tensor(134.9710, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3319, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
21 self_attn.k_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
80 H_error tensor(142.1597, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3339, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
21 self_attn.v_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
reducing lr to  3.8152042447694614e-05
reducing lr to  3.433683820292515e-05
reducing lr to  3.090315438263264e-05
79 H_error tensor(100.0607, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3138, device='cuda:6', grad_fn=<DivBackward0>)
37460 MiB free out of 48676 MiB total
21 self_attn.o_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
80 H_error tensor(29.3046, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3377, device='cuda:6', grad_fn=<DivBackward0>)
36634 MiB free out of 48676 MiB total
21 mlp.gate_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
reducing lr to  3.8152042447694614e-05
reducing lr to  3.433683820292515e-05
198 H_error tensor(199.7919, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3116, device='cuda:6', grad_fn=<DivBackward0>)
36784 MiB free out of 48676 MiB total
21 mlp.up_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
reducing lr to  3.8152042447694614e-05
reducing lr to  3.433683820292515e-05
199 H_error tensor(178.2645, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3093, device='cuda:6', grad_fn=<DivBackward0>)
36742 MiB free out of 48676 MiB total
21 mlp.down_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 2752])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
214 H_error tensor(8.3557, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3157, device='cuda:6', grad_fn=<DivBackward0>)
36644 MiB free out of 48676 MiB total
22 self_attn.q_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
79 H_error tensor(142.0187, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3281, device='cuda:6', grad_fn=<DivBackward0>)
37394 MiB free out of 48676 MiB total
22 self_attn.k_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
79 H_error tensor(146.5399, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3300, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
22 self_attn.v_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
reducing lr to  3.8152042447694614e-05
reducing lr to  3.433683820292515e-05
reducing lr to  3.090315438263264e-05
79 H_error tensor(101.4213, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3139, device='cuda:6', grad_fn=<DivBackward0>)
37460 MiB free out of 48676 MiB total
22 self_attn.o_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
79 H_error tensor(20.5617, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3455, device='cuda:6', grad_fn=<DivBackward0>)
36634 MiB free out of 48676 MiB total
22 mlp.gate_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
reducing lr to  3.8152042447694614e-05
reducing lr to  3.433683820292515e-05
200 H_error tensor(203.7935, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3101, device='cuda:6', grad_fn=<DivBackward0>)
36786 MiB free out of 48676 MiB total
22 mlp.up_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
199 H_error tensor(185.6183, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3084, device='cuda:6', grad_fn=<DivBackward0>)
36740 MiB free out of 48676 MiB total
22 mlp.down_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 2752])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
215 H_error tensor(8.5645, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3148, device='cuda:6', grad_fn=<DivBackward0>)
36644 MiB free out of 48676 MiB total
23 self_attn.q_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
79 H_error tensor(137.1086, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3336, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
23 self_attn.k_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
80 H_error tensor(138.1547, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3349, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
23 self_attn.v_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
79 H_error tensor(111.3924, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3139, device='cuda:6', grad_fn=<DivBackward0>)
37460 MiB free out of 48676 MiB total
23 self_attn.o_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
79 H_error tensor(37.8156, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3353, device='cuda:6', grad_fn=<DivBackward0>)
36636 MiB free out of 48676 MiB total
23 mlp.gate_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
reducing lr to  3.8152042447694614e-05
reducing lr to  3.433683820292515e-05
200 H_error tensor(206.5979, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3100, device='cuda:6', grad_fn=<DivBackward0>)
36784 MiB free out of 48676 MiB total
23 mlp.up_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
reducing lr to  3.8152042447694614e-05
reducing lr to  3.433683820292515e-05
reducing lr to  3.090315438263264e-05
reducing lr to  2.7812838944369376e-05
reducing lr to  2.503155504993244e-05
198 H_error tensor(187.4346, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3083, device='cuda:6', grad_fn=<DivBackward0>)
36740 MiB free out of 48676 MiB total
23 mlp.down_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 2752])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
217 H_error tensor(8.5217, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3146, device='cuda:6', grad_fn=<DivBackward0>)
36644 MiB free out of 48676 MiB total
24 self_attn.q_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
79 H_error tensor(136.1344, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3309, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
24 self_attn.k_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
80 H_error tensor(139.4864, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3327, device='cuda:6', grad_fn=<DivBackward0>)
37394 MiB free out of 48676 MiB total
24 self_attn.v_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
79 H_error tensor(114.2809, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3132, device='cuda:6', grad_fn=<DivBackward0>)
37460 MiB free out of 48676 MiB total
24 self_attn.o_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
80 H_error tensor(26.1999, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3385, device='cuda:6', grad_fn=<DivBackward0>)
36634 MiB free out of 48676 MiB total
24 mlp.gate_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
reducing lr to  3.8152042447694614e-05
reducing lr to  3.433683820292515e-05
reducing lr to  3.090315438263264e-05
198 H_error tensor(214.1080, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3097, device='cuda:6', grad_fn=<DivBackward0>)
36786 MiB free out of 48676 MiB total
24 mlp.up_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
reducing lr to  3.8152042447694614e-05
199 H_error tensor(194.3862, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3078, device='cuda:6', grad_fn=<DivBackward0>)
36740 MiB free out of 48676 MiB total
24 mlp.down_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 2752])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
214 H_error tensor(9.0742, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3148, device='cuda:6', grad_fn=<DivBackward0>)
36644 MiB free out of 48676 MiB total
25 self_attn.q_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
79 H_error tensor(148.7511, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3259, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
25 self_attn.k_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
79 H_error tensor(152.0390, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3273, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
25 self_attn.v_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
79 H_error tensor(120.0968, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3149, device='cuda:6', grad_fn=<DivBackward0>)
37460 MiB free out of 48676 MiB total
25 self_attn.o_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
79 H_error tensor(25.5186, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3465, device='cuda:6', grad_fn=<DivBackward0>)
36634 MiB free out of 48676 MiB total
25 mlp.gate_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
200 H_error tensor(223.0922, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3107, device='cuda:6', grad_fn=<DivBackward0>)
36784 MiB free out of 48676 MiB total
25 mlp.up_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
reducing lr to  3.8152042447694614e-05
reducing lr to  3.433683820292515e-05
reducing lr to  3.090315438263264e-05
198 H_error tensor(202.9324, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3081, device='cuda:6', grad_fn=<DivBackward0>)
36740 MiB free out of 48676 MiB total
25 mlp.down_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 2752])
reducing lr to  0.0009000000000000001
214 H_error tensor(9.7349, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3158, device='cuda:6', grad_fn=<DivBackward0>)
36644 MiB free out of 48676 MiB total
26 self_attn.q_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
80 H_error tensor(152.2134, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3247, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
26 self_attn.k_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
79 H_error tensor(159.9247, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3257, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
26 self_attn.v_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
79 H_error tensor(138.6402, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3135, device='cuda:6', grad_fn=<DivBackward0>)
37460 MiB free out of 48676 MiB total
26 self_attn.o_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
79 H_error tensor(23.6710, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3439, device='cuda:6', grad_fn=<DivBackward0>)
36634 MiB free out of 48676 MiB total
26 mlp.gate_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
reducing lr to  3.8152042447694614e-05
reducing lr to  3.433683820292515e-05
reducing lr to  3.090315438263264e-05
198 H_error tensor(233.2387, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3112, device='cuda:6', grad_fn=<DivBackward0>)
36784 MiB free out of 48676 MiB total
26 mlp.up_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
199 H_error tensor(214.5362, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3083, device='cuda:6', grad_fn=<DivBackward0>)
36740 MiB free out of 48676 MiB total
26 mlp.down_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 2752])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
213 H_error tensor(10.5978, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3168, device='cuda:6', grad_fn=<DivBackward0>)
36644 MiB free out of 48676 MiB total
27 self_attn.q_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
79 H_error tensor(150.8695, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3258, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
27 self_attn.k_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
79 H_error tensor(154.9331, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3262, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
27 self_attn.v_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
79 H_error tensor(140.4562, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3131, device='cuda:6', grad_fn=<DivBackward0>)
37460 MiB free out of 48676 MiB total
27 self_attn.o_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
80 H_error tensor(24.2940, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3532, device='cuda:6', grad_fn=<DivBackward0>)
36636 MiB free out of 48676 MiB total
27 mlp.gate_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
199 H_error tensor(236.0835, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3115, device='cuda:6', grad_fn=<DivBackward0>)
36786 MiB free out of 48676 MiB total
27 mlp.up_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
200 H_error tensor(218.9109, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3087, device='cuda:6', grad_fn=<DivBackward0>)
36740 MiB free out of 48676 MiB total
27 mlp.down_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 2752])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
215 H_error tensor(11.3571, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3196, device='cuda:6', grad_fn=<DivBackward0>)
36644 MiB free out of 48676 MiB total
28 self_attn.q_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
79 H_error tensor(141.8479, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3300, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
28 self_attn.k_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
79 H_error tensor(143.2098, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3313, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
28 self_attn.v_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
79 H_error tensor(135.7234, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3149, device='cuda:6', grad_fn=<DivBackward0>)
37460 MiB free out of 48676 MiB total
28 self_attn.o_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
79 H_error tensor(43.5704, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3434, device='cuda:6', grad_fn=<DivBackward0>)
36636 MiB free out of 48676 MiB total
28 mlp.gate_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
196 H_error tensor(255.4900, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3125, device='cuda:6', grad_fn=<DivBackward0>)
36786 MiB free out of 48676 MiB total
28 mlp.up_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
reducing lr to  3.8152042447694614e-05
reducing lr to  3.433683820292515e-05
197 H_error tensor(237.0246, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3094, device='cuda:6', grad_fn=<DivBackward0>)
36740 MiB free out of 48676 MiB total
28 mlp.down_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 2752])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
210 H_error tensor(13.7311, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3227, device='cuda:6', grad_fn=<DivBackward0>)
36644 MiB free out of 48676 MiB total
29 self_attn.q_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
79 H_error tensor(143.9589, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3292, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
29 self_attn.k_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
79 H_error tensor(147.8704, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3300, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
29 self_attn.v_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
79 H_error tensor(137.3365, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3573, device='cuda:6', grad_fn=<DivBackward0>)
37460 MiB free out of 48676 MiB total
29 self_attn.o_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
80 H_error tensor(39.8483, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3515, device='cuda:6', grad_fn=<DivBackward0>)
36634 MiB free out of 48676 MiB total
29 mlp.gate_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
199 H_error tensor(262.9282, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3139, device='cuda:6', grad_fn=<DivBackward0>)
36784 MiB free out of 48676 MiB total
29 mlp.up_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
198 H_error tensor(249.5920, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3106, device='cuda:6', grad_fn=<DivBackward0>)
36740 MiB free out of 48676 MiB total
29 mlp.down_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 2752])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
217 H_error tensor(16.0372, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3287, device='cuda:6', grad_fn=<DivBackward0>)
36644 MiB free out of 48676 MiB total
30 self_attn.q_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
79 H_error tensor(43.5692, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3994, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
30 self_attn.k_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
79 H_error tensor(29.6130, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.4181, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
30 self_attn.v_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
79 H_error tensor(-59.6292, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.4309, device='cuda:6', grad_fn=<DivBackward0>)
37460 MiB free out of 48676 MiB total
30 self_attn.o_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
79 H_error tensor(45.8473, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3432, device='cuda:6', grad_fn=<DivBackward0>)
36634 MiB free out of 48676 MiB total
30 mlp.gate_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
reducing lr to  5.81497370030401e-05
reducing lr to  5.233476330273609e-05
reducing lr to  4.7101286972462485e-05
reducing lr to  4.239115827521624e-05
reducing lr to  3.8152042447694614e-05
reducing lr to  3.433683820292515e-05
198 H_error tensor(279.5139, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3160, device='cuda:6', grad_fn=<DivBackward0>)
36784 MiB free out of 48676 MiB total
30 mlp.up_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
199 H_error tensor(269.4619, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3133, device='cuda:6', grad_fn=<DivBackward0>)
36740 MiB free out of 48676 MiB total
30 mlp.down_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 2752])
217 H_error tensor(-1.3104, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.4177, device='cuda:6', grad_fn=<DivBackward0>)
36644 MiB free out of 48676 MiB total
31 self_attn.q_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
80 H_error tensor(99.1897, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3314, device='cuda:6', grad_fn=<DivBackward0>)
37394 MiB free out of 48676 MiB total
31 self_attn.k_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
79 H_error tensor(109.6003, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3350, device='cuda:6', grad_fn=<DivBackward0>)
37396 MiB free out of 48676 MiB total
31 self_attn.v_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
78 H_error tensor(77.6951, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3192, device='cuda:6', grad_fn=<DivBackward0>)
37460 MiB free out of 48676 MiB total
31 self_attn.o_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
79 H_error tensor(67.1257, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3564, device='cuda:6', grad_fn=<DivBackward0>)
36636 MiB free out of 48676 MiB total
31 mlp.gate_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
199 H_error tensor(263.2889, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3216, device='cuda:6', grad_fn=<DivBackward0>)
36784 MiB free out of 48676 MiB total
31 mlp.up_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([11008, 1024])
reducing lr to  0.0009000000000000001
reducing lr to  0.0008100000000000001
reducing lr to  0.000729
reducing lr to  0.0006561000000000001
reducing lr to  0.00059049
reducing lr to  0.000531441
reducing lr to  0.0004782969
reducing lr to  0.00043046721
reducing lr to  0.000387420489
reducing lr to  0.0003486784401
reducing lr to  0.00031381059609000004
reducing lr to  0.00028242953648100003
reducing lr to  0.00025418658283290005
reducing lr to  0.00022876792454961005
reducing lr to  0.00020589113209464906
reducing lr to  0.00018530201888518417
reducing lr to  0.00016677181699666576
reducing lr to  0.0001500946352969992
reducing lr to  0.0001350851717672993
reducing lr to  0.00012157665459056936
reducing lr to  0.00010941898913151243
reducing lr to  9.847709021836118e-05
reducing lr to  8.862938119652506e-05
reducing lr to  7.976644307687256e-05
reducing lr to  7.17897987691853e-05
reducing lr to  6.461081889226677e-05
198 H_error tensor(245.8488, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.3178, device='cuda:6', grad_fn=<DivBackward0>)
36740 MiB free out of 48676 MiB total
31 mlp.down_proj
Pruning ...
using 0.01 of the magnitude
torch.Size([4096, 2752])
208 H_error tensor(-3348.9846, device='cuda:6', grad_fn=<ViewBackward0>) average_error tensor(0.5961, device='cuda:6', grad_fn=<DivBackward0>)
38630 MiB free out of 48676 MiB total
30320.169682979584
/home/lliu/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Token indices sequence length is longer than the specified maximum sequence length for this model (2824491 > 2048). Running this sequence through the model will result in indexing errors
Dataset: wikitext2
Evaluating ...
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
Perplexity: 39.330654
