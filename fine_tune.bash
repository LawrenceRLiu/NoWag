python -u post_quantization_fine_tune.py meta-llama/Llama-2-7b-hf ./models/llama2_20_bit_reasign_no_fine_tune wikitext2 --device cuda:7 --nsamples_val 0 