wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: m6481. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /data/lliu/huffman/wandb/run-20250107_023213-5lo7yfdu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sun-74
wandb: ‚≠êÔ∏è View project at https://wandb.ai/m6481/compression_no_finetune
wandb: üöÄ View run at https://wandb.ai/m6481/compression_no_finetune/runs/5lo7yfdu
Namespace(models_to_compress=['meta-llama/Llama-2-7b-hf', 'meta-llama/Llama-2-13b-hf'], seqlens=[4096, 4096], batch_size=1, hessian_path='/data/lliu/huffman/models/{model_name}/hessians_new/seed_0/pajama/128', discrete_update_hessian_path='/data/lliu/huffman/models/{model_name}/hessians_new/seed_42/pajama/128', weights_path='/data/lliu/huffman/models/{model_name}/original_weights', save_path='/data/lliu/huffman/models/{model_name}/compressed', self_attn_compression_algorithm='quantize', mlp_compression_algorithm='quantize', devices=['cuda:5', 'cuda:4', 'cuda:3', 'cuda:2'], yaml_path='/data/lliu/huffman/scripts/1layer_compress/quantizer_args.yaml', self_attn_yaml_path=None, mlp_yaml_path=None, use_already_done=False, use_wandb=True, resume_wandb=False, wandb_id=None, wandb_project='compression_no_finetune')
  0%|          | 0/504 [00:00<?, ?it/s]  0%|          | 1/504 [02:10<18:09:59, 130.02s/it]  0%|          | 2/504 [02:25<8:41:46, 62.36s/it]    1%|          | 3/504 [04:20<12:01:28, 86.40s/it]  1%|          | 4/504 [04:55<9:10:56, 66.11s/it] n_commands 504
sample command python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_3/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_3/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_3/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_3/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_3/mlp.gate_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_3/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_3/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_3/mlp.up_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_3/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_3/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_3/self_attn.q_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_3/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_3/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_3/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_3/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_3/self_attn.q_proj/compressed.log
best_loss 79.71517944335938 running bpv: 2.014652
COMMANDS_FINISHED 1 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_3/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_3/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_3/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_3/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_3/self_attn.k_proj/compressed.log
best_loss 87.68785858154297 running bpv: 2.014652
COMMANDS_FINISHED 2 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_3/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_3/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_3/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_3/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_3/self_attn.o_proj/compressed.log
best_loss 0.20060986280441284 running bpv: 2.014652
COMMANDS_FINISHED 3 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_3/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_3/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_3/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_3/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_3/mlp.gate_proj/compressed.log
best_loss 36.43164825439453 running bpv: 2.012043
COMMANDS_FINISHED 4 n_commands 504
meta-llama/Llama-2-7b-hf/layer_3/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_3/mlp.up_proj/compressed.log
best_loss 30.99160385131836 running bpv: 2.011109
COMMANDS_FINISHED 5 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_5/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_5/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_5/mlp.gate_proj/compressed.log 2>&1 &
  1%|          | 6/504 [06:25<7:35:52, 54.93s/it]  1%|‚ñè         | 7/504 [07:40<8:20:39, 60.44s/it]  2%|‚ñè         | 8/504 [08:35<8:06:59, 58.91s/it]  2%|‚ñè         | 9/504 [09:50<8:44:07, 63.53s/it]  2%|‚ñè         | 12/504 [10:45<5:16:33, 38.60s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_5/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_5/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_5/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_3/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_3/self_attn.v_proj/compressed.log
best_loss 22.253562927246094 running bpv: 2.011487
COMMANDS_FINISHED 6 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_5/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_5/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_5/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_3/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_3/mlp.down_proj/compressed.log
best_loss 0.7702421545982361 running bpv: 2.010608
COMMANDS_FINISHED 7 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_5/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_5/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_5/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_5/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_5/self_attn.q_proj/compressed.log
best_loss 92.02725219726562 running bpv: 2.010917
COMMANDS_FINISHED 8 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_5/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_5/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_5/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_5/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_5/mlp.gate_proj/compressed.log
best_loss 67.20345306396484 running bpv: 2.010612
COMMANDS_FINISHED 9 n_commands 504
meta-llama/Llama-2-7b-hf/layer_5/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_5/mlp.up_proj/compressed.log
best_loss 53.38199234008789 running bpv: 2.010397
COMMANDS_FINISHED 10 n_commands 504
meta-llama/Llama-2-7b-hf/layer_5/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_5/self_attn.k_proj/compressed.log
best_loss 100.73676300048828 running bpv: 2.010616
COMMANDS_FINISHED 11 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_5/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_5/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_5/mlp.down_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_5/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_5/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_5/self_attn.v_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_8/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_8/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_8/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_5/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_5/self_attn.o_proj/compressed.log
best_loss 0.6973356008529663 running bpv: 2.010813
COMMANDS_FINISHED 12 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_8/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_8/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_8/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_5/self_attn.v_proj is done
reading log   3%|‚ñé         | 13/504 [12:00<6:17:53, 46.18s/it]  3%|‚ñé         | 14/504 [14:05<8:44:36, 64.24s/it]  3%|‚ñé         | 15/504 [14:50<8:04:53, 59.50s/it]  3%|‚ñé         | 16/504 [15:05<6:29:38, 47.91s/it]  3%|‚ñé         | 17/504 [15:40<6:00:27, 44.41s/it]  4%|‚ñé         | 18/504 [16:15<5:38:26, 41.78s/it]  4%|‚ñç         | 19/504 [17:00<5:45:10, 42.70s/it]  4%|‚ñç         | 20/504 [17:45<5:49:50, 43.37s/it]/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_5/self_attn.v_proj/compressed.log
best_loss 27.379117965698242 running bpv: 2.010992
COMMANDS_FINISHED 13 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_8/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_8/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_8/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_8/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_8/self_attn.q_proj/compressed.log
best_loss 149.58367919921875 running bpv: 2.011155
COMMANDS_FINISHED 14 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_8/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_8/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_8/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_8/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_8/mlp.gate_proj/compressed.log
best_loss 104.31485748291016 running bpv: 2.010939
COMMANDS_FINISHED 15 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_8/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_8/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_8/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_5/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_5/mlp.down_proj/compressed.log
best_loss 2.0593976974487305 running bpv: 2.01061
COMMANDS_FINISHED 16 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_8/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_8/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_8/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_8/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_8/mlp.up_proj/compressed.log
best_loss 84.99991607666016 running bpv: 2.01048
COMMANDS_FINISHED 17 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_8/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_8/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_8/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_8/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_8/self_attn.k_proj/compressed.log
best_loss 151.86502075195312 running bpv: 2.010612
COMMANDS_FINISHED 18 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_12/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_12/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_12/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_8/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_8/self_attn.o_proj/compressed.log
best_loss 2.1894688606262207 running bpv: 2.010737
COMMANDS_FINISHED 19 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_12/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_12/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_12/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_8/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_8/self_attn.v_proj/compressed.log
best_loss 45.872779846191406 running bpv: 2.010854
COMMANDS_FINISHED 20 n_commands 504
  4%|‚ñç         | 21/504 [19:50<9:01:23, 67.25s/it]  4%|‚ñç         | 22/504 [20:15<7:20:14, 54.80s/it]  5%|‚ñç         | 23/504 [21:10<7:19:49, 54.86s/it]  5%|‚ñç         | 24/504 [21:55<6:55:27, 51.93s/it]  5%|‚ñå         | 26/504 [22:25<4:38:34, 34.97s/it]  5%|‚ñå         | 27/504 [24:00<6:35:55, 49.80s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_12/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_12/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_12/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_12/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_12/self_attn.q_proj/compressed.log
best_loss 194.8837432861328 running bpv: 2.010964
COMMANDS_FINISHED 21 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_12/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_12/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_12/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_8/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_8/mlp.down_proj/compressed.log
best_loss 4.870575428009033 running bpv: 2.010716
COMMANDS_FINISHED 22 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_12/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_12/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_12/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_12/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_12/mlp.gate_proj/compressed.log
best_loss 133.04452514648438 running bpv: 2.01061
COMMANDS_FINISHED 23 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_12/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_12/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_12/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_12/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_12/self_attn.k_proj/compressed.log
best_loss 208.75543212890625 running bpv: 2.010708
COMMANDS_FINISHED 24 n_commands 504
meta-llama/Llama-2-7b-hf/layer_12/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_12/mlp.up_proj/compressed.log
best_loss 121.64785766601562 running bpv: 2.010611
COMMANDS_FINISHED 25 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_12/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_12/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_12/self_attn.v_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_1/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_1/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_1/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_12/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_12/self_attn.o_proj/compressed.log
best_loss 5.1112799644470215 running bpv: 2.010702
COMMANDS_FINISHED 26 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_1/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_1/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_1/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_12/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_12/self_attn.v_proj/compressed.log
best_loss 69.23036193847656 running bpv: 2.010789
COMMANDS_FINISHED 27 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_1/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_1/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_1/self_attn.q_proj/compressed.log 2>&1 &
  6%|‚ñå         | 28/504 [26:05<9:10:45, 69.42s/it]  6%|‚ñå         | 29/504 [26:30<7:34:07, 57.36s/it]  6%|‚ñå         | 30/504 [26:55<6:21:44, 48.32s/it]  6%|‚ñå         | 31/504 [27:20<5:28:29, 41.67s/it]  6%|‚ñã         | 32/504 [28:15<5:58:10, 45.53s/it]  7%|‚ñã         | 33/504 [28:40<5:10:16, 39.53s/it]  7%|‚ñã         | 34/504 [29:25<5:22:16, 41.14s/it]  7%|‚ñã         | 35/504 [31:30<8:35:51, 66.00s/it]meta-llama/Llama-2-7b-hf/layer_1/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_1/self_attn.q_proj/compressed.log
best_loss 3.3405518531799316 running bpv: 2.010872
COMMANDS_FINISHED 28 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_1/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_1/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_1/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_12/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_12/mlp.down_proj/compressed.log
best_loss 8.774064064025879 running bpv: 2.01069
COMMANDS_FINISHED 29 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_1/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_1/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_1/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_1/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_1/mlp.gate_proj/compressed.log
best_loss 7.884561538696289 running bpv: 2.010609
COMMANDS_FINISHED 30 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_1/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_1/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_1/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_1/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_1/mlp.up_proj/compressed.log
best_loss 6.856504440307617 running bpv: 2.010536
COMMANDS_FINISHED 31 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_1/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_1/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_1/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_1/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_1/self_attn.k_proj/compressed.log
best_loss 3.356600284576416 running bpv: 2.01061
COMMANDS_FINISHED 32 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_7/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_7/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_7/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_1/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_1/self_attn.o_proj/compressed.log
best_loss 0.04190041497349739 running bpv: 2.010682
COMMANDS_FINISHED 33 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_7/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_7/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_7/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_1/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_1/self_attn.v_proj/compressed.log
best_loss 0.35415390133857727 running bpv: 2.010751
COMMANDS_FINISHED 34 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_7/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_7/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_7/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_7/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_7/self_attn.q_proj/compressed.log
best_loss 152.84832763671875 running bpv: 2.010817
COMMANDS_FINISHED 35 n_commands 504
  7%|‚ñã         | 36/504 [32:05<7:22:52, 56.78s/it]  7%|‚ñã         | 37/504 [33:10<7:41:01, 59.23s/it]  8%|‚ñä         | 38/504 [33:35<6:20:37, 49.01s/it]  8%|‚ñä         | 40/504 [34:05<4:17:54, 33.35s/it]  8%|‚ñä         | 41/504 [35:40<6:15:07, 48.61s/it]  8%|‚ñä         | 42/504 [37:45<8:47:58, 68.57s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_7/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_7/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_7/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_1/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_1/mlp.down_proj/compressed.log
best_loss 0.16132767498493195 running bpv: 2.010674
COMMANDS_FINISHED 36 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_7/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_7/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_7/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_7/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_7/mlp.gate_proj/compressed.log
best_loss 100.885986328125 running bpv: 2.010609
COMMANDS_FINISHED 37 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_7/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_7/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_7/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_7/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_7/self_attn.k_proj/compressed.log
best_loss 154.81845092773438 running bpv: 2.010671
COMMANDS_FINISHED 38 n_commands 504
meta-llama/Llama-2-7b-hf/layer_7/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_7/mlp.up_proj/compressed.log
best_loss 77.50127410888672 running bpv: 2.01061
COMMANDS_FINISHED 39 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_7/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_7/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_7/self_attn.v_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_0/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_0/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_0/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_7/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_7/self_attn.o_proj/compressed.log
best_loss 1.4583404064178467 running bpv: 2.010669
COMMANDS_FINISHED 40 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_0/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_0/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_0/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_7/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_7/self_attn.v_proj/compressed.log
best_loss 44.84684753417969 running bpv: 2.010726
COMMANDS_FINISHED 41 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_0/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_0/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_0/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_0/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_0/self_attn.q_proj/compressed.log
best_loss 0.07863299548625946 running bpv: 2.010781
COMMANDS_FINISHED 42 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_0/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_0/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_0/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_7/mlp.down_proj is done
reading log   9%|‚ñä         | 43/504 [38:20<7:36:45, 59.45s/it]  9%|‚ñä         | 44/504 [38:35<6:00:29, 47.02s/it]  9%|‚ñâ         | 45/504 [39:00<5:11:37, 40.74s/it]  9%|‚ñâ         | 46/504 [39:55<5:42:30, 44.87s/it]  9%|‚ñâ         | 47/504 [40:30<5:19:46, 41.98s/it] 10%|‚ñâ         | 48/504 [41:05<5:03:26, 39.93s/it] 10%|‚ñâ         | 49/504 [43:10<8:14:00, 65.14s/it] 10%|‚ñâ         | 50/504 [43:55<7:27:35, 59.15s/it]/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_7/mlp.down_proj/compressed.log
best_loss 4.007666110992432 running bpv: 2.010663
COMMANDS_FINISHED 43 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_0/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_0/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_0/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_0/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_0/mlp.gate_proj/compressed.log
best_loss 1.8309261798858643 running bpv: 2.010609
COMMANDS_FINISHED 44 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_0/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_0/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_0/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_0/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_0/mlp.up_proj/compressed.log
best_loss 1.7526757717132568 running bpv: 2.010558
COMMANDS_FINISHED 45 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_0/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_0/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_0/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_0/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_0/self_attn.k_proj/compressed.log
best_loss 0.080726757645607 running bpv: 2.01061
COMMANDS_FINISHED 46 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_31/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_31/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_31/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_0/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_0/self_attn.o_proj/compressed.log
best_loss 0.002418127143755555 running bpv: 2.01066
COMMANDS_FINISHED 47 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_31/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_31/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_31/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_0/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_0/self_attn.v_proj/compressed.log
best_loss 0.027433570474386215 running bpv: 2.010708
COMMANDS_FINISHED 48 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_31/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_31/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_31/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_31/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_31/self_attn.q_proj/compressed.log
best_loss 217.59742736816406 running bpv: 2.010756
COMMANDS_FINISHED 49 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_31/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_31/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_31/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_0/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_0/mlp.down_proj/compressed.log
best_loss 0.01713719591498375 running bpv: 2.010655
COMMANDS_FINISHED 50 n_commands 504
 10%|‚ñà         | 51/504 [44:50<7:17:16, 57.92s/it] 10%|‚ñà         | 52/504 [45:15<6:02:14, 48.09s/it] 11%|‚ñà         | 53/504 [45:30<4:47:03, 38.19s/it] 11%|‚ñà         | 54/504 [46:05<4:39:16, 37.24s/it] 11%|‚ñà         | 55/504 [47:20<6:03:19, 48.55s/it] 11%|‚ñà         | 56/504 [49:25<8:53:37, 71.47s/it] 11%|‚ñà‚ñè        | 57/504 [50:00<7:30:59, 60.54s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_31/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_31/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_31/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_31/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_31/mlp.gate_proj/compressed.log
best_loss 464.7175598144531 running bpv: 2.010608
COMMANDS_FINISHED 51 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_31/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_31/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_31/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_31/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_31/self_attn.k_proj/compressed.log
best_loss 237.42214965820312 running bpv: 2.010654
COMMANDS_FINISHED 52 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_31/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_31/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_31/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_31/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_31/mlp.up_proj/compressed.log
best_loss 416.57305908203125 running bpv: 2.010609
COMMANDS_FINISHED 53 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_21/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_21/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_21/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_31/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_31/self_attn.o_proj/compressed.log
best_loss 36.845211029052734 running bpv: 2.010653
COMMANDS_FINISHED 54 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_21/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_21/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_21/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_31/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_31/self_attn.v_proj/compressed.log
best_loss 163.29022216796875 running bpv: 2.010695
COMMANDS_FINISHED 55 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_21/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_21/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_21/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_21/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_21/self_attn.q_proj/compressed.log
best_loss 262.6057434082031 running bpv: 2.010737
COMMANDS_FINISHED 56 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_21/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_21/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_21/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_31/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_31/mlp.down_proj/compressed.log
best_loss 200.2910919189453 running bpv: 2.010649
COMMANDS_FINISHED 57 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_21/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_21/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_21/self_attn.o_proj/compressed.log 2>&1 &
 12%|‚ñà‚ñè        | 58/504 [50:25<6:10:47, 49.88s/it] 12%|‚ñà‚ñè        | 59/504 [51:00<5:36:52, 45.42s/it] 12%|‚ñà‚ñè        | 60/504 [51:25<4:50:48, 39.30s/it] 12%|‚ñà‚ñè        | 61/504 [52:00<4:40:38, 38.01s/it] 12%|‚ñà‚ñè        | 62/504 [53:05<5:39:39, 46.11s/it] 12%|‚ñà‚ñé        | 63/504 [55:10<8:32:51, 69.78s/it] 13%|‚ñà‚ñé        | 64/504 [55:35<6:53:12, 56.35s/it] 13%|‚ñà‚ñé        | 65/504 [56:20<6:27:22, 52.94s/it]meta-llama/Llama-2-7b-hf/layer_21/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_21/mlp.gate_proj/compressed.log
best_loss 343.7168884277344 running bpv: 2.010608
COMMANDS_FINISHED 58 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_21/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_21/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_21/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_21/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_21/mlp.up_proj/compressed.log
best_loss 293.59375 running bpv: 2.01057
COMMANDS_FINISHED 59 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_21/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_21/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_21/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_21/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_21/self_attn.k_proj/compressed.log
best_loss 269.9757080078125 running bpv: 2.010609
COMMANDS_FINISHED 60 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_26/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_26/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_26/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_21/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_21/self_attn.o_proj/compressed.log
best_loss 10.664382934570312 running bpv: 2.010648
COMMANDS_FINISHED 61 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_26/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_26/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_26/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_21/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_21/self_attn.v_proj/compressed.log
best_loss 165.59945678710938 running bpv: 2.010685
COMMANDS_FINISHED 62 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_26/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_26/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_26/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_26/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_26/self_attn.q_proj/compressed.log
best_loss 322.8765563964844 running bpv: 2.010723
COMMANDS_FINISHED 63 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_26/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_26/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_26/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_21/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_21/mlp.down_proj/compressed.log
best_loss 42.587249755859375 running bpv: 2.010645
COMMANDS_FINISHED 64 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_26/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_26/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_26/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_26/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_26/mlp.gate_proj/compressed.log
best_loss 482.5464782714844 running bpv: 2.010608
COMMANDS_FINISHED 65 n_commands 504
 13%|‚ñà‚ñé        | 66/504 [56:55<5:47:12, 47.56s/it] 13%|‚ñà‚ñé        | 67/504 [57:20<4:57:07, 40.80s/it] 13%|‚ñà‚ñé        | 68/504 [57:45<4:22:02, 36.06s/it] 14%|‚ñà‚ñé        | 69/504 [59:00<5:46:08, 47.74s/it] 14%|‚ñà‚ñç        | 70/504 [1:01:05<8:33:01, 70.92s/it] 14%|‚ñà‚ñç        | 71/504 [1:01:30<6:52:25, 57.15s/it] 14%|‚ñà‚ñç        | 72/504 [1:02:15<6:25:15, 53.51s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_26/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_26/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_26/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_26/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_26/mlp.up_proj/compressed.log
best_loss 414.8409423828125 running bpv: 2.010574
COMMANDS_FINISHED 66 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_26/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_26/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_26/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_26/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_26/self_attn.k_proj/compressed.log
best_loss 331.1729431152344 running bpv: 2.010609
COMMANDS_FINISHED 67 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_14/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_14/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_14/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_26/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_26/self_attn.o_proj/compressed.log
best_loss 21.524335861206055 running bpv: 2.010644
COMMANDS_FINISHED 68 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_14/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_14/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_14/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_26/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_26/self_attn.v_proj/compressed.log
best_loss 258.4314880371094 running bpv: 2.010678
COMMANDS_FINISHED 69 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_14/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_14/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_14/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_14/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_14/self_attn.q_proj/compressed.log
best_loss 206.34188842773438 running bpv: 2.010711
COMMANDS_FINISHED 70 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_14/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_14/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_14/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_26/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_26/mlp.down_proj/compressed.log
best_loss 64.05108642578125 running bpv: 2.010641
COMMANDS_FINISHED 71 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_14/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_14/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_14/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_14/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_14/mlp.gate_proj/compressed.log
best_loss 153.906494140625 running bpv: 2.010608
COMMANDS_FINISHED 72 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_14/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_14/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_14/mlp.down_proj/compressed.log 2>&1 &
 14%|‚ñà‚ñç        | 73/504 [1:02:40<5:22:56, 44.96s/it] 15%|‚ñà‚ñç        | 74/504 [1:03:15<5:00:48, 41.97s/it] 15%|‚ñà‚ñç        | 75/504 [1:03:40<4:23:42, 36.88s/it] 15%|‚ñà‚ñå        | 76/504 [1:04:45<5:23:17, 45.32s/it] 15%|‚ñà‚ñå        | 77/504 [1:06:50<8:12:39, 69.23s/it] 15%|‚ñà‚ñå        | 78/504 [1:07:35<7:19:55, 61.96s/it] 16%|‚ñà‚ñå        | 79/504 [1:08:10<6:21:36, 53.87s/it] 16%|‚ñà‚ñå        | 80/504 [1:08:35<5:19:30, 45.21s/it]meta-llama/Llama-2-7b-hf/layer_14/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_14/mlp.up_proj/compressed.log
best_loss 145.62442016601562 running bpv: 2.010577
COMMANDS_FINISHED 73 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_14/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_14/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_14/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_14/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_14/self_attn.k_proj/compressed.log
best_loss 215.87155151367188 running bpv: 2.010609
COMMANDS_FINISHED 74 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_15/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_15/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_15/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_14/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_14/self_attn.o_proj/compressed.log
best_loss 7.037111759185791 running bpv: 2.01064
COMMANDS_FINISHED 75 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_15/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_15/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_15/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_14/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_14/self_attn.v_proj/compressed.log
best_loss 77.44802856445312 running bpv: 2.010671
COMMANDS_FINISHED 76 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_15/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_15/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_15/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_15/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_15/self_attn.q_proj/compressed.log
best_loss 195.25033569335938 running bpv: 2.010701
COMMANDS_FINISHED 77 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_15/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_15/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_15/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_14/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_14/mlp.down_proj/compressed.log
best_loss 12.66624641418457 running bpv: 2.010638
COMMANDS_FINISHED 78 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_15/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_15/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_15/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_15/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_15/mlp.gate_proj/compressed.log
best_loss 167.75601196289062 running bpv: 2.010608
COMMANDS_FINISHED 79 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_15/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_15/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_15/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_15/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_15/mlp.up_proj/compressed.log
best_loss 158.78933715820312 running bpv: 2.01058
COMMANDS_FINISHED 80 n_commands 504
 16%|‚ñà‚ñå        | 81/504 [1:08:50<4:14:52, 36.15s/it] 16%|‚ñà‚ñã        | 82/504 [1:09:45<4:54:03, 41.81s/it] 16%|‚ñà‚ñã        | 83/504 [1:10:40<5:21:08, 45.77s/it] 17%|‚ñà‚ñã        | 84/504 [1:12:45<8:06:46, 69.54s/it] 17%|‚ñà‚ñã        | 85/504 [1:13:20<6:53:16, 59.18s/it] 17%|‚ñà‚ñã        | 86/504 [1:13:45<5:40:51, 48.93s/it] 17%|‚ñà‚ñã        | 87/504 [1:14:40<5:52:43, 50.75s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_15/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_15/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_15/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_15/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_15/self_attn.k_proj/compressed.log
best_loss 211.4791717529297 running bpv: 2.010609
COMMANDS_FINISHED 81 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_4/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_4/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_4/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_15/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_15/self_attn.o_proj/compressed.log
best_loss 7.566293239593506 running bpv: 2.010637
COMMANDS_FINISHED 82 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_4/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_4/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_4/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_15/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_15/self_attn.v_proj/compressed.log
best_loss 81.74012756347656 running bpv: 2.010666
COMMANDS_FINISHED 83 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_4/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_4/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_4/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_4/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_4/self_attn.q_proj/compressed.log
best_loss 78.19267272949219 running bpv: 2.010694
COMMANDS_FINISHED 84 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_4/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_4/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_4/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_15/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_15/mlp.down_proj/compressed.log
best_loss 15.733613014221191 running bpv: 2.010635
COMMANDS_FINISHED 85 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_4/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_4/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_4/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_4/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_4/mlp.gate_proj/compressed.log
best_loss 52.446678161621094 running bpv: 2.010608
COMMANDS_FINISHED 86 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_4/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_4/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_4/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_4/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_4/mlp.up_proj/compressed.log
best_loss 42.16460037231445 running bpv: 2.010582
COMMANDS_FINISHED 87 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_4/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_4/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_4/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_4/self_attn.k_proj is done
 17%|‚ñà‚ñã        | 88/504 [1:14:55<4:37:31, 40.03s/it] 18%|‚ñà‚ñä        | 89/504 [1:15:30<4:26:26, 38.52s/it] 18%|‚ñà‚ñä        | 90/504 [1:16:45<5:41:19, 49.47s/it] 18%|‚ñà‚ñä        | 91/504 [1:18:50<8:16:29, 72.13s/it] 18%|‚ñà‚ñä        | 92/504 [1:19:05<6:17:36, 54.99s/it] 18%|‚ñà‚ñä        | 93/504 [1:19:50<5:56:10, 52.00s/it] 19%|‚ñà‚ñä        | 94/504 [1:20:25<5:20:28, 46.90s/it] 19%|‚ñà‚ñâ        | 95/504 [1:21:00<4:55:22, 43.33s/it]reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_4/self_attn.k_proj/compressed.log
best_loss 82.4744644165039 running bpv: 2.010609
COMMANDS_FINISHED 88 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_27/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_27/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_27/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_4/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_4/self_attn.o_proj/compressed.log
best_loss 0.4297354519367218 running bpv: 2.010635
COMMANDS_FINISHED 89 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_27/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_27/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_27/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_4/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_4/self_attn.v_proj/compressed.log
best_loss 22.416648864746094 running bpv: 2.010661
COMMANDS_FINISHED 90 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_27/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_27/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_27/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_27/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_27/self_attn.q_proj/compressed.log
best_loss 359.2896728515625 running bpv: 2.010687
COMMANDS_FINISHED 91 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_27/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_27/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_27/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_4/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_4/mlp.down_proj/compressed.log
best_loss 1.3973091840744019 running bpv: 2.010633
COMMANDS_FINISHED 92 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_27/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_27/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_27/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_27/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_27/mlp.gate_proj/compressed.log
best_loss 509.626953125 running bpv: 2.010608
COMMANDS_FINISHED 93 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_27/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_27/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_27/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_27/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_27/mlp.up_proj/compressed.log
best_loss 441.0654296875 running bpv: 2.010584
COMMANDS_FINISHED 94 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_27/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_27/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_27/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_27/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_27/self_attn.k_proj/compressed.log
best_loss 369.1354675292969 running bpv: 2.010609
COMMANDS_FINISHED 95 n_commands 504
 19%|‚ñà‚ñâ        | 96/504 [1:21:15<3:56:52, 34.83s/it] 19%|‚ñà‚ñâ        | 97/504 [1:22:30<5:18:02, 46.89s/it] 19%|‚ñà‚ñâ        | 98/504 [1:24:35<7:55:51, 70.32s/it] 20%|‚ñà‚ñâ        | 99/504 [1:25:00<6:22:54, 56.73s/it] 20%|‚ñà‚ñâ        | 100/504 [1:25:55<6:18:29, 56.21s/it] 20%|‚ñà‚ñà        | 101/504 [1:26:10<4:54:31, 43.85s/it] 20%|‚ñà‚ñà        | 102/504 [1:26:45<4:36:01, 41.20s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_2/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_2/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_2/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_27/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_27/self_attn.o_proj/compressed.log
best_loss 17.840347290039062 running bpv: 2.010633
COMMANDS_FINISHED 96 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_2/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_2/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_2/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_27/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_27/self_attn.v_proj/compressed.log
best_loss 269.5435485839844 running bpv: 2.010657
COMMANDS_FINISHED 97 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_2/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_2/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_2/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_2/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_2/self_attn.q_proj/compressed.log
best_loss 26.344778060913086 running bpv: 2.010681
COMMANDS_FINISHED 98 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_2/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_2/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_2/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_27/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_27/mlp.down_proj/compressed.log
best_loss 71.74263000488281 running bpv: 2.010631
COMMANDS_FINISHED 99 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_2/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_2/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_2/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_2/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_2/mlp.gate_proj/compressed.log
best_loss 19.817092895507812 running bpv: 2.010608
COMMANDS_FINISHED 100 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_2/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_2/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_2/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_2/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_2/mlp.up_proj/compressed.log
best_loss 17.031539916992188 running bpv: 2.010585
COMMANDS_FINISHED 101 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_2/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_2/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_2/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_2/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_2/self_attn.k_proj/compressed.log
best_loss 29.65542221069336 running bpv: 2.010608
COMMANDS_FINISHED 102 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_28/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_28/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_28/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_2/self_attn.o_proj is done
 20%|‚ñà‚ñà        | 103/504 [1:27:00<3:42:49, 33.34s/it] 21%|‚ñà‚ñà        | 104/504 [1:28:15<5:05:36, 45.84s/it] 21%|‚ñà‚ñà        | 105/504 [1:30:20<7:42:46, 69.59s/it] 21%|‚ñà‚ñà        | 106/504 [1:31:05<6:52:41, 62.22s/it] 21%|‚ñà‚ñà        | 107/504 [1:31:40<5:57:39, 54.05s/it] 21%|‚ñà‚ñà‚ñè       | 108/504 [1:31:55<4:39:26, 42.34s/it] 22%|‚ñà‚ñà‚ñè       | 109/504 [1:32:30<4:24:14, 40.14s/it] 22%|‚ñà‚ñà‚ñè       | 110/504 [1:33:15<4:33:10, 41.60s/it]reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_2/self_attn.o_proj/compressed.log
best_loss 0.11281780153512955 running bpv: 2.010631
COMMANDS_FINISHED 103 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_28/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_28/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_28/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_2/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_2/self_attn.v_proj/compressed.log
best_loss 7.178545951843262 running bpv: 2.010654
COMMANDS_FINISHED 104 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_28/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_28/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_28/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_28/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_28/self_attn.q_proj/compressed.log
best_loss 347.7034912109375 running bpv: 2.010676
COMMANDS_FINISHED 105 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_28/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_28/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_28/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_2/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_2/mlp.down_proj/compressed.log
best_loss 0.37402498722076416 running bpv: 2.01063
COMMANDS_FINISHED 106 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_28/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_28/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_28/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_28/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_28/mlp.gate_proj/compressed.log
best_loss 526.9074096679688 running bpv: 2.010608
COMMANDS_FINISHED 107 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_28/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_28/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_28/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_28/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_28/mlp.up_proj/compressed.log
best_loss 469.921875 running bpv: 2.010587
COMMANDS_FINISHED 108 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_28/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_28/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_28/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_28/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_28/self_attn.k_proj/compressed.log
best_loss 358.93798828125 running bpv: 2.010608
COMMANDS_FINISHED 109 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_18/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_18/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_18/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_28/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_28/self_attn.o_proj/compressed.log
best_loss 26.46156120300293 running bpv: 2.01063
COMMANDS_FINISHED 110 n_commands 504
 22%|‚ñà‚ñà‚ñè       | 111/504 [1:34:00<4:39:10, 42.62s/it] 22%|‚ñà‚ñà‚ñè       | 112/504 [1:36:05<7:19:56, 67.34s/it] 22%|‚ñà‚ñà‚ñè       | 113/504 [1:36:50<6:35:09, 60.64s/it] 23%|‚ñà‚ñà‚ñé       | 114/504 [1:37:25<5:44:10, 52.95s/it] 23%|‚ñà‚ñà‚ñé       | 115/504 [1:38:10<5:27:50, 50.57s/it] 23%|‚ñà‚ñà‚ñé       | 117/504 [1:39:00<4:10:03, 38.77s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_18/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_18/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_18/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_28/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_28/self_attn.v_proj/compressed.log
best_loss 293.9024658203125 running bpv: 2.010651
COMMANDS_FINISHED 111 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_18/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_18/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_18/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_18/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_18/self_attn.q_proj/compressed.log
best_loss 239.578125 running bpv: 2.010672
COMMANDS_FINISHED 112 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_18/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_18/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_18/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_28/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_28/mlp.down_proj/compressed.log
best_loss 85.49263763427734 running bpv: 2.010628
COMMANDS_FINISHED 113 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_18/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_18/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_18/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_18/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_18/mlp.gate_proj/compressed.log
best_loss 265.0881652832031 running bpv: 2.010608
COMMANDS_FINISHED 114 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_18/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_18/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_18/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_18/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_18/mlp.up_proj/compressed.log
best_loss 234.28121948242188 running bpv: 2.010588
COMMANDS_FINISHED 115 n_commands 504
meta-llama/Llama-2-7b-hf/layer_18/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_18/self_attn.k_proj/compressed.log
best_loss 252.96893310546875 running bpv: 2.010608
COMMANDS_FINISHED 116 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_18/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_18/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_18/self_attn.v_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_25/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_25/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_25/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_18/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_18/self_attn.o_proj/compressed.log
best_loss 9.311711311340332 running bpv: 2.010628
COMMANDS_FINISHED 117 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_25/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_25/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_25/mlp.up_proj/compressed.log 2>&1 &
 23%|‚ñà‚ñà‚ñé       | 118/504 [1:40:15<5:07:12, 47.75s/it] 24%|‚ñà‚ñà‚ñé       | 119/504 [1:42:20<7:16:04, 67.96s/it] 24%|‚ñà‚ñà‚ñç       | 120/504 [1:42:35<5:42:45, 53.56s/it] 24%|‚ñà‚ñà‚ñç       | 121/504 [1:43:10<5:08:43, 48.36s/it] 24%|‚ñà‚ñà‚ñç       | 122/504 [1:43:55<5:01:49, 47.41s/it] 24%|‚ñà‚ñà‚ñç       | 123/504 [1:44:30<4:38:12, 43.81s/it] 25%|‚ñà‚ñà‚ñç       | 124/504 [1:44:45<3:44:03, 35.38s/it] 25%|‚ñà‚ñà‚ñç       | 125/504 [1:46:00<4:57:17, 47.07s/it]meta-llama/Llama-2-7b-hf/layer_18/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_18/self_attn.v_proj/compressed.log
best_loss 128.24801635742188 running bpv: 2.010648
COMMANDS_FINISHED 118 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_25/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_25/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_25/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_25/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_25/self_attn.q_proj/compressed.log
best_loss 348.72271728515625 running bpv: 2.010668
COMMANDS_FINISHED 119 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_25/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_25/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_25/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_18/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_18/mlp.down_proj/compressed.log
best_loss 29.30255889892578 running bpv: 2.010627
COMMANDS_FINISHED 120 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_25/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_25/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_25/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_25/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_25/mlp.gate_proj/compressed.log
best_loss 454.37969970703125 running bpv: 2.010608
COMMANDS_FINISHED 121 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_25/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_25/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_25/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_25/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_25/mlp.up_proj/compressed.log
best_loss 390.1080322265625 running bpv: 2.010589
COMMANDS_FINISHED 122 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_25/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_25/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_25/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_25/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_25/self_attn.k_proj/compressed.log
best_loss 352.7095031738281 running bpv: 2.010608
COMMANDS_FINISHED 123 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_30/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_30/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_30/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_25/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_25/self_attn.o_proj/compressed.log
best_loss 13.541476249694824 running bpv: 2.010627
COMMANDS_FINISHED 124 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_30/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_30/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_30/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_25/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_25/self_attn.v_proj/compressed.log
best_loss 261.8658142089844 running bpv: 2.010646
COMMANDS_FINISHED 125 n_commands 504
 25%|‚ñà‚ñà‚ñå       | 126/504 [1:48:05<7:22:03, 70.17s/it] 25%|‚ñà‚ñà‚ñå       | 127/504 [1:48:20<5:37:47, 53.76s/it] 25%|‚ñà‚ñà‚ñå       | 128/504 [1:49:25<5:57:54, 57.11s/it] 26%|‚ñà‚ñà‚ñå       | 129/504 [1:49:40<4:38:19, 44.53s/it] 26%|‚ñà‚ñà‚ñå       | 130/504 [1:50:15<4:19:49, 41.68s/it] 26%|‚ñà‚ñà‚ñå       | 131/504 [1:50:30<3:29:28, 33.70s/it] 26%|‚ñà‚ñà‚ñå       | 132/504 [1:51:45<4:45:38, 46.07s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_30/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_30/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_30/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_30/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_30/self_attn.q_proj/compressed.log
best_loss 323.8077392578125 running bpv: 2.010665
COMMANDS_FINISHED 126 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_30/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_30/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_30/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_25/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_25/mlp.down_proj/compressed.log
best_loss 58.34229278564453 running bpv: 2.010626
COMMANDS_FINISHED 127 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_30/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_30/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_30/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_30/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_30/mlp.gate_proj/compressed.log
best_loss 555.6550903320312 running bpv: 2.010608
COMMANDS_FINISHED 128 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_30/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_30/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_30/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_30/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_30/mlp.up_proj/compressed.log
best_loss 497.97332763671875 running bpv: 2.01059
COMMANDS_FINISHED 129 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_30/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_30/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_30/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_30/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_30/self_attn.k_proj/compressed.log
best_loss 336.4361572265625 running bpv: 2.010608
COMMANDS_FINISHED 130 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_29/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_29/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_29/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_30/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_30/self_attn.o_proj/compressed.log
best_loss 33.15596389770508 running bpv: 2.010626
COMMANDS_FINISHED 131 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_29/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_29/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_29/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_30/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_30/self_attn.v_proj/compressed.log
best_loss 301.75653076171875 running bpv: 2.010644
COMMANDS_FINISHED 132 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_29/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_29/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_29/self_attn.q_proj/compressed.log 2>&1 &
 26%|‚ñà‚ñà‚ñã       | 133/504 [1:53:50<7:11:09, 69.73s/it] 27%|‚ñà‚ñà‚ñã       | 134/504 [1:54:35<6:24:17, 62.32s/it] 27%|‚ñà‚ñà‚ñã       | 135/504 [1:55:10<5:32:53, 54.13s/it] 27%|‚ñà‚ñà‚ñã       | 136/504 [1:55:26<4:20:01, 42.40s/it] 27%|‚ñà‚ñà‚ñã       | 137/504 [1:55:51<3:47:25, 37.18s/it] 27%|‚ñà‚ñà‚ñã       | 138/504 [1:56:46<4:19:25, 42.53s/it] 28%|‚ñà‚ñà‚ñä       | 139/504 [1:57:31<4:23:14, 43.27s/it] 28%|‚ñà‚ñà‚ñä       | 140/504 [1:59:36<6:51:15, 67.79s/it]meta-llama/Llama-2-7b-hf/layer_29/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_29/self_attn.q_proj/compressed.log
best_loss 304.9870910644531 running bpv: 2.010662
COMMANDS_FINISHED 133 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_29/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_29/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_29/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_30/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_30/mlp.down_proj/compressed.log
best_loss 129.13265991210938 running bpv: 2.010625
COMMANDS_FINISHED 134 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_29/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_29/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_29/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_29/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_29/mlp.gate_proj/compressed.log
best_loss 542.71826171875 running bpv: 2.010608
COMMANDS_FINISHED 135 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_29/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_29/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_29/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_29/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_29/mlp.up_proj/compressed.log
best_loss 491.0498352050781 running bpv: 2.010591
COMMANDS_FINISHED 136 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_29/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_29/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_29/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_29/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_29/self_attn.k_proj/compressed.log
best_loss 314.3350830078125 running bpv: 2.010608
COMMANDS_FINISHED 137 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_16/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_16/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_16/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_29/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_29/self_attn.o_proj/compressed.log
best_loss 25.445215225219727 running bpv: 2.010625
COMMANDS_FINISHED 138 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_16/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_16/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_16/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_29/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_29/self_attn.v_proj/compressed.log
best_loss 272.4807434082031 running bpv: 2.010642
COMMANDS_FINISHED 139 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_16/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_16/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_16/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_16/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_16/self_attn.q_proj/compressed.log
best_loss 203.1370391845703 running bpv: 2.010659
COMMANDS_FINISHED 140 n_commands 504
 28%|‚ñà‚ñà‚ñä       | 141/504 [2:00:21<6:08:47, 60.96s/it] 28%|‚ñà‚ñà‚ñä       | 142/504 [2:00:46<5:02:41, 50.17s/it] 28%|‚ñà‚ñà‚ñä       | 143/504 [2:01:41<5:10:35, 51.62s/it] 29%|‚ñà‚ñà‚ñâ       | 145/504 [2:02:31<3:55:22, 39.34s/it] 29%|‚ñà‚ñà‚ñâ       | 146/504 [2:03:46<4:47:28, 48.18s/it] 29%|‚ñà‚ñà‚ñâ       | 147/504 [2:05:51<6:46:14, 68.28s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_16/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_16/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_16/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_29/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_29/mlp.down_proj/compressed.log
best_loss 99.9097900390625 running bpv: 2.010624
COMMANDS_FINISHED 141 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_16/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_16/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_16/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_16/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_16/mlp.gate_proj/compressed.log
best_loss 194.14498901367188 running bpv: 2.010608
COMMANDS_FINISHED 142 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_16/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_16/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_16/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_16/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_16/mlp.up_proj/compressed.log
best_loss 180.53536987304688 running bpv: 2.010592
COMMANDS_FINISHED 143 n_commands 504
meta-llama/Llama-2-7b-hf/layer_16/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_16/self_attn.k_proj/compressed.log
best_loss 216.72213745117188 running bpv: 2.010608
COMMANDS_FINISHED 144 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_16/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_16/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_16/self_attn.v_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_13/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_13/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_13/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_16/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_16/self_attn.o_proj/compressed.log
best_loss 10.686159133911133 running bpv: 2.010624
COMMANDS_FINISHED 145 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_13/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_13/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_13/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_16/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_16/self_attn.v_proj/compressed.log
best_loss 93.36512756347656 running bpv: 2.010641
COMMANDS_FINISHED 146 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_13/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_13/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_13/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_13/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_13/self_attn.q_proj/compressed.log
best_loss 200.21426391601562 running bpv: 2.010656
COMMANDS_FINISHED 147 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_13/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_13/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_13/self_attn.k_proj/compressed.log 2>&1 &
 29%|‚ñà‚ñà‚ñâ       | 148/504 [2:06:06<5:19:07, 53.79s/it] 30%|‚ñà‚ñà‚ñâ       | 149/504 [2:06:41<4:47:08, 48.53s/it] 30%|‚ñà‚ñà‚ñâ       | 150/504 [2:07:26<4:40:23, 47.52s/it] 30%|‚ñà‚ñà‚ñâ       | 151/504 [2:08:01<4:18:15, 43.90s/it] 30%|‚ñà‚ñà‚ñà       | 152/504 [2:08:16<3:27:54, 35.44s/it] 30%|‚ñà‚ñà‚ñà       | 153/504 [2:09:31<4:35:34, 47.11s/it] 31%|‚ñà‚ñà‚ñà       | 154/504 [2:11:36<6:49:29, 70.20s/it] 31%|‚ñà‚ñà‚ñà       | 155/504 [2:11:51<5:12:49, 53.78s/it]meta-llama/Llama-2-7b-hf/layer_16/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_16/mlp.down_proj/compressed.log
best_loss 21.86902618408203 running bpv: 2.010624
COMMANDS_FINISHED 148 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_13/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_13/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_13/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_13/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_13/mlp.gate_proj/compressed.log
best_loss 139.94314575195312 running bpv: 2.010608
COMMANDS_FINISHED 149 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_13/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_13/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_13/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_13/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_13/mlp.up_proj/compressed.log
best_loss 131.6159210205078 running bpv: 2.010593
COMMANDS_FINISHED 150 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_13/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_13/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_13/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_13/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_13/self_attn.k_proj/compressed.log
best_loss 208.50936889648438 running bpv: 2.010608
COMMANDS_FINISHED 151 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_10/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_10/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_10/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_13/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_13/self_attn.o_proj/compressed.log
best_loss 5.878100395202637 running bpv: 2.010624
COMMANDS_FINISHED 152 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_10/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_10/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_10/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_13/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_13/self_attn.v_proj/compressed.log
best_loss 77.78593444824219 running bpv: 2.010639
COMMANDS_FINISHED 153 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_10/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_10/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_10/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_10/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_10/self_attn.q_proj/compressed.log
best_loss 163.25669860839844 running bpv: 2.010654
COMMANDS_FINISHED 154 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_10/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_10/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_10/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_13/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_13/mlp.down_proj/compressed.log
best_loss 10.818561553955078 running bpv: 2.010623
COMMANDS_FINISHED 155 n_commands 504
 31%|‚ñà‚ñà‚ñà       | 156/504 [2:12:56<5:31:20, 57.13s/it] 31%|‚ñà‚ñà‚ñà       | 157/504 [2:13:11<4:17:36, 44.54s/it] 31%|‚ñà‚ñà‚ñà‚ñè      | 158/504 [2:13:36<3:43:09, 38.70s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 159/504 [2:14:01<3:18:56, 34.60s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 160/504 [2:15:16<4:27:46, 46.70s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 161/504 [2:17:21<6:41:09, 70.17s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 162/504 [2:18:06<5:56:58, 62.63s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_10/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_10/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_10/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_10/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_10/mlp.gate_proj/compressed.log
best_loss 114.92008972167969 running bpv: 2.010608
COMMANDS_FINISHED 156 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_10/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_10/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_10/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_10/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_10/mlp.up_proj/compressed.log
best_loss 99.37833404541016 running bpv: 2.010593
COMMANDS_FINISHED 157 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_10/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_10/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_10/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_10/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_10/self_attn.k_proj/compressed.log
best_loss 174.4517822265625 running bpv: 2.010608
COMMANDS_FINISHED 158 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_19/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_19/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_19/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_10/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_10/self_attn.o_proj/compressed.log
best_loss 4.363612174987793 running bpv: 2.010623
COMMANDS_FINISHED 159 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_19/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_19/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_19/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_10/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_10/self_attn.v_proj/compressed.log
best_loss 51.29685592651367 running bpv: 2.010638
COMMANDS_FINISHED 160 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_19/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_19/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_19/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_19/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_19/self_attn.q_proj/compressed.log
best_loss 233.31082153320312 running bpv: 2.010652
COMMANDS_FINISHED 161 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_19/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_19/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_19/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_10/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_10/mlp.down_proj/compressed.log
best_loss 6.67597770690918 running bpv: 2.010622
COMMANDS_FINISHED 162 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_19/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_19/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_19/self_attn.o_proj/compressed.log 2>&1 &
 32%|‚ñà‚ñà‚ñà‚ñè      | 163/504 [2:18:31<4:51:49, 51.35s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 164/504 [2:18:56<4:06:11, 43.45s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 165/504 [2:19:21<3:34:13, 37.92s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 166/504 [2:20:16<4:02:28, 43.04s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 167/504 [2:21:01<4:05:03, 43.63s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 168/504 [2:23:06<6:21:02, 68.04s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 169/504 [2:23:41<5:24:34, 58.13s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 170/504 [2:24:16<4:44:59, 51.20s/it]meta-llama/Llama-2-7b-hf/layer_19/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_19/mlp.gate_proj/compressed.log
best_loss 287.43994140625 running bpv: 2.010608
COMMANDS_FINISHED 163 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_19/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_19/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_19/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_19/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_19/mlp.up_proj/compressed.log
best_loss 252.73004150390625 running bpv: 2.010594
COMMANDS_FINISHED 164 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_19/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_19/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_19/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_19/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_19/self_attn.k_proj/compressed.log
best_loss 244.81036376953125 running bpv: 2.010608
COMMANDS_FINISHED 165 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_6/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_6/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_6/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_19/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_19/self_attn.o_proj/compressed.log
best_loss 8.68039321899414 running bpv: 2.010622
COMMANDS_FINISHED 166 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_6/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_6/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_6/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_19/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_19/self_attn.v_proj/compressed.log
best_loss 130.50851440429688 running bpv: 2.010636
COMMANDS_FINISHED 167 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_6/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_6/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_6/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_6/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_6/self_attn.q_proj/compressed.log
best_loss 137.44921875 running bpv: 2.01065
COMMANDS_FINISHED 168 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_6/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_6/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_6/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_19/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_19/mlp.down_proj/compressed.log
best_loss 32.62129211425781 running bpv: 2.010622
COMMANDS_FINISHED 169 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_6/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_6/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_6/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_6/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_6/mlp.gate_proj/compressed.log
best_loss 86.81033325195312 running bpv: 2.010608
COMMANDS_FINISHED 170 n_commands 504
 34%|‚ñà‚ñà‚ñà‚ñç      | 171/504 [2:25:11<4:50:28, 52.34s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 173/504 [2:25:41<3:13:40, 35.11s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 174/504 [2:27:16<4:34:46, 49.96s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 175/504 [2:29:21<6:21:34, 69.59s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 176/504 [2:29:36<4:59:15, 54.74s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 177/504 [2:30:11<4:28:14, 49.22s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_6/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_6/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_6/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_6/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_6/mlp.up_proj/compressed.log
best_loss 66.08674621582031 running bpv: 2.010594
COMMANDS_FINISHED 171 n_commands 504
meta-llama/Llama-2-7b-hf/layer_6/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_6/self_attn.k_proj/compressed.log
best_loss 143.49948120117188 running bpv: 2.010608
COMMANDS_FINISHED 172 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_6/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_6/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_6/self_attn.v_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_11/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_11/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_11/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_6/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_6/self_attn.o_proj/compressed.log
best_loss 1.032443881034851 running bpv: 2.010622
COMMANDS_FINISHED 173 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_11/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_11/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_11/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_6/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_6/self_attn.v_proj/compressed.log
best_loss 39.36637878417969 running bpv: 2.010635
COMMANDS_FINISHED 174 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_11/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_11/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_11/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_11/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_11/self_attn.q_proj/compressed.log
best_loss 183.8324737548828 running bpv: 2.010649
COMMANDS_FINISHED 175 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_11/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_11/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_11/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_6/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_6/mlp.down_proj/compressed.log
best_loss 3.0557327270507812 running bpv: 2.010621
COMMANDS_FINISHED 176 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_11/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_11/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_11/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_11/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_11/mlp.gate_proj/compressed.log
best_loss 125.61917877197266 running bpv: 2.010608
COMMANDS_FINISHED 177 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_11/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_11/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_11/mlp.down_proj/compressed.log 2>&1 &
 35%|‚ñà‚ñà‚ñà‚ñå      | 178/504 [2:30:36<3:49:50, 42.30s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 179/504 [2:31:31<4:09:04, 45.98s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 180/504 [2:31:46<3:19:20, 36.92s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 181/504 [2:32:41<3:47:26, 42.25s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 182/504 [2:34:46<5:58:23, 66.78s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 183/504 [2:35:21<5:06:42, 57.33s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 184/504 [2:36:26<5:17:58, 59.62s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 185/504 [2:36:41<4:06:06, 46.29s/it]meta-llama/Llama-2-7b-hf/layer_11/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_11/mlp.up_proj/compressed.log
best_loss 111.43798828125 running bpv: 2.010595
COMMANDS_FINISHED 178 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_11/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_11/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_11/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_11/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_11/self_attn.k_proj/compressed.log
best_loss 183.5587158203125 running bpv: 2.010608
COMMANDS_FINISHED 179 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_20/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_20/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_20/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_11/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_11/self_attn.o_proj/compressed.log
best_loss 4.749502658843994 running bpv: 2.010621
COMMANDS_FINISHED 180 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_20/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_20/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_20/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_11/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_11/self_attn.v_proj/compressed.log
best_loss 69.38990783691406 running bpv: 2.010634
COMMANDS_FINISHED 181 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_20/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_20/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_20/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_20/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_20/self_attn.q_proj/compressed.log
best_loss 241.2108154296875 running bpv: 2.010647
COMMANDS_FINISHED 182 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_20/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_20/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_20/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_11/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_11/mlp.down_proj/compressed.log
best_loss 7.622084617614746 running bpv: 2.01062
COMMANDS_FINISHED 183 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_20/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_20/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_20/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_20/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_20/mlp.gate_proj/compressed.log
best_loss 311.9132080078125 running bpv: 2.010608
COMMANDS_FINISHED 184 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_20/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_20/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_20/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_20/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_20/mlp.up_proj/compressed.log
best_loss 270.94000244140625 running bpv: 2.010595
COMMANDS_FINISHED 185 n_commands 504
 37%|‚ñà‚ñà‚ñà‚ñã      | 186/504 [2:36:56<3:15:44, 36.93s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 187/504 [2:37:21<2:56:15, 33.36s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 188/504 [2:38:46<4:17:11, 48.84s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 189/504 [2:40:51<6:16:14, 71.67s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 190/504 [2:41:36<5:33:13, 63.67s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 191/504 [2:41:51<4:16:02, 49.08s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 192/504 [2:42:16<3:37:40, 41.86s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_20/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_20/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_20/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_20/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_20/self_attn.k_proj/compressed.log
best_loss 252.29202270507812 running bpv: 2.010608
COMMANDS_FINISHED 186 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_23/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_23/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_23/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_20/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_20/self_attn.o_proj/compressed.log
best_loss 11.996825218200684 running bpv: 2.010621
COMMANDS_FINISHED 187 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_23/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_23/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_23/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_20/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_20/self_attn.v_proj/compressed.log
best_loss 136.49441528320312 running bpv: 2.010633
COMMANDS_FINISHED 188 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_23/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_23/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_23/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_23/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_23/self_attn.q_proj/compressed.log
best_loss 317.07708740234375 running bpv: 2.010646
COMMANDS_FINISHED 189 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_23/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_23/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_23/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_20/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_20/mlp.down_proj/compressed.log
best_loss 40.48631286621094 running bpv: 2.01062
COMMANDS_FINISHED 190 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_23/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_23/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_23/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_23/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_23/mlp.gate_proj/compressed.log
best_loss 397.4254150390625 running bpv: 2.010608
COMMANDS_FINISHED 191 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_23/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_23/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_23/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_23/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_23/mlp.up_proj/compressed.log
best_loss 339.22906494140625 running bpv: 2.010596
COMMANDS_FINISHED 192 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_23/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_23/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_23/self_attn.v_proj/compressed.log 2>&1 &
 38%|‚ñà‚ñà‚ñà‚ñä      | 193/504 [2:42:51<3:26:19, 39.81s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 194/504 [2:43:46<3:49:13, 44.37s/it] 39%|‚ñà‚ñà‚ñà‚ñä      | 195/504 [2:44:21<3:34:01, 41.56s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 196/504 [2:46:26<5:41:50, 66.59s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 197/504 [2:47:01<4:52:15, 57.12s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 198/504 [2:47:46<4:32:46, 53.49s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 199/504 [2:48:31<4:18:57, 50.94s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 200/504 [2:48:46<3:23:29, 40.16s/it]meta-llama/Llama-2-7b-hf/layer_23/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_23/self_attn.k_proj/compressed.log
best_loss 324.563720703125 running bpv: 2.010608
COMMANDS_FINISHED 193 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_17/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_17/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_17/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_23/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_23/self_attn.o_proj/compressed.log
best_loss 12.324451446533203 running bpv: 2.01062
COMMANDS_FINISHED 194 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_17/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_17/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_17/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_23/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_23/self_attn.v_proj/compressed.log
best_loss 216.88226318359375 running bpv: 2.010632
COMMANDS_FINISHED 195 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_17/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_17/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_17/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_17/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_17/self_attn.q_proj/compressed.log
best_loss 218.9239044189453 running bpv: 2.010644
COMMANDS_FINISHED 196 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_17/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_17/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_17/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_23/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_23/mlp.down_proj/compressed.log
best_loss 51.40672302246094 running bpv: 2.01062
COMMANDS_FINISHED 197 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_17/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_17/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_17/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_17/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_17/mlp.gate_proj/compressed.log
best_loss 229.23959350585938 running bpv: 2.010608
COMMANDS_FINISHED 198 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_17/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_17/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_17/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_17/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_17/self_attn.k_proj/compressed.log
best_loss 230.30419921875 running bpv: 2.01062
COMMANDS_FINISHED 199 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_17/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_17/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_17/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_17/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_17/mlp.up_proj/compressed.log
best_loss 207.72772216796875 running bpv: 2.010608
COMMANDS_FINISHED 200 n_commands 504
 40%|‚ñà‚ñà‚ñà‚ñâ      | 201/504 [2:49:01<2:44:42, 32.62s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 202/504 [2:50:36<4:18:22, 51.33s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 203/504 [2:52:41<6:08:24, 73.44s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 204/504 [2:52:56<4:39:32, 55.91s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 205/504 [2:53:41<4:22:18, 52.64s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 206/504 [2:53:56<3:25:21, 41.35s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 207/504 [2:54:41<3:30:06, 42.45s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_9/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_9/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_9/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_17/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_17/self_attn.o_proj/compressed.log
best_loss 8.14108943939209 running bpv: 2.01062
COMMANDS_FINISHED 201 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_9/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_9/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_9/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_17/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_17/self_attn.v_proj/compressed.log
best_loss 101.78548431396484 running bpv: 2.010631
COMMANDS_FINISHED 202 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_9/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_9/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_9/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_9/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_9/self_attn.q_proj/compressed.log
best_loss 158.11233520507812 running bpv: 2.010643
COMMANDS_FINISHED 203 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_9/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_9/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_9/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_17/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_17/mlp.down_proj/compressed.log
best_loss 24.784391403198242 running bpv: 2.010619
COMMANDS_FINISHED 204 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_9/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_9/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_9/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_9/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_9/mlp.gate_proj/compressed.log
best_loss 110.66316223144531 running bpv: 2.010608
COMMANDS_FINISHED 205 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_9/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_9/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_9/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_9/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_9/mlp.up_proj/compressed.log
best_loss 93.21133422851562 running bpv: 2.010597
COMMANDS_FINISHED 206 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_9/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_9/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_9/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_9/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_9/self_attn.k_proj/compressed.log
best_loss 166.82003784179688 running bpv: 2.010608
COMMANDS_FINISHED 207 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_22/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_22/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_22/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_9/self_attn.o_proj is done
 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 208/504 [2:55:06<3:03:35, 37.21s/it] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 209/504 [2:56:01<3:29:12, 42.55s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 210/504 [2:58:06<5:29:42, 67.29s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 211/504 [2:59:01<5:10:36, 63.60s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 212/504 [2:59:36<4:27:47, 55.02s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 213/504 [3:00:01<3:43:11, 46.02s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 214/504 [3:00:16<2:57:27, 36.71s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 215/504 [3:01:11<3:23:16, 42.20s/it]reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_9/self_attn.o_proj/compressed.log
best_loss 3.055661201477051 running bpv: 2.010619
COMMANDS_FINISHED 208 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_22/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_22/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_22/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_9/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_9/self_attn.v_proj/compressed.log
best_loss 50.552040100097656 running bpv: 2.010631
COMMANDS_FINISHED 209 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_22/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_22/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_22/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_22/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_22/self_attn.q_proj/compressed.log
best_loss 285.6452941894531 running bpv: 2.010642
COMMANDS_FINISHED 210 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_22/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_22/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_22/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_9/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_9/mlp.down_proj/compressed.log
best_loss 5.739275932312012 running bpv: 2.010619
COMMANDS_FINISHED 211 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_22/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_22/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_22/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_22/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_22/mlp.gate_proj/compressed.log
best_loss 370.9779052734375 running bpv: 2.010608
COMMANDS_FINISHED 212 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_22/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_22/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_22/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_22/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_22/mlp.up_proj/compressed.log
best_loss 312.998779296875 running bpv: 2.010597
COMMANDS_FINISHED 213 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_22/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_22/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_22/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_22/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_22/self_attn.k_proj/compressed.log
best_loss 295.1433410644531 running bpv: 2.010608
COMMANDS_FINISHED 214 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_24/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_24/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_24/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_22/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_22/self_attn.o_proj/compressed.log
best_loss 14.106754302978516 running bpv: 2.010619
COMMANDS_FINISHED 215 n_commands 504
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 216/504 [3:02:06<3:41:00, 46.04s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 217/504 [3:04:11<5:33:33, 69.73s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 218/504 [3:04:46<4:42:44, 59.31s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 219/504 [3:05:11<3:52:51, 49.02s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 220/504 [3:06:06<4:00:32, 50.82s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 221/504 [3:06:21<3:09:00, 40.07s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 222/504 [3:06:56<3:01:12, 38.55s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_24/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_24/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_24/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_22/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_22/self_attn.v_proj/compressed.log
best_loss 174.48648071289062 running bpv: 2.01063
COMMANDS_FINISHED 216 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_24/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_24/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_24/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_24/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_24/self_attn.q_proj/compressed.log
best_loss 292.6028747558594 running bpv: 2.010641
COMMANDS_FINISHED 217 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_24/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_24/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_24/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_22/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_22/mlp.down_proj/compressed.log
best_loss 48.35481262207031 running bpv: 2.010618
COMMANDS_FINISHED 218 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_24/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_24/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_24/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_24/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_24/mlp.gate_proj/compressed.log
best_loss 423.89215087890625 running bpv: 2.010608
COMMANDS_FINISHED 219 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_24/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_24/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_24/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_24/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_24/mlp.up_proj/compressed.log
best_loss 362.0531311035156 running bpv: 2.010597
COMMANDS_FINISHED 220 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_0/pajama/128/layer_24/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_24/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_24/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_24/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_24/self_attn.k_proj/compressed.log
best_loss 298.00042724609375 running bpv: 2.010608
COMMANDS_FINISHED 221 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_3/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_3/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_3/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_24/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_24/self_attn.o_proj/compressed.log
best_loss 17.274497985839844 running bpv: 2.010619
COMMANDS_FINISHED 222 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_3/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_3/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_3/mlp.up_proj/compressed.log 2>&1 &
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 223/504 [3:08:11<3:51:46, 49.49s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 224/504 [3:10:26<5:50:40, 75.15s/it]meta-llama/Llama-2-7b-hf/layer_24/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_24/self_attn.v_proj/compressed.log
best_loss 207.37445068359375 running bpv: 2.010629
COMMANDS_FINISHED 223 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_3/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_3/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_3/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-7b-hf/layer_24/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_24/mlp.down_proj/compressed.log
best_loss 54.9062614440918 running bpv: 2.010608
COMMANDS_FINISHED 224 n_commands 504
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_3/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_3/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_3/self_attn.k_proj/compressed.log 2>&1 &
done with meta-llama/Llama-2-7b-hf
done with {'meta-llama/Llama-2-7b-hf/layer_3/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_3/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_3/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_3/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_3/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_3/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_3/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_3/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_3/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_3/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_3/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_3/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_3/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_3/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_5/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_5/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_5/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_5/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_5/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_5/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_5/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_5/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_5/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_5/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_5/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_5/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_8/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_8/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_8/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_8/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_5/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_5/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_8/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_8/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_8/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_8/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_8/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_8/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_8/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_8/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_12/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_12/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_8/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_8/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_12/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_12/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_12/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_12/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_12/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_12/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_12/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_12/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_12/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_12/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_1/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_1/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_12/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_12/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_1/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_1/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_1/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_1/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_1/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_1/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_1/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_1/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_1/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_1/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_7/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_7/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_1/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_1/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_7/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_7/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_7/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_7/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_7/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_7/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_7/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_7/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_7/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_7/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_0/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_0/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_7/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_7/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_0/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_0/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_0/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_0/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_0/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_0/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_0/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_0/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_0/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_0/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_31/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_31/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_0/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_0/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_31/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_31/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_31/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_31/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_31/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_31/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_31/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_31/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_31/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_31/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_21/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_21/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_31/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_31/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_21/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_21/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_21/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_21/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_21/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_21/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_21/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_21/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_21/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_21/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_26/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_26/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_21/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_21/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_26/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_26/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_26/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_26/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_26/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_26/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_26/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_26/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_26/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_26/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_14/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_14/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_26/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_26/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_14/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_14/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_14/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_14/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_14/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_14/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_14/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_14/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_14/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_14/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_15/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_15/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_14/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_14/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_15/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_15/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_15/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_15/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_15/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_15/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_15/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_15/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_15/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_15/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_4/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_4/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_15/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_15/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_4/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_4/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_4/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_4/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_4/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_4/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_4/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_4/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_4/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_4/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_27/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_27/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_4/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_4/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_27/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_27/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_27/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_27/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_27/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_27/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_27/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_27/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_27/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_27/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_2/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_2/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_27/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_27/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_2/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_2/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_2/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_2/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_2/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_2/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_2/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_2/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_2/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_2/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_28/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_28/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_2/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_2/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_28/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_28/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_28/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_28/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_28/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_28/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_28/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_28/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_28/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_28/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_18/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_18/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_28/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_28/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_18/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_18/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_18/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_18/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_18/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_18/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_18/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_18/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_18/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_18/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_25/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_25/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_18/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_18/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_25/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_25/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_25/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_25/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_25/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_25/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_25/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_25/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_25/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_25/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_30/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_30/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_25/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_25/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_30/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_30/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_30/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_30/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_30/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_30/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_30/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_30/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_30/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_30/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_29/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_29/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_30/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_30/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_29/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_29/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_29/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_29/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_29/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_29/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_29/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_29/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_29/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_29/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_16/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_16/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_29/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_29/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_16/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_16/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_16/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_16/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_16/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_16/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_16/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_16/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_16/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_16/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_13/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_13/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_16/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_16/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_13/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_13/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_13/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_13/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_13/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_13/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_13/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_13/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_13/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_13/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_10/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_10/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_13/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_13/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_10/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_10/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_10/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_10/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_10/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_10/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_10/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_10/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_10/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_10/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_19/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_19/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_10/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_10/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_19/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_19/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_19/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_19/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_19/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_19/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_19/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_19/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_19/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_19/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_6/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_6/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_19/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_19/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_6/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_6/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_6/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_6/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_6/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_6/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_6/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_6/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_6/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_6/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_11/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_11/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_6/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_6/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_11/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_11/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_11/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_11/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_11/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_11/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_11/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_11/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_11/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_11/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_20/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_20/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_11/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_11/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_20/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_20/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_20/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_20/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_20/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_20/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_20/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_20/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_20/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_20/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_23/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_23/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_20/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_20/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_23/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_23/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_23/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_23/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_23/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_23/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_23/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_23/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_23/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_23/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_17/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_17/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_23/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_23/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_17/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_17/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_17/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_17/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_17/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_17/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_17/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_17/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_17/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_17/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_9/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_9/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_17/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_17/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_9/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_9/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_9/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_9/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_9/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_9/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_9/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_9/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_9/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_9/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_22/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_22/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_9/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_9/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_22/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_22/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_22/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_22/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_22/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_22/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_22/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_22/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_22/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_22/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_24/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_24/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_22/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_22/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_24/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_24/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_24/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_24/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_24/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_24/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_24/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_24/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_24/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_24/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-7b-hf/layer_24/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-7b-hf/layer_24/mlp.down_proj/compressed.pt'} 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 225/504 [3:11:11<5:07:25, 66.11s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 226/504 [3:13:26<6:42:05, 86.78s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 227/504 [3:13:51<5:15:05, 68.25s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 228/504 [3:14:26<4:28:04, 58.28s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 229/504 [3:16:31<5:58:51, 78.30s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 230/504 [3:17:26<5:25:39, 71.31s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 231/504 [3:22:06<10:09:20, 133.92s/it]
/data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/checkpoints.yaml
perplexity_inference_command:
 python -u perplexity_eval.py --base_model meta-llama/Llama-2-7b-hf --seqlen 4096 --checkpoint_list_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/checkpoints.yaml --log_wandb --wandb_project compression_no_finetune --wandb_id 5lo7yfdu
meta-llama/Llama-2-13b-hf/layer_3/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_3/self_attn.q_proj/compressed.log
best_loss 35.32109069824219 running bpv: 2.010603
COMMANDS_FINISHED 225 n_commands 505
running: nohup python -u perplexity_eval.py --base_model meta-llama/Llama-2-7b-hf --seqlen 4096 --checkpoint_list_path /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/checkpoints.yaml --log_wandb --wandb_project compression_no_finetune --wandb_id 5lo7yfdu --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-7b-hf/compressed/chocolate-sun-74/ppl_eval.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_3/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_3/self_attn.k_proj/compressed.log
best_loss 40.140899658203125 running bpv: 2.010598
COMMANDS_FINISHED 226 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_3/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_3/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_3/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_3/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_3/mlp.gate_proj/compressed.log
best_loss 38.30628967285156 running bpv: 2.010542
COMMANDS_FINISHED 227 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_3/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_3/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_3/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_3/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_3/mlp.up_proj/compressed.log
best_loss 32.668453216552734 running bpv: 2.010488
COMMANDS_FINISHED 228 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_3/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_3/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_3/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_3/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_3/self_attn.o_proj/compressed.log
best_loss 0.3670174777507782 running bpv: 2.010484
COMMANDS_FINISHED 229 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_5/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_5/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_5/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_3/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_3/self_attn.v_proj/compressed.log
best_loss 10.884946823120117 running bpv: 2.01048
COMMANDS_FINISHED 230 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_5/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_5/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_5/mlp.up_proj/compressed.log 2>&1 &
eval is done
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_5/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_5/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_5/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_3/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_3/mlp.down_proj/compressed.log
best_loss 1.3283591270446777 running bpv: 2.010429
COMMANDS_FINISHED 232 n_commands 505
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 232/504 [3:22:21<7:25:23, 98.25s/it]   46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 233/504 [3:24:06<7:32:54, 100.28s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 234/504 [3:25:01<6:30:07, 86.70s/it]  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 235/504 [3:25:16<4:52:15, 65.19s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 236/504 [3:25:31<3:43:55, 50.13s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 237/504 [3:27:56<5:49:45, 78.60s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 238/504 [3:30:51<7:56:40, 107.52s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_5/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_5/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_5/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_5/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_5/self_attn.q_proj/compressed.log
best_loss 93.02874755859375 running bpv: 2.010425
COMMANDS_FINISHED 233 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_5/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_5/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_5/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_5/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_5/mlp.gate_proj/compressed.log
best_loss 74.24079895019531 running bpv: 2.010373
COMMANDS_FINISHED 234 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_5/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_5/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_5/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_5/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_5/mlp.up_proj/compressed.log
best_loss 61.21141052246094 running bpv: 2.010323
COMMANDS_FINISHED 235 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_5/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_5/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_5/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_5/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_5/self_attn.k_proj/compressed.log
best_loss 91.12730407714844 running bpv: 2.01032
COMMANDS_FINISHED 236 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_8/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_8/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_8/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_5/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_5/self_attn.o_proj/compressed.log
best_loss 0.8987669944763184 running bpv: 2.010316
COMMANDS_FINISHED 237 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_8/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_8/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_8/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_5/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_5/self_attn.v_proj/compressed.log
best_loss 32.408485412597656 running bpv: 2.010313
COMMANDS_FINISHED 238 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_8/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_8/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_8/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_8/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_8/self_attn.q_proj/compressed.log
best_loss 148.4287109375 running bpv: 2.010309
COMMANDS_FINISHED 239 n_commands 505
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 239/504 [3:32:26<7:38:18, 103.77s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 240/504 [3:32:51<5:52:36, 80.14s/it]  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 241/504 [3:33:06<4:25:37, 60.60s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 242/504 [3:33:51<4:04:11, 55.92s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 243/504 [3:35:26<4:54:15, 67.65s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 244/504 [3:36:01<4:10:42, 57.86s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 245/504 [3:38:56<6:41:27, 93.00s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_8/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_8/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_8/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_5/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_5/mlp.down_proj/compressed.log
best_loss 3.0847861766815186 running bpv: 2.010262
COMMANDS_FINISHED 240 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_8/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_8/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_8/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_8/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_8/mlp.gate_proj/compressed.log
best_loss 132.50540161132812 running bpv: 2.010215
COMMANDS_FINISHED 241 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_8/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_8/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_8/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_8/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_8/mlp.up_proj/compressed.log
best_loss 108.4609375 running bpv: 2.010168
COMMANDS_FINISHED 242 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_8/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_8/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_8/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_8/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_8/self_attn.k_proj/compressed.log
best_loss 153.74700927734375 running bpv: 2.010166
COMMANDS_FINISHED 243 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_39/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_39/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_39/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_8/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_8/self_attn.o_proj/compressed.log
best_loss 3.2730979919433594 running bpv: 2.010163
COMMANDS_FINISHED 244 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_39/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_39/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_39/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_8/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_8/self_attn.v_proj/compressed.log
best_loss 58.62786102294922 running bpv: 2.01016
COMMANDS_FINISHED 245 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_39/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_39/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_39/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_39/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_39/self_attn.q_proj/compressed.log
best_loss 229.17755126953125 running bpv: 2.010157
COMMANDS_FINISHED 246 n_commands 505
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 246/504 [3:41:11<7:34:06, 105.60s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 247/504 [3:41:26<5:35:55, 78.42s/it]  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 248/504 [3:41:51<4:26:14, 62.40s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 249/504 [3:42:56<4:28:31, 63.18s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 250/504 [3:44:11<4:42:29, 66.73s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 251/504 [3:44:56<4:13:53, 60.21s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 252/504 [3:48:01<6:50:08, 97.65s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_39/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_39/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_39/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_8/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_8/mlp.down_proj/compressed.log
best_loss 7.975516319274902 running bpv: 2.010114
COMMANDS_FINISHED 247 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_39/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_39/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_39/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_39/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_39/mlp.gate_proj/compressed.log
best_loss 549.8367309570312 running bpv: 2.01007
COMMANDS_FINISHED 248 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_39/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_39/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_39/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_39/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_39/self_attn.k_proj/compressed.log
best_loss 237.14019775390625 running bpv: 2.010067
COMMANDS_FINISHED 249 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_39/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_39/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_39/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_39/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_39/mlp.up_proj/compressed.log
best_loss 470.9302673339844 running bpv: 2.010024
COMMANDS_FINISHED 250 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_12/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_12/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_12/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_39/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_39/self_attn.o_proj/compressed.log
best_loss 88.11050415039062 running bpv: 2.010022
COMMANDS_FINISHED 251 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_12/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_12/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_12/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_39/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_39/self_attn.v_proj/compressed.log
best_loss 241.62216186523438 running bpv: 2.01002
COMMANDS_FINISHED 252 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_12/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_12/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_12/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_12/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_12/self_attn.q_proj/compressed.log
best_loss 195.2042999267578 running bpv: 2.010018
COMMANDS_FINISHED 253 n_commands 505
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 253/504 [3:49:46<6:57:44, 99.86s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 254/504 [3:50:31<5:47:30, 83.40s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 255/504 [3:51:06<4:45:52, 68.88s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 256/504 [3:51:41<4:02:42, 58.72s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 257/504 [3:52:46<4:09:29, 60.61s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 258/504 [3:54:01<4:26:12, 64.93s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 259/504 [3:56:56<6:39:58, 97.95s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_12/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_12/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_12/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_39/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_39/mlp.down_proj/compressed.log
best_loss 224.4254150390625 running bpv: 2.009977
COMMANDS_FINISHED 254 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_12/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_12/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_12/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_12/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_12/mlp.gate_proj/compressed.log
best_loss 159.15185546875 running bpv: 2.009936
COMMANDS_FINISHED 255 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_12/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_12/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_12/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_12/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_12/self_attn.k_proj/compressed.log
best_loss 202.70416259765625 running bpv: 2.009935
COMMANDS_FINISHED 256 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_12/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_12/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_12/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_12/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_12/mlp.up_proj/compressed.log
best_loss 148.80760192871094 running bpv: 2.009894
COMMANDS_FINISHED 257 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_1/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_1/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_1/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_12/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_12/self_attn.o_proj/compressed.log
best_loss 8.11640453338623 running bpv: 2.009893
COMMANDS_FINISHED 258 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_1/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_1/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_1/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_12/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_12/self_attn.v_proj/compressed.log
best_loss 83.90452575683594 running bpv: 2.009891
COMMANDS_FINISHED 259 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_1/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_1/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_1/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_1/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_1/self_attn.q_proj/compressed.log
best_loss 2.7483885288238525 running bpv: 2.009889
COMMANDS_FINISHED 260 n_commands 505
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 260/504 [3:58:51<6:59:08, 103.07s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 261/504 [3:59:16<5:22:34, 79.65s/it]  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 262/504 [4:00:01<4:39:20, 69.26s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 263/504 [4:00:16<3:32:48, 52.98s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 264/504 [4:01:51<4:22:21, 65.59s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 265/504 [4:02:57<4:20:34, 65.41s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 266/504 [4:05:52<6:29:53, 98.29s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_1/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_1/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_1/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_12/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_12/mlp.down_proj/compressed.log
best_loss 13.27565860748291 running bpv: 2.009852
COMMANDS_FINISHED 261 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_1/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_1/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_1/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_1/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_1/mlp.gate_proj/compressed.log
best_loss 6.729611396789551 running bpv: 2.009813
COMMANDS_FINISHED 262 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_1/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_1/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_1/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_1/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_1/self_attn.k_proj/compressed.log
best_loss 2.8514208793640137 running bpv: 2.009812
COMMANDS_FINISHED 263 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_1/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_1/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_1/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_1/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_1/mlp.up_proj/compressed.log
best_loss 5.926314353942871 running bpv: 2.009775
COMMANDS_FINISHED 264 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_7/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_7/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_7/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_1/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_1/self_attn.o_proj/compressed.log
best_loss 0.06196438521146774 running bpv: 2.009773
COMMANDS_FINISHED 265 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_7/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_7/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_7/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_1/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_1/self_attn.v_proj/compressed.log
best_loss 0.6954295039176941 running bpv: 2.009772
COMMANDS_FINISHED 266 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_7/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_7/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_7/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_7/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_7/self_attn.q_proj/compressed.log
best_loss 121.22207641601562 running bpv: 2.009771
COMMANDS_FINISHED 267 n_commands 505
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 267/504 [4:07:37<6:36:13, 100.31s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 268/504 [4:07:52<4:53:53, 74.72s/it]  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 269/504 [4:08:47<4:29:29, 68.80s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 270/504 [4:09:22<3:48:47, 58.66s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 271/504 [4:10:37<4:06:51, 63.57s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 272/504 [4:11:42<4:07:27, 64.00s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 273/504 [4:14:37<6:14:37, 97.30s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_7/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_7/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_7/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_1/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_1/mlp.down_proj/compressed.log
best_loss 0.23989519476890564 running bpv: 2.009736
COMMANDS_FINISHED 268 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_7/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_7/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_7/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_7/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_7/mlp.gate_proj/compressed.log
best_loss 115.09477233886719 running bpv: 2.0097
COMMANDS_FINISHED 269 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_7/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_7/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_7/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_7/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_7/self_attn.k_proj/compressed.log
best_loss 125.46888732910156 running bpv: 2.009699
COMMANDS_FINISHED 270 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_7/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_7/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_7/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_7/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_7/mlp.up_proj/compressed.log
best_loss 91.91960144042969 running bpv: 2.009664
COMMANDS_FINISHED 271 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_33/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_33/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_33/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_7/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_7/self_attn.o_proj/compressed.log
best_loss 2.3407106399536133 running bpv: 2.009663
COMMANDS_FINISHED 272 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_33/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_33/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_33/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_7/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_7/self_attn.v_proj/compressed.log
best_loss 44.98308563232422 running bpv: 2.009662
COMMANDS_FINISHED 273 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_33/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_33/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_33/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_33/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_33/self_attn.q_proj/compressed.log
best_loss 383.85321044921875 running bpv: 2.009661
COMMANDS_FINISHED 274 n_commands 505
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 274/504 [4:16:12<6:10:21, 96.62s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 275/504 [4:16:57<5:09:39, 81.13s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 276/504 [4:17:32<4:15:43, 67.29s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 277/504 [4:18:07<3:37:57, 57.61s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 278/504 [4:19:12<3:45:21, 59.83s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 279/504 [4:20:27<4:01:25, 64.38s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 280/504 [4:23:22<6:04:15, 97.57s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_33/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_33/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_33/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_7/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_7/mlp.down_proj/compressed.log
best_loss 6.1772260665893555 running bpv: 2.009628
COMMANDS_FINISHED 275 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_33/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_33/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_33/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_33/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_33/mlp.gate_proj/compressed.log
best_loss 644.2680053710938 running bpv: 2.009594
COMMANDS_FINISHED 276 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_33/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_33/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_33/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_33/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_33/self_attn.k_proj/compressed.log
best_loss 394.4996032714844 running bpv: 2.009593
COMMANDS_FINISHED 277 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_33/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_33/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_33/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_33/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_33/mlp.up_proj/compressed.log
best_loss 556.8652954101562 running bpv: 2.00956
COMMANDS_FINISHED 278 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_34/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_34/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_34/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_33/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_33/self_attn.o_proj/compressed.log
best_loss 19.884601593017578 running bpv: 2.00956
COMMANDS_FINISHED 279 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_34/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_34/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_34/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_33/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_33/self_attn.v_proj/compressed.log
best_loss 317.8519592285156 running bpv: 2.009559
COMMANDS_FINISHED 280 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_34/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_34/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_34/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_34/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_34/self_attn.q_proj/compressed.log
best_loss 386.093505859375 running bpv: 2.009559
COMMANDS_FINISHED 281 n_commands 505
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 281/504 [4:25:17<6:22:04, 102.80s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 282/504 [4:25:42<4:54:00, 79.46s/it]  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 283/504 [4:26:17<4:03:33, 66.13s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 284/504 [4:26:42<3:17:13, 53.79s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 285/504 [4:28:17<4:01:28, 66.16s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 286/504 [4:29:12<3:48:12, 62.81s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 287/504 [4:32:17<5:59:45, 99.47s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_34/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_34/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_34/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_33/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_33/mlp.down_proj/compressed.log
best_loss 89.77647399902344 running bpv: 2.009528
COMMANDS_FINISHED 282 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_34/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_34/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_34/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_34/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_34/mlp.gate_proj/compressed.log
best_loss 661.5006713867188 running bpv: 2.009496
COMMANDS_FINISHED 283 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_34/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_34/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_34/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_34/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_34/self_attn.k_proj/compressed.log
best_loss 396.14459228515625 running bpv: 2.009496
COMMANDS_FINISHED 284 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_34/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_34/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_34/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_34/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_34/mlp.up_proj/compressed.log
best_loss 584.8775634765625 running bpv: 2.009464
COMMANDS_FINISHED 285 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_0/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_0/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_0/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_34/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_34/self_attn.o_proj/compressed.log
best_loss 28.230085372924805 running bpv: 2.009464
COMMANDS_FINISHED 286 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_0/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_0/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_0/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_34/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_34/self_attn.v_proj/compressed.log
best_loss 347.5350036621094 running bpv: 2.009464
COMMANDS_FINISHED 287 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_0/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_0/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_0/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_0/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_0/self_attn.q_proj/compressed.log
best_loss 0.06359345465898514 running bpv: 2.009464
COMMANDS_FINISHED 288 n_commands 505
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 288/504 [4:34:02<6:04:04, 101.13s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 289/504 [4:34:17<4:29:48, 75.29s/it]  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 290/504 [4:35:22<4:17:32, 72.21s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 291/504 [4:35:47<3:26:04, 58.05s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 292/504 [4:37:02<3:43:04, 63.14s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 293/504 [4:38:17<3:54:33, 66.70s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 294/504 [4:41:12<5:47:10, 99.19s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_0/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_0/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_0/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_34/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_34/mlp.down_proj/compressed.log
best_loss 99.27543640136719 running bpv: 2.009434
COMMANDS_FINISHED 289 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_0/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_0/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_0/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_0/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_0/mlp.gate_proj/compressed.log
best_loss 1.2447922229766846 running bpv: 2.009404
COMMANDS_FINISHED 290 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_0/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_0/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_0/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_0/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_0/self_attn.k_proj/compressed.log
best_loss 0.04480113834142685 running bpv: 2.009404
COMMANDS_FINISHED 291 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_0/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_0/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_0/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_0/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_0/mlp.up_proj/compressed.log
best_loss 1.1609965562820435 running bpv: 2.009375
COMMANDS_FINISHED 292 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_32/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_32/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_32/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_0/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_0/self_attn.o_proj/compressed.log
best_loss 0.002443091245368123 running bpv: 2.009375
COMMANDS_FINISHED 293 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_32/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_32/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_32/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_0/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_0/self_attn.v_proj/compressed.log
best_loss 0.013423135504126549 running bpv: 2.009375
COMMANDS_FINISHED 294 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_32/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_32/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_32/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_32/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_32/self_attn.q_proj/compressed.log
best_loss 418.1475830078125 running bpv: 2.009375
COMMANDS_FINISHED 295 n_commands 505
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 295/504 [4:42:37<5:30:41, 94.94s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 296/504 [4:43:22<4:37:11, 79.96s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 297/504 [4:44:17<4:10:01, 72.47s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 298/504 [4:44:32<3:09:37, 55.23s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 299/504 [4:45:37<3:18:43, 58.17s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 300/504 [4:47:12<3:55:20, 69.22s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 301/504 [4:50:07<5:41:34, 100.96s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_32/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_32/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_32/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_0/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_0/mlp.down_proj/compressed.log
best_loss 0.026599882170557976 running bpv: 2.009347
COMMANDS_FINISHED 296 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_32/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_32/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_32/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_32/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_32/mlp.gate_proj/compressed.log
best_loss 627.376220703125 running bpv: 2.009319
COMMANDS_FINISHED 297 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_32/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_32/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_32/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_32/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_32/self_attn.k_proj/compressed.log
best_loss 425.5325012207031 running bpv: 2.009319
COMMANDS_FINISHED 298 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_32/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_32/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_32/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_32/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_32/mlp.up_proj/compressed.log
best_loss 536.781494140625 running bpv: 2.009291
COMMANDS_FINISHED 299 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_31/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_31/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_31/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_32/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_32/self_attn.o_proj/compressed.log
best_loss 21.18423843383789 running bpv: 2.009291
COMMANDS_FINISHED 300 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_31/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_31/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_31/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_32/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_32/self_attn.v_proj/compressed.log
best_loss 357.0179138183594 running bpv: 2.009291
COMMANDS_FINISHED 301 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_31/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_31/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_31/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_31/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_31/self_attn.q_proj/compressed.log
best_loss 399.301513671875 running bpv: 2.009292
COMMANDS_FINISHED 302 n_commands 505
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 302/504 [4:51:42<5:33:52, 99.17s/it]  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 303/504 [4:52:07<4:17:41, 76.92s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 304/504 [4:53:02<3:54:29, 70.35s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 305/504 [4:53:17<2:58:15, 53.75s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 306/504 [4:54:42<3:28:18, 63.12s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 307/504 [4:55:57<3:38:57, 66.69s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 308/504 [4:58:52<5:24:00, 99.19s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_31/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_31/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_31/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_32/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_32/mlp.down_proj/compressed.log
best_loss 85.30726623535156 running bpv: 2.009265
COMMANDS_FINISHED 303 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_31/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_31/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_31/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_31/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_31/mlp.gate_proj/compressed.log
best_loss 605.99267578125 running bpv: 2.009238
COMMANDS_FINISHED 304 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_31/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_31/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_31/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_31/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_31/self_attn.k_proj/compressed.log
best_loss 413.97869873046875 running bpv: 2.009239
COMMANDS_FINISHED 305 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_31/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_31/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_31/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_31/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_31/mlp.up_proj/compressed.log
best_loss 511.72210693359375 running bpv: 2.009212
COMMANDS_FINISHED 306 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_21/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_21/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_21/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_31/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_31/self_attn.o_proj/compressed.log
best_loss 20.83800506591797 running bpv: 2.009213
COMMANDS_FINISHED 307 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_21/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_21/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_21/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_31/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_31/self_attn.v_proj/compressed.log
best_loss 309.6305847167969 running bpv: 2.009213
COMMANDS_FINISHED 308 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_21/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_21/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_21/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_21/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_21/self_attn.q_proj/compressed.log
best_loss 263.5611877441406 running bpv: 2.009214
COMMANDS_FINISHED 309 n_commands 505
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 309/504 [5:00:27<5:18:16, 97.93s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 310/504 [5:00:52<4:05:54, 76.06s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 311/504 [5:01:47<3:44:20, 69.74s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 312/504 [5:02:12<3:00:13, 56.32s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 313/504 [5:03:27<3:17:07, 61.93s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 314/504 [5:04:42<3:28:31, 65.85s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 315/504 [5:07:37<5:10:35, 98.60s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_21/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_21/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_21/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_31/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_31/mlp.down_proj/compressed.log
best_loss 80.03982543945312 running bpv: 2.009189
COMMANDS_FINISHED 310 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_21/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_21/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_21/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_21/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_21/mlp.gate_proj/compressed.log
best_loss 351.28387451171875 running bpv: 2.009163
COMMANDS_FINISHED 311 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_21/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_21/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_21/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_21/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_21/self_attn.k_proj/compressed.log
best_loss 273.62164306640625 running bpv: 2.009164
COMMANDS_FINISHED 312 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_21/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_21/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_21/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_21/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_21/mlp.up_proj/compressed.log
best_loss 310.8160400390625 running bpv: 2.009138
COMMANDS_FINISHED 313 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_26/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_26/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_26/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_21/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_21/self_attn.o_proj/compressed.log
best_loss 20.99327850341797 running bpv: 2.009139
COMMANDS_FINISHED 314 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_26/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_26/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_26/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_21/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_21/self_attn.v_proj/compressed.log
best_loss 160.6942901611328 running bpv: 2.00914
COMMANDS_FINISHED 315 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_26/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_26/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_26/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_26/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_26/self_attn.q_proj/compressed.log
best_loss 333.3533935546875 running bpv: 2.00914
COMMANDS_FINISHED 316 n_commands 505
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 316/504 [5:09:12<5:05:34, 97.52s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 317/504 [5:09:47<4:05:29, 78.77s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 318/504 [5:10:42<3:42:05, 71.64s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 319/504 [5:10:57<2:48:30, 54.65s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 320/504 [5:12:12<3:06:19, 60.76s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 321/504 [5:13:47<3:36:39, 71.03s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 322/504 [5:16:52<5:19:11, 105.23s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_26/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_26/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_26/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_21/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_21/mlp.down_proj/compressed.log
best_loss 53.495872497558594 running bpv: 2.009116
COMMANDS_FINISHED 317 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_26/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_26/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_26/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_26/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_26/mlp.gate_proj/compressed.log
best_loss 489.1866455078125 running bpv: 2.009092
COMMANDS_FINISHED 318 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_26/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_26/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_26/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_26/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_26/self_attn.k_proj/compressed.log
best_loss 341.6159362792969 running bpv: 2.009093
COMMANDS_FINISHED 319 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_26/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_26/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_26/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_26/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_26/mlp.up_proj/compressed.log
best_loss 409.8697509765625 running bpv: 2.009069
COMMANDS_FINISHED 320 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_14/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_14/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_14/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_26/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_26/self_attn.o_proj/compressed.log
best_loss 20.858654022216797 running bpv: 2.00907
COMMANDS_FINISHED 321 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_14/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_14/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_14/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_26/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_26/self_attn.v_proj/compressed.log
best_loss 254.14157104492188 running bpv: 2.00907
COMMANDS_FINISHED 322 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_14/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_14/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_14/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_14/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_14/self_attn.q_proj/compressed.log
best_loss 229.6436309814453 running bpv: 2.009071
COMMANDS_FINISHED 323 n_commands 505
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 323/504 [5:18:07<4:50:05, 96.16s/it]  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 324/504 [5:18:32<3:44:43, 74.91s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 325/504 [5:19:47<3:43:33, 74.94s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 326/504 [5:20:02<2:48:58, 56.96s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 327/504 [5:21:07<2:55:09, 59.37s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 328/504 [5:22:42<3:25:31, 70.06s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 329/504 [5:25:47<5:04:55, 104.55s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_14/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_14/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_14/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_26/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_26/mlp.down_proj/compressed.log
best_loss 68.36532592773438 running bpv: 2.009049
COMMANDS_FINISHED 324 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_14/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_14/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_14/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_14/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_14/mlp.gate_proj/compressed.log
best_loss 185.07513427734375 running bpv: 2.009025
COMMANDS_FINISHED 325 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_14/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_14/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_14/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_14/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_14/mlp.up_proj/compressed.log
best_loss 179.02223205566406 running bpv: 2.009002
COMMANDS_FINISHED 326 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_14/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_14/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_14/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_14/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_14/self_attn.k_proj/compressed.log
best_loss 238.68701171875 running bpv: 2.009003
COMMANDS_FINISHED 327 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_15/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_15/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_15/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_14/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_14/self_attn.o_proj/compressed.log
best_loss 11.757185935974121 running bpv: 2.009004
COMMANDS_FINISHED 328 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_15/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_15/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_15/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_14/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_14/self_attn.v_proj/compressed.log
best_loss 101.61164855957031 running bpv: 2.009005
COMMANDS_FINISHED 329 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_15/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_15/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_15/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_15/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_15/self_attn.q_proj/compressed.log
best_loss 217.55581665039062 running bpv: 2.009006
COMMANDS_FINISHED 330 n_commands 505
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 330/504 [5:26:52<4:28:47, 92.69s/it]  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 331/504 [5:27:37<3:46:00, 78.38s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 332/504 [5:28:42<3:33:11, 74.37s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 333/504 [5:28:57<2:41:11, 56.56s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 334/504 [5:29:52<2:38:56, 56.09s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 335/504 [5:31:47<3:27:47, 73.77s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 336/504 [5:35:02<5:08:24, 110.14s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_15/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_15/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_15/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_14/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_14/mlp.down_proj/compressed.log
best_loss 18.76617431640625 running bpv: 2.008984
COMMANDS_FINISHED 331 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_15/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_15/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_15/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_15/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_15/mlp.gate_proj/compressed.log
best_loss 201.46974182128906 running bpv: 2.008962
COMMANDS_FINISHED 332 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_15/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_15/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_15/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_15/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_15/mlp.up_proj/compressed.log
best_loss 195.66329956054688 running bpv: 2.00894
COMMANDS_FINISHED 333 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_15/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_15/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_15/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_15/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_15/self_attn.k_proj/compressed.log
best_loss 231.98004150390625 running bpv: 2.008941
COMMANDS_FINISHED 334 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_4/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_4/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_4/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_15/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_15/self_attn.o_proj/compressed.log
best_loss 13.784908294677734 running bpv: 2.008942
COMMANDS_FINISHED 335 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_4/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_4/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_4/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_15/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_15/self_attn.v_proj/compressed.log
best_loss 106.7752456665039 running bpv: 2.008943
COMMANDS_FINISHED 336 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_4/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_4/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_4/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_4/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_4/self_attn.q_proj/compressed.log
best_loss 79.46160888671875 running bpv: 2.008944
COMMANDS_FINISHED 337 n_commands 505
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 337/504 [5:36:27<4:45:34, 102.60s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 338/504 [5:36:52<3:39:27, 79.32s/it]  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 339/504 [5:37:47<3:18:04, 72.03s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 340/504 [5:38:12<2:38:19, 57.92s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 341/504 [5:39:27<2:51:16, 63.05s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 342/504 [5:40:52<3:08:01, 69.64s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 343/504 [5:44:07<4:47:47, 107.25s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_4/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_4/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_4/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_15/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_15/mlp.down_proj/compressed.log
best_loss 21.98776626586914 running bpv: 2.008924
COMMANDS_FINISHED 338 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_4/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_4/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_4/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_4/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_4/mlp.gate_proj/compressed.log
best_loss 53.97792053222656 running bpv: 2.008903
COMMANDS_FINISHED 339 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_4/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_4/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_4/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_4/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_4/mlp.up_proj/compressed.log
best_loss 45.660057067871094 running bpv: 2.008882
COMMANDS_FINISHED 340 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_4/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_4/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_4/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_4/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_4/self_attn.k_proj/compressed.log
best_loss 81.329345703125 running bpv: 2.008883
COMMANDS_FINISHED 341 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_27/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_27/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_27/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_4/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_4/self_attn.o_proj/compressed.log
best_loss 0.5877338647842407 running bpv: 2.008884
COMMANDS_FINISHED 342 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_27/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_27/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_27/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_4/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_4/self_attn.v_proj/compressed.log
best_loss 25.64206886291504 running bpv: 2.008885
COMMANDS_FINISHED 343 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_27/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_27/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_27/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_27/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_27/self_attn.q_proj/compressed.log
best_loss 381.86669921875 running bpv: 2.008886
COMMANDS_FINISHED 344 n_commands 505
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 344/504 [5:45:22<4:20:12, 97.58s/it]  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 345/504 [5:45:57<3:28:50, 78.81s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 346/504 [5:47:12<3:24:31, 77.67s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 348/504 [5:48:22<2:30:44, 57.98s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 349/504 [5:50:07<2:59:53, 69.64s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 350/504 [5:53:03<4:09:28, 97.20s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_27/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_27/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_27/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_4/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_4/mlp.down_proj/compressed.log
best_loss 1.929100513458252 running bpv: 2.008867
COMMANDS_FINISHED 345 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_27/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_27/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_27/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_27/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_27/mlp.gate_proj/compressed.log
best_loss 516.4873046875 running bpv: 2.008846
COMMANDS_FINISHED 346 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_27/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_27/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_27/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_27/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_27/mlp.up_proj/compressed.log
best_loss 430.9075622558594 running bpv: 2.008826
COMMANDS_FINISHED 347 n_commands 505
meta-llama/Llama-2-13b-hf/layer_27/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_27/self_attn.k_proj/compressed.log
best_loss 389.10760498046875 running bpv: 2.008827
COMMANDS_FINISHED 348 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_27/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_27/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_27/self_attn.v_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_2/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_2/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_2/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_27/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_27/self_attn.o_proj/compressed.log
best_loss 19.9537296295166 running bpv: 2.008829
COMMANDS_FINISHED 349 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_2/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_2/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_2/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_27/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_27/self_attn.v_proj/compressed.log
best_loss 286.4368896484375 running bpv: 2.00883
COMMANDS_FINISHED 350 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_2/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_2/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_2/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_2/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_2/self_attn.q_proj/compressed.log
best_loss 21.362796783447266 running bpv: 2.008831
COMMANDS_FINISHED 351 n_commands 505
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 351/504 [5:54:18<3:52:27, 91.16s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 352/504 [5:54:53<3:11:08, 75.45s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 353/504 [5:55:58<3:02:22, 72.47s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 354/504 [5:56:13<2:19:32, 55.82s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 355/504 [5:57:18<2:25:17, 58.51s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 356/504 [5:58:53<2:50:52, 69.27s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 357/504 [6:01:58<4:13:45, 103.58s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_2/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_2/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_2/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_27/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_27/mlp.down_proj/compressed.log
best_loss 70.31822967529297 running bpv: 2.008812
COMMANDS_FINISHED 352 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_2/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_2/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_2/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_2/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_2/mlp.gate_proj/compressed.log
best_loss 21.264507293701172 running bpv: 2.008793
COMMANDS_FINISHED 353 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_2/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_2/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_2/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_2/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_2/mlp.up_proj/compressed.log
best_loss 18.125694274902344 running bpv: 2.008774
COMMANDS_FINISHED 354 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_2/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_2/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_2/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_2/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_2/self_attn.k_proj/compressed.log
best_loss 23.08623504638672 running bpv: 2.008775
COMMANDS_FINISHED 355 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_36/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_36/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_36/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_2/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_2/self_attn.o_proj/compressed.log
best_loss 0.17520996928215027 running bpv: 2.008776
COMMANDS_FINISHED 356 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_36/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_36/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_36/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_2/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_2/self_attn.v_proj/compressed.log
best_loss 6.170430660247803 running bpv: 2.008777
COMMANDS_FINISHED 357 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_36/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_36/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_36/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_36/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_36/self_attn.q_proj/compressed.log
best_loss 334.778076171875 running bpv: 2.008779
COMMANDS_FINISHED 358 n_commands 505
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 358/504 [6:03:03<3:44:07, 92.10s/it]  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 359/504 [6:03:48<3:08:38, 78.06s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 360/504 [6:04:53<2:57:58, 74.16s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 362/504 [6:06:03<2:12:50, 56.13s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 363/504 [6:07:58<2:46:09, 70.70s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 364/504 [6:10:53<3:48:33, 97.95s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_36/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_36/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_36/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_2/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_2/mlp.down_proj/compressed.log
best_loss 0.6562497615814209 running bpv: 2.008761
COMMANDS_FINISHED 359 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_36/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_36/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_36/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_36/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_36/mlp.gate_proj/compressed.log
best_loss 693.7279052734375 running bpv: 2.008742
COMMANDS_FINISHED 360 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_36/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_36/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_36/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_36/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_36/mlp.up_proj/compressed.log
best_loss 636.7870483398438 running bpv: 2.008723
COMMANDS_FINISHED 361 n_commands 505
meta-llama/Llama-2-13b-hf/layer_36/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_36/self_attn.k_proj/compressed.log
best_loss 348.3739013671875 running bpv: 2.008725
COMMANDS_FINISHED 362 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_36/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_36/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_36/self_attn.v_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_28/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_28/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_28/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_36/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_36/self_attn.o_proj/compressed.log
best_loss 39.112953186035156 running bpv: 2.008726
COMMANDS_FINISHED 363 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_28/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_28/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_28/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_36/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_36/self_attn.v_proj/compressed.log
best_loss 318.3593444824219 running bpv: 2.008727
COMMANDS_FINISHED 364 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_28/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_28/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_28/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_28/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_28/self_attn.q_proj/compressed.log
best_loss 380.9080810546875 running bpv: 2.008729
COMMANDS_FINISHED 365 n_commands 505
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 365/504 [6:12:08<3:32:28, 91.72s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 366/504 [6:12:33<2:48:02, 73.06s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 367/504 [6:13:38<2:41:34, 70.76s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 368/504 [6:13:53<2:03:46, 54.61s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 369/504 [6:15:08<2:16:18, 60.58s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 370/504 [6:16:33<2:31:22, 67.78s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 371/504 [6:19:38<3:47:16, 102.53s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_28/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_28/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_28/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_36/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_36/mlp.down_proj/compressed.log
best_loss 128.316650390625 running bpv: 2.008711
COMMANDS_FINISHED 366 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_28/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_28/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_28/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_28/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_28/mlp.gate_proj/compressed.log
best_loss 535.3707885742188 running bpv: 2.008694
COMMANDS_FINISHED 367 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_28/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_28/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_28/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_28/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_28/mlp.up_proj/compressed.log
best_loss 447.99212646484375 running bpv: 2.008676
COMMANDS_FINISHED 368 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_28/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_28/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_28/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_28/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_28/self_attn.k_proj/compressed.log
best_loss 387.2958068847656 running bpv: 2.008677
COMMANDS_FINISHED 369 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_18/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_18/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_18/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_28/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_28/self_attn.o_proj/compressed.log
best_loss 18.788827896118164 running bpv: 2.008679
COMMANDS_FINISHED 370 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_18/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_18/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_18/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_28/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_28/self_attn.v_proj/compressed.log
best_loss 290.68804931640625 running bpv: 2.00868
COMMANDS_FINISHED 371 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_18/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_18/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_18/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_18/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_18/self_attn.q_proj/compressed.log
best_loss 262.78594970703125 running bpv: 2.008681
COMMANDS_FINISHED 372 n_commands 505
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 372/504 [6:20:53<3:27:33, 94.34s/it]  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 373/504 [6:21:28<2:47:20, 76.65s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 374/504 [6:22:43<2:45:00, 76.16s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 376/504 [6:23:53<2:02:02, 57.21s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 377/504 [6:25:48<2:31:22, 71.51s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 378/504 [6:28:53<3:32:26, 101.16s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_18/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_18/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_18/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_28/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_28/mlp.down_proj/compressed.log
best_loss 71.16986083984375 running bpv: 2.008665
COMMANDS_FINISHED 373 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_18/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_18/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_18/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_18/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_18/mlp.gate_proj/compressed.log
best_loss 281.02099609375 running bpv: 2.008647
COMMANDS_FINISHED 374 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_18/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_18/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_18/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_18/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_18/mlp.up_proj/compressed.log
best_loss 259.143310546875 running bpv: 2.00863
COMMANDS_FINISHED 375 n_commands 505
meta-llama/Llama-2-13b-hf/layer_18/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_18/self_attn.k_proj/compressed.log
best_loss 276.1610412597656 running bpv: 2.008632
COMMANDS_FINISHED 376 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_18/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_18/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_18/self_attn.v_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_25/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_25/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_25/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_18/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_18/self_attn.o_proj/compressed.log
best_loss 13.566072463989258 running bpv: 2.008633
COMMANDS_FINISHED 377 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_25/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_25/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_25/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_18/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_18/self_attn.v_proj/compressed.log
best_loss 144.68966674804688 running bpv: 2.008635
COMMANDS_FINISHED 378 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_25/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_25/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_25/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_25/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_25/self_attn.q_proj/compressed.log
best_loss 330.6962890625 running bpv: 2.008636
COMMANDS_FINISHED 379 n_commands 505
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 379/504 [6:29:58<3:10:17, 91.34s/it]  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 380/504 [6:30:33<2:36:12, 75.58s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 381/504 [6:31:38<2:28:45, 72.56s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 382/504 [6:32:03<1:59:32, 58.79s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 383/504 [6:32:58<1:56:19, 57.68s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 384/504 [6:34:43<2:23:16, 71.64s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 385/504 [6:37:58<3:34:35, 108.20s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_25/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_25/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_25/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_18/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_18/mlp.down_proj/compressed.log
best_loss 33.73187255859375 running bpv: 2.00862
COMMANDS_FINISHED 380 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_25/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_25/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_25/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_25/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_25/mlp.gate_proj/compressed.log
best_loss 469.06072998046875 running bpv: 2.008604
COMMANDS_FINISHED 381 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_25/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_25/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_25/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_25/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_25/mlp.up_proj/compressed.log
best_loss 394.07171630859375 running bpv: 2.008587
COMMANDS_FINISHED 382 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_25/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_25/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_25/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_25/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_25/self_attn.k_proj/compressed.log
best_loss 339.1030578613281 running bpv: 2.008589
COMMANDS_FINISHED 383 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_37/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_37/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_37/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_25/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_25/self_attn.o_proj/compressed.log
best_loss 17.687089920043945 running bpv: 2.00859
COMMANDS_FINISHED 384 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_37/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_37/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_37/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_25/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_25/self_attn.v_proj/compressed.log
best_loss 245.760498046875 running bpv: 2.008592
COMMANDS_FINISHED 385 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_37/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_37/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_37/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_37/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_37/self_attn.q_proj/compressed.log
best_loss 295.5527648925781 running bpv: 2.008593
COMMANDS_FINISHED 386 n_commands 505
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 386/504 [6:39:13<3:13:22, 98.33s/it]  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 387/504 [6:39:58<2:40:43, 82.43s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 388/504 [6:40:53<2:23:31, 74.23s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 389/504 [6:41:08<1:48:19, 56.52s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 390/504 [6:42:13<1:52:12, 59.06s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 391/504 [6:43:58<2:17:09, 72.82s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 392/504 [6:47:03<3:18:42, 106.45s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_37/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_37/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_37/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_25/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_25/mlp.down_proj/compressed.log
best_loss 64.8873291015625 running bpv: 2.008578
COMMANDS_FINISHED 387 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_37/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_37/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_37/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_37/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_37/mlp.gate_proj/compressed.log
best_loss 689.17333984375 running bpv: 2.008562
COMMANDS_FINISHED 388 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_37/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_37/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_37/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_37/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_37/mlp.up_proj/compressed.log
best_loss 636.4061279296875 running bpv: 2.008546
COMMANDS_FINISHED 389 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_37/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_37/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_37/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_37/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_37/self_attn.k_proj/compressed.log
best_loss 296.47137451171875 running bpv: 2.008547
COMMANDS_FINISHED 390 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_30/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_30/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_30/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_37/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_37/self_attn.o_proj/compressed.log
best_loss 47.956626892089844 running bpv: 2.008549
COMMANDS_FINISHED 391 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_30/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_30/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_30/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_37/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_37/self_attn.v_proj/compressed.log
best_loss 315.0909423828125 running bpv: 2.008551
COMMANDS_FINISHED 392 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_30/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_30/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_30/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_30/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_30/self_attn.q_proj/compressed.log
best_loss 439.07464599609375 running bpv: 2.008552
COMMANDS_FINISHED 393 n_commands 505
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 393/504 [6:48:18<2:59:29, 97.02s/it]  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 394/504 [6:48:43<2:18:17, 75.43s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 395/504 [6:49:48<2:11:21, 72.30s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 396/504 [6:50:03<1:39:12, 55.12s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 397/504 [6:51:18<1:48:55, 61.08s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 398/504 [6:52:43<2:00:35, 68.26s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 399/504 [6:55:38<2:55:29, 100.28s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_30/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_30/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_30/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_37/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_37/mlp.down_proj/compressed.log
best_loss 148.9552001953125 running bpv: 2.008537
COMMANDS_FINISHED 394 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_30/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_30/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_30/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_30/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_30/mlp.gate_proj/compressed.log
best_loss 584.11328125 running bpv: 2.008522
COMMANDS_FINISHED 395 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_30/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_30/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_30/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_30/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_30/mlp.up_proj/compressed.log
best_loss 492.40667724609375 running bpv: 2.008506
COMMANDS_FINISHED 396 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_30/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_30/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_30/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_30/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_30/self_attn.k_proj/compressed.log
best_loss 445.0493469238281 running bpv: 2.008508
COMMANDS_FINISHED 397 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_29/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_29/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_29/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_30/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_30/self_attn.o_proj/compressed.log
best_loss 19.6777286529541 running bpv: 2.00851
COMMANDS_FINISHED 398 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_29/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_29/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_29/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_30/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_30/self_attn.v_proj/compressed.log
best_loss 366.90869140625 running bpv: 2.008511
COMMANDS_FINISHED 399 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_29/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_29/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_29/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_29/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_29/self_attn.q_proj/compressed.log
best_loss 407.29425048828125 running bpv: 2.008513
COMMANDS_FINISHED 400 n_commands 505
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 400/504 [6:57:03<2:45:52, 95.70s/it]  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 401/504 [6:57:38<2:13:01, 77.49s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 402/504 [6:58:33<2:00:16, 70.75s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 403/504 [6:58:58<1:35:59, 57.03s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 404/504 [7:00:03<1:39:02, 59.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 405/504 [7:01:28<1:50:42, 67.10s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 406/504 [7:04:23<2:42:28, 99.47s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_29/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_29/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_29/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_30/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_30/mlp.down_proj/compressed.log
best_loss 77.93446350097656 running bpv: 2.008498
COMMANDS_FINISHED 401 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_29/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_29/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_29/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_29/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_29/mlp.gate_proj/compressed.log
best_loss 554.7576293945312 running bpv: 2.008484
COMMANDS_FINISHED 402 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_29/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_29/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_29/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_29/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_29/self_attn.k_proj/compressed.log
best_loss 418.2757263183594 running bpv: 2.008485
COMMANDS_FINISHED 403 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_29/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_29/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_29/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_29/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_29/mlp.up_proj/compressed.log
best_loss 468.15032958984375 running bpv: 2.00847
COMMANDS_FINISHED 404 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_16/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_16/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_16/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_29/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_29/self_attn.o_proj/compressed.log
best_loss 17.291446685791016 running bpv: 2.008472
COMMANDS_FINISHED 405 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_16/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_16/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_16/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_29/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_29/self_attn.v_proj/compressed.log
best_loss 306.2804260253906 running bpv: 2.008474
COMMANDS_FINISHED 406 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_16/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_16/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_16/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_16/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_16/self_attn.q_proj/compressed.log
best_loss 243.5079345703125 running bpv: 2.008475
COMMANDS_FINISHED 407 n_commands 505
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 407/504 [7:05:58<2:38:38, 98.13s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 408/504 [7:06:33<2:06:42, 79.20s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 409/504 [7:07:28<1:53:54, 71.94s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 410/504 [7:07:43<1:25:56, 54.86s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 411/504 [7:08:58<1:34:24, 60.91s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 412/504 [7:10:33<1:49:04, 71.14s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 413/504 [7:13:28<2:35:09, 102.30s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_16/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_16/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_16/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_29/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_29/mlp.down_proj/compressed.log
best_loss 74.43153381347656 running bpv: 2.008461
COMMANDS_FINISHED 408 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_16/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_16/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_16/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_16/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_16/mlp.gate_proj/compressed.log
best_loss 224.17410278320312 running bpv: 2.008447
COMMANDS_FINISHED 409 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_16/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_16/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_16/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_16/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_16/self_attn.k_proj/compressed.log
best_loss 254.65457153320312 running bpv: 2.008449
COMMANDS_FINISHED 410 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_16/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_16/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_16/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_16/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_16/mlp.up_proj/compressed.log
best_loss 216.427978515625 running bpv: 2.008434
COMMANDS_FINISHED 411 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_13/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_13/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_13/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_16/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_16/self_attn.o_proj/compressed.log
best_loss 15.183006286621094 running bpv: 2.008436
COMMANDS_FINISHED 412 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_13/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_13/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_13/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_16/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_16/self_attn.v_proj/compressed.log
best_loss 121.85494995117188 running bpv: 2.008438
COMMANDS_FINISHED 413 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_13/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_13/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_13/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_13/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_13/self_attn.q_proj/compressed.log
best_loss 224.1696014404297 running bpv: 2.008439
COMMANDS_FINISHED 414 n_commands 505
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 414/504 [7:14:53<2:25:40, 97.11s/it]  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 415/504 [7:15:18<1:51:57, 75.48s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 416/504 [7:16:33<1:50:29, 75.34s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 418/504 [7:17:53<1:24:36, 59.03s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 419/504 [7:19:28<1:36:15, 67.95s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 420/504 [7:22:33<2:17:59, 98.57s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_13/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_13/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_13/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_16/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_16/mlp.down_proj/compressed.log
best_loss 27.70390510559082 running bpv: 2.008426
COMMANDS_FINISHED 415 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_13/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_13/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_13/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_13/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_13/mlp.gate_proj/compressed.log
best_loss 170.71725463867188 running bpv: 2.008412
COMMANDS_FINISHED 416 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_13/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_13/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_13/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_13/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_13/mlp.up_proj/compressed.log
best_loss 162.53414916992188 running bpv: 2.008398
COMMANDS_FINISHED 417 n_commands 505
meta-llama/Llama-2-13b-hf/layer_13/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_13/self_attn.k_proj/compressed.log
best_loss 222.80760192871094 running bpv: 2.0084
COMMANDS_FINISHED 418 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_13/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_13/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_13/self_attn.v_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_10/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_10/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_10/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_13/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_13/self_attn.o_proj/compressed.log
best_loss 9.99948501586914 running bpv: 2.008401
COMMANDS_FINISHED 419 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_10/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_10/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_10/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_13/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_13/self_attn.v_proj/compressed.log
best_loss 104.31036376953125 running bpv: 2.008403
COMMANDS_FINISHED 420 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_10/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_10/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_10/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_10/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_10/self_attn.q_proj/compressed.log
best_loss 182.6572265625 running bpv: 2.008405
COMMANDS_FINISHED 421 n_commands 505
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 421/504 [7:23:38<2:03:43, 89.44s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 422/504 [7:24:13<1:41:24, 74.21s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 423/504 [7:25:28<1:40:29, 74.44s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 425/504 [7:26:38<1:14:40, 56.72s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 426/504 [7:28:23<1:28:59, 68.45s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 427/504 [7:31:28<2:06:23, 98.49s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_10/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_10/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_10/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_13/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_13/mlp.down_proj/compressed.log
best_loss 15.787444114685059 running bpv: 2.008392
COMMANDS_FINISHED 422 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_10/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_10/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_10/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_10/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_10/mlp.gate_proj/compressed.log
best_loss 149.16734313964844 running bpv: 2.008378
COMMANDS_FINISHED 423 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_10/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_10/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_10/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_10/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_10/self_attn.k_proj/compressed.log
best_loss 189.3209228515625 running bpv: 2.00838
COMMANDS_FINISHED 424 n_commands 505
meta-llama/Llama-2-13b-hf/layer_10/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_10/mlp.up_proj/compressed.log
best_loss 131.85096740722656 running bpv: 2.008366
COMMANDS_FINISHED 425 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_10/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_10/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_10/self_attn.v_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_19/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_19/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_19/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_10/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_10/self_attn.o_proj/compressed.log
best_loss 6.097173690795898 running bpv: 2.008368
COMMANDS_FINISHED 426 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_19/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_19/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_19/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_10/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_10/self_attn.v_proj/compressed.log
best_loss 72.0389404296875 running bpv: 2.00837
COMMANDS_FINISHED 427 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_19/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_19/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_19/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_19/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_19/self_attn.q_proj/compressed.log
best_loss 261.1307678222656 running bpv: 2.008372
COMMANDS_FINISHED 428 n_commands 505
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 428/504 [7:32:33<1:53:20, 89.48s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 429/504 [7:33:08<1:32:56, 74.36s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 430/504 [7:34:13<1:28:25, 71.70s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 431/504 [7:34:28<1:07:19, 55.34s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 432/504 [7:35:33<1:09:47, 58.16s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 433/504 [7:37:08<1:21:39, 69.01s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 434/504 [7:40:03<1:57:06, 100.38s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_19/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_19/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_19/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_10/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_10/mlp.down_proj/compressed.log
best_loss 10.832062721252441 running bpv: 2.008359
COMMANDS_FINISHED 429 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_19/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_19/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_19/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_19/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_19/mlp.gate_proj/compressed.log
best_loss 306.7142028808594 running bpv: 2.008346
COMMANDS_FINISHED 430 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_19/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_19/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_19/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_19/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_19/mlp.up_proj/compressed.log
best_loss 279.0014343261719 running bpv: 2.008333
COMMANDS_FINISHED 431 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_19/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_19/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_19/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_19/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_19/self_attn.k_proj/compressed.log
best_loss 270.4922790527344 running bpv: 2.008335
COMMANDS_FINISHED 432 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_6/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_6/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_6/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_19/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_19/self_attn.o_proj/compressed.log
best_loss 14.899099349975586 running bpv: 2.008336
COMMANDS_FINISHED 433 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_6/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_6/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_6/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_19/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_19/self_attn.v_proj/compressed.log
best_loss 149.99996948242188 running bpv: 2.008338
COMMANDS_FINISHED 434 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_6/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_6/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_6/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_6/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_6/self_attn.q_proj/compressed.log
best_loss 119.01298522949219 running bpv: 2.00834
COMMANDS_FINISHED 435 n_commands 505
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 435/504 [7:41:28<1:50:11, 95.81s/it]  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 436/504 [7:42:03<1:28:03, 77.69s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 437/504 [7:42:58<1:19:11, 70.92s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 438/504 [7:43:13<59:37, 54.20s/it]   87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 439/504 [7:44:28<1:05:27, 60.43s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 440/504 [7:45:53<1:12:18, 67.79s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 441/504 [7:48:48<1:44:55, 99.92s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_6/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_6/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_6/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_19/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_19/mlp.down_proj/compressed.log
best_loss 37.824317932128906 running bpv: 2.008328
COMMANDS_FINISHED 436 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_6/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_6/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_6/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_6/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_6/mlp.gate_proj/compressed.log
best_loss 97.53013610839844 running bpv: 2.008315
COMMANDS_FINISHED 437 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_6/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_6/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_6/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_6/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_6/self_attn.k_proj/compressed.log
best_loss 122.88922119140625 running bpv: 2.008317
COMMANDS_FINISHED 438 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_6/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_6/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_6/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_6/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_6/mlp.up_proj/compressed.log
best_loss 78.30315399169922 running bpv: 2.008304
COMMANDS_FINISHED 439 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_11/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_11/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_11/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_6/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_6/self_attn.o_proj/compressed.log
best_loss 1.497739315032959 running bpv: 2.008306
COMMANDS_FINISHED 440 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_11/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_11/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_11/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_6/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_6/self_attn.v_proj/compressed.log
best_loss 43.772804260253906 running bpv: 2.008307
COMMANDS_FINISHED 441 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_11/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_11/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_11/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_11/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_11/self_attn.q_proj/compressed.log
best_loss 179.53152465820312 running bpv: 2.008309
COMMANDS_FINISHED 442 n_commands 505
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 442/504 [7:50:23<1:41:43, 98.45s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 443/504 [7:50:48<1:17:42, 76.43s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 444/504 [7:51:43<1:10:00, 70.00s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 445/504 [7:51:58<52:37, 53.51s/it]   88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 446/504 [7:53:23<1:00:51, 62.96s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 447/504 [7:54:38<1:03:14, 66.57s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 448/504 [7:57:33<1:32:29, 99.10s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_11/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_11/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_11/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_6/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_6/mlp.down_proj/compressed.log
best_loss 4.6287522315979 running bpv: 2.008297
COMMANDS_FINISHED 443 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_11/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_11/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_11/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_11/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_11/mlp.gate_proj/compressed.log
best_loss 151.57589721679688 running bpv: 2.008285
COMMANDS_FINISHED 444 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_11/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_11/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_11/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_11/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_11/self_attn.k_proj/compressed.log
best_loss 188.0313720703125 running bpv: 2.008287
COMMANDS_FINISHED 445 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_11/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_11/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_11/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_11/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_11/mlp.up_proj/compressed.log
best_loss 138.69850158691406 running bpv: 2.008275
COMMANDS_FINISHED 446 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_20/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_20/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_20/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_11/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_11/self_attn.o_proj/compressed.log
best_loss 7.077958583831787 running bpv: 2.008276
COMMANDS_FINISHED 447 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_20/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_20/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_20/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_11/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_11/self_attn.v_proj/compressed.log
best_loss 68.89385223388672 running bpv: 2.008278
COMMANDS_FINISHED 448 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_20/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_20/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_20/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_20/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_20/self_attn.q_proj/compressed.log
best_loss 246.41629028320312 running bpv: 2.00828
COMMANDS_FINISHED 449 n_commands 505
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 449/504 [7:59:08<1:29:43, 97.87s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 450/504 [7:59:33<1:08:24, 76.02s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 451/504 [8:00:38<1:04:13, 72.71s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 452/504 [8:00:53<48:00, 55.40s/it]   90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 453/504 [8:02:08<52:05, 61.28s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 454/504 [8:03:33<57:00, 68.40s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 455/504 [8:06:28<1:21:58, 100.38s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_20/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_20/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_20/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_11/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_11/mlp.down_proj/compressed.log
best_loss 11.939752578735352 running bpv: 2.008268
COMMANDS_FINISHED 450 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_20/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_20/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_20/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_20/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_20/mlp.gate_proj/compressed.log
best_loss 324.11859130859375 running bpv: 2.008256
COMMANDS_FINISHED 451 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_20/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_20/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_20/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_20/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_20/self_attn.k_proj/compressed.log
best_loss 258.3695068359375 running bpv: 2.008258
COMMANDS_FINISHED 452 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_20/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_20/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_20/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_20/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_20/mlp.up_proj/compressed.log
best_loss 293.01531982421875 running bpv: 2.008246
COMMANDS_FINISHED 453 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_23/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_23/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_23/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_20/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_20/self_attn.o_proj/compressed.log
best_loss 16.06959342956543 running bpv: 2.008248
COMMANDS_FINISHED 454 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_23/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_23/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_23/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_20/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_20/self_attn.v_proj/compressed.log
best_loss 138.4526824951172 running bpv: 2.00825
COMMANDS_FINISHED 455 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_23/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_23/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_23/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_23/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_23/self_attn.q_proj/compressed.log
best_loss 290.69500732421875 running bpv: 2.008252
COMMANDS_FINISHED 456 n_commands 505
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 456/504 [8:07:53<1:16:37, 95.77s/it]  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 457/504 [8:08:28<1:00:44, 77.54s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 458/504 [8:09:23<54:15, 70.78s/it]   91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 459/504 [8:09:38<40:32, 54.05s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 460/504 [8:10:53<44:14, 60.34s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 461/504 [8:12:28<50:41, 70.74s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 462/504 [8:15:23<1:11:24, 102.02s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_23/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_23/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_23/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_20/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_20/mlp.down_proj/compressed.log
best_loss 42.14192199707031 running bpv: 2.00824
COMMANDS_FINISHED 457 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_23/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_23/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_23/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_23/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_23/mlp.gate_proj/compressed.log
best_loss 416.0267639160156 running bpv: 2.008229
COMMANDS_FINISHED 458 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_23/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_23/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_23/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_23/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_23/self_attn.k_proj/compressed.log
best_loss 299.25091552734375 running bpv: 2.008231
COMMANDS_FINISHED 459 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_23/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_23/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_23/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_23/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_23/mlp.up_proj/compressed.log
best_loss 355.08709716796875 running bpv: 2.008219
COMMANDS_FINISHED 460 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_35/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_35/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_35/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_23/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_23/self_attn.o_proj/compressed.log
best_loss 16.60639762878418 running bpv: 2.008221
COMMANDS_FINISHED 461 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_35/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_35/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_35/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_23/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_23/self_attn.v_proj/compressed.log
best_loss 205.060791015625 running bpv: 2.008223
COMMANDS_FINISHED 462 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_35/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_35/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_35/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_35/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_35/self_attn.q_proj/compressed.log
best_loss 356.2159729003906 running bpv: 2.008224
COMMANDS_FINISHED 463 n_commands 505
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 463/504 [8:16:48<1:06:13, 96.92s/it]  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 464/504 [8:17:13<50:13, 75.34s/it]   92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 465/504 [8:18:18<46:57, 72.24s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 466/504 [8:18:33<34:52, 55.07s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 467/504 [8:19:48<37:38, 61.05s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 468/504 [8:21:13<40:56, 68.24s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 469/504 [8:24:19<1:00:14, 103.27s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_35/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_35/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_35/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_23/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_23/mlp.down_proj/compressed.log
best_loss 59.494903564453125 running bpv: 2.008213
COMMANDS_FINISHED 464 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_35/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_35/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_35/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_35/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_35/mlp.gate_proj/compressed.log
best_loss 678.524169921875 running bpv: 2.008202
COMMANDS_FINISHED 465 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_35/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_35/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_35/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_35/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_35/self_attn.k_proj/compressed.log
best_loss 366.8982849121094 running bpv: 2.008204
COMMANDS_FINISHED 466 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_35/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_35/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_35/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_35/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_35/mlp.up_proj/compressed.log
best_loss 614.5831909179688 running bpv: 2.008193
COMMANDS_FINISHED 467 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_38/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_38/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_38/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_35/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_35/self_attn.o_proj/compressed.log
best_loss 28.546106338500977 running bpv: 2.008195
COMMANDS_FINISHED 468 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_38/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_38/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_38/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_35/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_35/self_attn.v_proj/compressed.log
best_loss 326.5128173828125 running bpv: 2.008196
COMMANDS_FINISHED 469 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_38/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_38/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_38/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_38/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_38/self_attn.q_proj/compressed.log
best_loss 280.37835693359375 running bpv: 2.008198
COMMANDS_FINISHED 470 n_commands 505
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 470/504 [8:25:34<53:42, 94.79s/it]    93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 471/504 [8:26:09<42:16, 76.86s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 472/504 [8:27:24<40:41, 76.30s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 474/504 [8:28:34<28:37, 57.24s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 475/504 [8:30:19<33:23, 69.09s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 476/504 [8:33:14<45:10, 96.79s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_38/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_38/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_38/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_35/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_35/mlp.down_proj/compressed.log
best_loss 111.03266906738281 running bpv: 2.008188
COMMANDS_FINISHED 471 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_38/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_38/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_38/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_38/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_38/mlp.gate_proj/compressed.log
best_loss 680.6065673828125 running bpv: 2.008177
COMMANDS_FINISHED 472 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_38/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_38/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_38/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_38/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_38/mlp.up_proj/compressed.log
best_loss 601.3712768554688 running bpv: 2.008166
COMMANDS_FINISHED 473 n_commands 505
meta-llama/Llama-2-13b-hf/layer_38/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_38/self_attn.k_proj/compressed.log
best_loss 285.4649658203125 running bpv: 2.008167
COMMANDS_FINISHED 474 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_38/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_38/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_38/self_attn.v_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_17/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_17/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_17/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_38/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_38/self_attn.o_proj/compressed.log
best_loss 69.09268188476562 running bpv: 2.008169
COMMANDS_FINISHED 475 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_17/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_17/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_17/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_38/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_38/self_attn.v_proj/compressed.log
best_loss 335.13775634765625 running bpv: 2.008171
COMMANDS_FINISHED 476 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_17/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_17/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_17/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_17/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_17/self_attn.q_proj/compressed.log
best_loss 245.3951416015625 running bpv: 2.008173
COMMANDS_FINISHED 477 n_commands 505
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 477/504 [8:34:29<40:53, 90.87s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 478/504 [8:34:54<31:23, 72.44s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 479/504 [8:36:09<30:29, 73.17s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 480/504 [8:36:24<22:31, 56.32s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 481/504 [8:37:29<22:33, 58.86s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 482/504 [8:39:14<26:34, 72.47s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 483/504 [8:42:09<36:00, 102.87s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_17/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_17/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_17/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_38/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_38/mlp.down_proj/compressed.log
best_loss 175.16006469726562 running bpv: 2.008163
COMMANDS_FINISHED 478 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_17/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_17/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_17/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_17/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_17/mlp.gate_proj/compressed.log
best_loss 254.8861541748047 running bpv: 2.008152
COMMANDS_FINISHED 479 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_17/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_17/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_17/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_17/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_17/mlp.up_proj/compressed.log
best_loss 240.18319702148438 running bpv: 2.008141
COMMANDS_FINISHED 480 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_17/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_17/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_17/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_17/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_17/self_attn.k_proj/compressed.log
best_loss 257.99176025390625 running bpv: 2.008143
COMMANDS_FINISHED 481 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_9/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_9/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_9/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_17/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_17/self_attn.o_proj/compressed.log
best_loss 15.005204200744629 running bpv: 2.008145
COMMANDS_FINISHED 482 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_9/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_9/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_9/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_17/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_17/self_attn.v_proj/compressed.log
best_loss 127.72744750976562 running bpv: 2.008147
COMMANDS_FINISHED 483 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_9/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_9/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_9/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_9/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_9/self_attn.q_proj/compressed.log
best_loss 184.69834899902344 running bpv: 2.008148
COMMANDS_FINISHED 484 n_commands 505
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 484/504 [8:43:14<30:32, 91.60s/it]  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 485/504 [8:43:59<24:36, 77.71s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 486/504 [8:45:04<22:10, 73.91s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 488/504 [8:46:14<14:55, 56.00s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 489/504 [8:48:09<17:39, 70.60s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 490/504 [8:51:04<22:50, 97.88s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_9/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_9/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_9/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_17/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_17/mlp.down_proj/compressed.log
best_loss 31.174991607666016 running bpv: 2.008138
COMMANDS_FINISHED 485 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_9/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_9/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_9/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_9/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_9/mlp.gate_proj/compressed.log
best_loss 146.12887573242188 running bpv: 2.008128
COMMANDS_FINISHED 486 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_9/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_9/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_9/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_9/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_9/mlp.up_proj/compressed.log
best_loss 124.61228942871094 running bpv: 2.008118
COMMANDS_FINISHED 487 n_commands 505
meta-llama/Llama-2-13b-hf/layer_9/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_9/self_attn.k_proj/compressed.log
best_loss 185.1564178466797 running bpv: 2.008119
COMMANDS_FINISHED 488 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_9/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_9/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_9/self_attn.v_proj/compressed.log 2>&1 &
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_22/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_22/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_22/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_9/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_9/self_attn.o_proj/compressed.log
best_loss 4.328632831573486 running bpv: 2.008121
COMMANDS_FINISHED 489 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_22/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_22/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_22/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_9/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_9/self_attn.v_proj/compressed.log
best_loss 72.95256042480469 running bpv: 2.008123
COMMANDS_FINISHED 490 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_22/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_22/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_22/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_22/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_22/self_attn.q_proj/compressed.log
best_loss 295.4320983886719 running bpv: 2.008125
COMMANDS_FINISHED 491 n_commands 505
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 491/504 [8:52:19<19:51, 91.66s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 492/504 [8:52:44<14:36, 73.02s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 493/504 [8:53:49<12:58, 70.73s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 494/504 [8:54:04<09:05, 54.59s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 495/504 [8:55:19<09:05, 60.57s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 496/504 [8:56:44<09:02, 67.77s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 497/504 [8:59:39<11:36, 99.56s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_22/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_22/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_22/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_9/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_9/mlp.down_proj/compressed.log
best_loss 9.330018043518066 running bpv: 2.008115
COMMANDS_FINISHED 492 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_22/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_22/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_22/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_22/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_22/mlp.gate_proj/compressed.log
best_loss 387.7470703125 running bpv: 2.008105
COMMANDS_FINISHED 493 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_22/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_22/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_22/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_22/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_22/mlp.up_proj/compressed.log
best_loss 336.5816955566406 running bpv: 2.008095
COMMANDS_FINISHED 494 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_22/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_22/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_22/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_22/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_22/self_attn.k_proj/compressed.log
best_loss 308.28955078125 running bpv: 2.008097
COMMANDS_FINISHED 495 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_24/mlp.gate_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_24/mlp.gate_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_24/mlp.gate_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_22/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_22/self_attn.o_proj/compressed.log
best_loss 16.402591705322266 running bpv: 2.008098
COMMANDS_FINISHED 496 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_24/mlp.up_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_24/mlp.up_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_24/mlp.up_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_22/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_22/self_attn.v_proj/compressed.log
best_loss 204.022216796875 running bpv: 2.0081
COMMANDS_FINISHED 497 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_24/self_attn.q_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_24/self_attn.q_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_24/self_attn.q_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_24/self_attn.q_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_24/self_attn.q_proj/compressed.log
best_loss 304.86431884765625 running bpv: 2.008102
COMMANDS_FINISHED 498 n_commands 505
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 498/504 [9:01:04<09:31, 95.23s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 499/504 [9:01:39<06:26, 77.27s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 500/504 [9:02:34<04:42, 70.62s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 501/504 [9:02:49<02:41, 53.98s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 502/504 [9:03:59<01:57, 58.78s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 503/504 [9:05:39<01:11, 71.13s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 504/504 [9:09:59<00:00, 127.74s/it]running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_24/self_attn.k_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_24/self_attn.k_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_24/self_attn.k_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_22/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_22/mlp.down_proj/compressed.log
best_loss 56.875282287597656 running bpv: 2.008092
COMMANDS_FINISHED 499 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_24/self_attn.o_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_24/self_attn.o_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:3 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_24/self_attn.o_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_24/mlp.gate_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_24/mlp.gate_proj/compressed.log
best_loss 439.2091979980469 running bpv: 2.008083
COMMANDS_FINISHED 500 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_24/mlp.down_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_24/mlp.down_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:4 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_24/mlp.down_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_24/self_attn.k_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_24/self_attn.k_proj/compressed.log
best_loss 313.5706787109375 running bpv: 2.008084
COMMANDS_FINISHED 501 n_commands 505
running: nohup python -u scripts/1layer_compress/quantize_compress.py --hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_0/pajama/128/layer_24/self_attn.v_proj.pt --save_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_24/self_attn.v_proj/compressed.pt --yaml_path tmp/chocolate-sun-74/yaml.yaml --weights_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/original_weights --discrete_update_hessian_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/hessians_new/seed_42/pajama/128 --device cuda:2 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_24/self_attn.v_proj/compressed.log 2>&1 &
meta-llama/Llama-2-13b-hf/layer_24/mlp.up_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_24/mlp.up_proj/compressed.log
best_loss 371.61737060546875 running bpv: 2.008074
COMMANDS_FINISHED 502 n_commands 505
meta-llama/Llama-2-13b-hf/layer_24/self_attn.o_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_24/self_attn.o_proj/compressed.log
best_loss 15.333513259887695 running bpv: 2.008076
COMMANDS_FINISHED 503 n_commands 505
meta-llama/Llama-2-13b-hf/layer_24/self_attn.v_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_24/self_attn.v_proj/compressed.log
best_loss 214.7826690673828 running bpv: 2.008078
COMMANDS_FINISHED 504 n_commands 505
meta-llama/Llama-2-13b-hf/layer_24/mlp.down_proj is done
reading log /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_24/mlp.down_proj/compressed.log
best_loss 61.206539154052734 running bpv: 2.008069
COMMANDS_FINISHED 505 n_commands 505
done with meta-llama/Llama-2-13b-hf
done with {'meta-llama/Llama-2-13b-hf/layer_3/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_3/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_3/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_3/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_3/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_3/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_3/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_3/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_3/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_3/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_3/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_3/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_3/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_3/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_5/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_5/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_5/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_5/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_5/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_5/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_5/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_5/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_5/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_5/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_5/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_5/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_8/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_8/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_5/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_5/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_8/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_8/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_8/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_8/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_8/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_8/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_8/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_8/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_8/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_8/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_39/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_39/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_8/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_8/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_39/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_39/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_39/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_39/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_39/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_39/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_39/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_39/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_39/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_39/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_12/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_12/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_39/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_39/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_12/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_12/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_12/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_12/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_12/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_12/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_12/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_12/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_12/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_12/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_1/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_1/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_12/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_12/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_1/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_1/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_1/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_1/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_1/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_1/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_1/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_1/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_1/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_1/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_7/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_7/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_1/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_1/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_7/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_7/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_7/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_7/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_7/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_7/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_7/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_7/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_7/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_7/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_33/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_33/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_7/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_7/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_33/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_33/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_33/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_33/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_33/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_33/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_33/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_33/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_33/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_33/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_34/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_34/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_33/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_33/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_34/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_34/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_34/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_34/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_34/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_34/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_34/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_34/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_34/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_34/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_0/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_0/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_34/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_34/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_0/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_0/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_0/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_0/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_0/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_0/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_0/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_0/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_0/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_0/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_32/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_32/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_0/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_0/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_32/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_32/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_32/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_32/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_32/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_32/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_32/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_32/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_32/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_32/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_31/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_31/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_32/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_32/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_31/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_31/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_31/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_31/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_31/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_31/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_31/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_31/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_31/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_31/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_21/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_21/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_31/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_31/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_21/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_21/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_21/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_21/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_21/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_21/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_21/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_21/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_21/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_21/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_26/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_26/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_21/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_21/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_26/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_26/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_26/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_26/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_26/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_26/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_26/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_26/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_26/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_26/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_14/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_14/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_26/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_26/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_14/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_14/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_14/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_14/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_14/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_14/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_14/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_14/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_14/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_14/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_15/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_15/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_14/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_14/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_15/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_15/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_15/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_15/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_15/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_15/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_15/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_15/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_15/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_15/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_4/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_4/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_15/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_15/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_4/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_4/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_4/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_4/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_4/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_4/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_4/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_4/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_4/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_4/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_27/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_27/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_4/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_4/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_27/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_27/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_27/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_27/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_27/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_27/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_27/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_27/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_27/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_27/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_2/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_2/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_27/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_27/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_2/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_2/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_2/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_2/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_2/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_2/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_2/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_2/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_2/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_2/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_36/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_36/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_2/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_2/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_36/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_36/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_36/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_36/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_36/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_36/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_36/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_36/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_36/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_36/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_28/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_28/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_36/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_36/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_28/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_28/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_28/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_28/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_28/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_28/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_28/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_28/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_28/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_28/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_18/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_18/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_28/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_28/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_18/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_18/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_18/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_18/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_18/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_18/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_18/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_18/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_18/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_18/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_25/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_25/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_18/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_18/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_25/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_25/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_25/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_25/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_25/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_25/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_25/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_25/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_25/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_25/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_37/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_37/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_25/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_25/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_37/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_37/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_37/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_37/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_37/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_37/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_37/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_37/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_37/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_37/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_30/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_30/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_37/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_37/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_30/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_30/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_30/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_30/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_30/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_30/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_30/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_30/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_30/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_30/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_29/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_29/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_30/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_30/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_29/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_29/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_29/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_29/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_29/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_29/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_29/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_29/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_29/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_29/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_16/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_16/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_29/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_29/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_16/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_16/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_16/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_16/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_16/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_16/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_16/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_16/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_16/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_16/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_13/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_13/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_16/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_16/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_13/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_13/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_13/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_13/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_13/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_13/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_13/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_13/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_13/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_13/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_10/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_10/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_13/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_13/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_10/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_10/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_10/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_10/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_10/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_10/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_10/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_10/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_10/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_10/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_19/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_19/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_10/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_10/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_19/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_19/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_19/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_19/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_19/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_19/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_19/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_19/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_19/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_19/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_6/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_6/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_19/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_19/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_6/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_6/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_6/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_6/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_6/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_6/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_6/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_6/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_6/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_6/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_11/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_11/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_6/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_6/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_11/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_11/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_11/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_11/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_11/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_11/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_11/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_11/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_11/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_11/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_20/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_20/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_11/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_11/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_20/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_20/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_20/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_20/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_20/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_20/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_20/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_20/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_20/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_20/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_23/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_23/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_20/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_20/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_23/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_23/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_23/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_23/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_23/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_23/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_23/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_23/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_23/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_23/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_35/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_35/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_23/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_23/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_35/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_35/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_35/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_35/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_35/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_35/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_35/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_35/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_35/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_35/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_38/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_38/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_35/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_35/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_38/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_38/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_38/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_38/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_38/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_38/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_38/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_38/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_38/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_38/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_17/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_17/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_38/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_38/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_17/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_17/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_17/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_17/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_17/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_17/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_17/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_17/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_17/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_17/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_9/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_9/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_17/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_17/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_9/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_9/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_9/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_9/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_9/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_9/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_9/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_9/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_9/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_9/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_22/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_22/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_9/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_9/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_22/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_22/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_22/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_22/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_22/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_22/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_22/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_22/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_22/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_22/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_24/self_attn.q_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_24/self_attn.q_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_22/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_22/mlp.down_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_24/mlp.gate_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_24/mlp.gate_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_24/self_attn.k_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_24/self_attn.k_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_24/mlp.up_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_24/mlp.up_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_24/self_attn.o_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_24/self_attn.o_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_24/self_attn.v_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_24/self_attn.v_proj/compressed.pt', 'meta-llama/Llama-2-13b-hf/layer_24/mlp.down_proj': '/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/meta-llama/Llama-2-13b-hf/layer_24/mlp.down_proj/compressed.pt'}
/data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/checkpoints.yaml
perplexity_inference_command:
 python -u perplexity_eval.py --base_model meta-llama/Llama-2-13b-hf --seqlen 4096 --checkpoint_list_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/checkpoints.yaml --log_wandb --wandb_project compression_no_finetune --wandb_id 5lo7yfdu
running: nohup python -u perplexity_eval.py --base_model meta-llama/Llama-2-13b-hf --seqlen 4096 --checkpoint_list_path /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/checkpoints.yaml --log_wandb --wandb_project compression_no_finetune --wandb_id 5lo7yfdu --device cuda:5 > /data/lliu/huffman/models/meta-llama/Llama-2-13b-hf/compressed/chocolate-sun-74/ppl_eval.log 2>&1 &
eval is done
dict_keys([])
wandb run_id 5lo7yfdu
wandb_project compression_no_finetune
done
[1;34mwandb[0m: üöÄ View run [33mchocolate-sun-74[0m at: [34mhttps://wandb.ai/m6481/compression_no_finetune/runs/5lo7yfdu[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250107_023213-5lo7yfdu/logs[0m
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 504/504 [9:23:45<00:00, 67.11s/it] 
